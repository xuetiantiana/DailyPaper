{
  "data": [
    {
      "id": "2505.14414",
      "abstract": "The matching formulation makes it naturally hard for the stereo matching to handle ill-posed regions like occlusions and non-Lambertian surfaces. Fusing monocular priors has been proven helpful for ill-posed matching, but the biased monocular prior learned from small stereo datasets constrains the generalization. Recently, stereo matching has progressed by leveraging the unbiased monocular prior from the vision foundation model (VFM) to improve the generalization in ill-posed regions. We dive into the fusion process and observe three main problems limiting the fusion of the VFM monocular prior. The first problem is the misalignment between affine-invariant relative monocular depth and absolute depth of disparity. Besides, when we use the monocular feature in an iterative update structure, the over-confidence in the disparity update leads to local optima results. A direct fusion of a monocular depth map could alleviate the local optima problem, but noisy disparity results computed at the first several iterations will misguide the fusion. In this paper, we propose a binary local ordering map to guide the fusion, which converts the depth map into a binary relative format, unifying the relative and absolute depth representation. The computed local ordering map is also used to re-weight the initial disparity update, resolving the local optima and noisy problem. In addition, we formulate the final direct fusion of monocular depth to the disparity as a registration problem, where a pixel-wise linear regression module can globally and adaptively align them. Our method fully exploits the monocular prior to support stereo matching results effectively and efficiently. We significantly improve the performance from the experiments when generalizing from SceneFlow to Middlebury and Booster datasets while barely reducing the efficiency.",
      "authors": [
        "Chengtang Yao",
        "Lidong Yu",
        "Zhidan Liu",
        "Jiaxi Zeng",
        "Yuwei Wu",
        "Yunde Jia"
      ],
      "last_revised_date": "2025/05/20",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.14414",
        "HTML": "https://arxiv.org/html/2505.14414",
        "PDF": "https://arxiv.org/pdf/2505.14414"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 20 May 2025 14:27:45 GMT",
          "size": "33875kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/05/20",
      "title": "Diving into the Fusion of Monocular Priors for Generalized Stereo Matching",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper addresses the fusion of monocular priors in stereo matching, focusing on visual depth estimation tasks. It does not relate to LLM training data or its processing."
      },
      "tasks": [
        "Stereo Matching"
      ],
      "repo_urls": [
        "https://github.com/YaoChengTang/Diving-into-the-Fusion-of-Monocular-Priors-for-Generalized-Stereo-Matching"
      ],
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2405.14830",
      "abstract": "Monte Carlo methods have led to profound insights into the strong-coupling behaviour of lattice gauge theories and produced remarkable results such as first-principles computations of hadron masses. Despite tremendous progress over the last four decades, fundamental challenges such as the sign problem and the inability to simulate real-time dynamics remain. Neural network quantum states have emerged as an alternative method that seeks to overcome these challenges. In this work, we use gauge-invariant neural network quantum states to accurately compute the ground state of $\\mathbb{Z}_N$ lattice gauge theories in $2+1$ dimensions. Using transfer learning, we study the distinct topological phases and the confinement phase transition of these theories. For $\\mathbb{Z}_2$, we identify a continuous transition and compute critical exponents, finding excellent agreement with existing numerics for the expected Ising universality class. In the $\\mathbb{Z}_3$ case, we observe a weakly first-order transition and identify the critical coupling. Our findings suggest that neural network quantum states are a promising method for precise studies of lattice gauge theory.",
      "authors": [
        "Anuj Apte",
        "Anthony Ashmore",
        "Clay Cordova",
        "Tzu-Chen Huang"
      ],
      "last_revised_date": "2024/05/23",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2405.14830",
        "HTML": "https://arxiv.org/html/2405.14830",
        "PDF": "https://arxiv.org/pdf/2405.14830"
      },
      "subjects": [
        "High Energy Physics - Lattice (hep-lat)",
        "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
        "Strongly Correlated Electrons (cond-mat.str-el)",
        "Machine Learning (cs.LG)",
        "High Energy Physics - Theory (hep-th)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 23 May 2024 17:46:49 GMT",
          "size": "1314kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2024/05/23",
      "title": "Deep learning lattice gauge theories",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on the use of neural network quantum states for computing ground states in lattice gauge theories, which is unrelated to LLM training data processing."
      },
      "tasks": [
        "Deep Learning",
        "Transfer Learning"
      ],
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2409.09204",
      "abstract": "Educational Process Mining (EPM) is a data analysis technique that is used to improve educational processes. It is based on Process Mining (PM), which involves gathering records (logs) of events to discover process models and analyze the data from a process-centric perspective. One specific application of EPM is curriculum mining, which focuses on understanding the learning program students follow to achieve educational goals. This is important for institutional curriculum decision-making and quality improvement. Therefore, academic institutions can benefit from organizing the existing techniques, capabilities, and limitations. We conducted a systematic literature review to identify works on applying PM to curricular analysis and provide insights for further research. We reviewed 27 primary studies published across seven major databases. Our analysis classified these studies into five main research objectives: discovery of educational trajectories, identification of deviations in student behavior, bottleneck analysis, dropout / stopout analysis, and generation of recommendations. Key findings highlight challenges such as standardization to facilitate cross-university analysis, better integration of process and data mining techniques, and improved tools for educational stakeholders. This review provides a comprehensive overview of the current landscape in curricular process mining and outlines specific research opportunities to support more robust and actionable curricular analyses in educational settings.",
      "authors": [
        "Daniel Calegari and Andrea Delgado"
      ],
      "last_revised_date": "2024/12/03",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2409.09204",
        "HTML": "https://arxiv.org/html/2409.09204",
        "PDF": "https://arxiv.org/pdf/2409.09204"
      },
      "subjects": [
        "Databases (cs.DB)",
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "Fri, 13 Sep 2024 21:35:11 GMT",
          "size": "541kb",
          "version": "v1"
        },
        {
          "date": "Tue, 03 Dec 2024 10:51:24 GMT",
          "size": "1716kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2024/12/03",
      "title": "A Systematic Review on Process Mining for Curricular Analysis",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper conducts a systematic review of process mining for curricular analysis, focusing on educational process improvement. It does not relate to LLM training data processing."
      },
      "repo_urls": [
        "https://zenodo.org/record/14253622"
      ],
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2308.09424",
      "abstract": "Mid-air haptic interfaces employ focused ultrasound waves to generate touchless haptic sensations on the skin. Prior studies have demonstrated the potential positive impact of mid-air haptic feedback on virtual experiences, enhancing aspects such as enjoyment, immersion, and sense of agency. As a highly immersive environment, Virtual Reality (VR) is being explored as a tool for stress management and relaxation in current research. However, the impact of incorporating mid-air haptic stimuli into relaxing experiences in VR has not been studied thus far. In this paper, for the first time, we design a mid-air haptic stimulation that is congruent with a relaxing scene in VR, and conduct a user study investigating the effectiveness of this experience. Our user study encompasses three different conditions: a control group with no relaxation intervention, a VR-only relaxation experience, and a VR+Haptics relaxation experience that includes the mid-air haptic feedback. While we did not find any significant differences between the conditions, a trend suggesting that the VR+Haptics condition might be associated with greater pleasure emerged, requiring further validation with a larger sample size. These initial findings set the foundation for future investigations into leveraging multimodal interventions in VR, utilising mid-air haptics to potentially enhance relaxation experiences.",
      "authors": [
        "Naga Sai Surya Vamsy Malladi",
        "Viktorija Paneva",
        "J\\\"org M\\\"uller"
      ],
      "last_revised_date": "2023/08/18",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2308.09424",
        "HTML": "https://arxiv.org/html/2308.09424",
        "PDF": "https://arxiv.org/pdf/2308.09424"
      },
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "Fri, 18 Aug 2023 09:45:42 GMT",
          "size": "4998kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2023/08/18",
      "title": "Feel the Breeze: Promoting Relaxation in Virtual Reality using Mid-Air Haptics",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper explores mid-air haptic interfaces in virtual reality environments for relaxation and includes a user study, without mentioning any aspects related to LLM training data collection or processing."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2502.09731",
      "abstract": "Brain tumors require an assessment to ensure timely diagnosis and effective patient treatment. Morphological factors such as size, location, texture, and variable appearance complicate tumor inspection. Medical imaging presents challenges, including noise and incomplete images. This research article presents a methodology for processing Magnetic Resonance Imaging (MRI) data, encompassing techniques for image classification and denoising. The effective use of MRI images allows medical professionals to detect brain disorders, including tumors. This research aims to categorize healthy brain tissue and brain tumors by analyzing the provided MRI data. Unlike alternative methods like Computed Tomography (CT), MRI technology offers a more detailed representation of internal anatomical components, making it a suitable option for studying data related to brain tumors. The MRI picture is first subjected to a denoising technique utilizing an Anisotropic diffusion filter. The dataset utilized for the models creation is a publicly accessible and validated Brain Tumour Classification (MRI) database, comprising 3,264 brain MRI scans. SMOTE was employed for data augmentation and dataset balancing. Convolutional Neural Networks(CNN) such as ResNet152V2, VGG, ViT, and EfficientNet were employed for the classification procedure. EfficientNet attained an accuracy of 98%, the highest recorded.",
      "authors": [
        "Md. Zahid Hasan",
        "Abdullah Tamim",
        "D.M. Asadujjaman",
        "Md. Mahfujur Rahman",
        "Md. Abu Ahnaf Mollick",
        "Nosin Anjum Dristi",
        "Abdullah-Al-Noman"
      ],
      "last_revised_date": "2025/02/13",
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.09731",
        "HTML": "https://arxiv.org/html/2502.09731",
        "PDF": "https://arxiv.org/pdf/2502.09731"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 13 Feb 2025 19:33:26 GMT",
          "size": "2440kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/02/13",
      "title": "A CNN Approach to Automated Detection and Classification of Brain Tumors",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper discusses medical imaging data processing specifically for MRI images related to brain tumors, employing CNN models for classification. It does not cover LLM training data processing or engineering."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2501.13963",
      "abstract": "This study introduces a robust framework for generating procedural 3D models of maize (Zea mays) plants from LiDAR point cloud data, offering a scalable alternative to traditional field-based phenotyping. Our framework leverages Non-Uniform Rational B-Spline (NURBS) surfaces to model the leaves of maize plants, combining Particle Swarm Optimization (PSO) for an initial approximation of the surface and a differentiable programming framework for precise refinement of the surface to fit the point cloud data. In the first optimization phase, PSO generates an approximate NURBS surface by optimizing its control points, aligning the surface with the LiDAR data, and providing a reliable starting point for refinement. The second phase uses NURBS-Diff, a differentiable programming framework, to enhance the accuracy of the initial fit by refining the surface geometry and capturing intricate leaf details. Our results demonstrate that, while PSO establishes a robust initial fit, the integration of differentiable NURBS significantly improves the overall quality and fidelity of the reconstructed surface. This hierarchical optimization strategy enables accurate 3D reconstruction of maize leaves across diverse genotypes, facilitating the subsequent extraction of complex traits like phyllotaxy. We demonstrate our approach on diverse genotypes of field-grown maize plants. All our codes are open-source to democratize these phenotyping approaches.",
      "authors": [
        "Mozhgan Hadadi",
        "Mehdi Saraeian",
        "Jackson Godbersen",
        "Talukder Jubery",
        "Yawei Li",
        "Lakshmi Attigala",
        "Aditya Balu",
        "Soumik Sarkar",
        "Patrick S. Schnable",
        "Adarsh Krishnamurthy",
        "Baskar Ganapathysubramanian"
      ],
      "last_revised_date": "2025/01/21",
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.13963",
        "HTML": "https://arxiv.org/html/2501.13963",
        "PDF": "https://arxiv.org/pdf/2501.13963"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 21 Jan 2025 22:53:09 GMT",
          "size": "11433kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/01/21",
      "title": "Procedural Generation of 3D Maize Plant Architecture from LIDAR Data",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper presents a framework for procedural generation of 3D plant models from LIDAR data, focusing on plant architecture and phenotyping. It does not involve LLM training data engineering or processing."
      },
      "tasks": [
        "3D Reconstruction"
      ],
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2410.21635",
      "abstract": "We study the problem of learning an unknown quantum many-body Hamiltonian $H$ from black-box queries to its time evolution $e^{-\\mathrm{i} H t}$. Prior proposals for solving this task either impose some assumptions on $H$, such as its interaction structure or locality, or otherwise use an exponential amount of computational postprocessing. In this paper, we present algorithms to learn any $n$-qubit Hamiltonian, which do not need to know the Hamiltonian terms in advance, nor are they restricted to local interactions. Our algorithms are efficient as long as the number of terms $m$ is polynomially bounded in the system size $n$. We consider two models of control over the time evolution:~the first has access to time reversal ($t < 0$), enabling an algorithm that outputs an $\\epsilon$-accurate classical description of $H$ after querying its dynamics for a total of $\\widetilde{\\mathcal{O}}(m/\\epsilon)$ evolution time. The second access model is more conventional, allowing only forward-time evolutions;~our algorithm requires $\\widetilde{\\mathcal{O}}(\\|H\\|^3/\\epsilon^4)$ evolution time in this setting. Central to our results is the recently introduced concept of a pseudo-Choi state of $H$. We extend the utility of this learning resource by showing how to use it to learn the Fourier spectrum of $H$, how to achieve nearly Heisenberg-limited scaling with it, and how to prepare it even under our more restricted access models.",
      "authors": [
        "Andrew Zhao"
      ],
      "last_revised_date": "2025/04/21",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.21635",
        "HTML": "https://arxiv.org/html/2410.21635",
        "PDF": "https://arxiv.org/pdf/2410.21635"
      },
      "subjects": [
        "Quantum Physics (quant-ph)",
        "Data Structures and Algorithms (cs.DS)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 29 Oct 2024 00:43:33 GMT",
          "size": "86kb",
          "version": "v1"
        },
        {
          "date": "Mon, 21 Apr 2025 20:47:27 GMT",
          "size": "87kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/04/21",
      "title": "Learning the structure of any Hamiltonian from minimal assumptions",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper addresses quantum many-body Hamiltonian learning using black-box queries and presents algorithms for efficient Hamiltonian learning. It does not relate to LLM training data processing."
      },
      "tasks": [],
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2412.17587",
      "abstract": "Cotton crops, often called \"white gold,\" face significant production challenges, primarily due to various leaf-affecting diseases. As a major global source of fiber, timely and accurate disease identification is crucial to ensure optimal yields and maintain crop health. While deep learning and machine learning techniques have been explored to address this challenge, there remains a gap in developing lightweight models with fewer parameters which could be computationally effective for agricultural practitioners. To address this, we propose an innovative deep learning framework integrating a subset of trainable layers from MobileNet, transfer learning, data augmentation, a learning rate decay schedule, model checkpoints, and early stopping mechanisms. Our model demonstrates exceptional performance, accurately classifying seven cotton disease types with an overall accuracy of 98.42% and class-wise precision ranging from 96% to 100%. This results in significantly enhanced efficiency, surpassing recent approaches in accuracy and model complexity. The existing models in the literature have yet to attain such high accuracy, even when tested on data sets with fewer disease types. The substantial performance improvement, combined with the lightweight nature of the model, makes it practically suitable for real-world applications in smart farming. By offering a high-performing and efficient solution, our framework can potentially address challenges in cotton cultivation, contributing to sustainable agricultural practices.",
      "authors": [
        "Aswini Kumar Patra",
        "Tejashwini Gajurel"
      ],
      "last_revised_date": "2024/12/23",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.17587",
        "HTML": "https://arxiv.org/html/2412.17587",
        "PDF": "https://arxiv.org/pdf/2412.17587"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Mon, 23 Dec 2024 14:01:10 GMT",
          "size": "2136kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2024/12/23",
      "title": "Improved Cotton Leaf Disease Classification Using Parameter-Efficient Deep Learning Framework",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on a deep learning framework for cotton leaf disease classification and does not address any aspect of LLM training data collection, construction, or processing."
      },
      "tasks": [
        "Data Augmentation",
        "Transfer Learning"
      ],
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2501.18224",
      "abstract": "Ambisonics rendering has become an integral part of 3D audio for headphones. It works well with existing recording hardware, the processing cost is mostly independent of the number of sound sources, and it elegantly allows for rotating the scene and listener. One challenge in Ambisonics headphone rendering is to find a perceptually well behaved low-order representation of the Head-Related Transfer Functions (HRTFs) that are contained in the rendering pipe-line. Low-order rendering is of interest, when working with microphone arrays containing only a few sensors, or for reducing the bandwidth for signal transmission. Magnitude Least Squares rendering became the de facto standard for this, which discards high-frequency interaural phase information in favor of reducing magnitude errors. Building upon this idea, we suggest Masked Magnitude Least Squares, which optimized the Ambisonics coefficients with a neural network and employs a spatio-spectral weighting mask to control the accuracy of the magnitude reconstruction. In the tested case, the weighting mask helped to maintain high-frequency notches in the low-order HRTFs and improved the modeled median plane localization performance in comparison to MagLS, while only marginally affecting the overall accuracy of the magnitude reconstruction.",
      "authors": [
        "Or Berebi",
        "Fabian Brinkmann",
        "Stefan Weinzierl and Boaz Rafaely"
      ],
      "last_revised_date": "2025/01/30",
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.18224",
        "HTML": "https://arxiv.org/html/2501.18224",
        "PDF": "https://arxiv.org/pdf/2501.18224"
      },
      "subjects": [
        "Audio and Speech Processing (eess.AS)",
        "Sound (cs.SD)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 30 Jan 2025 09:26:49 GMT",
          "size": "1877kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/01/30",
      "title": "Ambisonics Binaural Rendering via Masked Magnitude Least Squares",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper deals with 3D audio rendering using Ambisonics and does not focus on any aspect of training data for LLMs."
      },
      "tasks": [],
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2409.09212",
      "abstract": "Process mining on business process execution data has focused primarily on orchestration-type processes performed in a single organization (intra-organizational). Collaborative (inter-organizational) processes, unlike those of orchestration type, expand several organizations (for example, in e-Government), adding complexity and various challenges both for their implementation and for their discovery, prediction, and analysis of their execution. Predictive process monitoring is based on exploiting execution data from past instances to predict the execution of current cases. It is possible to make predictions on the next activity and remaining time, among others, to anticipate possible deviations, violations, and delays in the processes to take preventive measures (e.g., re-allocation of resources). In this work, we propose an extension for collaborative processes of traditional process prediction, considering particularities of this type of process, which add information of interest in this context, for example, the next activity of which participant or the following message to be exchanged between two participants.",
      "authors": [
        "Daniel Calegari and Andrea Delgado"
      ],
      "last_revised_date": "2024/09/13",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2409.09212",
        "HTML": "https://arxiv.org/html/2409.09212",
        "PDF": "https://arxiv.org/pdf/2409.09212"
      },
      "subjects": [
        "Databases (cs.DB)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Fri, 13 Sep 2024 21:56:23 GMT",
          "size": "6018kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2024/09/13",
      "title": "Extending predictive process monitoring for collaborative processes",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on predictive process monitoring for business processes, particularly expanding to collaborative processes. It does not address any aspect of LLM training data processing."
      },
      "tasks": [
        "Predictive Process Monitoring"
      ],
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2411.14278",
      "abstract": "Modern cyberattacks in cyber-physical systems (CPS) rapidly evolve and cannot be deterred effectively with most current methods which focused on characterizing past threats. Adaptive anomaly detection (AAD) is among the most promising techniques to detect evolving cyberattacks focused on fast data processing and model adaptation. AAD has been researched in the literature extensively; however, to the best of our knowledge, our work is the first systematic literature review (SLR) on the current research within this field. We present a comprehensive SLR, gathering 397 relevant papers and systematically analyzing 65 of them (47 research and 18 survey papers) on AAD in CPS studies from 2013 to 2023 (November). We introduce a novel taxonomy considering attack types, CPS application, learning paradigm, data management, and algorithms. Our analysis indicates, among other findings, that reviewed works focused on a single aspect of adaptation (either data processing or model adaptation) but rarely in both at the same time. We aim to help researchers to advance the state of the art and help practitioners to become familiar with recent progress in this field. We identify the limitations of the state of the art and provide recommendations for future research directions.",
      "authors": [
        "Pablo Moriano",
        "Steven C. Hespeler",
        "Mingyan Li",
        "Maria Mahbub"
      ],
      "last_revised_date": "2025/01/03",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.14278",
        "HTML": "https://arxiv.org/html/2411.14278",
        "PDF": "https://arxiv.org/pdf/2411.14278"
      },
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 21 Nov 2024 16:32:02 GMT",
          "size": "4284kb",
          "version": "v1"
        },
        {
          "date": "Fri, 03 Jan 2025 21:56:28 GMT",
          "size": "8579kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/01/03",
      "title": "Adaptive Anomaly Detection for Identifying Attacks in Cyber-Physical Systems: A Systematic Literature Review",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This systematic literature review focuses on adaptive anomaly detection in cyber-physical systems, not on LLM training data processing or related data engineering tasks."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2403.09026",
      "abstract": "This paper introduces FlexNN, a Flexible Neural Network accelerator, which adopts agile design principles to enable versatile dataflows, enhancing energy efficiency. Unlike conventional convolutional neural network accelerator architectures that adhere to fixed dataflows (such as input, weight, output, or row stationary) for transferring activations and weights between storage and compute units, our design revolutionizes by enabling adaptable dataflows of any type through software configurable descriptors. Considering that data movement costs considerably outweigh compute costs from an energy perspective, the flexibility in dataflow allows us to optimize the movement per layer for minimal data transfer and energy consumption, a capability unattainable in fixed dataflow architectures. To further enhance throughput and reduce energy consumption in the FlexNN architecture, we propose a novel sparsity-based acceleration logic that utilizes fine-grained sparsity in both the activation and weight tensors to bypass redundant computations, thus optimizing the convolution engine within the hardware accelerator. Extensive experimental results underscore a significant enhancement in the performance and energy efficiency of FlexNN relative to existing DNN accelerators.",
      "authors": [
        "Arnab Raha",
        "Deepak A. Mathaikutty",
        "Soumendu K. Ghosh",
        "Shamik Kundu"
      ],
      "last_revised_date": "2024/04/11",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2403.09026",
        "HTML": "https://arxiv.org/html/2403.09026",
        "PDF": "https://arxiv.org/pdf/2403.09026"
      },
      "subjects": [
        "Hardware Architecture (cs.AR)",
        "Neural and Evolutionary Computing (cs.NE)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 14 Mar 2024 01:39:12 GMT",
          "size": "13526kb",
          "version": "v1"
        },
        {
          "date": "Thu, 11 Apr 2024 23:26:33 GMT",
          "size": "7631kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2024/04/11",
      "title": "FlexNN: A Dataflow-aware Flexible Deep Learning Accelerator for Energy-Efficient Edge Devices",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on a flexible neural network hardware accelerator aimed at improving energy efficiency and computational performance. It does not discuss LLM training data processing, collection, or enhancement."
      },
      "tasks": [],
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2406.02839",
      "abstract": "Implicit-explicit (IMEX) time integration schemes are well suited for nonlinear structural dynamics because of their low computational cost and high accuracy. However, stability of IMEX schemes cannot be guaranteed for general nonlinear problems. In this article, we present a scalar auxiliary variable (SAV) stabilization of high-order IMEX time integration schemes that leads to unconditional stability. The proposed IMEX-BDFk-SAV schemes treat linear terms implicitly using kth-order backward difference formulas (BDFk) and nonlinear terms explicitly. This eliminates the need for iterations in nonlinear problems and leads to low computational cost. Truncation error analysis of the proposed IMEX-BDFk-SAV schemes confirms that up to kth-order accuracy can be achieved and this is verified through a series of convergence tests. Unlike existing SAV schemes for first-order ordinary differential equations (ODEs), we introduce a novel SAV for the proposed schemes that allows direct solution of the second-order ODEs without transforming them to a system of first-order ODEs. Finally, we demonstrate the performance of the proposed schemes by solving several nonlinear problems in structural dynamics and show that the proposed schemes can achieve high accuracy at a low computational cost while maintaining unconditional stability.",
      "authors": [
        "Sun-Beom Kwon and Arun Prakash"
      ],
      "last_revised_date": "2024/06/05",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2406.02839",
        "HTML": "https://arxiv.org/html/2406.02839",
        "PDF": "https://arxiv.org/pdf/2406.02839"
      },
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 05 Jun 2024 01:30:47 GMT",
          "size": "7511kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2024/06/05",
      "title": "Scalar auxiliary variable (SAV) stabilization of implicit-explicit (IMEX) time integration schemes for nonlinear structural dynamics",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This work addresses time integration schemes in structural dynamics, which is not related to LLM training data processing or the data engineering stage for LLMs."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2501.04618",
      "abstract": "We investigate the numerical approximation of the stochastic Allen--Cahn equation with multiplicative noise on a periodic domain. The considered scheme uses a recently proposed augmented variant of scalar auxiliary variable method for the discretization with respect to time. While scalar auxiliary variable methods in general allow for the construction of unconditionally stable, efficient linear schemes, the considered augmented version (cf. [S. Metzger, 2024, IMA J. Numer. Anal.]) additionally compensates for the typically poor temporal regularity of solutions to stochastic partial differential equations and hence extends the range of applicability of the scheme. In this work, we establish strong rates of convergence and show that the proposed linear scheme exhibits the same optimal rates of convergence that were established in [A. K. Majee & A. Prohl, 2018, Comput. Methods Appl. Math.] for a nonlinear structure preserving scheme. Finally, we provide numerical simulations verifying our theoretical findings.",
      "authors": [
        "Stefan Metzger"
      ],
      "last_revised_date": "2025/01/08",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.04618",
        "HTML": "https://arxiv.org/html/2501.04618",
        "PDF": "https://arxiv.org/pdf/2501.04618"
      },
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 08 Jan 2025 17:00:31 GMT",
          "size": "547kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/01/08",
      "title": "Strong error estimates for a fully discrete SAV scheme for the stochastic Allen--Cahn equation with multiplicative noise",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on numerical approximations for the stochastic Allen-Cahn equation, which is unrelated to LLM training data processing."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2205.02736",
      "abstract": "In today's era of information disorder, many organizations are moving to verify the veracity of news published on the web and social media. In particular, some agencies are exploring the world of online media and, through a largely manual process, ranking the credibility and transparency of news sources around the world. In this paper, we evaluate two procedures for assessing the risk of online media exposing their readers to m/disinformation. The procedures have been dictated by NewsGuard and The Global Disinformation Index, two well-known organizations combating d/misinformation via practices of good journalism. Specifically, considering a fixed set of media outlets, we examine how many of them were rated equally by the two procedures, and which aspects led to disagreement in the assessment. The result of our analysis shows a good degree of agreement, which in our opinion has a double value: it fortifies the correctness of the procedures and lays the groundwork for their automation.",
      "authors": [
        "Manuel Pratelli",
        "Marinella Petrocchi"
      ],
      "last_revised_date": "2022/05/05",
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2205.02736",
        "HTML": "https://arxiv.org/html/2205.02736",
        "PDF": "https://arxiv.org/pdf/2205.02736"
      },
      "subjects": [
        "Computers and Society (cs.CY)",
        "Information Retrieval (cs.IR)",
        "Social and Information Networks (cs.SI)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 05 May 2022 16:16:03 GMT",
          "size": "143kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2022/05/05",
      "title": "A Structured Analysis of Journalistic Evaluations for News Source Reliability",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper analyzes journalistic evaluations of news source reliability and does not discuss any processing of training data for LLMs."
      },
      "tasks": [
        "Misinformation"
      ],
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2505.12246",
      "abstract": "Online scene perception and topology reasoning are critical for autonomous vehicles to understand their driving environments, particularly for mapless driving systems that endeavor to reduce reliance on costly High-Definition (HD) maps. However, recent advances in online scene understanding still face limitations, especially in long-range or occluded scenarios, due to the inherent constraints of onboard sensors. To address this challenge, we propose a Standard-Definition (SD) Map Enhanced scene Perception and Topology reasoning (SEPT) framework, which explores how to effectively incorporate the SD map as prior knowledge into existing perception and reasoning pipelines. Specifically, we introduce a novel hybrid feature fusion strategy that combines SD maps with Bird's-Eye-View (BEV) features, considering both rasterized and vectorized representations, while mitigating potential misalignment between SD maps and BEV feature spaces. Additionally, we leverage the SD map characteristics to design an auxiliary intersection-aware keypoint detection task, which further enhances the overall scene understanding performance. Experimental results on the large-scale OpenLane-V2 dataset demonstrate that by effectively integrating SD map priors, our framework significantly improves both scene perception and topology reasoning, outperforming existing methods by a substantial margin.",
      "authors": [
        "Muleilan Pei",
        "Jiayao Shan",
        "Peiliang Li",
        "Jieqi Shi",
        "Jing Huo",
        "Yang Gao",
        "and Shaojie Shen"
      ],
      "last_revised_date": "2025/05/18",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.12246",
        "HTML": "https://arxiv.org/html/2505.12246",
        "PDF": "https://arxiv.org/pdf/2505.12246"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "Sun, 18 May 2025 05:57:31 GMT",
          "size": "4141kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/05/18",
      "title": "SEPT: Standard-Definition Map Enhanced Scene Perception and Topology Reasoning for Autonomous Driving",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper proposes a scene perception and topology reasoning framework for autonomous driving, with no discussion on LLM training data processing or collection."
      },
      "tasks": [
        "Autonomous Driving",
        "Autonomous Vehicles",
        "Keypoint Detection",
        "Scene Understanding"
      ],
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.07640",
      "abstract": "Class groups of real quadratic fields represent fundamental structures in algebraic number theory with significant computational implications. While Stark's conjecture establishes theoretical connections between special units and class group structures, explicit constructions have remained elusive, and precise quantum complexity bounds for class group computations are lacking. Here we establish an integrated framework defining Stark-Coleman invariants $\\kappa_p(K) = \\log_p \\left( \\frac{\\varepsilon_{\\mathrm{St},p}}{\\sigma(\\varepsilon_{\\mathrm{St},p})} \\right) \\mod p^{\\mathrm{ord}_p(\\Delta_K)}$ through a synthesis of $p$-adic Hodge theory and extended Coleman integration. We prove these invariants classify class groups under the Generalized Riemann Hypothesis (GRH), resolving the isomorphism problem for discriminants $D > 10^{32}$. Furthermore, we demonstrate that this approach yields the quantum lower bound $\\exp\\left(\\Omega\\left(\\frac{\\log D}{(\\log \\log D)^2}\\right)\\right)$ for the class group discrete logarithm problem, improving upon previous bounds lacking explicit constants. Our results indicate that Stark units constrain the geometric organization of class groups, providing theoretical insight into computational complexity barriers.",
      "authors": [
        "Ruopengyu Xu and Chenglian Liu"
      ],
      "last_revised_date": "2025/06/09",
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.07640",
        "HTML": "https://arxiv.org/html/2506.07640",
        "PDF": "https://arxiv.org/pdf/2506.07640"
      },
      "subjects": [
        "Number Theory (math.NT)",
        "Cryptography and Security (cs.CR)",
        "Group Theory (math.GR)",
        "Quantum Physics (quant-ph)"
      ],
      "submission_historys": [
        {
          "date": "Mon, 09 Jun 2025 11:06:17 GMT",
          "size": "28kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/09",
      "title": "Stark-Coleman Invariants and Quantum Lower Bounds: An Integrated Framework for Real Quadratic Fields",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper is concerned with algebraic number theory and quantum complexity, lacking any discussion on LLM training data processing."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2312.06893",
      "abstract": "Developing stateful cloud applications, such as low-latency workflows and microservices with strict consistency requirements, remains arduous for programmers. The Stateful Functions-as-a-Service (SFaaS) paradigm aims to serve these use cases. However, existing approaches provide weak transactional guarantees or perform expensive external state accesses requiring inefficient transactional protocols that increase execution latency.\n  In this paper, we present Styx, a novel dataflow-based SFaaS runtime that executes serializable transactions consisting of stateful functions that form arbitrary call-graphs with exactly-once guarantees. Styx extends a deterministic transactional protocol by contributing: i) a function acknowledgment scheme to determine transaction boundaries required in SFaaS workloads, ii) a function-execution caching mechanism, and iii) an early-commit reply mechanism that substantially reduces transaction execution latency. Experiments with the YCSB, TPC-C, and Deathstar benchmarks show that Styx outperforms state-of-the-art approaches by achieving at least one order of magnitude higher throughput while exhibiting near-linear scalability and low latency.",
      "authors": [
        "Kyriakos Psarakis",
        "George Christodoulou",
        "George Siachamis",
        "Marios Fragkoulis",
        "Asterios Katsifodimos"
      ],
      "last_revised_date": "2025/02/06",
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2312.06893",
        "HTML": "https://arxiv.org/html/2312.06893",
        "PDF": "https://arxiv.org/pdf/2312.06893"
      },
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "Databases (cs.DB)"
      ],
      "submission_historys": [
        {
          "date": "Mon, 11 Dec 2023 23:34:23 GMT",
          "size": "1084kb",
          "version": "v1"
        },
        {
          "date": "Mon, 04 Mar 2024 10:46:43 GMT",
          "size": "1930kb",
          "version": "v2"
        },
        {
          "date": "Tue, 27 Aug 2024 17:30:41 GMT",
          "size": "1761kb",
          "version": "v3"
        },
        {
          "date": "Thu, 06 Feb 2025 12:32:34 GMT",
          "size": "946kb",
          "version": "v4"
        }
      ],
      "submitted_date": "2025/02/06",
      "title": "Styx: Transactional Stateful Functions on Streaming Dataflows",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "Styx is a dataflow-based runtime system for cloud applications focusing on transactional stateful functions. It does not address LLM training data processing or engineering."
      },
      "repo_urls": [
        "https://github.com/delftdata/styx"
      ],
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2305.19717",
      "abstract": "Graph neural networks compute node representations by performing multiple message-passing steps that consist in local aggregations of node features. Having deep models that can leverage longer-range interactions between nodes is hindered by the issues of over-smoothing and over-squashing. In particular, the latter is attributed to the graph topology which guides the message-passing, causing a node representation to become insensitive to information contained at distant nodes. Many graph rewiring methods have been proposed to remedy or mitigate this problem. However, properly evaluating the benefits of these methods is made difficult by the coupling of over-squashing with other issues strictly related to model training, such as vanishing gradients. Therefore, we propose an evaluation setting based on message-passing models that do not require training to compute node and graph representations. We perform a systematic experimental comparison on real-world node and graph classification tasks, showing that rewiring the underlying graph rarely does confer a practical benefit for message-passing.",
      "authors": [
        "Alessio Micheli",
        "Domenico Tortorella"
      ],
      "last_revised_date": "2025/05/28",
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2305.19717",
        "HTML": "https://arxiv.org/html/2305.19717",
        "PDF": "https://arxiv.org/pdf/2305.19717"
      },
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 31 May 2023 10:12:23 GMT",
          "size": "496kb",
          "version": "v1"
        },
        {
          "date": "Wed, 28 May 2025 13:51:47 GMT",
          "size": "224kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/05/28",
      "title": "An Empirical Evaluation of Rewiring Approaches in Graph Neural Networks",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on evaluating graph neural network rewiring approaches, which are not related to the processing of training data for LLMs."
      },
      "tasks": [
        "Graph Classification"
      ],
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.20243",
      "abstract": "Automatic fluency assessment (AFA) remains challenging, particularly in capturing speech rhythm, pauses, and disfluencies in non-native speakers. We introduce a chunk-based approach integrating self-supervised learning (SSL) models (Wav2Vec2, HuBERT, and WavLM) selected for their complementary strengths in phonetic, prosodic, and noisy speech modeling, with a hierarchical CNN-BiLSTM framework. Speech is segmented into breath-group chunks using Silero voice activity detection (Silero-VAD), enabling fine-grained temporal analysis while mitigating over-segmentation artifacts. SSL embeddings are fused via a learnable weighted mechanism, balancing acoustic and linguistic features, and enriched with chunk-level fluency markers (e.g., speech rate, pause durations, n-gram repetitions). The CNN-BiLSTM captures local and long-term dependencies across chunks. Evaluated on Avalinguo and Speechocean762, our approach improves F1-score by 2.8 and Pearson correlation by 6.2 points over single SSL baselines on Speechocean762, with gains of 4.2 F1-score and 4.0 Pearson points on Avalinguo, surpassing Pyannote.audio-based segmentation baselines. These findings highlight chunk-based multi-SSL fusion for robust fluency evaluation, though future work should explore generalization to dialects with irregular prosody.",
      "authors": [
        "Papa S\\'ega Wade",
        "Mihai Andries",
        "Ioannis Kanellos and Thierry Moudenc"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20243",
        "HTML": "https://arxiv.org/html/2506.20243",
        "PDF": "https://arxiv.org/pdf/2506.20243"
      },
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 08:39:22 GMT",
          "size": "375kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "CBF-AFA: Chunk-Based Multi-SSL Fusion for Automatic Fluency Assessment",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This work is related to automatic fluency assessment using speech models. Although it references data processing in terms of speech segmentation and feature extraction, there is no direct relevance to LLM training data processing or engineering in its context."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.20442",
      "abstract": "Biodiversity loss is a critical planetary boundary, yet its connection to computing remains largely unexamined. Prior sustainability efforts in computing have focused on carbon and water, overlooking biodiversity due to the lack of appropriate metrics and modeling frameworks. This paper presents the first end-to-end analysis of biodiversity impact from computing systems. We introduce two new metrics--Embodied Biodiversity Index (EBI) and Operational Biodiversity Index (OBI)--to quantify biodiversity impact across the lifecycle, and present FABRIC, a modeling framework that links computing workloads to biodiversity impacts. Our evaluation highlights the need to consider biodiversity alongside carbon and water in sustainable computing design and optimization. The code is available at https://github.com/TianyaoShi/FABRIC.",
      "authors": [
        "Tianyao Shi",
        "Ritbik Kumar",
        "Inez Hua",
        "Yi Ding"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20442",
        "HTML": "https://arxiv.org/html/2506.20442",
        "PDF": "https://arxiv.org/pdf/2506.20442"
      },
      "subjects": [
        "Computers and Society (cs.CY)",
        "Hardware Architecture (cs.AR)",
        "Distributed, Parallel, and Cluster Computing (cs.DC)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 13:50:04 GMT",
          "size": "770kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "When Servers Meet Species: A Fab-to-Grave Lens on Computing's Biodiversity Impact",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper is centered around biodiversity impact assessments of computing systems and does not pertain to LLM training data processing."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2406.00260",
      "abstract": "Learning to optimize is an approach that leverages training data to accelerate the solution of optimization problems. Many approaches use unrolling to parametrize the update step and learn optimal parameters. Although L2O has shown empirical advantages over classical optimization algorithms, memory restrictions often greatly limit the unroll length and learned algorithms usually do not provide convergence guarantees. In contrast, we introduce a novel method employing a greedy strategy that learns iteration-specific parameters by minimizing the function value at the next iteration. This enables training over significantly more iterations while maintaining constant device memory usage. We parameterize the update such that parameter learning is convex when the objective function is convex. In particular, we explore preconditioned gradient descent and an extension of Polyak's Heavy Ball Method with multiple parametrizations including a novel convolutional preconditioner. With our learned algorithms, convergence in the training set is proved even when the preconditioners are not necessarily symmetric nor positive definite. Convergence on a class of unseen functions is also obtained under certain assumptions, ensuring robust performance and generalization beyond the training data. We test our learned algorithms on two inverse problems, image deblurring and Computed Tomography, on which learned convolutional preconditioners demonstrate improved empirical performance over classical optimization algorithms such as Nesterov's Accelerated Gradient Method and the quasi-Newton method L-BFGS.",
      "authors": [
        "Patrick Fahy",
        "Mohammad Golbabaee",
        "Matthias J. Ehrhardt"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2406.00260",
        "HTML": "https://arxiv.org/html/2406.00260",
        "PDF": "https://arxiv.org/pdf/2406.00260"
      },
      "subjects": [
        "Optimization and Control (math.OC)",
        "Numerical Analysis (cs.NA)",
        "Numerical Analysis (math.NA)"
      ],
      "submission_historys": [
        {
          "date": "Sat, 01 Jun 2024 01:49:37 GMT",
          "size": "11888kb",
          "version": "v1"
        },
        {
          "date": "Tue, 15 Oct 2024 16:22:52 GMT",
          "size": "16483kb",
          "version": "v2"
        },
        {
          "date": "Mon, 11 Nov 2024 13:15:58 GMT",
          "size": "16483kb",
          "version": "v3"
        },
        {
          "date": "Sat, 30 Nov 2024 02:32:31 GMT",
          "size": "34023kb",
          "version": "v4"
        },
        {
          "date": "Thu, 05 Dec 2024 01:21:47 GMT",
          "size": "34023kb",
          "version": "v5"
        },
        {
          "date": "Thu, 06 Feb 2025 00:00:53 GMT",
          "size": "34019kb",
          "version": "v6"
        },
        {
          "date": "Wed, 25 Jun 2025 22:04:46 GMT",
          "size": "4132kb",
          "version": "v7"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Greedy Learning to Optimize with Convergence Guarantees",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper develops a learning method for optimization problems, using training data to improve optimization but not focusing on data processing for LLM training."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2310.06930",
      "abstract": "Recent advances in text-to-speech have made it possible to generate natural-sounding audio from text. However, audiobook narrations involve dramatic vocalizations and intonations by the reader, with greater reliance on emotions, dialogues, and descriptions in the narrative. Using our dataset of 93 aligned book-audiobook pairs, we present improved models for prosody prediction properties (pitch, volume, and rate of speech) from narrative text using language modeling. Our predicted prosody attributes correlate much better with human audiobook readings than results from a state-of-the-art commercial TTS system: our predicted pitch shows a higher correlation with human reading for 22 out of the 24 books, while our predicted volume attribute proves more similar to human reading for 23 out of the 24 books. Finally, we present a human evaluation study to quantify the extent that people prefer prosody-enhanced audiobook readings over commercial text-to-speech systems.",
      "authors": [
        "Charuta Pethe",
        "Bach Pham",
        "Felix D Childress",
        "Yunting Yin",
        "Steven Skiena"
      ],
      "last_revised_date": "2025/01/08",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2310.06930",
        "HTML": "https://arxiv.org/html/2310.06930",
        "PDF": "https://arxiv.org/pdf/2310.06930"
      },
      "subjects": [
        "Sound (cs.SD)",
        "Machine Learning (cs.LG)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 10 Oct 2023 18:33:47 GMT",
          "size": "8911kb",
          "version": "v1"
        },
        {
          "date": "Sat, 05 Oct 2024 21:07:38 GMT",
          "size": "8911kb",
          "version": "v2"
        },
        {
          "date": "Wed, 08 Jan 2025 01:33:56 GMT",
          "size": "2393kb",
          "version": "v3"
        }
      ],
      "submitted_date": "2025/01/08",
      "title": "Prosody Analysis of Audiobooks",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper investigates prosody prediction in audiobook narrations, using prosody attributes modeling but does not address the training data preparation for LLMs."
      },
      "tasks": [
        "Attribute",
        "Language Modeling",
        "Language Modelling",
        "Prosody Prediction",
        "text-to-speech",
        "Text to Speech"
      ],
      "repo_urls": [
        "https://github.com/sbu-dsl/prosody-analysis-of-audiobooks"
      ],
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2501.10102",
      "abstract": "We present a new algorithm for iterating over all permutations of a sequence. The algorithm leverages elementary $O(1)$ operations on recursive lists. As a result, no new nodes are allocated during the computation. Instead, all elements are rearranged within the original nodes of the singly linked list throughout the process. While permutations are generated in an unusual order, the transitions between consecutive permutations remain smooth. A proof of concept written in the Lisp programming language is proposed and discussed.",
      "authors": [
        "Thomas Baruchel"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.10102",
        "HTML": "https://arxiv.org/html/2501.10102",
        "PDF": "https://arxiv.org/pdf/2501.10102"
      },
      "subjects": [
        "Data Structures and Algorithms (cs.DS)",
        "Discrete Mathematics (cs.DM)",
        "Combinatorics (math.CO)"
      ],
      "submission_historys": [
        {
          "date": "Fri, 17 Jan 2025 10:41:26 GMT",
          "size": "7kb",
          "version": "v1"
        },
        {
          "date": "Wed, 22 Jan 2025 13:45:09 GMT",
          "size": "8kb",
          "version": "v2"
        },
        {
          "date": "Thu, 23 Jan 2025 07:18:45 GMT",
          "size": "8kb",
          "version": "v3"
        },
        {
          "date": "Sat, 25 Jan 2025 18:13:40 GMT",
          "size": "9kb",
          "version": "v4"
        },
        {
          "date": "Wed, 29 Jan 2025 08:09:56 GMT",
          "size": "9kb",
          "version": "v5"
        },
        {
          "date": "Thu, 26 Jun 2025 14:57:55 GMT",
          "size": "10kb",
          "version": "v6"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "An Efficient Algorithm for Permutation Iteration Using a Singly Linked List",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper presents an algorithm for permutation iteration using linked lists, with no relation to LLM training data processes."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2406.00367",
      "abstract": "Effectively analyzing the comments to uncover latent intentions holds immense value in making strategic decisions across various domains. However, several challenges hinder the process of sentiment analysis including the lexical diversity exhibited in comments, the presence of long dependencies within the text, encountering unknown symbols and words, and dealing with imbalanced datasets. Moreover, existing sentiment analysis tasks mostly leveraged sequential models to encode the long dependent texts and it requires longer execution time as it processes the text sequentially. In contrast, the Transformer requires less execution time due to its parallel processing nature. In this work, we introduce a novel hybrid deep learning model, RoBERTa-BiLSTM, which combines the Robustly Optimized BERT Pretraining Approach (RoBERTa) with Bidirectional Long Short-Term Memory (BiLSTM) networks. RoBERTa is utilized to generate meaningful word embedding vectors, while BiLSTM effectively captures the contextual semantics of long-dependent texts. The RoBERTa-BiLSTM hybrid model leverages the strengths of both sequential and Transformer models to enhance performance in sentiment analysis. We conducted experiments using datasets from IMDb, Twitter US Airline, and Sentiment140 to evaluate the proposed model against existing state-of-the-art methods. Our experimental findings demonstrate that the RoBERTa-BiLSTM model surpasses baseline models (e.g., BERT, RoBERTa-base, RoBERTa-GRU, and RoBERTa-LSTM), achieving accuracies of 80.74%, 92.36%, and 82.25% on the Twitter US Airline, IMDb, and Sentiment140 datasets, respectively. Additionally, the model achieves F1-scores of 80.73%, 92.35%, and 82.25% on the same datasets, respectively.",
      "authors": [
        "Md. Mostafizer Rahman",
        "Ariful Islam Shiplu",
        "Yutaka Watanobe",
        "and Md. Ashad Alam"
      ],
      "last_revised_date": "2025/05/15",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2406.00367",
        "HTML": "https://arxiv.org/html/2406.00367",
        "PDF": "https://arxiv.org/pdf/2406.00367"
      },
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Computational Engineering, Finance, and Science (cs.CE)"
      ],
      "submission_historys": [
        {
          "date": "Sat, 01 Jun 2024 08:59:46 GMT",
          "size": "1953kb",
          "version": "v1"
        },
        {
          "date": "Thu, 15 May 2025 01:38:21 GMT",
          "size": "1953kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/05/15",
      "title": "RoBERTa-BiLSTM: A Context-Aware Hybrid Model for Sentiment Analysis",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on sentiment analysis models and does not discuss any contributions to LLM training data processing or data engineering stages for LLM development."
      },
      "tasks": [
        "Sentiment Analysis"
      ],
      "repo_urls": [
        "https://github.com/MindCode-4/code-4/tree/main/roberta"
      ],
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2311.06362",
      "abstract": "Dictionary definitions are historically the arbitrator of what words mean, but this primacy has come under threat by recent progress in NLP, including word embeddings and generative models like ChatGPT. We present an exploratory study of the degree of alignment between word definitions from classical dictionaries and these newer computational artifacts. Specifically, we compare definitions from three published dictionaries to those generated from variants of ChatGPT. We show that (i) definitions from different traditional dictionaries exhibit more surface form similarity than do model-generated definitions, (ii) that the ChatGPT definitions are highly accurate, comparable to traditional dictionaries, and (iii) ChatGPT-based embedding definitions retain their accuracy even on low frequency words, much better than GloVE and FastText word embeddings.",
      "authors": [
        "Bach Pham",
        "JuiHsuan Wong",
        "Samuel Kim",
        "Yunting Yin and Steven Skiena"
      ],
      "last_revised_date": "2025/01/06",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2311.06362",
        "HTML": "https://arxiv.org/html/2311.06362",
        "PDF": "https://arxiv.org/pdf/2311.06362"
      },
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "Fri, 10 Nov 2023 19:27:20 GMT",
          "size": "10560kb",
          "version": "v1"
        },
        {
          "date": "Thu, 31 Oct 2024 23:55:10 GMT",
          "size": "10561kb",
          "version": "v2"
        },
        {
          "date": "Mon, 06 Jan 2025 05:37:29 GMT",
          "size": "3928kb",
          "version": "v3"
        }
      ],
      "submitted_date": "2025/01/06",
      "title": "Word Definitions from Large Language Models",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on comparing word definitions from classical dictionaries and ChatGPT-generated ones. It does not discuss or propose improvements in data processing or engineering specifically for LLMs."
      },
      "tasks": [
        "Word Embeddings"
      ],
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "1608.04112",
      "abstract": "We introduce a new concept of approximation applicable to decision problems and functions, inspired by Bayesian probability. From the perspective of a Bayesian reasoner with limited computational resources, the answer to a problem that cannot be solved exactly is uncertain and therefore should be described by a random variable. It thus should make sense to talk about the expected value of this random variable, an idea we formalize in the language of average-case complexity theory by introducing the concept of \"optimal polynomial-time estimators.\" We prove some existence theorems and completeness results, and show that optimal polynomial-time estimators exhibit many parallels with \"classical\" probability theory.",
      "authors": [
        "Vanessa Kosoy",
        "Alexander Appel"
      ],
      "last_revised_date": "2019/06/04",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/1608.04112",
        "HTML": "https://arxiv.org/html/1608.04112",
        "PDF": "https://arxiv.org/pdf/1608.04112"
      },
      "subjects": [
        "Computational Complexity (cs.CC)"
      ],
      "submission_historys": [
        {
          "date": "Sun, 14 Aug 2016 15:34:24 GMT",
          "size": "53kb",
          "version": "v1"
        },
        {
          "date": "Tue, 13 Sep 2016 07:18:29 GMT",
          "size": "56kb",
          "version": "v2"
        },
        {
          "date": "Thu, 15 Sep 2016 07:32:47 GMT",
          "size": "56kb",
          "version": "v3"
        },
        {
          "date": "Wed, 28 Dec 2016 19:57:53 GMT",
          "size": "57kb",
          "version": "v4"
        },
        {
          "date": "Fri, 31 May 2019 18:06:43 GMT",
          "size": "63kb",
          "version": "v5"
        },
        {
          "date": "Tue, 04 Jun 2019 19:53:27 GMT",
          "size": "63kb",
          "version": "v6"
        }
      ],
      "submitted_date": "2019/06/04",
      "title": "Optimal Polynomial-Time Estimators: A Bayesian Notion of Approximation Algorithm",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on a Bayesian perspective on approximation algorithms and average-case complexity but does not address any aspect of LLM training data processing or data engineering tasks."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2103.09431",
      "abstract": "The evolution of a Master's programme, like many other human institutions, can be viewed as a self-organising system whose underlying structures and dynamics arise primarily from the interaction of its faculty and students. Identifying these hidden properties may not be a trivial task, due to the complex behaviour implicit in such evolution. Nonetheless, we argue that the programme's body of research production (represented mainly by dissertations) can serve this purpose. Bibliometric analyses of such data can reveal insights about production growth, collaborative networks, and visual mapping of established, niche, and emerging research topics, among other facets. Thus, we propose a bibliometric workflow aimed at discovering the production dynamics, as well as the conceptual, social and intellectual structures developed by the Master's degree, in the interest of guiding decision-makers to better assess the strengths of the programme and to prioritise strategic goals. In addition, we report two case studies to illustrate the realisation of the proposed workflow. We conclude with considerations on the possible application of the approach to other academic research units.",
      "authors": [
        "Nathalia Chaparro and Sergio Rojas-Galeano"
      ],
      "last_revised_date": "2021/03/17",
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2103.09431",
        "HTML": "https://arxiv.org/html/2103.09431",
        "PDF": "https://arxiv.org/pdf/2103.09431"
      },
      "subjects": [
        "Digital Libraries (cs.DL)",
        "Social and Information Networks (cs.SI)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 17 Mar 2021 04:18:16 GMT",
          "size": "16730kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2021/03/17",
      "title": "Revealing the research landscape of Master's degrees via bibliometric analyses",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper proposes a bibliometric workflow to analyze Master's program research output but is not concerned with LLM training data processing or related data engineering tasks."
      },
      "repo_urls": [
        "https://github.com/sargaleano/bibliomasters"
      ],
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2110.08483",
      "abstract": "Decision forests, including random forests and gradient boosting trees, remain the leading machine learning methods for many real-world data problems, especially on tabular data. However, most of the current implementations only operate in batch mode, and therefore cannot incrementally update when more data arrive. Several previous works developed streaming trees and ensembles to overcome this limitation. Nonetheless, we found that those state-of-the-art algorithms suffer from a number of drawbacks, including low accuracy on some problems and high memory usage on others. We therefore developed an extremely simple extension of decision trees: given new data, simply update existing trees by continuing to grow them, and replace some old trees with new ones to control the total number of trees. In a benchmark suite containing 72 classification problems (the OpenML-CC18 data suite), we illustrate that our approach, $\\textit{Extremely Simple Streaming Forest}$ (XForest), does not suffer from either of the aforementioned limitations. On those datasets, we also demonstrate that our approach often performs as well as, and sometimes even better than, conventional batch decision forest algorithms. With a $\\textit{zero-added-node}$ approach, XForest-Zero, we also further extend existing splits to new tasks, and this very efficient method only requires inference time. Thus, XForests establish a simple standard for streaming trees and forests that could readily be applied to many real-world problems.",
      "authors": [
        "Haoyin Xu",
        "Jayanta Dey",
        "Sambit Panda",
        "Joshua T. Vogelstein"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2110.08483",
        "HTML": "https://arxiv.org/html/2110.08483",
        "PDF": "https://arxiv.org/pdf/2110.08483"
      },
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Data Structures and Algorithms (cs.DS)"
      ],
      "submission_historys": [
        {
          "date": "Sat, 16 Oct 2021 06:06:36 GMT",
          "size": "78kb",
          "version": "v1"
        },
        {
          "date": "Sun, 23 Jan 2022 00:51:56 GMT",
          "size": "2178kb",
          "version": "v2"
        },
        {
          "date": "Mon, 21 Feb 2022 15:50:08 GMT",
          "size": "2170kb",
          "version": "v3"
        },
        {
          "date": "Tue, 08 Mar 2022 21:24:54 GMT",
          "size": "2343kb",
          "version": "v4"
        },
        {
          "date": "Thu, 10 Nov 2022 14:39:53 GMT",
          "size": "2331kb",
          "version": "v5"
        },
        {
          "date": "Tue, 24 Oct 2023 13:35:47 GMT",
          "size": "377kb",
          "version": "v6"
        },
        {
          "date": "Thu, 26 Jun 2025 01:33:13 GMT",
          "size": "1022kb",
          "version": "v7"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Extremely Simple Streaming Forest",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper primarily focuses on developing a streaming algorithm for decision forests and does not address any aspect of LLM training data collection or processing."
      },
      "tasks": [
        "Continual Learning",
        "Transfer Learning"
      ],
      "repo_urls": [
        "https://github.com/neurodata/SDTF",
        "https://github.com/PSSF23/scikit-learn-stream"
      ],
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.20673",
      "abstract": "Network failure diagnosis is challenging yet critical for high-performance computing (HPC) systems. Existing methods cannot be directly applied to HPC scenarios due to data heterogeneity and lack of accuracy. This paper proposes a novel framework, called ClusterRCA, to localize culprit nodes and determine failure types by leveraging multimodal data. ClusterRCA extracts features from topologically connected network interface controller (NIC) pairs to analyze the diverse, multimodal data in HPC systems. To accurately localize culprit nodes and determine failure types, ClusterRCA combines classifier-based and graph-based approaches. A failure graph is constructed based on the output of the state classifier, and then it performs a customized random walk on the graph to localize the root cause. Experiments on datasets collected by a top-tier global HPC device vendor show ClusterRCA achieves high accuracy in diagnosing network failure for HPC systems. ClusterRCA also maintains robust performance across different application scenarios.",
      "authors": [
        "Yongqian Sun",
        "Xijie Pan",
        "Xiao Xiong",
        "Lei Tao",
        "Jiaju Wang",
        "Shenglin Zhang",
        "Yuan Yuan",
        "Yuqi Li and Kunlin Jian"
      ],
      "last_revised_date": "2025/06/17",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20673",
        "HTML": "https://arxiv.org/html/2506.20673",
        "PDF": "https://arxiv.org/pdf/2506.20673"
      },
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 17 Jun 2025 16:52:09 GMT",
          "size": "297kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/17",
      "title": "ClusterRCA: Network Failure Diagnosis in HPC Systems Using Multimodal Data",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The study is centered on network failure diagnosis in HPC systems using multimodal data to localize failures. It does not relate to the processing of training data for large language models at any stage."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.20674",
      "abstract": "Analyzing large-scale performance logs from GPU profilers often requires terabytes of memory and hours of runtime, even for basic summaries. These constraints prevent timely insight and hinder the integration of performance analytics into automated workflows. Existing analysis tools typically process data sequentially, making them ill-suited for HPC workflows with growing trace complexity and volume. We introduce a distributed data analysis framework that scales with dataset size and compute availability. Rather than treating the dataset as a single entity, our system partitions it into independently analyzable shards and processes them concurrently across MPI ranks. This design reduces per-node memory pressure, avoids central bottlenecks, and enables low-latency exploration of high-dimensional trace data. We apply the framework to end-to-end Nsight Compute traces from real HPC and AI workloads, demonstrate its ability to diagnose performance variability, and uncover the impact of memory transfer latency on GPU kernel behavior.",
      "authors": [
        "Ankur Lahiry",
        "Ayush Pokharel",
        "Seth Ockerman",
        "Amal Gueroudji",
        "Line Pouchard",
        "Tanzima Z. Islam"
      ],
      "last_revised_date": "2025/06/17",
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20674",
        "HTML": "https://arxiv.org/html/2506.20674",
        "PDF": "https://arxiv.org/pdf/2506.20674"
      },
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "Performance (cs.PF)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 17 Jun 2025 18:23:26 GMT",
          "size": "5989kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/17",
      "title": "Scalable GPU Performance Variability Analysis framework",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper presents a framework for analyzing GPU performance logs, focusing on performance variability and not involving any aspect of LLM training data engineering or processing."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.20675",
      "abstract": "GPU memory bandwidth is the main bottleneck for low-latency Large Language Model (LLM) inference. Speculative decoding leverages idle GPU compute by using a lightweight drafter to propose K tokens, which the LLM verifies in parallel, boosting token throughput. In conventional dense LLMs, all model weights are fetched each iteration, so speculation adds no latency overhead. Emerging Mixture of Experts (MoE) models activate only a subset of weights per token, greatly reducing data movement. However, we show that speculation is ineffective for MoEs: draft tokens collectively activate more weights, increasing data movement and verification time by 2-3x. When token throughput gains fail to offset this overhead, speculation causes slowdowns up to 1.5x, making it infeasible. Even when useful, the optimal K varies by task, model, and even between requests and iterations. Thus, despite widespread use in dense LLMs, speculation remains impractical in leading MoEs.\n  We present Cascade, a utility-driven framework that selectively enables speculation to avoid slowdowns and dynamically tunes K to accelerate MoE serving. Cascade uses a lightweight metric, speculation utility, the ratio of token gains to verification cost, which shows iteration-level locality, enabling periodic decisions via short test and longer set phases. For each request, Cascade disables speculation if utility drops below one during testing, and when utility exceeds one, tests multiple K-values to choose the utility-maximizing K for the set phase. We implement Cascade in vLLM and evaluate it on five popular MoEs with workloads spanning code, math, extraction, and mixed tasks. Cascade limits slowdown to 5% (vs. 1.5x) and improves throughput by 7-14% over static K, making speculative decoding practical for MoEs.",
      "authors": [
        "Anish Saxena",
        "Po-An Tsai",
        "Hritvik Taneja",
        "Aamer Jaleel",
        "Moinuddin Qureshi"
      ],
      "last_revised_date": "2025/06/17",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20675",
        "HTML": "https://arxiv.org/html/2506.20675",
        "PDF": "https://arxiv.org/pdf/2506.20675"
      },
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 17 Jun 2025 20:06:08 GMT",
          "size": "1516kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/17",
      "title": "Utility-Driven Speculative Decoding for Mixture-of-Experts",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper focuses on GPU memory optimization for inference using Mixture-of-Experts models and does not discuss data engineering or training data processing for LLMs."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.20677",
      "abstract": "Sorting is an essential operation in computer science with direct consequences on the performance of large scale data systems, real-time systems, and embedded computation. However, no sorting algorithm is optimal under all distributions of data. The new adaptive hybrid sorting paradigm proposed in this paper is the paradigm that automatically selects the most effective sorting algorithm Counting Sort, Radix Sort, or QuickSort based on real-time monitoring of patterns in input data. The architecture begins by having a feature extraction module to compute significant parameters such as data volume, value range and entropy. These parameters are sent to a decision engine involving Finite State Machine and XGBoost classifier to aid smart and effective in choosing the optimal sorting strategy. It implements Counting Sort on small key ranges, Radix Sort on large range structured input with low-entropy keys and QuickSort on general purpose sorting. The experimental findings of both synthetic and real life dataset confirm that the proposed solution is actually inclined to excel significantly by comparison in execution time, flexibility and the efficiency of conventional static sorting algorithms. The proposed framework provides a scalable, high perhaps and applicable to a wide range of data processing operations like big data analytics, edge computing, and systems with hardware limitations.",
      "authors": [
        "Shrinivass Arunachalam Balasubramanian"
      ],
      "last_revised_date": "2025/06/22",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20677",
        "HTML": "https://arxiv.org/html/2506.20677",
        "PDF": "https://arxiv.org/pdf/2506.20677"
      },
      "subjects": [
        "Data Structures and Algorithms (cs.DS)",
        "Databases (cs.DB)",
        "Performance (cs.PF)"
      ],
      "submission_historys": [
        {
          "date": "Sun, 22 Jun 2025 03:13:08 GMT",
          "size": "821kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/22",
      "title": "Adaptive Hybrid Sort: Dynamic Strategy Selection for Optimal Sorting Across Diverse Data Distributions",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper proposes a hybrid sorting algorithm, which is a general data processing method not specifically tailored to or contributing to the training data processing for LLMs."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.20679",
      "abstract": "Smartphone location data have transformed urban mobility research, providing unprecedented insights into how people navigate and interact in cities. However, leveraging location data at scale presents methodological challenges. Accurately identifying individuals' home and work locations is critical for a range of applications, including commuting analysis, unemployment estimation, and urban accessibility studies. Despite their widespread use, home-work detection methods lack a standardized framework that accounts for differing data quality and that is validated against ground-truth observations. This limits the comparability and reproducibility of results across studies and datasets. In this paper, we present HoWDe, a robust algorithm for identifying home and work locations from mobility data, explicitly designed to handle missing data and varying data quality across individuals. Using two unique ground-truth datasets comprising over 5100 individuals from more than 80 countries, HoWDe achieves home and work detection accuracies of up to 97% and 88%, respectively, with consistent performance across countries and demographic groups. We examine how parameter choices shape the trade-off between accuracy and user retention, and demonstrate how these methodological decisions influence downstream applications such as employment estimation and commuting pattern analysis. By supporting in-house pre-processing through a transparent and validated pipeline, HoWDe also facilitates the sharing of privacy-preserving mobility data. Together, our tools and findings establish methodological standards that support more robust, scalable, and reproducible mobility research at both individual and urban scales.",
      "authors": [
        "Silvia de Sojo",
        "Lorenzo Lucchini",
        "Ollin D. Langle-Chimal",
        "Samuel P. Fraiberger and Laura Alessandretti"
      ],
      "last_revised_date": "2025/06/23",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20679",
        "HTML": "https://arxiv.org/html/2506.20679",
        "PDF": "https://arxiv.org/pdf/2506.20679"
      },
      "subjects": [
        "Social and Information Networks (cs.SI)",
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "Mon, 23 Jun 2025 15:21:57 GMT",
          "size": "20100kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/23",
      "title": "Establishing validated standards for Home and Work location Detection",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper deals with location data standards and detection methods in mobility research, not directly addressing LLM training data processing."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.20685",
      "abstract": "Federated Learning (FL) has emerged as a transformative paradigm for distributed machine learning while preserving data privacy. However, existing approaches predominantly focus on model heterogeneity and aggregation techniques, largely overlooking the fundamental impact of dataset size characteristics on federated training dynamics. This paper introduces Size-Based Adaptive Federated Learning (SAFL), a novel progressive training framework that systematically organizes federated learning based on dataset size characteristics across heterogeneous multi-modal data. Our comprehensive experimental evaluation across 13 diverse datasets spanning 7 modalities (vision, text, time series, audio, sensor, medical vision, and multimodal) reveals critical insights: 1) an optimal dataset size range of 1000-1500 samples for federated learning effectiveness; 2) a clear modality performance hierarchy with structured data (time series, sensor) significantly outperforming unstructured data (text, multimodal); and 3) systematic performance degradation for large datasets exceeding 2000 samples. SAFL achieves an average accuracy of 87.68% across all datasets, with structured data modalities reaching 99%+ accuracy. The framework demonstrates superior communication efficiency, reducing total data transfer to 7.38 GB across 558 communications while maintaining high performance. Our real-time monitoring framework provides unprecedented insights into system resource utilization, network efficiency, and training dynamics. This work fills critical gaps in understanding how data characteristics should drive federated learning strategies, providing both theoretical insights and practical guidance for real-world FL deployments in neural network and learning systems.",
      "authors": [
        "Sajid Hussain",
        "Muhammad Sohail",
        "Nauman Ali Khan",
        "Naima Iltaf",
        "and Ihtesham ul Islam"
      ],
      "last_revised_date": "2025/06/24",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20685",
        "HTML": "https://arxiv.org/html/2506.20685",
        "PDF": "https://arxiv.org/pdf/2506.20685"
      },
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 24 Jun 2025 18:50:33 GMT",
          "size": "251kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/24",
      "title": "Progressive Size-Adaptive Federated Learning: A Comprehensive Framework for Heterogeneous Multi-Modal Data Systems",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper focuses on federated learning and the effects of dataset size characteristics in distributed systems, without contributions to LLM training data processing."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.20687",
      "abstract": "The original description of the k-d tree recognized that rebalancing techniques, such as used to build an AVL tree or a red-black tree, are not applicable to a k-d tree. Hence, in order to build a balanced k-d tree, it is necessary to find the median of a set of data for each recursive subdivision of that set. The sort or selection used to find the median, and the technique used to partition the set about that median, strongly influence the computational complexity of building a k-d tree. This article describes and contrasts three variants of the k-d tree that differ in their technique used to partition the set, and compares the performance of those variants. In addition, dual-threaded execution is proposed and analyzed for one of the three variants.",
      "authors": [
        "Russell A. Brown"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20687",
        "HTML": "https://arxiv.org/html/2506.20687",
        "PDF": "https://arxiv.org/pdf/2506.20687"
      },
      "subjects": [
        "Data Structures and Algorithms (cs.DS)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 01:01:38 GMT",
          "size": "714kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Review of Three Variants of the k-d Tree",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This article reviews variants of k-d trees, with no direct relation to the processing of training data for large language models."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.20693",
      "abstract": "The increasing availability of large-scale omics data calls for robust analytical frameworks capable of handling complex gene expression datasets while offering interpretable results. Recent advances in artificial intelligence have enabled the identification of aberrant molecular patterns distinguishing disease states from healthy controls. Coupled with improvements in model interpretability, these tools now support the identification of genes potentially driving disease phenotypes. However, current approaches to gene anomaly detection often remain limited to single datasets and lack accessible graphical interfaces. Here, we introduce E-ABIN, a general-purpose, explainable framework for Anomaly detection in Biological Networks. E-ABIN combines classical machine learning and graph-based deep learning techniques within a unified, user-friendly platform, enabling the detection and interpretation of anomalies from gene expression or methylation-derived networks. By integrating algorithms such as Support Vector Machines, Random Forests, Graph Autoencoders (GAEs), and Graph Adversarial Attributed Networks (GAANs), E-ABIN ensures a high predictive accuracy while maintaining interpretability. We demonstrate the utility of E-ABIN through case studies of bladder cancer and coeliac disease, where it effectively uncovers biologically relevant anomalies and offers insights into disease mechanisms.",
      "authors": [
        "Ugo Lomoio",
        "Tommaso Mazza",
        "Pierangelo Veltri",
        "and Pietro Hiram Guzzi"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20693",
        "HTML": "https://arxiv.org/html/2506.20693",
        "PDF": "https://arxiv.org/pdf/2506.20693"
      },
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 08:25:17 GMT",
          "size": "3458kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "E-ABIN: an Explainable module for Anomaly detection in BIological Networks",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on anomaly detection in biological networks using machine learning techniques, without any mention of large language model training data or data processing relevant to LLMs."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.20695",
      "abstract": "With its features of remix, TikTok is the designated platform for meme-making and dissemination. Creative combinations of video, emoji, and filters allow for an endless stream of memes and trends animated by sound. The platform has focused its moderation on upholding physical safety, hence investing in the detection of harmful challenges. In response to the DSA, TikTok implemented opt-outs for personalized feeds and features allowing users to report illegal content. At the same time, the platform remains subject to scrutiny. Centering on the role of sound and its intersections with ambiguous memes, the presented research probed right-wing extremist formations relating to the 2024 German state elections. The analysis evidences how the TikTok sound infrastructure affords a sustained presence of xenophobic content, often cloaked through vernacular modes of communication. These cloaking practices benefit from a sound infrastructure that affords the ongoing posting of user-generated sounds that instantly spread through the use-this-sound button. Importantly, these sounds are often not clearly recognizable as networkers of extremist content. Songs that do contain hateful lyrics are not eligible for personalized feeds, however, they remain online where they profit from intersecting with benign meme trends, rendering them visible in search results.",
      "authors": [
        "Marloes Geboers and Marcus B\\\"osch"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20695",
        "HTML": "https://arxiv.org/html/2506.20695",
        "PDF": "https://arxiv.org/pdf/2506.20695"
      },
      "subjects": [
        "Social and Information Networks (cs.SI)",
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 09:49:34 GMT",
          "size": "1358kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Malicious earworms and useful memes, how the far-right surfs on TikTok audio trends",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The research concentrates on meme dissemination and extremist content on TikTok, with no relation to LLM training data processing or engineering."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.20699",
      "abstract": "The Context-Content Uncertainty Principle (CCUP) proposes that inference under uncertainty is governed by an entropy asymmetry between context and content: high-entropy contexts must be interpreted through alignment with low-entropy, structured content. In this paper, we develop a layered computational framework that derives operational principles from this foundational asymmetry. At the base level, CCUP formalizes inference as directional entropy minimization, establishing a variational gradient that favors content-first structuring. Building upon this, we identify four hierarchical layers of operational principles: (\\textbf{L1}) \\emph{Core Inference Constraints}, including structure-before-specificity, asymmetric inference flow, cycle-consistent bootstrapping, and conditional compression, all shown to be mutually reducible; (\\textbf{L2}) \\emph{Resource Allocation Principles}, such as precision-weighted attention, asymmetric learning rates, and attractor-based memory encoding; (\\textbf{L3}) \\emph{Temporal Bootstrapping Dynamics}, which organize learning over time via structure-guided curricula; and (\\textbf{L4}) \\emph{Spatial Hierarchical Composition}, which integrates these mechanisms into self-organizing cycles of memory, inference, and planning. We present formal equivalence theorems, a dependency lattice among principles, and computational simulations demonstrating the efficiency gains of CCUP-aligned inference. This work provides a unified theoretical foundation for understanding how brains and machines minimize uncertainty through recursive structure-specificity alignment. The brain is not just an inference machine. It is a cycle-consistent entropy gradient resolver, aligning structure and specificity via path-dependent, content-seeded simulation.",
      "authors": [
        "Xin Li"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/publicdomain/zero/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20699",
        "HTML": "https://arxiv.org/html/2506.20699",
        "PDF": "https://arxiv.org/pdf/2506.20699"
      },
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 17:21:19 GMT",
          "size": "82kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "On Context-Content Uncertainty Principle",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on the Context-Content Uncertainty Principle and a framework for inference under uncertainty, without mentioning LLM training data or its processing."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.20701",
      "abstract": "Adapting a pretrained diffusion model to new objectives at inference time remains an open problem in generative modeling. Existing steering methods suffer from inaccurate value estimation, especially at high noise levels, which biases guidance. Moreover, information from past runs is not reused to improve sample quality, resulting in inefficient use of compute. Inspired by the success of Monte Carlo Tree Search, we address these limitations by casting inference-time alignment as a search problem that reuses past computations. We introduce a tree-based approach that samples from the reward-aligned target density by propagating terminal rewards back through the diffusion chain and iteratively refining value estimates with each additional generation. Our proposed method, Diffusion Tree Sampling (DTS), produces asymptotically exact samples from the target distribution in the limit of infinite rollouts, and its greedy variant, Diffusion Tree Search (DTS$^\\star$), performs a global search for high reward samples. On MNIST and CIFAR-10 class-conditional generation, DTS matches the FID of the best-performing baseline with up to $10\\times$ less compute. In text-to-image generation and language completion tasks, DTS$^\\star$ effectively searches for high reward samples that match best-of-N with up to $5\\times$ less compute. By reusing information from previous generations, we get an anytime algorithm that turns additional compute into steadily better samples, providing a scalable approach for inference-time alignment of diffusion models.",
      "authors": [
        "Vineet Jain",
        "Kusha Sareen",
        "Mohammad Pedramfar",
        "Siamak Ravanbakhsh"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20701",
        "HTML": "https://arxiv.org/html/2506.20701",
        "PDF": "https://arxiv.org/pdf/2506.20701"
      },
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 17:59:10 GMT",
          "size": "40835kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Diffusion Tree Sampling: Scalable inference-time alignment of diffusion models",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper addresses inference-time alignment for diffusion models, involving sampling methods rather than any LLM training data processing."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.20702",
      "abstract": "Rapidly improving AI capabilities and autonomy hold significant promise of transformation, but are also driving vigorous debate on how to ensure that AI is safe, i.e., trustworthy, reliable, and secure. Building a trusted ecosystem is therefore essential -- it helps people embrace AI with confidence and gives maximal space for innovation while avoiding backlash.\n  The \"2025 Singapore Conference on AI (SCAI): International Scientific Exchange on AI Safety\" aimed to support research in this space by bringing together AI scientists across geographies to identify and synthesise research priorities in AI safety. This resulting report builds on the International AI Safety Report chaired by Yoshua Bengio and backed by 33 governments. By adopting a defence-in-depth model, this report organises AI safety research domains into three types: challenges with creating trustworthy AI systems (Development), challenges with evaluating their risks (Assessment), and challenges with monitoring and intervening after deployment (Control).",
      "authors": [
        "Yoshua Bengio",
        "Tegan Maharaj",
        "Luke Ong",
        "Stuart Russell",
        "Dawn Song",
        "Max Tegmark",
        "Lan Xue",
        "Ya-Qin Zhang",
        "Stephen Casper",
        "Wan Sie Lee",
        "S\\\"oren Mindermann",
        "Vanessa Wilfred",
        "Vidhisha Balachandran",
        "Fazl Barez",
        "Michael Belinsky",
        "Imane Bello",
        "Malo Bourgon",
        "Mark Brakel",
        "Sim\\'eon Campos",
        "Duncan Cass-Beggs",
        "Jiahao Chen",
        "Rumman Chowdhury",
        "Kuan Chua Seah",
        "Jeff Clune",
        "Juntao Dai",
        "Agnes Delaborde",
        "Nouha Dziri",
        "Francisco Eiras",
        "Joshua Engels",
        "Jinyu Fan",
        "Adam Gleave",
        "Noah Goodman",
        "Fynn Heide",
        "Dan Hendrycks",
        "Cyrus Hodes",
        "Bryan Low Kian Hsiang",
        "Minlie Huang",
        "Sami Jawhar",
        "Wang Jingyu",
        "Adam Tauman Kalai",
        "Meindert Kamphuis",
        "Mohan Kankanhalli",
        "Subhash Kantamneni",
        "Mathias Bonde Kirk",
        "Thomas Kwa",
        "Jeffrey Ladish",
        "Kwok-Yan Lam",
        "Wan Lee Sie",
        "Taewhi Lee",
        "Xiaojian Li",
        "Jiajun Liu",
        "Chaochao Lu",
        "Yifan Mai",
        "Richard Mallah",
        "Julian Michael",
        "Nick Mo\\\"es",
        "Simon M\\\"oller",
        "Kihyuk Nam",
        "Kwan Yee Ng",
        "Mark Nitzberg",
        "Besmira Nushi",
        "Se\\'an O h\\'Eigeartaigh",
        "Alejandro Ortega",
        "Pierre Peign\\'e",
        "James Petrie",
        "Benjamin Prud'Homme",
        "Reihaneh Rabbany",
        "Nayat Sanchez-Pi",
        "Sarah Schwettmann",
        "Buck Shlegeris",
        "Saad Siddiqui",
        "Aradhana Sinha",
        "Mart\\'in Soto",
        "Cheston Tan",
        "Dong Ting",
        "Robert Trager",
        "Brian Tse",
        "Anthony Tung K. H.",
        "Vanessa Wilfred",
        "John Willes",
        "Denise Wong",
        "Wei Xu",
        "Rongwu Xu",
        "Yi Zeng",
        "HongJiang Zhang",
        "Djordje \\v{Z}ikeli\\'c"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20702",
        "HTML": "https://arxiv.org/html/2506.20702",
        "PDF": "https://arxiv.org/pdf/2506.20702"
      },
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 17:59:50 GMT",
          "size": "2671kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "The Singapore Consensus on Global AI Safety Research Priorities",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "It discusses AI safety research priorities without addressing LLM training data processing or related methods."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.20703",
      "abstract": "We describe Generative Blocks World to interact with the scene of a generated image by manipulating simple geometric abstractions. Our method represents scenes as assemblies of convex 3D primitives, and the same scene can be represented by different numbers of primitives, allowing an editor to move either whole structures or small details. Once the scene geometry has been edited, the image is generated by a flow-based method which is conditioned on depth and a texture hint. Our texture hint takes into account the modified 3D primitives, exceeding texture-consistency provided by existing key-value caching techniques. These texture hints (a) allow accurate object and camera moves and (b) largely preserve the identity of objects depicted. Quantitative and qualitative experiments demonstrate that our approach outperforms prior works in visual fidelity, editability, and compositional generalization.",
      "authors": [
        "Vaibhav Vavilala",
        "Seemandhar Jain",
        "Rahul Vasanth",
        "D.A. Forsyth",
        "and Anand Bhattad"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20703",
        "HTML": "https://arxiv.org/html/2506.20703",
        "PDF": "https://arxiv.org/pdf/2506.20703"
      },
      "subjects": [
        "Graphics (cs.GR)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 17:59:55 GMT",
          "size": "7124kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Generative Blocks World: Moving Things Around in Pictures",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper describes a method for editing scenes in generated images, which does not pertain to LLM training data processing or engineering."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.20705",
      "abstract": "The manifold hypothesis asserts that data of interest in high-dimensional ambient spaces, such as image data, lies on unknown low-dimensional submanifolds. Diffusion models (DMs) -- which operate by convolving data with progressively larger amounts of Gaussian noise and then learning to revert this process -- have risen to prominence as the most performant generative models, and are known to be able to learn distributions with low-dimensional support. For a given datum in one of these submanifolds, we should thus intuitively expect DMs to have implicitly learned its corresponding local intrinsic dimension (LID), i.e. the dimension of the submanifold it belongs to. Kamkari et al. (2024b) recently showed that this is indeed the case by linking this LID to the rate of change of the log marginal densities of the DM with respect to the amount of added noise, resulting in an LID estimator known as FLIPD. LID estimators such as FLIPD have a plethora of uses, among others they quantify the complexity of a given datum, and can be used to detect outliers, adversarial examples and AI-generated text. FLIPD achieves state-of-the-art performance at LID estimation, yet its theoretical underpinnings are incomplete since Kamkari et al. (2024b) only proved its correctness under the highly unrealistic assumption of affine submanifolds. In this work we bridge this gap by formally proving the correctness of FLIPD under realistic assumptions. Additionally, we show that an analogous result holds when Gaussian convolutions are replaced with uniform ones, and discuss the relevance of this result.",
      "authors": [
        "Kin Kwan Leung",
        "Rasa Hosseinzadeh",
        "Gabriel Loaiza-Ganem"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/publicdomain/zero/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20705",
        "HTML": "https://arxiv.org/html/2506.20705",
        "PDF": "https://arxiv.org/pdf/2506.20705"
      },
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 18:00:00 GMT",
          "size": "66kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "On Convolutions, Intrinsic Dimension, and Diffusion Models",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The work examines intrinsic dimensions and diffusion models, with no connection to the processing of training data for LLMs."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.20728",
      "abstract": "Nonlinear networks are often multistable, exhibiting coexisting stable states with competing regions of attraction (ROAs). As a result, ROAs can have complex \"tentacle-like\" morphologies that are challenging to characterize analytically or computationally. In addition, the high dimensionality of the state space prohibits the automated construction of Lyapunov functions using state-of-the-art optimization methods, such as sum-of-squares (SOS) programming. In this letter, we propose a distributed approach for the construction of Lyapunov functions based solely on local information. To this end, we establish an augmented comparison lemma that characterizes the existence conditions of partial Lyapunov functions, while also accounting for residual effects caused by the associated dimensionality reduction. These theoretical results allow us to formulate an SOS optimization that iteratively constructs such partial functions, whose aggregation forms a composite Lyapunov function. The resulting composite function provides accurate convex approximations of both the volumes and shapes of the ROAs. We validate our method on networks of van der Pol and Ising oscillators, demonstrating its effectiveness in characterizing high-dimensional systems with non-convex ROAs.",
      "authors": [
        "Yiming Wang",
        "Arthur N. Montanari",
        "Adilson E. Motter"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20728",
        "HTML": "https://arxiv.org/html/2506.20728",
        "PDF": "https://arxiv.org/pdf/2506.20728"
      },
      "subjects": [
        "Systems and Control (eess.SY)",
        "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
        "Systems and Control (cs.SY)",
        "Dynamical Systems (math.DS)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 18:00:12 GMT",
          "size": "1181kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Distributed Lyapunov Functions for Nonlinear Networks",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper discusses distributed Lyapunov functions for nonlinear networks and optimization methods but does not address any aspects related to the processing of training data for large language models."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.20729",
      "abstract": "Large language models (LLMs) have shown strong capabilities in complex reasoning, and test-time scaling techniques can enhance their performance with comparably low cost. Many of these methods have been developed and evaluated on mathematical reasoning benchmarks such as AIME. This paper investigates whether the lessons learned from these benchmarks generalize to the domain of advanced theoretical physics. We evaluate a range of common test-time scaling methods on the TPBench physics dataset and compare their effectiveness with results on AIME. To better leverage the structure of physics problems, we develop a novel, symbolic weak-verifier framework to improve parallel scaling results. Our empirical results demonstrate that this method significantly outperforms existing test-time scaling approaches on TPBench. We also evaluate our method on AIME, confirming its effectiveness in solving advanced mathematical problems. Our findings highlight the power of step-wise symbolic verification for tackling complex scientific problems.",
      "authors": [
        "Zhiqi Gao",
        "Tianyi Li",
        "Yurii Kvasiuk",
        "Sai Chaitanya Tadepalli",
        "Maja Rudolph",
        "Daniel J.H. Chung",
        "Frederic Sala",
        "Moritz M\\\"unchmeyer"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20729",
        "HTML": "https://arxiv.org/html/2506.20729",
        "PDF": "https://arxiv.org/pdf/2506.20729"
      },
      "subjects": [
        "Machine Learning (cs.LG)",
        "Cosmology and Nongalactic Astrophysics (astro-ph.CO)",
        "Artificial Intelligence (cs.AI)",
        "High Energy Physics - Phenomenology (hep-ph)",
        "High Energy Physics - Theory (hep-th)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 18:00:18 GMT",
          "size": "1060kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Test-time Scaling Techniques in Theoretical Physics -- A Comparison of Methods on the TPBench Dataset",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on test-time scaling techniques for improving LLM performance in the domain of theoretical physics and does not discuss any data engineering or data processing stages related to LLM training data."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.20741",
      "abstract": "Survival prediction using whole slide images (WSIs) can be formulated as a multiple instance learning (MIL) problem. However, existing MIL methods often fail to explicitly capture pathological heterogeneity within WSIs, both globally -- through long-tailed morphological distributions, and locally through -- tile-level prediction uncertainty. Optimal transport (OT) provides a principled way of modeling such heterogeneity by incorporating marginal distribution constraints. Building on this insight, we propose OTSurv, a novel MIL framework from an optimal transport perspective. Specifically, OTSurv formulates survival predictions as a heterogeneity-aware OT problem with two constraints: (1) global long-tail constraint that models prior morphological distributions to avert both mode collapse and excessive uniformity by regulating transport mass allocation, and (2) local uncertainty-aware constraint that prioritizes high-confidence patches while suppressing noise by progressively raising the total transport mass. We then recast the initial OT problem, augmented by these constraints, into an unbalanced OT formulation that can be solved with an efficient, hardware-friendly matrix scaling algorithm. Empirically, OTSurv sets new state-of-the-art results across six popular benchmarks, achieving an absolute 3.6% improvement in average C-index. In addition, OTSurv achieves statistical significance in log-rank tests and offers high interpretability, making it a powerful tool for survival prediction in digital pathology. Our codes are available at https://github.com/Y-Research-SBU/OTSurv.",
      "authors": [
        "Qin Ren",
        "Yifan Wang",
        "Ruogu Fang",
        "Haibin Ling",
        "Chenyu You"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20741",
        "HTML": "https://arxiv.org/html/2506.20741",
        "PDF": "https://arxiv.org/pdf/2506.20741"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 18:09:42 GMT",
          "size": "735kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "OTSurv: A Novel Multiple Instance Learning Framework for Survival Prediction with Heterogeneity-aware Optimal Transport",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The focus of the paper is on survival prediction using whole slide images with a novel MIL framework. It is related to digital pathology, not to LLM training data processing."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.20746",
      "abstract": "When an LLM learns a relation during finetuning (e.g., new movie releases, corporate mergers, etc.), where does this information go? Is it extracted when the model processes an entity, recalled just-in-time before a prediction, or are there multiple separate heuristics? Existing localization approaches (e.g. activation patching) are ill-suited for this analysis because they tend to replace parts of the residual stream, potentially deleting information. To fill this gap, we propose dynamic weight-grafting between fine-tuned and pre-trained language models to show that fine-tuned language models both (1) extract relation information learned during finetuning while processing entities and (2) ``recall\" this information in later layers while generating predictions. In some cases, models need both of these pathways to correctly generate finetuned information while, in other cases, a single ``enrichment\" or ``recall\" pathway alone is sufficient. We examine the necessity and sufficiency of these information pathways, examining what layers they occur at, how much redundancy they exhibit, and which model components are involved -- finding that the ``recall\" pathway occurs via both task-specific attention mechanisms and a relation extraction step in the output of the attention and the feedforward networks at the final layers before next token prediction.",
      "authors": [
        "Todd Nief",
        "David Reber",
        "Sean Richardson",
        "Ari Holtzman"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20746",
        "HTML": "https://arxiv.org/html/2506.20746",
        "PDF": "https://arxiv.org/pdf/2506.20746"
      },
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 18:13:34 GMT",
          "size": "7456kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Multiple Streams of Relation Extraction: Enriching and Recalling in Transformers",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper explores relation extraction in transformers and fine-tuning without focusing on data processing or data engineering for LLM training data. It mostly discusses model internals during relation recall and enrichment."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.20747",
      "abstract": "Current approaches for question answering (QA) over tabular data, such as NL2SQL systems, perform well for factual questions where answers are directly retrieved from tables. However, they fall short on probabilistic questions requiring reasoning under uncertainty. In this paper, we introduce a new benchmark LUCARIO and a framework for probabilistic QA over large tabular data. Our method induces Bayesian Networks from tables, translates natural language queries into probabilistic queries, and uses large language models (LLMs) to generate final answers. Empirical results demonstrate significant improvements over baselines, highlighting the benefits of hybrid symbolic-neural reasoning.",
      "authors": [
        "Chen Shen",
        "Sajjadur Rahman",
        "Estevam Hruschka"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20747",
        "HTML": "https://arxiv.org/html/2506.20747",
        "PDF": "https://arxiv.org/pdf/2506.20747"
      },
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 18:15:33 GMT",
          "size": "3072kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Towards Probabilistic Question Answering Over Tabular Data",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "Although it discusses QA over tabular data using LLMs, the paper does not focus on data processing or engineering for training LLMs. It is more about a new benchmark and framework for probabilistic QA rather than LLM training data processing."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.20748",
      "abstract": "Chatbots are increasingly integrated into people's lives and are widely used to help people. Recently, there has also been growing interest in the reverse direction-humans help chatbots-due to a wide range of benefits including better chatbot performance, human well-being, and collaborative outcomes. However, little research has explored the factors that motivate people to help chatbots. To address this gap, we draw on the Computers Are Social Actors (CASA) framework to examine how chatbot anthropomorphism-including human-like identity, emotional expression, and non-verbal expression-influences human empathy toward chatbots and their subsequent prosocial behaviors and intentions. We also explore people's own interpretations of their prosocial behaviors toward chatbots. We conducted an online experiment (N = 244) in which chatbots made mistakes in a collaborative image labeling task and explained the reasons to participants. We then measured participants' prosocial behaviors and intentions toward the chatbots. Our findings revealed that human identity and emotional expression of chatbots increased participants' prosocial behavior and intention toward chatbots, with empathy mediating these effects. Qualitative analysis further identified two motivations for participants' prosocial behaviors: empathy for the chatbot and perceiving the chatbot as human-like. We discuss the implications of these results for understanding and promoting human prosocial behaviors toward chatbots.",
      "authors": [
        "Jingshu Li",
        "Zicheng Zhu",
        "Renwen Zhang",
        "Yi-Chieh Lee"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20748",
        "HTML": "https://arxiv.org/html/2506.20748",
        "PDF": "https://arxiv.org/pdf/2506.20748"
      },
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 18:16:14 GMT",
          "size": "2445kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Exploring the Effects of Chatbot Anthropomorphism and Human Empathy on Human Prosocial Behavior Toward Chatbots",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper is about human interaction with chatbots, examining factors influencing empathy and prosocial behavior. It does not discuss any aspect of LLM training data or data processing."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.20752",
      "abstract": "Training large language models is an expensive, compute-bound process that must be repeated as models scale, algorithms improve, and new data is collected. To address this, next-generation hardware accelerators increasingly support lower-precision arithmetic formats, such as the Microscaling (MX) formats introduced in NVIDIA's Blackwell architecture. These formats use a shared scale within blocks of parameters to extend representable range and perform forward/backward GEMM operations in reduced precision for efficiency gains. In this work, we investigate the challenges and viability of block-scaled precision formats during model training. Across nearly one thousand language models trained from scratch -- spanning compute budgets from $2 \\times 10^{17}$ to $4.8 \\times 10^{19}$ FLOPs and sweeping over a broad range of weight-activation precision combinations -- we consistently observe that training in MX formats exhibits sharp, stochastic instabilities in the loss, particularly at larger compute scales. To explain this phenomenon, we conduct controlled experiments and ablations on a smaller proxy model that exhibits similar behavior as the language model, sweeping across architectural settings, hyperparameters, and precision formats. These experiments motivate a simple model in which multiplicative gradient bias introduced by the quantization of layer-norm affine parameters and a small fraction of activations can trigger runaway divergence. Through \\emph{in situ} intervention experiments on our proxy model, we demonstrate that instabilities can be averted or delayed by modifying precision schemes mid-training. Guided by these findings, we evaluate stabilization strategies in the LLM setting and show that certain hybrid configurations recover performance competitive with full-precision training. We release our code at https://github.com/Hither1/systems-scaling.",
      "authors": [
        "Huangyuan Su and Mujin Kwun and Stephanie Gil and Sham Kakade and Nikhil Anand"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20752",
        "HTML": "https://arxiv.org/html/2506.20752",
        "PDF": "https://arxiv.org/pdf/2506.20752"
      },
      "subjects": [
        "Machine Learning (cs.LG)",
        "Hardware Architecture (cs.AR)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 18:25:08 GMT",
          "size": "4289kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Characterization and Mitigation of Training Instabilities in Microscaling Formats",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper investigates training instabilities with specific hardware precision formats. Although it deals with LLM training stability, it does not address training data engineering or processing specifically."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.20754",
      "abstract": "[Context] Domain knowledge is recognized as a key component for the success of Requirements Engineering (RE), as it provides the conceptual support needed to understand the system context, ensure alignment with stakeholder needs, and reduce ambiguity in requirements specification. Despite its relevance, the scientific literature still lacks a systematic consolidation of how domain knowledge can be effectively used and operationalized in RE. [Goal] This paper addresses this gap by offering a comprehensive overview of existing contributions, including methods, techniques, and tools to incorporate domain knowledge into RE practices. [Method] We conducted a systematic mapping study using a hybrid search strategy that combines database searches with iterative backward and forward snowballing. [Results] In total, we found 75 papers that met our inclusion criteria. The analysis highlights the main types of requirements addressed, the most frequently considered quality attributes, and recurring challenges in the formalization, acquisition, and long-term maintenance of domain knowledge. The results provide support for researchers and practitioners in identifying established approaches and unresolved issues. The study also outlines promising directions for future research, emphasizing the development of scalable, automated, and sustainable solutions to integrate domain knowledge into RE processes. [Conclusion] The study contributes by providing a comprehensive overview that helps to build a conceptual and methodological foundation for knowledge-driven requirements engineering.",
      "authors": [
        "Marina Ara\\'ujo",
        "J\\'ulia Ara\\'ujo",
        "Romeu Oliveira",
        "Lucas Romao",
        "Marcos Kalinowski"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20754",
        "HTML": "https://arxiv.org/html/2506.20754",
        "PDF": "https://arxiv.org/pdf/2506.20754"
      },
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 18:27:51 GMT",
          "size": "459kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Domain Knowledge in Requirements Engineering: A Systematic Mapping Study",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This research paper deals with domain knowledge in requirements engineering and proposes methods to incorporate it into RE practices. It does not address LLM training data processing or data engineering for LLMs."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.20757",
      "abstract": "Vision and touch are two fundamental sensory modalities for robots, offering complementary information that enhances perception and manipulation tasks. Previous research has attempted to jointly learn visual-tactile representations to extract more meaningful information. However, these approaches often rely on direct combination, such as feature addition and concatenation, for modality fusion, which tend to result in poor feature integration. In this paper, we propose ConViTac, a visual-tactile representation learning network designed to enhance the alignment of features during fusion using contrastive representations. Our key contribution is a Contrastive Embedding Conditioning (CEC) mechanism that leverages a contrastive encoder pretrained through self-supervised contrastive learning to project visual and tactile inputs into unified latent embeddings. These embeddings are used to couple visual-tactile feature fusion through cross-modal attention, aiming at aligning the unified representations and enhancing performance on downstream tasks. We conduct extensive experiments to demonstrate the superiority of ConViTac in real world over current state-of-the-art methods and the effectiveness of our proposed CEC mechanism, which improves accuracy by up to 12.0% in material classification and grasping prediction tasks.",
      "authors": [
        "Zhiyuan Wu",
        "Yongqiang Zhao",
        "Shan Luo"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20757",
        "HTML": "https://arxiv.org/html/2506.20757",
        "PDF": "https://arxiv.org/pdf/2506.20757"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 18:43:35 GMT",
          "size": "446kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "ConViTac: Aligning Visual-Tactile Fusion with Contrastive Representations",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The study introduces a model for visual-tactile representation learning aimed at enhancing robot sensory modalities and perception tasks, without relevance to LLM data engineering or processing."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.20759",
      "abstract": "[Context] Machine learning (ML)-enabled systems are present in our society, driving significant digital transformations. The dynamic nature of ML development, characterized by experimental cycles and rapid changes in data, poses challenges to traditional project management. Agile methods, with their flexibility and incremental delivery, seem well-suited to address this dynamism. However, it is unclear how to effectively apply these methods in the context of ML-enabled systems, where challenges require tailored approaches. [Goal] Our goal is to outline the state of the art in agile management for ML-enabled systems. [Method] We conducted a systematic mapping study using a hybrid search strategy that combines database searches with backward and forward snowballing iterations. [Results] Our study identified 27 papers published between 2008 and 2024. From these, we identified eight frameworks and categorized recommendations and practices into eight key themes, such as Iteration Flexibility, Innovative ML-specific Artifacts, and the Minimal Viable Model. The main challenge identified across studies was accurate effort estimation for ML-related tasks. [Conclusion] This study contributes by mapping the state of the art and identifying open gaps in the field. While relevant work exists, more robust empirical evaluation is still needed to validate these contributions.",
      "authors": [
        "Lucas Romao",
        "Hugo Villamizar",
        "Romeu Oliveira",
        "Silvio Alonso",
        "Marcos Kalinowski"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20759",
        "HTML": "https://arxiv.org/html/2506.20759",
        "PDF": "https://arxiv.org/pdf/2506.20759"
      },
      "subjects": [
        "Software Engineering (cs.SE)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 18:47:08 GMT",
          "size": "474kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Agile Management for Machine Learning: A Systematic Mapping Study",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper examines agile management practices for ML-enabled systems, focusing on methodology rather than any specific data engineering or processing techniques related to LLMs."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.20761",
      "abstract": "We present a general framework for designing efficient data structures for high-dimensional pattern-matching problems ($\\exists \\;? i\\in[n], f(x_i,y)=1$) through communication models in which $f(x,y)$ admits sublinear communication protocols with exponentially-small error. Specifically, we reduce the data structure problem to the Unambiguous Arthur-Merlin (UAM) communication complexity of $f(x,y)$ under product distributions.\n  We apply our framework to the Partial Match problem (a.k.a, matching with wildcards), whose underlying communication problem is sparse set-disjointness. When the database consists of $n$ points in dimension $d$, and the number of $\\star$'s in the query is at most $w = c\\log n \\;(\\ll d)$, the fastest known linear-space data structure (Cole, Gottlieb and Lewenstein, STOC'04) had query time $t \\approx 2^w = n^c$, which is nontrivial only when $c<1$. By contrast, our framework produces a data structure with query time $n^{1-1/(c \\log^2 c)}$ and space close to linear.\n  To achieve this, we develop a one-sided $\\epsilon$-error communication protocol for Set-Disjointness under product distributions with $\\tilde{\\Theta}(\\sqrt{d\\log(1/\\epsilon)})$ complexity, improving on the classical result of Babai, Frankl and Simon (FOCS'86). Building on this protocol, we show that the Unambiguous AM communication complexity of $w$-Sparse Set-Disjointness with $\\epsilon$-error under product distributions is $\\tilde{O}(\\sqrt{w \\log(1/\\epsilon)})$, independent of the ambient dimension $d$, which is crucial for the Partial Match result. Our framework sheds further light on the power of data-dependent data structures, which is instrumental for reducing to the (much easier) case of product distributions.",
      "authors": [
        "Alexandr Andoni",
        "Shunhua Jiang",
        "Omri Weinstein"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20761",
        "HTML": "https://arxiv.org/html/2506.20761",
        "PDF": "https://arxiv.org/pdf/2506.20761"
      },
      "subjects": [
        "Data Structures and Algorithms (cs.DS)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 18:51:17 GMT",
          "size": "48kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "A Framework for Building Data Structures from Communication Protocols",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on designing data structures for pattern-matching problems through communication protocols, not on processing or preparing data for LLM training."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.20762",
      "abstract": "In this paper, we propose a novel drift-adaptive slicing-based resource management scheme for cooperative integrated sensing and communication (ISAC) networks. Particularly, we establish two network slices to provide sensing and communication services, respectively. In the large-timescale planning for the slices, we partition the sensing region of interest (RoI) of each mobile device and reserve network resources accordingly, facilitating low-complexity distance-based sensing target assignment in small timescales. To cope with the non-stationary spatial distributions of mobile devices and sensing targets, which can result in the drift in modeling the distributions and ineffective planning decisions, we construct digital twins (DTs) of the slices. In each DT, a drift-adaptive statistical model and an emulation function are developed for the spatial distributions in the corresponding slice, which facilitates closed-form decision-making and efficient validation of a planning decision, respectively. Numerical results show that the proposed drift-adaptive slicing-based resource management scheme can increase the service satisfaction ratio by up to 18% and reduce resource consumption by up to 13.1% when compared with benchmark schemes.",
      "authors": [
        "Shisheng Hu",
        "Jie Gao",
        "Xue Qin",
        "Conghao Zhou",
        "Xinyu Huang",
        "Mushu Li",
        "Mingcheng He",
        "Xuemin Shen"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20762",
        "HTML": "https://arxiv.org/html/2506.20762",
        "PDF": "https://arxiv.org/pdf/2506.20762"
      },
      "subjects": [
        "Networking and Internet Architecture (cs.NI)",
        "Signal Processing (eess.SP)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 18:52:00 GMT",
          "size": "8115kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Drift-Adaptive Slicing-Based Resource Management for Cooperative ISAC Networks",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper presents a resource management scheme for ISAC networks, which is unrelated to LLM training data processing or data engineering."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.20763",
      "abstract": "We present a novel, generalised formulation to treat coupled structural integrity problems by combining phase field and multi-physics modelling. The approach exploits the versatility of the heat transfer equation and is therefore well suited to be adopted in commercial finite element packages, requiring only integration point-level implementation. This aspect is demonstrated here by implementing coupled, multi-variable phenomena through simple \\texttt{UMAT} and \\texttt{UMATHT} subroutines in the finite element package \\texttt{Abaqus}. The generalised theoretical and computational framework presented is particularised to four problems of engineering and scientific relevance: thermo-mechanical fracture, hydraulic fracture, hydrogen-assisted cracking and metallic corrosion. 2D and 3D problems are considered. The results reveal a very good agreement with experimental data, and existing numerical and analytical solutions.The user subroutines developed are made freely available at https://mechmat.web.ox.ac.uk/codes.",
      "authors": [
        "Y. Navidtehrani",
        "C. Beteg\\'on",
        "E. Mart\\'inez-Pa\\~neda"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20763",
        "HTML": "https://arxiv.org/html/2506.20763",
        "PDF": "https://arxiv.org/pdf/2506.20763"
      },
      "subjects": [
        "Computational Engineering, Finance, and Science (cs.CE)",
        "Numerical Analysis (cs.NA)",
        "Numerical Analysis (math.NA)",
        "Applied Physics (physics.app-ph)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 18:53:01 GMT",
          "size": "4040kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "A generalised framework for phase field-based modelling of coupled problems: application to thermo-mechanical fracture, hydraulic fracture, hydrogen embrittlement and corrosion",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The focus is on a phase field-based modeling framework for coupled problems like fracture and corrosion, with no relevance to LLM training data processing."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.20770",
      "abstract": "Cyber deception aims to distract, delay, and detect network attackers with fake assets such as honeypots, decoy credentials, or decoy files. However, today, it is difficult for operators to experiment, explore, and evaluate deception approaches. Existing tools and platforms have non-portable and complex implementations that are difficult to modify and extend. We address this pain point by introducing Perry, a high-level framework that accelerates the design and exploration of deception what-if scenarios. Perry has two components: a high-level abstraction layer for security operators to specify attackers and deception strategies, and an experimentation module to run these attackers and defenders in realistic emulated networks. To translate these high-level specifications we design four key modules for Perry: 1) an action planner that translates high-level actions into low-level implementations, 2) an observability module to translate low-level telemetry into high-level observations, 3) an environment state service that enables environment agnostic strategies, and 4) an attack graph service to reason about how attackers could explore an environment. We illustrate that Perry's abstractions reduce the implementation effort of exploring a wide variety of deception defenses, attackers, and environments. We demonstrate the value of Perry by emulating 55 unique deception what-if scenarios and illustrate how these experiments enable operators to shed light on subtle tradeoffs.",
      "authors": [
        "Brian Singer",
        "Yusuf Saquib",
        "Lujo Bauer",
        "Vyas Sekar"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20770",
        "HTML": "https://arxiv.org/html/2506.20770",
        "PDF": "https://arxiv.org/pdf/2506.20770"
      },
      "subjects": [
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 19:03:57 GMT",
          "size": "2838kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Perry: A High-level Framework for Accelerating Cyber Deception Experimentation",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The study on Perry, a framework for cyber deception, does not address aspects of LLM training data collection or processing."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.20771",
      "abstract": "We propose a latent score-based generative AI framework for learning stochastic, non-local closure models and constitutive laws in nonlinear dynamical systems of computational mechanics. This work addresses a key challenge of modeling complex multiscale dynamical systems without a clear scale separation, for which numerically resolving all scales is prohibitively expensive, e.g., for engineering turbulent flows. While classical closure modeling methods leverage domain knowledge to approximate subgrid-scale phenomena, their deterministic and local assumptions can be too restrictive in regimes lacking a clear scale separation. Recent developments of diffusion-based stochastic models have shown promise in the context of closure modeling, but their prohibitive computational inference cost limits practical applications for many real-world applications. This work addresses this limitation by jointly training convolutional autoencoders with conditional diffusion models in the latent spaces, significantly reducing the dimensionality of the sampling process while preserving essential physical characteristics. Numerical results demonstrate that the joint training approach helps discover a proper latent space that not only guarantees small reconstruction errors but also ensures good performance of the diffusion model in the latent space. When integrated into numerical simulations, the proposed stochastic modeling framework via latent conditional diffusion models achieves significant computational acceleration while maintaining comparable predictive accuracy to standard diffusion models in physical spaces.",
      "authors": [
        "Xinghao Dong",
        "Huchen Yang",
        "Jin-Long Wu"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20771",
        "HTML": "https://arxiv.org/html/2506.20771",
        "PDF": "https://arxiv.org/pdf/2506.20771"
      },
      "subjects": [
        "Machine Learning (cs.LG)",
        "Dynamical Systems (math.DS)",
        "Computational Physics (physics.comp-ph)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 19:04:02 GMT",
          "size": "8804kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Stochastic and Non-local Closure Modeling for Nonlinear Dynamical Systems via Latent Score-based Generative Models",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper primarily focuses on closure modeling for nonlinear dynamical systems using generative AI methods, with no mention of LLMs or processing of training data relevant to LLMs."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.20773",
      "abstract": "An efficient numerical framework is presented for modeling viscoelasticity and permanent set of polymers. It is based on the hereditary integral form of transient network theory, in which polymer chains belong to distinct networks each with different natural equilibrium states. Chains continually detach from previously formed networks and reattach to new networks in a state of zero stress. The free energy of these networks is given in terms of the deformation gradient relative to the configuration at which the network was born. A decomposition of the kernel for various free energies allows for a recurrence relationship to be established, bypassing the need to integrate over all time history. The technique is established for both highly compressible and nearly incompressible materials through the use of neo-Hookean, Blatz-Ko, Yeoh, and Ogden-Hill material models. Multiple examples are presented showing the ability to handle rate-dependent response and residual strains under complex loading histories.",
      "authors": [
        "Stephen T. Castonguay",
        "Joshua B. Fernandes",
        "Michael A. Puso",
        "Sylvie Aubry"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20773",
        "HTML": "https://arxiv.org/html/2506.20773",
        "PDF": "https://arxiv.org/pdf/2506.20773"
      },
      "subjects": [
        "Computational Engineering, Finance, and Science (cs.CE)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 19:05:00 GMT",
          "size": "1917kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "A Hereditary Integral, Transient Network Approach to Modeling Permanent Set and Viscoelastic Response in Polymers",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper discusses numerical frameworks for modeling polymers' viscoelasticity, which is unrelated to LLM training data processing."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.20777",
      "abstract": "We study an inverse problem for the time-dependent Maxwell system in an inhomogeneous and anisotropic medium. The objective is to recover the initial electric field $\\mathbf{E}_0$ in a bounded domain $\\Omega \\subset \\mathbb{R}^3$, using boundary measurements of the electric field and its normal derivative over a finite time interval. Informed by practical constraints, we adopt an under-determined formulation of Maxwell's equations that avoids the need for initial magnetic field data and charge density information. To address this inverse problem, we develop a time-dimension reduction approach by projecting the electric field onto a finite-dimensional Legendre polynomial-exponential basis in time. This reformulates the original space-time problem into a sequence of spatial systems for the projection coefficients. The reconstruction is carried out using the quasi-reversibility method within a minimum-norm framework, which accommodates the inherent non-uniqueness of the under-determined setting. We prove a convergence theorem that ensures the quasi-reversibility solution approximates the true solution as the noise and regularization parameters vanish. Numerical experiments in a fully three-dimensional setting validate the method's performance. The reconstructed initial electric field remains accurate even with $10\\%$ noise in the data, demonstrating the robustness and applicability of the proposed approach to realistic inverse electromagnetic problems.",
      "authors": [
        "Thuy T. Le",
        "Cong B. Van",
        "Trong D. Dang",
        "Loc H. Nguyen"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/publicdomain/zero/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20777",
        "HTML": "https://arxiv.org/html/2506.20777",
        "PDF": "https://arxiv.org/pdf/2506.20777"
      },
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 19:08:53 GMT",
          "size": "1608kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Inverse initial data reconstruction for Maxwell's equations via time-dimensional reduction method",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The study addresses inverse problems for Maxwell's equations and does not pertain to LLM training data processing or related engineering tasks."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.20780",
      "abstract": "This paper focuses on a key challenge in hybrid data-driven predictive control: the effect of measurement noise on Hankel matrices. While noise is handled in direct and indirect methods, hybrid approaches often overlook its impact during trajectory estimation. We propose a Noise-Tolerant Data-Driven Predictive Control (NTDPC) framework that integrates singular value decomposition to separate system dynamics from noise within reduced-order Hankel matrices. This enables accurate prediction with shorter data horizons and lower computational effort. A sensitivity index is introduced to support horizon selection under different noise levels. Simulation results indicate improved robustness and efficiency compared to existing hybrid methods.",
      "authors": [
        "Mahmood Mazare",
        "Hossein Ramezani"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20780",
        "HTML": "https://arxiv.org/html/2506.20780",
        "PDF": "https://arxiv.org/pdf/2506.20780"
      },
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 19:10:23 GMT",
          "size": "249kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Noise-Tolerant Hybrid Approach for Data-Driven Predictive Control",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The focus is on predictive control methods for system dynamics with noise, unrelated to LLM training data processing."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.20782",
      "abstract": "We present the first theoretical framework for applying spiking neural networks (SNNs) to synthetic aperture radar (SAR) interferometric phase unwrapping. Despite extensive research in both domains, our comprehensive literature review confirms that SNNs have never been applied to phase unwrapping, representing a significant gap in current methodologies. As Earth observation data volumes continue to grow exponentially (with missions like NISAR expected to generate 100PB in two years) energy-efficient processing becomes critical for sustainable data center operations. SNNs, with their event-driven computation model, offer potential energy savings of 30-100x compared to conventional approaches while maintaining comparable accuracy. We develop spike encoding schemes specifically designed for wrapped phase data, propose SNN architectures that leverage the spatial propagation nature of phase unwrapping, and provide theoretical analysis of computational complexity and convergence properties. Our framework demonstrates how the temporal dynamics inherent in SNNs can naturally model the spatial continuity constraints fundamental to phase unwrapping. This work opens a new research direction at the intersection of neuromorphic computing and SAR interferometry, offering a complementary approach to existing algorithms that could enable more sustainable large-scale InSAR processing.",
      "authors": [
        "Marc Bara"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20782",
        "HTML": "https://arxiv.org/html/2506.20782",
        "PDF": "https://arxiv.org/pdf/2506.20782"
      },
      "subjects": [
        "Neural and Evolutionary Computing (cs.NE)",
        "Emerging Technologies (cs.ET)",
        "Machine Learning (cs.LG)",
        "Signal Processing (eess.SP)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 19:12:16 GMT",
          "size": "13kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Spiking Neural Networks for SAR Interferometric Phase Unwrapping: A Theoretical Framework for Energy-Efficient Processing",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on spiking neural networks for SAR interferometric phase unwrapping, a specialized topic that does not address the processing or engineering of training data for large language models."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.20786",
      "abstract": "Medical image segmentation has greatly aided medical diagnosis, with U-Net based architectures and nnU-Net providing state-of-the-art performance. There have been numerous general promptable models and medical variations introduced in recent years, but there is currently a lack of evaluation and comparison of these models across a variety of prompt qualities on a common medical dataset. This research uses Segment Anything Model (SAM), Segment Anything Model 2 (SAM 2), MedSAM, SAM-Med-3D, and nnU-Net to obtain zero-shot inference on the BraTS 2023 adult glioma and pediatrics dataset across multiple prompt qualities for both points and bounding boxes. Several of these models exhibit promising Dice scores, particularly SAM and SAM 2 achieving scores of up to 0.894 and 0.893, respectively when given extremely accurate bounding box prompts which exceeds nnU-Net's segmentation performance. However, nnU-Net remains the dominant medical image segmentation network due to the impracticality of providing highly accurate prompts to the models. The model and prompt evaluation, as well as the comparison, are extended through fine-tuning SAM, SAM 2, MedSAM, and SAM-Med-3D on the pediatrics dataset. The improvements in point prompt performance after fine-tuning are substantial and show promise for future investigation, but are unable to achieve better segmentation than bounding boxes or nnU-Net.",
      "authors": [
        "Connor Ludwig",
        "Khashayar Namdar",
        "Farzad Khalvati"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20786",
        "HTML": "https://arxiv.org/html/2506.20786",
        "PDF": "https://arxiv.org/pdf/2506.20786"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 19:18:26 GMT",
          "size": "447kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "AI-Driven MRI-based Brain Tumour Segmentation Benchmarking",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper discusses MRI-based brain tumor segmentation and benchmarking of AI models, without any focus on LLM training data processing or engineering."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.20790",
      "abstract": "A key step in reverse engineering neural networks is to decompose them into simpler parts that can be studied in relative isolation. Linear parameter decomposition -- a framework that has been proposed to resolve several issues with current decomposition methods -- decomposes neural network parameters into a sum of sparsely used vectors in parameter space. However, the current main method in this framework, Attribution-based Parameter Decomposition (APD), is impractical on account of its computational cost and sensitivity to hyperparameters. In this work, we introduce \\textit{Stochastic Parameter Decomposition} (SPD), a method that is more scalable and robust to hyperparameters than APD, which we demonstrate by decomposing models that are slightly larger and more complex than was possible to decompose with APD. We also show that SPD avoids other issues, such as shrinkage of the learned parameters, and better identifies ground truth mechanisms in toy models. By bridging causal mediation analysis and network decomposition methods, this demonstration opens up new research possibilities in mechanistic interpretability by removing barriers to scaling linear parameter decomposition methods to larger models. We release a library for running SPD and reproducing our experiments at https://github.com/goodfire-ai/spd.",
      "authors": [
        "Lucius Bushnaq",
        "Dan Braun",
        "Lee Sharkey"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20790",
        "HTML": "https://arxiv.org/html/2506.20790",
        "PDF": "https://arxiv.org/pdf/2506.20790"
      },
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 19:26:31 GMT",
          "size": "5341kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Stochastic Parameter Decomposition",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The research introduces Stochastic Parameter Decomposition for neural networks, focusing on parameter analysis and decomposition, with no mention of LLM training data processing or engineering."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.20795",
      "abstract": "Gestures enable non-verbal human-robot communication, especially in noisy environments like agile production. Traditional deep learning-based gesture recognition relies on task-specific architectures using images, videos, or skeletal pose estimates as input. Meanwhile, Vision Foundation Models (VFMs) and Vision Language Models (VLMs) with their strong generalization abilities offer potential to reduce system complexity by replacing dedicated task-specific modules. This study investigates adapting such models for dynamic, full-body gesture recognition, comparing V-JEPA (a state-of-the-art VFM), Gemini Flash 2.0 (a multimodal VLM), and HD-GCN (a top-performing skeleton-based approach). We introduce NUGGET, a dataset tailored for human-robot communication in intralogistics environments, to evaluate the different gesture recognition approaches. In our experiments, HD-GCN achieves best performance, but V-JEPA comes close with a simple, task-specific classification head - thus paving a possible way towards reducing system complexity, by using it as a shared multi-task model. In contrast, Gemini struggles to differentiate gestures based solely on textual descriptions in the zero-shot setting, highlighting the need of further research on suitable input representations for gestures.",
      "authors": [
        "Stephanie K\\\"as",
        "Anton Burenko",
        "Louis Markert",
        "Onur Alp Culha",
        "Dennis Mack",
        "Timm Linder",
        "Bastian Leibe"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20795",
        "HTML": "https://arxiv.org/html/2506.20795",
        "PDF": "https://arxiv.org/pdf/2506.20795"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Human-Computer Interaction (cs.HC)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 19:36:45 GMT",
          "size": "5209kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "How do Foundation Models Compare to Skeleton-Based Approaches for Gesture Recognition in Human-Robot Interaction?",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper investigates gesture recognition models for human-robot interaction, which is unrelated to LLM training data processing or engineering."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.20800",
      "abstract": "SIM tracing -- the ability to inspect, modify, and relay communication between a SIM card and modem -- has become a significant technique in cellular network research. It enables essential security- and development-related applications such as fuzzing communication interfaces, extracting session keys, monitoring hidden SIM activity (e.g., proactive SIM commands or over-the-air updates), and facilitating scalable, distributed measurement platforms through SIM reuse. Traditionally, achieving these capabilities has relied on specialized hardware, which can pose financial and logistical burdens for researchers, particularly those new to the field. In this work, we show that full SIM tracing functionality can be achieved using only simple, widely available components, such as UART interfaces and GPIO ports. We port these capabilities to low-cost microcontrollers, exemplified by the Raspberry Pi Pico (4~USD). Unlike other approaches, it dramatically reduces hardware complexity by electrically decoupling the SIM and the modem and only transferring on APDU level. By significantly reducing hardware requirements and associated costs, we aim to make SIM tracing techniques accessible to a broader community of researchers and hobbyists, fostering wider exploration and experimentation in cellular network research.",
      "authors": [
        "Gabriel K. Gegenhuber",
        "Philipp \\'E. Frenzel",
        "Adrian Dabrowski"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20800",
        "HTML": "https://arxiv.org/html/2506.20800",
        "PDF": "https://arxiv.org/pdf/2506.20800"
      },
      "subjects": [
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 19:44:18 GMT",
          "size": "2366kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "SIMulator: SIM Tracing on a (Pico-)Budget",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on SIM tracing and reducing hardware complexity for cellular network research. There is no relevance to LLM training data processing or engineering."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.20801",
      "abstract": "Robotic catching of flying objects typically generates high impact forces that might lead to task failure and potential hardware damages. This is accentuated when the object mass to robot payload ratio increases, given the strong inertial components characterizing this task. This paper aims to address this problem by proposing an implicitly impact-aware framework that accomplishes the catching task in both pre- and post-catching phases. In the first phase, a motion planner generates optimal trajectories that minimize catching forces, while in the second, the object's energy is dissipated smoothly, minimizing bouncing. In particular, in the pre-catching phase, a real-time optimal planner is responsible for generating trajectories of the end-effector that minimize the velocity difference between the robot and the object to reduce impact forces during catching. In the post-catching phase, the robot's position, velocity, and stiffness trajectories are generated based on human demonstrations when catching a series of free-falling objects with unknown masses. A hierarchical quadratic programming-based controller is used to enforce the robot's constraints (i.e., joint and torque limits) and create a stack of tasks that minimizes the reflected mass at the end-effector as a secondary objective. The initial experiments isolate the problem along one dimension to accurately study the effects of each contribution on the metrics proposed. We show how the same task, without velocity matching, would be infeasible due to excessive joint torques resulting from the impact. The addition of reflected mass minimization is then investigated, and the catching height is increased to evaluate the method's robustness. Finally, the setup is extended to catching along multiple Cartesian axes, to prove its generalization in space.",
      "authors": [
        "Francesco Tassi (1)",
        "Jianzhuang Zhao (1)",
        "Gustavo J. G. Lahr (1)",
        "Luna Gava (2)",
        "Marco Monforte (2)",
        "Arren Glover (2)",
        "Chiara Bartolozzi (2)",
        "and Arash Ajoudani (1) ((1) Human-Robot Interfaces and Interaction Lab.",
        "Istituto Italiano di Tecnologia",
        "Italy (2) Event-Driven Perception for Robotics Lab",
        "Istituto Italiano di Tecnologia",
        "Italy)"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20801",
        "HTML": "https://arxiv.org/html/2506.20801",
        "PDF": "https://arxiv.org/pdf/2506.20801"
      },
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 19:46:17 GMT",
          "size": "15030kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "IMA-Catcher: An IMpact-Aware Nonprehensile Catching Framework based on Combined Optimization and Learning",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper presents a framework for robotic catching tasks related to motion planning and impact minimization. It does not involve LLM training data processing or any related data engineering tasks."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.20803",
      "abstract": "Large Language Models (LLMs) have shown promise in accelerating the scientific research pipeline. A key capability for this process is the ability to generate novel research ideas, and prior studies have found settings in which LLM-generated research ideas were judged as more novel than human-expert ideas. However, a good idea should not simply appear to be novel, it should also result in better research after being executed. To test whether AI-generated ideas lead to better research outcomes, we conduct an execution study by recruiting 43 expert researchers to execute randomly-assigned ideas, either written by experts or generated by an LLM. Each expert spent over 100 hours implementing the idea and wrote a 4-page short paper to document the experiments. All the executed projects are then reviewed blindly by expert NLP researchers. Comparing the review scores of the same ideas before and after execution, the scores of the LLM-generated ideas decrease significantly more than expert-written ideas on all evaluation metrics (novelty, excitement, effectiveness, and overall; p < 0.05), closing the gap between LLM and human ideas observed at the ideation stage. When comparing the aggregated review scores from the execution study, we even observe that for many metrics there is a flip in rankings where human ideas score higher than LLM ideas. This ideation-execution gap highlights the limitations of current LLMs in generating truly effective research ideas and the challenge of evaluating research ideas in the absence of execution outcomes.",
      "authors": [
        "Chenglei Si",
        "Tatsunori Hashimoto",
        "Diyi Yang"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20803",
        "HTML": "https://arxiv.org/html/2506.20803",
        "PDF": "https://arxiv.org/pdf/2506.20803"
      },
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Computers and Society (cs.CY)",
        "Human-Computer Interaction (cs.HC)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 19:47:23 GMT",
          "size": "5606kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "The Ideation-Execution Gap: Execution Outcomes of LLM-Generated versus Human Research Ideas",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The research investigates the outcomes of LLM-generated versus human-generated research ideas. It does not focus on the training data processing or engineering aspects of LLMs."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.20804",
      "abstract": "We consider an online variant of the fuel-constrained UAV routing problem with a ground-based mobile refueling station (FCURP-MRS), where targets incur unknown fuel costs. We develop a two-phase solution: an offline heuristic-based planner computes initial UAV and UGV paths, and a novel online planning algorithm that dynamically adjusts rendezvous points based on real-time fuel consumption during target processing. Preliminary Gazebo simulations demonstrate the feasibility of our approach in maintaining UAV-UGV path validity, ensuring mission completion. Link to video: https://youtu.be/EmpVj-fjqNY",
      "authors": [
        "Ritvik Agarwal",
        "Behnoushsadat Hatami",
        "Alvika Gautam and Parikshit Maini"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20804",
        "HTML": "https://arxiv.org/html/2506.20804",
        "PDF": "https://arxiv.org/pdf/2506.20804"
      },
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 19:47:33 GMT",
          "size": "1141kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Online Planning for Cooperative Air-Ground Robot Systems with Unknown Fuel Requirements",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper is about online planning for cooperative air-ground robot systems involving UAV and UGV routing. It does not discuss LLM training data processing or data engineering."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.20806",
      "abstract": "Graph Neural Networks (GNNs) show great promise for Network Intrusion Detection Systems (NIDS), particularly in IoT environments, but suffer performance degradation due to distribution drift and lack robustness against realistic adversarial attacks. Current robustness evaluations often rely on unrealistic synthetic perturbations and lack demonstrations on systematic analysis of different kinds of adversarial attack, which encompass both black-box and white-box scenarios. This work proposes a novel approach to enhance GNN robustness and generalization by employing Large Language Models (LLMs) in an agentic pipeline as simulated cybersecurity expert agents. These agents scrutinize graph structures derived from network flow data, identifying and potentially mitigating suspicious or adversarially perturbed elements before GNN processing. Our experiments, using a framework designed for realistic evaluation and testing with a variety of adversarial attacks including a dataset collected from physical testbed experiments, demonstrate that integrating LLM analysis can significantly improve the resilience of GNN-based NIDS against challenges, showcasing the potential of LLM agent as a complementary layer in intrusion detection architectures.",
      "authors": [
        "Zhonghao Zhan",
        "Huichi Zhou",
        "Hamed Haddadi"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20806",
        "HTML": "https://arxiv.org/html/2506.20806",
        "PDF": "https://arxiv.org/pdf/2506.20806"
      },
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 19:49:55 GMT",
          "size": "857kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Poster: Enhancing GNN Robustness for Network Intrusion Detection via Agent-based Analysis",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on enhancing GNN robustness for network intrusion detection and employs LLMs as cybersecurity expert agents, but does not address LLM training data processing tasks."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.20807",
      "abstract": "Optimizing GPU kernels for high performance is a complex task, often demanding deep architectural knowledge, extensive profiling, and iterative experimentation. This challenge is amplified when targeting newer or less-documented GPU architectures where traditional development aids are scarce. This paper introduces an LLM-powered \"GPU Kernel Scientist,\" an automated methodology for iteratively refining accelerator kernels.\n  Our methodology employs LLMs in a multi-stage, evolutionary process: (a) strategically selecting promising prior code versions as a basis for new iterations; (b) generating hypotheses for optimization experiments, based on existing code and assimilated knowledge from general GPU literature; and (c) autonomously implementing these experiments through code modification and subsequent submission to an external evaluation system, using only observed timing data as performance feedback. We detail how this approach navigates the challenges of the AMD MI300 target architecture and leverages LLMs to compensate for limited domain-specific human expertise.\n  Since quantitative results from an ongoing performance competition were embargoed on paper submission date, we present the architectural design, operational workflow, and qualitative insights, highlighting the potential of LLM-driven agents to democratise and accelerate GPU kernel optimization, especially in resource-constrained or rapidly evolving hardware environments.",
      "authors": [
        "Martin Andrews",
        "Sam Witteveen"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20807",
        "HTML": "https://arxiv.org/html/2506.20807",
        "PDF": "https://arxiv.org/pdf/2506.20807"
      },
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Performance (cs.PF)",
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 19:59:34 GMT",
          "size": "70kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "GPU Kernel Scientist: An LLM-Driven Framework for Iterative Kernel Optimization",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper discusses an LLM-driven framework for GPU kernel optimization. It does not involve any processing or engineering of LLM training data."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.20809",
      "abstract": "In this work, we provide a fast, spectrally accurate method for the evaluation of boundary integral operators (BIOs) on a suspension of prolate and oblate spheroids. We first derive formulas for the standard layer potential operators for the Laplace equation applied to an expansion of the integral densities in the appropriate spheroidal harmonic basis. These then lead to analytical expressions in solid harmonics that allow spectrally accurate evaluation of near-field particle interactions. Finally, a standard quadrature scheme is used to evaluate smooth, far-field interactions; these are then accelerated using the fast multipole method.\n  Through a number of numerical test cases, we verify the accuracy and efficiency of our BIO evaluation framework for dense, polydisperse suspensions of spheroids. Through the use of standard formulas linking Stokes and Laplace potentials, we show our scheme can be readily applied to problems involving particulate suspension flows. For both Laplace and Stokes, our method allows us to evaluate BIOs for suspensions up to hundreds of particles on a single processor.",
      "authors": [
        "Leo Crowder",
        "Tianyue Li",
        "Eduardo Corona",
        "Shravan Veerapaneni"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20809",
        "HTML": "https://arxiv.org/html/2506.20809",
        "PDF": "https://arxiv.org/pdf/2506.20809"
      },
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)",
        "Computational Physics (physics.comp-ph)",
        "Fluid Dynamics (physics.flu-dyn)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 20:07:16 GMT",
          "size": "2217kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Boundary integral equation analysis for spheroidal suspensions",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The work presents a numerical analysis method for spheroidal suspensions and does not relate to LLM training data processing or data engineering."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.20810",
      "abstract": "Recurrent neural networks (RNNs), particularly LSTMs, are effective for time-series tasks like sentiment analysis and short-term stock prediction. However, their computational complexity poses challenges for real-time deployment in resource constrained environments. While FPGAs offer a promising platform for energy-efficient AI acceleration, existing tools mainly target feed-forward networks, and LSTM acceleration typically requires full custom implementation. In this paper, we address this gap by leveraging the open-source and extensible FINN framework to enable the generalized deployment of LSTMs on FPGAs. Specifically, we leverage the Scan operator from the Open Neural Network Exchange (ONNX) specification to model the recurrent nature of LSTM computations, enabling support for mixed quantisation within them and functional verification of LSTM-based models. Furthermore, we introduce custom transformations within the FINN compiler to map the quantised ONNX computation graph to hardware blocks from the HLS kernel library of the FINN compiler and Vitis HLS. We validate the proposed tool-flow by training a quantised ConvLSTM model for a mid-price stock prediction task using the widely used dataset and generating a corresponding hardware IP of the model using our flow, targeting the XCZU7EV device. We show that the generated quantised ConvLSTM accelerator through our flow achieves a balance between performance (latency) and resource consumption, while matching (or bettering) inference accuracy of state-of-the-art models with reduced precision. We believe that the generalisable nature of the proposed flow will pave the way for resource-efficient RNN accelerator designs on FPGAs.",
      "authors": [
        "Shashwat Khandelwal",
        "Jakoba Petri-Koenig",
        "Thomas B. Preu{\\ss}er",
        "Michaela Blott",
        "Shreejith Shanker"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20810",
        "HTML": "https://arxiv.org/html/2506.20810",
        "PDF": "https://arxiv.org/pdf/2506.20810"
      },
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Hardware Architecture (cs.AR)",
        "Signal Processing (eess.SP)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 20:07:46 GMT",
          "size": "560kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "FINN-GL: Generalized Mixed-Precision Extensions for FPGA-Accelerated LSTMs",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper describes FPGA-accelerated implementations of LSTMs for AI tasks, focusing on hardware efficiency rather than LLM training data processing."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.20812",
      "abstract": "Drones can inspect overhead power lines while they remain energized, significantly simplifying the inspection process. However, localizing a drone relative to all conductors using an onboard LiDAR sensor presents several challenges: (1) conductors provide minimal surface for LiDAR beams limiting the number of conductor points in a scan, (2) not all conductors are consistently detected, and (3) distinguishing LiDAR points corresponding to conductors from other objects, such as trees and pylons, is difficult. This paper proposes an estimation approach that minimizes the error between LiDAR measurements and a single geometric model representing the entire conductor array, rather than tracking individual conductors separately. Experimental results, using data from a power line drone inspection, demonstrate that this method achieves accurate tracking, with a solver converging under 50 ms per frame, even in the presence of partial observations, noise, and outliers. A sensitivity analysis shows that the estimation approach can tolerate up to twice as many outlier points as valid conductors measurements.",
      "authors": [
        "Alexandre Girard",
        "Steven A. Parkison",
        "Philippe Hamelin"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20812",
        "HTML": "https://arxiv.org/html/2506.20812",
        "PDF": "https://arxiv.org/pdf/2506.20812"
      },
      "subjects": [
        "Robotics (cs.RO)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 20:16:54 GMT",
          "size": "4298kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Model-Based Real-Time Pose and Sag Estimation of Overhead Power Lines Using LiDAR for Drone Inspection",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper is about using LiDAR data for pose and sag estimation in drone inspection of power lines, with no connection to LLM training data processing."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.20813",
      "abstract": "Following a growing number of studies that, over the past 15 years, have established entropy inequalities via ideas and tools from additive combinatorics, in this work we obtain a number of new bounds for the differential entropy of sums, products, and sum-product combinations of continuous random variables. Partly motivated by recent work by Goh on the discrete entropic version of the notion of \"additive energy\", we introduce the additive energy of pairs of continuous random variables and prove various versions of the statement that \"the additive energy is large if and only if the entropy of the sum is small\", along with a version of the Balog-Szemer\\'edi-Gowers theorem for differential entropy. Then, motivated in part by recent work by M\\'ath\\'e and O'Regan, we establish a series of new differential entropy inequalities for products and sum-product combinations of continuous random variables. In particular, we prove a new, general, ring Pl\\\"unnecke-Ruzsa entropy inequality. We briefly return to the case of discrete entropy and provide a characterization of discrete random variables with \"large doubling\", analogous to Tao's Freiman-type inverse sumset theory for the case of small doubling. Finally, we consider the natural entropic analog of the Erd\\\"os-Szemer\\'edi sum-product phenomenon for integer-valued random variables. We show that, if it does hold, then the range of parameters for which it does would necessarily be significantly more restricted than its anticipated combinatorial counterpart.",
      "authors": [
        "Rupert Li",
        "Lampros Gavalakis",
        "Ioannis Kontoyiannis"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20813",
        "HTML": "https://arxiv.org/html/2506.20813",
        "PDF": "https://arxiv.org/pdf/2506.20813"
      },
      "subjects": [
        "Information Theory (cs.IT)",
        "Combinatorics (math.CO)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 20:22:12 GMT",
          "size": "32kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Entropic additive energy and entropy inequalities for sums and products",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper is focused on entropy inequalities and additive combinatorics, specifically studying mathematical bounds for differential entropy. It does not address LLM training data processing or data engineering for LLMs."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.20814",
      "abstract": "Ensemble learning has proven effective in boosting predictive performance, but traditional methods such as bagging, boosting, and dynamic ensemble selection (DES) suffer from high computational cost and limited adaptability to heterogeneous data distributions. To address these limitations, we propose Hellsemble, a novel and interpretable ensemble framework for binary classification that leverages dataset complexity during both training and inference. Hellsemble incrementally partitions the dataset into circles of difficulty by iteratively passing misclassified instances from simpler models to subsequent ones, forming a committee of specialised base learners. Each model is trained on increasingly challenging subsets, while a separate router model learns to assign new instances to the most suitable base model based on inferred difficulty. Hellsemble achieves strong classification accuracy while maintaining computational efficiency and interpretability. Experimental results on OpenML-CC18 and Tabzilla benchmarks demonstrate that Hellsemble often outperforms classical ensemble methods. Our findings suggest that embracing instance-level difficulty offers a promising direction for constructing efficient and robust ensemble systems.",
      "authors": [
        "Jakub Piwko",
        "J\\k{e}drzej Ruci\\'nski",
        "Dawid P{\\l}udowski",
        "Antoni Zajko",
        "Patryzja \\.Zak",
        "Mateusz Zacharecki",
        "Anna Kozak",
        "Katarzyna Wo\\'znica"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20814",
        "HTML": "https://arxiv.org/html/2506.20814",
        "PDF": "https://arxiv.org/pdf/2506.20814"
      },
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 20:26:04 GMT",
          "size": "3827kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Divide, Specialize, and Route: A New Approach to Efficient Ensemble Learning",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper discusses a novel ensemble learning framework called Hellsemble, which is not related to LLM training data processing. It focuses on improving classification accuracy and efficiency for binary classification tasks, without discussing data handling for LLMs."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.20815",
      "abstract": "LLM-powered applications are highly susceptible to the quality of user prompts, and crafting high-quality prompts can often be challenging especially for domain-specific applications. This paper presents a novel dynamic context-aware prompt recommendation system for domain-specific AI applications. Our solution combines contextual query analysis, retrieval-augmented knowledge grounding, hierarchical skill organization, and adaptive skill ranking to generate relevant and actionable prompt suggestions.\n  The system leverages behavioral telemetry and a two-stage hierarchical reasoning process to dynamically select and rank relevant skills, and synthesizes prompts using both predefined and adaptive templates enhanced with few-shot learning. Experiments on real-world datasets demonstrate that our approach achieves high usefulness and relevance, as validated by both automated and expert evaluations.",
      "authors": [
        "Xinye Tang",
        "Haijun Zhai",
        "Chaitanya Belwal",
        "Vineeth Thayanithi",
        "Philip Baumann",
        "Yogesh K Roy"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20815",
        "HTML": "https://arxiv.org/html/2506.20815",
        "PDF": "https://arxiv.org/pdf/2506.20815"
      },
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 20:29:46 GMT",
          "size": "178kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Dynamic Context-Aware Prompt Recommendation for Domain-Specific AI Applications",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper proposes a dynamic prompt recommendation system for AI applications, mainly involving prompt crafting and ranking, which is not directly related to processing LLM training data. It addresses prompt generation, which occurs post-training."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.20816",
      "abstract": "Deep Neural Networks (DNNs) are notoriously vulnerable to adversarial input designs with limited noise budgets. While numerous successful attacks with subtle modifications to original input have been proposed, defense techniques against these attacks are relatively understudied. Existing defense approaches either focus on improving DNN robustness by negating the effects of perturbations or use a secondary model to detect adversarial data. Although equally important, the attack detection approach, which is studied in this work, provides a more practical defense compared to the robustness approach. We show that the existing detection methods are either ineffective against the state-of-the-art attack techniques or computationally inefficient for real-time processing. We propose a novel universal and efficient method to detect adversarial examples by analyzing the varying degrees of impact of attacks on different DNN layers. {Our method trains a lightweight regression model that predicts deeper-layer features from early-layer features, and uses the prediction error to detect adversarial samples.} Through theoretical arguments and extensive experiments, we demonstrate that our detection method is highly effective, computationally efficient for real-time processing, compatible with any DNN architecture, and applicable across different domains, such as image, video, and audio.",
      "authors": [
        "Furkan Mumcu",
        "Yasin Yilmaz"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20816",
        "HTML": "https://arxiv.org/html/2506.20816",
        "PDF": "https://arxiv.org/pdf/2506.20816"
      },
      "subjects": [
        "Machine Learning (cs.LG)",
        "Cryptography and Security (cs.CR)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 20:30:28 GMT",
          "size": "2917kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Universal and Efficient Detection of Adversarial Data through Nonuniform Impact on Network Layers",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "Focused on adversarial data detection in DNNs, this paper discusses novel methods for identifying adversarial examples. It does not engage with LLM training data engineering or processing."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.20817",
      "abstract": "This paper addresses the challenge of developing multimodal recommender systems for the movie domain, where limited metadata (e.g., title, genre) often hinders the generation of robust recommendations. We introduce a resource that combines LLM-generated plot descriptions with trailer-derived visual embeddings in a unified pipeline supporting both Retrieval-Augmented Generation (RAG) and collaborative filtering. Central to our approach is a data augmentation step that transforms sparse metadata into richer textual signals, alongside fusion strategies (e.g., PCA, CCA) that integrate visual cues. Experimental evaluations demonstrate that CCA-based fusion significantly boosts recall compared to unimodal baselines, while an LLM-driven re-ranking step further improves NDCG, particularly in scenarios with limited textual data. By releasing this framework, we invite further exploration of multi-modal recommendation techniques tailored to cold-start, novelty-focused, and domain-specific settings. All code, data, and detailed documentation are publicly available at: https://github.com/RecSys-lab/RAG-VisualRec",
      "authors": [
        "Ali Tourani",
        "Fatemeh Nazary",
        "Yashar Deldjoo"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20817",
        "HTML": "https://arxiv.org/html/2506.20817",
        "PDF": "https://arxiv.org/pdf/2506.20817"
      },
      "subjects": [
        "Information Retrieval (cs.IR)",
        "Multimedia (cs.MM)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 20:32:12 GMT",
          "size": "1883kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "RAG-VisualRec: An Open Resource for Vision- and Text-Enhanced Retrieval-Augmented Generation in Recommendation",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "While this paper involves LLM-generated content, it focuses on multimodal recommender systems and data augmentation within that context. It does not directly address LLM training data processing or data engineering stages."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.20818",
      "abstract": "Graph neural networks (GNNs) are powerful tools for solving graph-related problems. Distributed GNN frameworks and systems enhance the scalability of GNNs and accelerate model training, yet most are optimized for node classification. Their performance on link prediction remains underexplored. This paper demystifies distributed training of GNNs for link prediction by investigating the issue of performance degradation when each worker trains a GNN on its assigned partitioned subgraph without having access to the entire graph. We discover that the main sources of the issue come from not only the information loss caused by graph partitioning but also the ways of drawing negative samples during model training. While sharing the complete graph information with each worker resolves the issue and preserves link prediction accuracy, it incurs a high communication cost. We propose SpLPG, which effectively leverages graph sparsification to mitigate the issue of performance degradation at a reduced communication cost. Experiment results on several public real-world datasets demonstrate the effectiveness of SpLPG, which reduces the communication overhead by up to about 80% while mostly preserving link prediction accuracy.",
      "authors": [
        "Xin Huang and Chul-Ho Lee"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20818",
        "HTML": "https://arxiv.org/html/2506.20818",
        "PDF": "https://arxiv.org/pdf/2506.20818"
      },
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 20:32:23 GMT",
          "size": "544kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Demystifying Distributed Training of Graph Neural Networks for Link Prediction",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on distributed training of Graph Neural Networks for link prediction, specifically dealing with graph partitioning and negative sampling, without discussing the processing of LLM training data."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.20819",
      "abstract": "\\textit{DPLib} is an open-source MATLAB-based benchmark library created to support research and development in distributed and decentralized power system analysis and optimization. Distributed and decentralized methods offer scalability, privacy preservation, and resilience to single points of failure, making them increasingly important for modern power systems. However, unlike centralized tools such as MATPOWER, no general-purpose, reproducible data library package currently exists for distributed power system studies. DPLib fills this gap by providing a standard power system library featuring over 20 multi-region benchmark test cases of varying sizes, along with a graph-based partitioning toolkit that decomposes any MATPOWER test system into multiple electrically coherent regions. The partitioning toolkit, an easy-to-use MATLAB code, generates standardized \\texttt{.mat} and \\texttt{.m} files, along with region visualizations for intuitive understanding. We also provide modular, easy-to-use distributed optimal power flow (OPF) solvers: an alternating direction method of multipliers(ADMM)-based DC-OPF solver implemented in YALMIP, and an ADMM-based AC-OPF solver leveraging IPOPT. These solvers validate the generated test systems for distributed optimization applications. Numerical results validate the generated test cases, establishing DPLib as a foundation for reproducible distributed power system research.",
      "authors": [
        "Milad Hasanzadeh and Amin Kargarian"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20819",
        "HTML": "https://arxiv.org/html/2506.20819",
        "PDF": "https://arxiv.org/pdf/2506.20819"
      },
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 20:34:35 GMT",
          "size": "6895kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "DPLib: A Standard Benchmark Library for Distributed Power System Analysis and Optimization",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper is centered around developing a benchmark library for distributed power systems analysis and does not address LLM training data processing or engineering."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.20822",
      "abstract": "Large language models (LLMs) are increasingly proposed for detecting and responding to violent content online, yet their ability to reason about morally ambiguous, real-world scenarios remains underexamined. We present the first study to evaluate LLMs using a validated social science instrument designed to measure human response to everyday conflict, namely the Violent Behavior Vignette Questionnaire (VBVQ). To assess potential bias, we introduce persona-based prompting that varies race, age, and geographic identity within the United States. Six LLMs developed across different geopolitical and organizational contexts are evaluated under a unified zero-shot setting. Our study reveals two key findings: (1) LLMs surface-level text generation often diverges from their internal preference for violent responses; (2) their violent tendencies vary across demographics, frequently contradicting established findings in criminology, social science, and psychology.",
      "authors": [
        "Quintin Myers",
        "Yanjun Gao"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20822",
        "HTML": "https://arxiv.org/html/2506.20822",
        "PDF": "https://arxiv.org/pdf/2506.20822"
      },
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 20:43:04 GMT",
          "size": "2464kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Uncovering Hidden Violent Tendencies in LLMs: A Demographic Analysis via Behavioral Vignettes",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper evaluates LLMs for their capabilities in detecting violent content using behavioral vignettes, focusing on model assessment rather than training data processing."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.20828",
      "abstract": "The rise of massive networks across diverse domains necessitates sophisticated graph analytics, often involving sensitive data and raising privacy concerns. This paper addresses these challenges using local differential privacy (LDP), which enforces privacy at the individual level, where no third-party entity is trusted, unlike centralized models that assume a trusted curator. We introduce novel LDP algorithms for two fundamental graph statistics: k-core decomposition and triangle counting. Our approach leverages input-dependent private graph properties, specifically the degeneracy and maximum degree of the graph, to improve theoretical utility. Unlike prior methods, our error bounds are determined by the maximum degree rather than the total number of edges, resulting in significantly tighter guarantees. For triangle counting, we improve upon the work of Imola, Murakami, and Chaudhury~\\cite{IMC21locally, IMC21communication}, which bounds error in terms of edge count. Instead, our algorithm achieves bounds based on graph degeneracy by leveraging a private out-degree orientation, a refined variant of Eden et al.'s randomized response technique~\\cite{ELRS23, and a novel analysis, yielding stronger guarantees than prior work. Beyond theoretical gains, we are the first to evaluate local DP algorithms in a distributed simulation, unlike prior work tested on a single processor. Experiments on real-world graphs show substantial accuracy gains: our k-core decomposition achieves errors within 3x of exact values, far outperforming the 131x error in the baseline of Dhulipala et al.~\\cite{DLRSSY22}. Our triangle counting algorithm reduces multiplicative approximation errors by up to six orders of magnitude, while maintaining competitive runtime.",
      "authors": [
        "Pranay Mundra",
        "Charalampos Papamanthou",
        "Julian Shun",
        "Quanquan C. Liu"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20828",
        "HTML": "https://arxiv.org/html/2506.20828",
        "PDF": "https://arxiv.org/pdf/2506.20828"
      },
      "subjects": [
        "Data Structures and Algorithms (cs.DS)",
        "Cryptography and Security (cs.CR)",
        "Databases (cs.DB)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 20:54:07 GMT",
          "size": "3422kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Practical and Accurate Local Edge Differentially Private Graph Algorithms",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper presents differential privacy algorithms for graph data analytics, specifically focusing on graph statistics like k-core decomposition and triangle counting, unrelated to LLM training data."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.20832",
      "abstract": "Super-resolution (SR) is an ill-posed inverse problem with many feasible solutions consistent with a given low-resolution image. On one hand, regressive SR models aim to balance fidelity and perceptual quality to yield a single solution, but this trade-off often introduces artifacts that create ambiguity in information-critical applications such as recognizing digits or letters. On the other hand, diffusion models generate a diverse set of SR images, but selecting the most trustworthy solution from this set remains a challenge. This paper introduces a robust, automated framework for identifying the most trustworthy SR sample from a diffusion-generated set by leveraging the semantic reasoning capabilities of vision-language models (VLMs). Specifically, VLMs such as BLIP-2, GPT-4o, and their variants are prompted with structured queries to assess semantic correctness, visual quality, and artifact presence. The top-ranked SR candidates are then ensembled to yield a single trustworthy output in a cost-effective manner. To rigorously assess the validity of VLM-selected samples, we propose a novel Trustworthiness Score (TWS) a hybrid metric that quantifies SR reliability based on three complementary components: semantic similarity via CLIP embeddings, structural integrity using SSIM on edge maps, and artifact sensitivity through multi-level wavelet decomposition. We empirically show that TWS correlates strongly with human preference in both ambiguous and natural images, and that VLM-guided selections consistently yield high TWS values. Compared to conventional metrics like PSNR, LPIPS, which fail to reflect information fidelity, our approach offers a principled, scalable, and generalizable solution for navigating the uncertainty of the diffusion SR space. By aligning outputs with human expectations and semantic correctness, this work sets a new benchmark for trustworthiness in generative SR.",
      "authors": [
        "Cansu Korkmaz",
        "Ahmet Murat Tekalp",
        "Zafer Dogan"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20832",
        "HTML": "https://arxiv.org/html/2506.20832",
        "PDF": "https://arxiv.org/pdf/2506.20832"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 21:00:44 GMT",
          "size": "5778kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Leveraging Vision-Language Models to Select Trustworthy Super-Resolution Samples Generated by Diffusion Models",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper focuses on super-resolution using vision-language models and diffusion models. It does not involve any aspect of data processing for LLM training."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.20834",
      "abstract": "Transfer learning enhances the training of novel sensory and decision models by employing rich feature representations from large, pre-trained teacher models. Cognitive neuroscience shows that the human brain creates low-dimensional, abstract representations for efficient sensorimotor coding. Importantly, the brain can learn these representations with significantly fewer data points and less computational power than artificial models require. We introduce Brain2Model Transfer Learning (B2M), a framework where neural activity from human sensory and decision-making tasks acts as the teacher model for training artificial neural networks. We propose two B2M strategies: (1) Brain Contrastive Transfer, which aligns brain activity and network activations through a contrastive objective; and (2) Brain Latent Transfer, which projects latent dynamics from similar cognitive tasks onto student networks via supervised regression of brain-derived features. We validate B2M in memory-based decision-making with a recurrent neural network and scene reconstruction for autonomous driving with a variational autoencoder. The results show that student networks benefiting from brain-based transfer converge faster and achieve higher predictive accuracy than networks trained in isolation. Our findings indicate that the brain's representations are valuable for artificial learners, paving the way for more efficient learning of complex decision-making representations, which would be costly or slow through purely artificial training.",
      "authors": [
        "Tomas Gallo Aquino",
        "Victoria Liu",
        "Habiba Azab",
        "Raissa Mathura",
        "Andrew J Watrous",
        "Eleonora Bartoli",
        "Benjamin Y Hayden",
        "Paul Sajda",
        "Sameer A Sheth",
        "Nuttida Rungratsameetaweemana"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20834",
        "HTML": "https://arxiv.org/html/2506.20834",
        "PDF": "https://arxiv.org/pdf/2506.20834"
      },
      "subjects": [
        "Neural and Evolutionary Computing (cs.NE)",
        "Emerging Technologies (cs.ET)",
        "Neurons and Cognition (q-bio.NC)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 21:03:51 GMT",
          "size": "15113kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Brain2Model Transfer: Training sensory and decision models with human neural activity as a teacher",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper discusses a framework that uses human neural activity as a 'teacher' for enhancing sensory and decision models, but it does not cover any LLM training data processing or engineering."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.20841",
      "abstract": "Semi-supervised domain generalization (SSDG) aims to solve the problem of generalizing to out-of-distribution data when only a few labels are available. Due to label scarcity, applying domain generalization methods often underperform. Consequently, existing SSDG methods combine semi-supervised learning methods with various regularization terms. However, these methods do not explicitly regularize to learn domains invariant representations across all domains, which is a key goal for domain generalization. To address this, we introduce FixCLR. Inspired by success in self-supervised learning, we change two crucial components to adapt contrastive learning for explicit domain invariance regularization: utilization of class information from pseudo-labels and using only a repelling term. FixCLR can also be added on top of most existing SSDG and semi-supervised methods for complementary performance improvements. Our research includes extensive experiments that have not been previously explored in SSDG studies. These experiments include benchmarking different improvements to semi-supervised methods, evaluating the performance of pretrained versus non-pretrained models, and testing on datasets with many domains. Overall, FixCLR proves to be an effective SSDG method, especially when combined with other semi-supervised methods.",
      "authors": [
        "Ha Min Son",
        "Shahbaz Rezaei",
        "Xin Liu"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20841",
        "HTML": "https://arxiv.org/html/2506.20841",
        "PDF": "https://arxiv.org/pdf/2506.20841"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 21:25:05 GMT",
          "size": "5829kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "FixCLR: Negative-Class Contrastive Learning for Semi-Supervised Domain Generalization",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The focus is on a semi-supervised domain generalization method for vision tasks, which does not relate to LLM training data processing or engineering."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.20844",
      "abstract": "Scientific fact-checking aims to determine the veracity of scientific claims by retrieving and analysing evidence from research literature. The problem is inherently more complex than general fact-checking since it must accommodate the evolving nature of scientific knowledge, the structural complexity of academic literature and the challenges posed by long-form, multimodal scientific expression. However, existing approaches focus on simplified versions of the problem based on small-scale datasets consisting of abstracts rather than full papers, thereby avoiding the distinct challenges associated with processing complete documents. This paper examines the limitations of current scientific fact-checking systems and reveals the many potential features and resources that could be exploited to advance their performance. It identifies key research challenges within evidence retrieval, including (1) evidence-driven retrieval that addresses semantic limitations and topic imbalance (2) time-aware evidence retrieval with citation tracking to mitigate outdated information, (3) structured document parsing to leverage long-range context, (4) handling complex scientific expressions, including tables, figures, and domain-specific terminology and (5) assessing the credibility of scientific literature. Preliminary experiments were conducted to substantiate these challenges and identify potential solutions. This perspective paper aims to advance scientific fact-checking with a specialised IR system tailored for real-world applications.",
      "authors": [
        "Xingyu Deng",
        "Xi Wang",
        "Mark Stevenson"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20844",
        "HTML": "https://arxiv.org/html/2506.20844",
        "PDF": "https://arxiv.org/pdf/2506.20844"
      },
      "subjects": [
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 21:29:33 GMT",
          "size": "1421kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "The Next Phase of Scientific Fact-Checking: Advanced Evidence Retrieval from Complex Structured Academic Papers",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on scientific fact-checking and evidence retrieval from academic literature, which is unrelated to the processing of LLM training data. It does not involve data engineering or training-stage data processing for language models."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.20849",
      "abstract": "In this paper, we tackle the task of adaptive time allocation in integrated sensing and communication systems equipped with radar and communication units. The dual-functional radar-communication system's task involves allocating dwell times for tracking multiple targets and utilizing the remaining time for data transmission towards estimated target locations. We introduce a novel constrained deep reinforcement learning (CDRL) approach, designed to optimize resource allocation between tracking and communication under time budget constraints, thereby enhancing target communication quality. Our numerical results demonstrate the efficiency of our proposed CDRL framework, confirming its ability to maximize communication quality in highly dynamic environments while adhering to time constraints.",
      "authors": [
        "Ziyang Lu",
        "M. Cenk Gursoy",
        "Chilukuri K. Mohan",
        "Pramod K. Varshney"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20849",
        "HTML": "https://arxiv.org/html/2506.20849",
        "PDF": "https://arxiv.org/pdf/2506.20849"
      },
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 21:44:07 GMT",
          "size": "301kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Learning-Based Resource Management in Integrated Sensing and Communication Systems",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper addresses resource management in integrated sensing and communication systems using deep reinforcement learning. It does not pertain to any aspect of training data processing for LLMs."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.20850",
      "abstract": "Contrastive learning (CL) has become a cornerstone of self-supervised pretraining (SSP) in foundation models, however, extending CL to pixel-wise representation, crucial for medical vision, remains an open problem. Standard CL formulates SSP as a binary optimization problem (binary CL) where the excessive pursuit of feature dispersion leads to an over-dispersion problem, breaking pixel-wise feature correlation thus disrupting the intra-class distribution. Our vector CL reformulates CL as a vector regression problem, enabling dispersion quantification in pixel-wise pretraining via modeling feature distances in regressing displacement vectors. To implement this novel paradigm, we propose the COntrast in VEctor Regression (COVER) framework. COVER establishes an extendable vector-based self-learning, enforces a consistent optimization flow from vector regression to distance modeling, and leverages a vector pyramid architecture for granularity adaptation, thus preserving pixel-wise feature correlations in SSP. Extensive experiments across 8 tasks, spanning 2 dimensions and 4 modalities, show that COVER significantly improves pixel-wise SSP, advancing generalizable medical visual foundation models.",
      "authors": [
        "Yuting He",
        "Shuo Li"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20850",
        "HTML": "https://arxiv.org/html/2506.20850",
        "PDF": "https://arxiv.org/pdf/2506.20850"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 21:44:50 GMT",
          "size": "8622kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Vector Contrastive Learning For Pixel-Wise Pretraining In Medical Vision",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "While the paper discusses contrastive learning for pixel-wise pretraining in medical vision, it does not relate to LLM training data processing or data engineering stages connected to language models."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.20851",
      "abstract": "As data and knowledge expand rapidly, adopting systematic methodologies for ontology generation has become crucial. With the daily increases in data volumes and frequent content changes, the demand for databases to store and retrieve information for the creation of knowledge graphs has become increasingly urgent. The previously established Knowledge Acquisition and Representation Methodology (KNARM) outlines a systematic approach to address these challenges and create knowledge graphs. However, following this methodology highlights the existing challenge of seamlessly integrating Neo4j databases with the Web Ontology Language (OWL). Previous attempts to integrate data from Neo4j into an ontology have been discussed, but these approaches often require an understanding of description logics (DL) syntax, which may not be familiar to many users. Thus, a more accessible method is necessary to bridge this gap. This paper presents a user-friendly approach that utilizes Python and its rdflib library to support ontology development. We showcase our novel approach through a Neo4j database we created by integrating data from the Food and Drug Administration (FDA) Adverse Event Reporting System (FAERS) database. Using this dataset, we developed a Python script that automatically generates the required classes and their axioms, facilitating a smoother integration process. This approach offers a practical solution to the challenges of ontology generation in the context of rapidly growing adverse drug event datasets, supporting improved drug safety monitoring and public health decision-making.",
      "authors": [
        "Srikar Reddy Gadusu",
        "Larry Callahan",
        "Samir Lababidi",
        "Arunasri Nishtala",
        "Sophia Healey and Hande McGinty"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20851",
        "HTML": "https://arxiv.org/html/2506.20851",
        "PDF": "https://arxiv.org/pdf/2506.20851"
      },
      "subjects": [
        "Software Engineering (cs.SE)",
        "Artificial Intelligence (cs.AI)",
        "Databases (cs.DB)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 21:48:21 GMT",
          "size": "381kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Generating Reliable Adverse event Profiles for Health through Automated Integrated Data (GRAPH-AID): A Semi-Automated Ontology Building Approach",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper discusses ontology generation with a methodology for integrating data into knowledge graphs. It focuses on ontology generation and integration, not LLM training data processing."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.20853",
      "abstract": "The time allocation problem in multi-function cognitive radar systems focuses on the trade-off between scanning for newly emerging targets and tracking the previously detected targets. We formulate this as a multi-objective optimization problem and employ deep reinforcement learning to find Pareto-optimal solutions and compare deep deterministic policy gradient (DDPG) and soft actor-critic (SAC) algorithms. Our results demonstrate the effectiveness of both algorithms in adapting to various scenarios, with SAC showing improved stability and sample efficiency compared to DDPG. We further employ the NSGA-II algorithm to estimate an upper bound on the Pareto front of the considered problem. This work contributes to the development of more efficient and adaptive cognitive radar systems capable of balancing multiple competing objectives in dynamic environments.",
      "authors": [
        "Ziyang Lu",
        "Subodh Kalia",
        "M. Cenk Gursoy",
        "Chilukuri K. Mohan",
        "Pramod K. Varshney"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20853",
        "HTML": "https://arxiv.org/html/2506.20853",
        "PDF": "https://arxiv.org/pdf/2506.20853"
      },
      "subjects": [
        "Machine Learning (cs.LG)",
        "Signal Processing (eess.SP)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 21:56:30 GMT",
          "size": "242kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Multi-Objective Reinforcement Learning for Cognitive Radar Resource Management",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper deals with reinforcement learning for cognitive radar resource management, which is unrelated to LLM data processing or training data engineering methodologies for language models."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.20854",
      "abstract": "Counterfactual learning to rank (CLTR) aims to learn a ranking policy from user interactions while correcting for the inherent biases in interaction data, such as position bias. Existing CLTR methods assume a single ranking policy that selects top-K ranking from the entire document candidate set. In real-world applications, the candidate document set is on the order of millions, making a single-stage ranking policy impractical. In order to scale to millions of documents, real-world ranking systems are designed in a two-stage fashion, with a candidate generator followed by a ranker. The existing CLTR method for a two-stage offline ranking system only considers the top-1 ranking set-up and only focuses on training the candidate generator, with the ranker fixed. A CLTR method for training both the ranker and candidate generator jointly is missing from the existing literature. In this paper, we propose a two-stage CLTR estimator that considers the interaction between the two stages and estimates the joint value of the two policies offline. In addition, we propose a novel joint optimization method to train the candidate and ranker policies, respectively. To the best of our knowledge, we are the first to propose a CLTR estimator and learning method for two-stage ranking. Experimental results on a semi-synthetic benchmark demonstrate the effectiveness of the proposed joint CLTR method over baselines.",
      "authors": [
        "Shashank Gupta",
        "Yiming Liao",
        "and Maarten de Rijke"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20854",
        "HTML": "https://arxiv.org/html/2506.20854",
        "PDF": "https://arxiv.org/pdf/2506.20854"
      },
      "subjects": [
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 22:00:12 GMT",
          "size": "67kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Towards Two-Stage Counterfactual Learning to Rank",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on counterfactual learning to rank (CLTR) methods and does not address any aspect of processing training data for LLMs."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.20867",
      "abstract": "Dynamic facial expression recognition (DFER) is a task that estimates emotions from facial expression video sequences. For practical applications, accurately recognizing ambiguous facial expressions -- frequently encountered in in-the-wild data -- is essential. In this study, we propose MIDAS, a data augmentation method designed to enhance DFER performance for ambiguous facial expression data using soft labels representing probabilities of multiple emotion classes. MIDAS augments training data by convexly combining pairs of video frames and their corresponding emotion class labels. This approach extends mixup to soft-labeled video data, offering a simple yet highly effective method for handling ambiguity in DFER. To evaluate MIDAS, we conducted experiments on both the DFEW dataset and FERV39k-Plus, a newly constructed dataset that assigns soft labels to an existing DFER dataset. The results demonstrate that models trained with MIDAS-augmented data achieve superior performance compared to the state-of-the-art method trained on the original dataset.",
      "authors": [
        "Ryosuke Kawamura",
        "Hideaki Hayashi",
        "Shunsuke Otake",
        "Noriko Takemura",
        "Hajime Nagahara"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20867",
        "HTML": "https://arxiv.org/html/2506.20867",
        "PDF": "https://arxiv.org/pdf/2506.20867"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 22:36:42 GMT",
          "size": "5017kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Enhancing Ambiguous Dynamic Facial Expression Recognition with Soft Label-based Data Augmentation",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper is concerned with dynamic facial expression recognition and a data augmentation method for this task, unrelated to LLM training data processing."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.20869",
      "abstract": "Retrieval-Augmented Generation (RAG) systems are emerging as a key approach for grounding Large Language Models (LLMs) in external knowledge, addressing limitations in factual accuracy and contextual relevance. However, there is a lack of empirical studies that report on the development of RAG-based implementations grounded in real-world use cases, evaluated through general user involvement, and accompanied by systematic documentation of lessons learned. This paper presents five domain-specific RAG applications developed for real-world scenarios across governance, cybersecurity, agriculture, industrial research, and medical diagnostics. Each system incorporates multilingual OCR, semantic retrieval via vector embeddings, and domain-adapted LLMs, deployed through local servers or cloud APIs to meet distinct user needs. A web-based evaluation involving a total of 100 participants assessed the systems across six dimensions: (i) Ease of Use, (ii) Relevance, (iii) Transparency, (iv) Responsiveness, (v) Accuracy, and (vi) Likelihood of Recommendation. Based on user feedback and our development experience, we documented twelve key lessons learned, highlighting technical, operational, and ethical challenges affecting the reliability and usability of RAG systems in practice.",
      "authors": [
        "Md Toufique Hasan",
        "Muhammad Waseem",
        "Kai-Kristian Kemell",
        "Ayman Asad Khan",
        "Mika Saari",
        "Pekka Abrahamsson"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20869",
        "HTML": "https://arxiv.org/html/2506.20869",
        "PDF": "https://arxiv.org/pdf/2506.20869"
      },
      "subjects": [
        "Software Engineering (cs.SE)",
        "Artificial Intelligence (cs.AI)",
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 22:40:00 GMT",
          "size": "3482kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Engineering RAG Systems for Real-World Applications: Design, Development, and Evaluation",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper describes applications of Retrieval-Augmented Generation (RAG) systems for LLMs in various domains but does not focus on processing training data for LLMs."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.20872",
      "abstract": "Data-driven agriculture, which integrates technology and data into agricultural practices, has the potential to improve crop yield, disease resilience, and long-term soil health. However, privacy concerns, such as adverse pricing, discrimination, and resource manipulation, deter farmers from sharing data, as it can be used against them. To address this barrier, we propose a privacy-preserving framework that enables secure data sharing and collaboration for research and development while mitigating privacy risks. The framework combines dimensionality reduction techniques (like Principal Component Analysis (PCA)) and differential privacy by introducing Laplacian noise to protect sensitive information. The proposed framework allows researchers to identify potential collaborators for a target farmer and train personalized machine learning models either on the data of identified collaborators via federated learning or directly on the aggregated privacy-protected data. It also allows farmers to identify potential collaborators based on similarities. We have validated this on real-life datasets, demonstrating robust privacy protection against adversarial attacks and utility performance comparable to a centralized system. We demonstrate how this framework can facilitate collaboration among farmers and help researchers pursue broader research objectives. The adoption of the framework can empower researchers and policymakers to leverage agricultural data responsibly, paving the way for transformative advances in data-driven agriculture. By addressing critical privacy challenges, this work supports secure data integration, fostering innovation and sustainability in agricultural systems.",
      "authors": [
        "Osama Zafar",
        "Rosemarie Santa Gonz\\'alez",
        "Mina Namazi",
        "Alfonso Morales and Erman Ayday"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20872",
        "HTML": "https://arxiv.org/html/2506.20872",
        "PDF": "https://arxiv.org/pdf/2506.20872"
      },
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 22:46:30 GMT",
          "size": "1335kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Empowering Digital Agriculture: A Privacy-Preserving Framework for Data Sharing and Collaborative Research",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper presents a privacy-preserving framework for data sharing in agriculture, which is not related to the processing of LLM training data."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.20875",
      "abstract": "We present 3DGH, an unconditional generative model for 3D human heads with composable hair and face components. Unlike previous work that entangles the modeling of hair and face, we propose to separate them using a novel data representation with template-based 3D Gaussian Splatting, in which deformable hair geometry is introduced to capture the geometric variations across different hairstyles. Based on this data representation, we design a 3D GAN-based architecture with dual generators and employ a cross-attention mechanism to model the inherent correlation between hair and face. The model is trained on synthetic renderings using carefully designed objectives to stabilize training and facilitate hair-face separation. We conduct extensive experiments to validate the design choice of 3DGH, and evaluate it both qualitatively and quantitatively by comparing with several state-of-the-art 3D GAN methods, demonstrating its effectiveness in unconditional full-head image synthesis and composable 3D hairstyle editing. More details will be available on our project page: https://c-he.github.io/projects/3dgh/.",
      "authors": [
        "Chengan He",
        "Junxuan Li",
        "Tobias Kirschstein",
        "Artem Sevastopolsky",
        "Shunsuke Saito",
        "Qingyang Tan",
        "Javier Romero",
        "Chen Cao",
        "Holly Rushmeier",
        "Giljoo Nam"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20875",
        "HTML": "https://arxiv.org/html/2506.20875",
        "PDF": "https://arxiv.org/pdf/2506.20875"
      },
      "subjects": [
        "Graphics (cs.GR)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 22:53:52 GMT",
          "size": "31387kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "3DGH: 3D Head Generation with Composable Hair and Face",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper is focused on a generative model for 3D human head modeling with separate hair and face components. It doesn't discuss LLM training data processing or data engineering."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.20876",
      "abstract": "Technological progress has led to concrete advancements in tasks that were regarded as challenging, such as automatic fact-checking. Interest in adopting these systems for public health and medicine has grown due to the high-stakes nature of medical decisions and challenges in critically appraising a vast and diverse medical literature. Evidence-based medicine connects to every individual, and yet the nature of it is highly technical, rendering the medical literacy of majority users inadequate to sufficiently navigate the domain. Such problems with medical communication ripens the ground for end-to-end fact-checking agents: check a claim against current medical literature and return with an evidence-backed verdict. And yet, such systems remain largely unused. To understand this, we present the first study examining how clinical experts verify real claims from social media by synthesizing medical evidence. In searching for this upper-bound, we reveal fundamental challenges in end-to-end fact-checking when applied to medicine: Difficulties connecting claims in the wild to scientific evidence in the form of clinical trials; ambiguities in underspecified claims mixed with mismatched intentions; and inherently subjective veracity labels. We argue that fact-checking should be approached and evaluated as an interactive communication problem, rather than an end-to-end process.",
      "authors": [
        "Sebastian Joseph",
        "Lily Chen",
        "Barry Wei",
        "Michael Mackert",
        "Iain J. Marshall",
        "Paul Pu Liang",
        "Ramez Kouzy",
        "Byron C. Wallace",
        "Junyi Jessy Li"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20876",
        "HTML": "https://arxiv.org/html/2506.20876",
        "PDF": "https://arxiv.org/pdf/2506.20876"
      },
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 22:58:08 GMT",
          "size": "1352kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Decide less, communicate more: On the construct validity of end-to-end fact-checking in medicine",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper discusses challenges in end-to-end fact-checking in medicine and does not address data engineering or processing related to LLM training data."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.20877",
      "abstract": "Monocular depth estimation methods traditionally train deep models to infer depth directly from RGB pixels. This implicit learning often overlooks explicit monocular cues that the human visual system relies on, such as occlusion boundaries, shading, and perspective. Rather than expecting a network to discover these cues unaided, we present ThirdEye, a cue-aware pipeline that deliberately supplies each cue through specialised, pre-trained, and frozen networks. These cues are fused in a three-stage cortical hierarchy (V1->V2->V3) equipped with a key-value working-memory module that weights them by reliability. An adaptive-bins transformer head then produces a high-resolution disparity map. Because the cue experts are frozen, ThirdEye inherits large amounts of external supervision while requiring only modest fine-tuning. This extended version provides additional architectural detail, neuroscientific motivation, and an expanded experimental protocol; quantitative results will appear in a future revision.",
      "authors": [
        "Calin Teodor Ioan"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20877",
        "HTML": "https://arxiv.org/html/2506.20877",
        "PDF": "https://arxiv.org/pdf/2506.20877"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 22:59:40 GMT",
          "size": "260kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "THIRDEYE: Cue-Aware Monocular Depth Estimation via Brain-Inspired Multi-Stage Fusion",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper describes a monocular depth estimation method using a cue-aware pipeline inspired by human vision, with no mention of LLM training data processing or data engineering."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.20882",
      "abstract": "Satellite systems increasingly face operational risks from jamming, cyberattacks, and electromagnetic disruptions. Traditional redundancy strategies often fail against dynamic, multi-vector threats. This paper introduces a resilience-by-design framework grounded in the PACE (Primary, Alternate, Contingency, Emergency) methodology, originally developed for tactical communications in military operations, adapting it to satellite systems through a layered state-transition model informed by threat scoring frameworks such as CVSS, DREAD, and NASA's risk matrix. We define a dynamic resilience index to quantify system adaptability and implement three PACE variants: static, adaptive, and softmax-based decision models, to evaluate resilience under diverse disruption scenarios. The proposed approach highlights the effectiveness of lightweight, decision-aware fallback mechanisms in improving survivability and operational continuity for next-generation space assets.",
      "authors": [
        "Anouar Boumeftah",
        "Sarah McKenzie-Picot",
        "Peter Klimas",
        "Gunes Karabulut Kurt"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20882",
        "HTML": "https://arxiv.org/html/2506.20882",
        "PDF": "https://arxiv.org/pdf/2506.20882"
      },
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 23:09:19 GMT",
          "size": "2927kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Resilience Through Escalation: A Graph-Based PACE Architecture for Satellite Threat Response",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper introduces a framework for satellite threat response based on resilience strategies. It does not cover topics related to LLM training data processing or data engineering."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.20883",
      "abstract": "Model-driven engineering problems often require complex model transformations (MTs), i.e., MTs that are chained in extensive sequences. Pertinent examples of such problems include model synchronization, automated model repair, and design space exploration. Manually developing complex MTs is an error-prone and often infeasible process. Reinforcement learning (RL) is an apt way to alleviate these issues. In RL, an autonomous agent explores the state space through trial and error to identify beneficial sequences of actions, such as MTs. However, RL methods exhibit performance issues in complex problems. In these situations, human guidance can be of high utility. In this paper, we present an approach and technical framework for developing complex MT sequences through RL, guided by potentially uncertain human advice. Our framework allows user-defined MTs to be mapped onto RL primitives, and executes them as RL programs to find optimal MT sequences. Our evaluation shows that human guidance, even if uncertain, substantially improves RL performance, and results in more efficient development of complex MTs. Through a trade-off between the certainty and timeliness of human advice, our method takes a step towards RL-driven human-in-the-loop engineering methods.",
      "authors": [
        "Kyanna Dagenais",
        "Istvan David"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20883",
        "HTML": "https://arxiv.org/html/2506.20883",
        "PDF": "https://arxiv.org/pdf/2506.20883"
      },
      "subjects": [
        "Software Engineering (cs.SE)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 23:10:12 GMT",
          "size": "1284kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Complex Model Transformations by Reinforcement Learning with Uncertain Human Guidance",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on model-driven engineering problems and reinforcement learning with human guidance for model transformations. There is no mention of LLM training data processing or techniques related to data engineering or training-stage data preparation."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.20884",
      "abstract": "''TikTok, Do Your Thing'' is a viral trend where users attempt to identify strangers they see in public via information crowd-sourcing. The trend started as early as 2021 and users typically engage with it for romantic purposes (similar to a ''Missed Connections'' personal advertisement). This practice includes acts of surveillance and identification in the public sphere, although by peers rather than governments or corporations. To understand users' reactions to this trend we conducted a qualitative analysis of 60 TikTok videos and 1,901 user comments. Of the 60 videos reviewed, we find 19 individuals were successfully identified. We also find that while there were comments expressing disapproval (n=310), more than double the number expressed support (n=883). Supportive comments demonstrated genuine interest and empathy, reflecting evolving conceptions of community and algorithmic engagement. On the other hand, disapproving comments highlighted concerns about inappropriate relationships, stalking, consent, and gendered double standards. We discuss these insights in relation to the normalization of interpersonal surveillance, online stalking, and as an evolution of social surveillance to offer a new perspective on user perceptions surrounding interpersonal surveillance and identification in the public sphere.",
      "authors": [
        "Meira Gilbert",
        "Miranda Wei",
        "Lindah Kotut"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20884",
        "HTML": "https://arxiv.org/html/2506.20884",
        "PDF": "https://arxiv.org/pdf/2506.20884"
      },
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 23:13:43 GMT",
          "size": "1215kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "\"TikTok, Do Your Thing\": User Reactions to Social Surveillance in the Public Sphere",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper analyzes user reactions to a TikTok trend focusing on surveillance and identification in the public sphere. It does not tackle issues related to LLM training data processing or any relevant data engineering aspects."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.20890",
      "abstract": "In this paper, we derive multicontinuum poroelasticity models using the multicontinuum homogenization method. Poroelasticity models are widely used in many areas of science and engineering to describe coupled flow and mechanics processes in porous media. However, in many applications, the properties of poroelastic media possess high contrast, presenting serious computational challenges. It is well known that standard homogenization approaches often fail to give an accurate solution due to the lack of macroscopic parameters. Multicontinuum approaches allow us to consider such cases by defining several average states known as continua. In the field of poroelasticity, multiple-network models arising from the multiple porous media theory are representatives of these approaches. In this work, we extend previous findings by deriving the generalized multicontinuum poroelasticity model. We apply the recently developed multicontinuum homogenization method and provide a rigorous derivation of multicontinuum equations. For this purpose, we formulate coupled constraint cell problems in oversampled regions to consider different homogenized effects. Then, we obtain a multicontinuum expansion of the fine-scale fields and derive the multicontinuum model supposing the smoothness of macroscopic variables. We present the most general version of equations and the simplified ones based on our numerical experiments. Numerical results are presented for different heterogeneous media cases and demonstrate the high accuracy of our proposed multicontinuum models.",
      "authors": [
        "Dmitry Ammosov",
        "Mohammed Al-Kobaisi",
        "Yalchin Efendiev"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20890",
        "HTML": "https://arxiv.org/html/2506.20890",
        "PDF": "https://arxiv.org/pdf/2506.20890"
      },
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Computational Engineering, Finance, and Science (cs.CE)",
        "Numerical Analysis (cs.NA)",
        "Computational Physics (physics.comp-ph)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 23:48:57 GMT",
          "size": "4631kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Multicontinuum Homogenization for Poroelasticity Model",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper discusses a new approach for deriving poroelasticity models using multicontinuum homogenization, which is unrelated to training data processing or engineering for LLMs."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.20893",
      "abstract": "In this work, we introduce an output-reweighting unlearning method, RWFT, a lightweight technique that erases an entire class from a trained classifier without full retraining. Forgetting specific classes from trained models is essential for enforcing user deletion rights and mitigating harmful or biased predictions. The full retraining is costly and existing unlearning methods fail to replicate the behavior of the retrained models when predicting samples from the unlearned class. We prove this failure by designing a variant of membership inference attacks, MIA-NN that successfully reveals the unlearned class for any of these methods. We propose a simple redistribution of the probability mass for the prediction on the samples in the forgotten class which is robust to MIA-NN. We also introduce a new metric based on the total variation (TV) distance of the prediction probabilities to quantify residual leakage to prevent future methods from susceptibility to the new attack. Through extensive experiments with state of the art baselines in machine unlearning, we show that our approach matches the results of full retraining in both metrics used for evaluation by prior work and the new metric we propose in this work. Compare to state-of-the-art methods, we gain 2.79% in previously used metrics and 111.45% in our new TV-based metric over the best existing method.",
      "authors": [
        "Yian Wang",
        "Ali Ebrahimpour-Boroojeny",
        "and Hari Sundaram"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20893",
        "HTML": "https://arxiv.org/html/2506.20893",
        "PDF": "https://arxiv.org/pdf/2506.20893"
      },
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 23:53:56 GMT",
          "size": "487kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "On the Necessity of Output Distribution Reweighting for Effective Class Unlearning",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper presents a method for machine unlearning aimed at forgetting specific classes from trained models. It does not focus on LLM training data processing, collection, or preparation."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.20898",
      "abstract": "Online conformal prediction has demonstrated its capability to construct a prediction set for each incoming data point that covers the true label with a predetermined probability. To cope with potential distribution shift, multi-model online conformal prediction has been introduced to select and leverage different models from a preselected candidate set. Along with the improved flexibility, the choice of the preselected set also brings challenges. A candidate set that includes a large number of models may increase the computational complexity. In addition, the inclusion of irrelevant models with poor performance may negatively impact the performance and lead to unnecessarily large prediction sets. To address these challenges, we propose a novel multi-model online conformal prediction algorithm that identifies a subset of effective models at each time step by collecting feedback from a bipartite graph, which is refined upon receiving new data. A model is then selected from this subset to construct the prediction set, resulting in reduced computational complexity and smaller prediction sets. Additionally, we demonstrate that using prediction set size as feedback, alongside model loss, can significantly improve efficiency by constructing smaller prediction sets while still satisfying the required coverage guarantee. The proposed algorithms are proven to ensure valid coverage and achieve sublinear regret. Experiments on real and synthetic datasets validate that the proposed methods construct smaller prediction sets and outperform existing multi-model online conformal prediction approaches.",
      "authors": [
        "Erfan Hajihashemi and Yanning Shen"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20898",
        "HTML": "https://arxiv.org/html/2506.20898",
        "PDF": "https://arxiv.org/pdf/2506.20898"
      },
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 00:06:11 GMT",
          "size": "209kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Graph-Structured Feedback Multimodel Ensemble Online Conformal Prediction",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper discusses improvements in online conformal prediction algorithms for model ensembles, without addressing any aspects related to LLM training data engineering or processing."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.20900",
      "abstract": "This work investigates the geometric foundations of modern stereo vision systems, with a focus on how 3D structure and human-inspired perception contribute to accurate depth reconstruction. We revisit the Cyclopean Eye model and propose novel geometric constraints that account for occlusions and depth discontinuities. Our analysis includes the evaluation of stereo feature matching quality derived from deep learning models, as well as the role of attention mechanisms in recovering meaningful 3D surfaces. Through both theoretical insights and empirical studies on real datasets, we demonstrate that combining strong geometric priors with learned features provides internal abstractions for understanding stereo vision systems.",
      "authors": [
        "Sherlon Almeida da Silva",
        "Davi Geiger",
        "Luiz Velho",
        "Moacir Antonelli Ponti"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20900",
        "HTML": "https://arxiv.org/html/2506.20900",
        "PDF": "https://arxiv.org/pdf/2506.20900"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 00:11:26 GMT",
          "size": "8836kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "The Role of Cyclopean-Eye in Stereo Vision",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This work focuses on stereo vision systems and geometric constraints, without any mention of processing or preparation of training data for LLMs."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.20901",
      "abstract": "Financial literacy empowers individuals to make informed and effective financial decisions, improving their overall financial well-being and security. However, for many people understanding financial concepts can be daunting and only half of US adults are considered financially literate. Data visualization simplifies these concepts, making them accessible and engaging for learners of all ages. This systematic review analyzes 37 research papers exploring the use of data visualization and visual analytics in financial education and literacy enhancement. We classify these studies into five key areas: (1) the evolution of visualization use across time and space, (2) motivations for using visualization tools, (3) the financial topics addressed and instructional approaches used, (4) the types of tools and technologies applied, and (5) how the effectiveness of teaching interventions was evaluated. Furthermore, we identify research gaps and highlight opportunities for advancing financial literacy. Our findings offer practical insights for educators and professionals to effectively utilize or design visual tools for financial literacy.",
      "authors": [
        "Meng Du",
        "Robert Amor",
        "Kwan-Liu Ma",
        "Burkhard C. W\\\"unsche"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20901",
        "HTML": "https://arxiv.org/html/2506.20901",
        "PDF": "https://arxiv.org/pdf/2506.20901"
      },
      "subjects": [
        "Graphics (cs.GR)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 00:13:52 GMT",
          "size": "4362kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Data Visualization for Improving Financial Literacy: A Systematic Review",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper is a systematic review about using data visualization for financial literacy. It does not involve LLM training data collection, construction, or processing."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.20904",
      "abstract": "We study offline reinforcement learning in average-reward MDPs, which presents increased challenges from the perspectives of distribution shift and non-uniform coverage, and has been relatively underexamined from a theoretical perspective. While previous work obtains performance guarantees under single-policy data coverage assumptions, such guarantees utilize additional complexity measures which are uniform over all policies, such as the uniform mixing time. We develop sharp guarantees depending only on the target policy, specifically the bias span and a novel policy hitting radius, yielding the first fully single-policy sample complexity bound for average-reward offline RL. We are also the first to handle general weakly communicating MDPs, contrasting restrictive structural assumptions made in prior work. To achieve this, we introduce an algorithm based on pessimistic discounted value iteration enhanced by a novel quantile clipping technique, which enables the use of a sharper empirical-span-based penalty function. Our algorithm also does not require any prior parameter knowledge for its implementation. Remarkably, we show via hard examples that learning under our conditions requires coverage assumptions beyond the stationary distribution of the target policy, distinguishing single-policy complexity measures from previously examined cases. We also develop lower bounds nearly matching our main result.",
      "authors": [
        "Matthew Zurek",
        "Guy Zamir",
        "Yudong Chen"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20904",
        "HTML": "https://arxiv.org/html/2506.20904",
        "PDF": "https://arxiv.org/pdf/2506.20904"
      },
      "subjects": [
        "Machine Learning (cs.LG)",
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)",
        "Optimization and Control (math.OC)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 00:22:39 GMT",
          "size": "56kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Optimal Single-Policy Sample Complexity and Transient Coverage for Average-Reward Offline RL",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper discusses offline reinforcement learning in average-reward MDPs and does not relate to LLM training data processing or data engineering tasks."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.20906",
      "abstract": "We consider the \\emph{$k$-edge connected spanning subgraph} (kECSS) problem, where we are given an undirected graph $G = (V, E)$ with nonnegative edge costs $\\{c_e\\}_{e\\in E}$, and we seek a minimum-cost \\emph{$k$-edge connected} subgraph $H$ of $G$. For even $k$, we present a polytime algorithm that computes a $(k-2)$-edge connected subgraph of cost at most the optimal value $LP^*$ of the natural LP-relaxation for kECSS; for odd $k$, we obtain a $(k-3)$-edge connected subgraph of cost at most $LP^*$. Since kECSS is APX-hard for all $k\\geq 2$, our results are nearly optimal. They also significantly improve upon the recent work of Hershkowitz et al., both in terms of solution quality and the simplicity of algorithm and its analysis. Our techniques also yield an alternate guarantee, where we obtain a $(k-1)$-edge connected subgraph of cost at most $1.5\\cdot LP^*$; with unit edge costs, the cost guarantee improves to $(1+\\frac{4}{3k})\\cdot LP^*$, which improves upon the state-of-the-art approximation for unit edge costs, but with a unit loss in edge connectivity.\n  Our kECSS-result also yields results for the \\emph{$k$-edge connected spanning multigraph} (kECSM) problem, where multiple copies of an edge can be selected: we obtain a $(1+2/k)$-approximation algorithm for even $k$, and a $(1+3/k)$-approximation algorithm for odd $k$.\n  Our techniques extend to the degree-bounded versions of kECSS and kECSM, wherein we also impose degree lower- and upper- bounds on the nodes. We obtain the same cost and connectivity guarantees for these degree-bounded versions with an additive violation of (roughly) $2$ for the degree bounds. These are the first results for degree-bounded \\{kECSS,kECSM\\} of the form where the cost of the solution obtained is at most the optimum, and the connectivity constraints are violated by an additive constant.",
      "authors": [
        "Nikhil Kumar and Chaitanya Swamy"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20906",
        "HTML": "https://arxiv.org/html/2506.20906",
        "PDF": "https://arxiv.org/pdf/2506.20906"
      },
      "subjects": [
        "Data Structures and Algorithms (cs.DS)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 00:23:48 GMT",
          "size": "176kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Almost Tight Additive Guarantees for \\boldmath $k$-Edge-Connectivity",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper is concerned with edge connectivity in graphs and efficient algorithm design, with no reference to language model training data or processing."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.20908",
      "abstract": "Online advertising systems have recently transitioned to autobidding, enabling advertisers to delegate bidding decisions to automated agents. Each advertiser directs their agent to optimize a valuation-dependent objective subject to return-on-investment (ROI) or budget constraints. Given their relevance, there has been a surge in literature studying the liquid welfare price of anarchy (POA) of core auction formats in autobidding, among which simultaneous first-price auctions (FPA). These models capture a large range of heterogeneous agent behaviors, requiring advanced proofs to derive tight POA bounds. Recently, Deng et al. (NeurIPS 2024) showed that the POA of FPA for mixed autobidders (i.e., value and utility maximizers) under ROI is 2.18 for additive valuations.\n  We extend the smoothness framework of Syrgkanis and Tardos (STOC 2013) to autobidding. A key contribution is a technique to balance smoothness parameters across heterogeneous agent types. Finding the best POA bound reduces to solving a POA-revealing mathematical program. Our approach has three strengths: (1) Simplicity: We prove smoothness for single-item FPA. Results for simultaneous FPA follow via our theorem. For example, by showing smoothness for value and utility maximizers, we obtain the tight POA of 2.18 for mixed autobidding. (2) Extendibility: Our Extension Theorem adapts to simultaneous FPA with reserve prices and agents with fractionally subadditive valuations and heterogeneous payment sensitivities and target ROI parameters. We establish the first (mostly) tight POA bounds for several models beyond the autobidding state of the art. (3) Generality: Our framework bounds the POA of coarse correlated equilibria (CCE), which arise when hybrid agents employ regret-minimizing algorithms. Building on Kolumbus and Nisan (WWW 2022), we show that CCE from such agents have properties that keep their POA low.",
      "authors": [
        "Riccardo Colini-Baldeschi",
        "Sophie Klumper",
        "Twan Kroll",
        "Stefano Leonardi",
        "Guido Sch\\\"afer",
        "Artem Tsikiridis"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20908",
        "HTML": "https://arxiv.org/html/2506.20908",
        "PDF": "https://arxiv.org/pdf/2506.20908"
      },
      "subjects": [
        "Computer Science and Game Theory (cs.GT)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 00:27:21 GMT",
          "size": "45kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Smoothness Meets Autobidding: Tight Price of Anarchy Bounds for Simultaneous First-Price Auctions",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on autobidding in auction systems and mathematical analysis of auction frameworks, unrelated to LLM training data processing."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.20915",
      "abstract": "As the deployment of large language models (LLMs) grows in sensitive domains, ensuring the integrity of their computational provenance becomes a critical challenge, particularly in regulated sectors such as healthcare, where strict requirements are applied in dataset usage. We introduce ZKPROV, a novel cryptographic framework that enables zero-knowledge proofs of LLM provenance. It allows users to verify that a model is trained on a reliable dataset without revealing sensitive information about it or its parameters. Unlike prior approaches that focus on complete verification of the training process (incurring significant computational cost) or depend on trusted execution environments, ZKPROV offers a distinct balance. Our method cryptographically binds a trained model to its authorized training dataset(s) through zero-knowledge proofs while avoiding proof of every training step. By leveraging dataset-signed metadata and compact model parameter commitments, ZKPROV provides sound and privacy-preserving assurances that the result of the LLM is derived from a model trained on the claimed authorized and relevant dataset. Experimental results demonstrate the efficiency and scalability of the ZKPROV in generating this proof and verifying it, achieving a practical solution for real-world deployments. We also provide formal security guarantees, proving that our approach preserves dataset confidentiality while ensuring trustworthy dataset provenance.",
      "authors": [
        "Mina Namazi",
        "Alexander Nemecek",
        "Erman Ayday"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20915",
        "HTML": "https://arxiv.org/html/2506.20915",
        "PDF": "https://arxiv.org/pdf/2506.20915"
      },
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 00:49:02 GMT",
          "size": "241kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "ZKPROV: A Zero-Knowledge Approach to Dataset Provenance for Large Language Models",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on a cryptographic framework for ensuring dataset provenance rather than the processing of training data itself. It does not discuss data engineering or training-stage data processing relevant to LLM training."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.20916",
      "abstract": "Deep reinforcement learning has been extensively studied in decision-making processes and has demonstrated superior performance over conventional approaches in various fields, including radar resource management (RRM). However, a notable limitation of neural networks is their ``black box\" nature and recent research work has increasingly focused on explainable AI (XAI) techniques to describe the rationale behind neural network decisions. One promising XAI method is local interpretable model-agnostic explanations (LIME). However, the sampling process in LIME ignores the correlations between features. In this paper, we propose a modified LIME approach that integrates deep learning (DL) into the sampling process, which we refer to as DL-LIME. We employ DL-LIME within deep reinforcement learning for radar resource management. Numerical results show that DL-LIME outperforms conventional LIME in terms of both fidelity and task performance, demonstrating superior performance with both metrics. DL-LIME also provides insights on which factors are more important in decision making for radar resource management.",
      "authors": [
        "Ziyang Lu",
        "M. Cenk Gursoy",
        "Chilukuri K. Mohan",
        "Pramod K. Varshney"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20916",
        "HTML": "https://arxiv.org/html/2506.20916",
        "PDF": "https://arxiv.org/pdf/2506.20916"
      },
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 00:49:25 GMT",
          "size": "405kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Explainable AI for Radar Resource Management: Modified LIME in Deep Reinforcement Learning",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper discusses explainable AI techniques in the context of deep reinforcement learning for radar resource management, with no mention of LLM training data processing or data engineering stages."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.20918",
      "abstract": "In this project, we semantically enriched and enhanced the metadata of long text documents, theses and dissertations, retrieved from the HathiTrust Digital Library in English published from 1920 to 2020 through a combination of manual efforts and large language models. This dataset provides a valuable resource for advancing research in areas such as computational social science, digital humanities, and information science. Our paper shows that enriching metadata using LLMs is particularly beneficial for digital repositories by introducing additional metadata access points that may not have originally been foreseen to accommodate various content types. This approach is particularly effective for repositories that have significant missing data in their existing metadata fields, enhancing search results and improving the accessibility of the digital repository.",
      "authors": [
        "Manika Lamba",
        "You Peng",
        "Sophie Nikolov",
        "Glen Layne-Worthey",
        "J. Stephen Downie"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20918",
        "HTML": "https://arxiv.org/html/2506.20918",
        "PDF": "https://arxiv.org/pdf/2506.20918"
      },
      "subjects": [
        "Digital Libraries (cs.DL)",
        "Emerging Technologies (cs.ET)",
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 00:55:47 GMT",
          "size": "416kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Metadata Enrichment of Long Text Documents using Large Language Models",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The focus is on metadata enrichment using LLMs for digital repositories, rather than on LLM training data processing or data engineering stages."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.20921",
      "abstract": "Chemical process optimization is crucial to maximize production efficiency and economic performance. Traditional methods, including gradient-based solvers, evolutionary algorithms, and parameter grid searches, become impractical when operating constraints are ill-defined or unavailable, requiring engineers to rely on subjective heuristics to estimate feasible parameter ranges. To address this constraint definition bottleneck, we present a multi-agent framework of large language model (LLM) agents that autonomously infer operating constraints from minimal process descriptions, then collaboratively guide optimization using the inferred constraints. Our AutoGen-based agentic framework employs OpenAI's o3 model, with specialized agents for constraint generation, parameter validation, simulation execution, and optimization guidance. Through two phases - autonomous constraint generation using embedded domain knowledge, followed by iterative multi-agent optimization - the framework eliminates the need for predefined operational bounds. Validated on the hydrodealkylation process across cost, yield, and yield-to-cost ratio metrics, the framework demonstrated competitive performance with conventional optimization methods while achieving better computational efficiency, requiring fewer iterations to converge. Our approach converged in under 20 minutes, achieving a 31-fold speedup over grid search. Beyond computational efficiency, the framework's reasoning-guided search demonstrates sophisticated process understanding, correctly identifying utility trade-offs, and applying domain-informed heuristics. This approach shows significant potential for optimization scenarios where operational constraints are poorly characterized or unavailable, particularly for emerging processes and retrofit applications.",
      "authors": [
        "Tong Zeng",
        "Srivathsan Badrinarayanan",
        "Janghoon Ock",
        "Cheng-Kai Lai",
        "Amir Barati Farimani"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20921",
        "HTML": "https://arxiv.org/html/2506.20921",
        "PDF": "https://arxiv.org/pdf/2506.20921"
      },
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Computational Engineering, Finance, and Science (cs.CE)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 01:03:44 GMT",
          "size": "807kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "LLM-guided Chemical Process Optimization with a Multi-Agent Approach",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on optimizing chemical processes using a multi-agent framework with large language models but does not address the processing of training data for LLMs as its primary contribution."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.20922",
      "abstract": "Image editing techniques have rapidly advanced, facilitating both innovative use cases and malicious manipulation of digital images. Deep learning-based methods have recently achieved high accuracy in pixel-level forgery localization, yet they frequently struggle with computational overhead and limited representation power, particularly for subtle or complex tampering. In this paper, we propose M2SFormer, a novel Transformer encoder-based framework designed to overcome these challenges. Unlike approaches that process spatial and frequency cues separately, M2SFormer unifies multi-frequency and multi-scale attentions in the skip connection, harnessing global context to better capture diverse forgery artifacts. Additionally, our framework addresses the loss of fine detail during upsampling by utilizing a global prior map, a curvature metric indicating the difficulty of forgery localization, which then guides a difficulty-guided attention module to preserve subtle manipulations more effectively. Extensive experiments on multiple benchmark datasets demonstrate that M2SFormer outperforms existing state-of-the-art models, offering superior generalization in detecting and localizing forgeries across unseen domains.",
      "authors": [
        "Ju-Hyeon Nam",
        "Dong-Hyun Moon",
        "Sang-Chul Lee"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20922",
        "HTML": "https://arxiv.org/html/2506.20922",
        "PDF": "https://arxiv.org/pdf/2506.20922"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 01:06:57 GMT",
          "size": "17504kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "M2SFormer: Multi-Spectral and Multi-Scale Attention with Edge-Aware Difficulty Guidance for Image Forgery Localization",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper proposes a new framework for image forgery localization using Transformers. It does not mention or relate to the processing of training data for large language models."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.20926",
      "abstract": "Generative code models (GCMs) significantly enhance development efficiency through automated code generation and code summarization. However, building and training these models require computational resources and time, necessitating effective digital copyright protection to prevent unauthorized leaks and misuse. Backdoor watermarking, by embedding hidden identifiers, simplifies copyright verification by breaking the model's black-box nature. Current backdoor watermarking techniques face two main challenges: first, limited generalization across different tasks and datasets, causing fluctuating verification rates; second, insufficient stealthiness, as watermarks are easily detected and removed by automated methods. To address these issues, we propose CodeGuard, a novel watermarking method combining attention mechanisms with distributed trigger embedding strategies. Specifically, CodeGuard employs attention mechanisms to identify watermark embedding positions, ensuring verifiability. Moreover, by using homomorphic character replacement, it avoids manual detection, while distributed trigger embedding reduces the likelihood of automated detection. Experimental results demonstrate that CodeGuard achieves up to 100% watermark verification rates in both code summarization and code generation tasks, with no impact on the primary task performance. In terms of stealthiness, CodeGuard performs exceptionally, with a maximum detection rate of only 0.078 against ONION detection methods, significantly lower than baseline methods.",
      "authors": [
        "Haoxuan Li",
        "Jiale Zhang",
        "Xiaobing Sun",
        "Xiapu Luo"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20926",
        "HTML": "https://arxiv.org/html/2506.20926",
        "PDF": "https://arxiv.org/pdf/2506.20926"
      },
      "subjects": [
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 01:14:35 GMT",
          "size": "1095kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "CodeGuard: A Generalized and Stealthy Backdoor Watermarking for Generative Code Models",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper presents a backdoor watermarking method for generative code models, focusing on copyright protection rather than any aspect of LLM training data processing."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.20927",
      "abstract": "Small additive ensembles of symbolic rules offer interpretable prediction models. Traditionally, these ensembles use rule conditions based on conjunctions of simple threshold propositions $x \\geq t$ on a single input variable $x$ and threshold $t$, resulting geometrically in axis-parallel polytopes as decision regions. While this form ensures a high degree of interpretability for individual rules and can be learned efficiently using the gradient boosting approach, it relies on having access to a curated set of expressive and ideally independent input features so that a small ensemble of axis-parallel regions can describe the target variable well. Absent such features, reaching sufficient accuracy requires increasing the number and complexity of individual rules, which diminishes the interpretability of the model. Here, we extend classical rule ensembles by introducing logical propositions with learnable sparse linear transformations of input variables, i.e., propositions of the form $\\mathbf{x}^\\mathrm{T}\\mathbf{w} \\geq t$, where $\\mathbf{w}$ is a learnable sparse weight vector, enabling decision regions as general polytopes with oblique faces. We propose a learning method using sequential greedy optimization based on an iteratively reweighted formulation of logistic regression. Experimental results demonstrate that the proposed method efficiently constructs rule ensembles with the same test risk as state-of-the-art methods while significantly reducing model complexity across ten benchmark datasets.",
      "authors": [
        "Shahrzad Behzadimanesh",
        "Pierre Le Bodic",
        "Geoffrey I. Webb",
        "Mario Boley"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20927",
        "HTML": "https://arxiv.org/html/2506.20927",
        "PDF": "https://arxiv.org/pdf/2506.20927"
      },
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 01:24:08 GMT",
          "size": "437kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Interpretable Representation Learning for Additive Rule Ensembles",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This research discusses interpretable representation learning for rule ensembles but does not involve processing or construction of training data for large language models."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.20931",
      "abstract": "Federated Learning (FL) has emerged as a leading paradigm for privacy-preserving distributed machine learning, yet the distributed nature of FL introduces unique security challenges, notably the threat of backdoor attacks. Existing backdoor strategies predominantly rely on end-to-end label supervision, which, despite their efficacy, often results in detectable feature disentanglement and limited persistence. In this work, we propose a novel and stealthy backdoor attack framework, named SPA, which fundamentally departs from traditional approaches by leveraging feature-space alignment rather than direct trigger-label association. Specifically, SPA reduces representational distances between backdoor trigger features and target class features, enabling the global model to misclassify trigger-embedded inputs with high stealth and persistence. We further introduce an adaptive, adversarial trigger optimization mechanism, utilizing boundary-search in the feature space to enhance attack longevity and effectiveness, even against defensive FL scenarios and non-IID data distributions. Extensive experiments on various FL benchmarks demonstrate that SPA consistently achieves high attack success rates with minimal impact on model utility, maintains robustness under challenging participation and data heterogeneity conditions, and exhibits persistent backdoor effects far exceeding those of conventional techniques. Our results call urgent attention to the evolving sophistication of backdoor threats in FL and emphasize the pressing need for advanced, feature-level defense techniques.",
      "authors": [
        "Chengcheng Zhu",
        "Ye Li",
        "Bosen Rao",
        "Jiale Zhang",
        "Yunlong Mao",
        "Sheng Zhong"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20931",
        "HTML": "https://arxiv.org/html/2506.20931",
        "PDF": "https://arxiv.org/pdf/2506.20931"
      },
      "subjects": [
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 01:33:14 GMT",
          "size": "9471kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "SPA: Towards More Stealth and Persistent Backdoor Attacks in Federated Learning",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper addresses backdoor attacks in federated learning and does not discuss LLM data processing. The methodology centers on stealth and feature alignment strategies for attacks in distributed settings."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.20936",
      "abstract": "Skinning and rigging are fundamental components in animation, articulated object reconstruction, motion transfer, and 4D generation. Existing approaches predominantly rely on Linear Blend Skinning (LBS), due to its simplicity and differentiability. However, LBS introduces artifacts such as volume loss and unnatural deformations, and it fails to model elastic materials like soft tissues, fur, and flexible appendages (e.g., elephant trunks, ears, and fatty tissues). In this work, we propose PhysRig: a differentiable physics-based skinning and rigging framework that overcomes these limitations by embedding the rigid skeleton into a volumetric representation (e.g., a tetrahedral mesh), which is simulated as a deformable soft-body structure driven by the animated skeleton. Our method leverages continuum mechanics and discretizes the object as particles embedded in an Eulerian background grid to ensure differentiability with respect to both material properties and skeletal motion. Additionally, we introduce material prototypes, significantly reducing the learning space while maintaining high expressiveness. To evaluate our framework, we construct a comprehensive synthetic dataset using meshes from Objaverse, The Amazing Animals Zoo, and MixaMo, covering diverse object categories and motion patterns. Our method consistently outperforms traditional LBS-based approaches, generating more realistic and physically plausible results. Furthermore, we demonstrate the applicability of our framework in the pose transfer task highlighting its versatility for articulated object modeling.",
      "authors": [
        "Hao Zhang",
        "Haolan Xu",
        "Chun Feng",
        "Varun Jampani",
        "and Narendra Ahuja"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20936",
        "HTML": "https://arxiv.org/html/2506.20936",
        "PDF": "https://arxiv.org/pdf/2506.20936"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 01:58:09 GMT",
          "size": "25297kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "PhysRig: Differentiable Physics-Based Skinning and Rigging Framework for Realistic Articulated Object Modeling",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper is centered around a physics-based skinning and rigging framework for animation and object modeling, without addressing LLM training data construction or processing."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.20939",
      "abstract": "Machine Learning for aviation weather is a growing area of research for providing low-cost alternatives for traditional, expensive weather sensors; however, in the area of atmospheric visibility estimation, publicly available datasets, tagged with visibility estimates, of distances relevant for aviation, of diverse locations, of sufficient size for use in supervised learning, are absent. This paper introduces a new dataset which represents the culmination of a year-long data collection campaign of images from the FAA weather camera network suitable for this purpose. We also present a benchmark when applying three commonly used approaches and a general-purpose baseline when trained and tested on three publicly available datasets, in addition to our own, when compared against a recently ratified ASTM standard.",
      "authors": [
        "Chad Mourning",
        "Zhewei Wang",
        "Justin Murray"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20939",
        "HTML": "https://arxiv.org/html/2506.20939",
        "PDF": "https://arxiv.org/pdf/2506.20939"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 02:04:04 GMT",
          "size": "482kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "AIR-VIEW: The Aviation Image Repository for Visibility Estimation of Weather, A Dataset and Benchmark",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper introduces a dataset for weather visibility estimation in aviation but does not relate to LLM training data processing or data engineering."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.20940",
      "abstract": "In this paper, we consider a novel two-dimensional randomized Kaczmarz method and its improved version with simple random sampling, which chooses two active rows with probability proportional to the square of their cross-product-like constant, for solving large-scale linear systems. From the greedy selection strategy with grasping two larger entries of the residual vector at each iteration, we then devise a two-dimensional greedy randomized Kaczmarz method. To improve the above methods further, motivated by the semi-randomized Kaczmarz method and Chebyshev's law of large numbers, we propose a two-dimensional semi-randomized Kaczmarz method and its modified version with simple random sampling, which is particularly advantageous for big data problems. Theoretically, we prove that the proposed methods converge to the unique least-norm solution of the consistent linear systems. Numerical results on some practical applications illustrate the superiority of the proposed methods compared with some existing ones in terms of computing time.",
      "authors": [
        "Tao Li",
        "Meng-Long Xiao",
        "Xin-Fang Zhang"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20940",
        "HTML": "https://arxiv.org/html/2506.20940",
        "PDF": "https://arxiv.org/pdf/2506.20940"
      },
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 02:08:27 GMT",
          "size": "5180kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Two-dimensional greedy randomized Kaczmarz methods for solving large-scale linear systems",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper discusses a novel method for solving linear systems with the Kaczmarz method and does not involve LLM training data processing or data engineering."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.20944",
      "abstract": "The rapid spread of misinformation in mobile and wireless networks presents critical security challenges. This study introduces a training-free, retrieval-based multimodal fact verification system that leverages pretrained vision-language models and large language models for credibility assessment. By dynamically retrieving and cross-referencing trusted data sources, our approach mitigates vulnerabilities of traditional training-based models, such as adversarial attacks and data poisoning. Additionally, its lightweight design enables seamless edge device integration without extensive on-device processing. Experiments on two fact-checking benchmarks achieve SOTA results, confirming its effectiveness in misinformation detection and its robustness against various attack vectors, highlighting its potential to enhance security in mobile and wireless communication environments.",
      "authors": [
        "Van-Hoang Phan",
        "Long-Khanh Pham",
        "Dang Vu",
        "Anh-Duy Tran",
        "Minh-Son Dao"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20944",
        "HTML": "https://arxiv.org/html/2506.20944",
        "PDF": "https://arxiv.org/pdf/2506.20944"
      },
      "subjects": [
        "Multimedia (cs.MM)",
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 02:20:45 GMT",
          "size": "372kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "E-FreeM2: Efficient Training-Free Multi-Scale and Cross-Modal News Verification via MLLMs",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper concerns a training-free fact verification system using pretrained models and does not discuss the collection, construction, or preprocessing of training data for LLMs."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.20945",
      "abstract": "Controllable speech synthesis aims to control the style of generated speech using reference input, which can be of various modalities. Existing face-based methods struggle with robustness and generalization due to data quality constraints, while text prompt methods offer limited diversity and fine-grained control. Although multimodal approaches aim to integrate various modalities, their reliance on fully matched training data significantly constrains their performance and applicability. This paper proposes a 3-stage multimodal controllable speech synthesis framework to address these challenges. For face encoder, we use supervised learning and knowledge distillation to tackle generalization issues. Furthermore, the text encoder is trained on both text-face and text-speech data to enhance the diversity of the generated speech. Experimental results demonstrate that this method outperforms single-modal baseline methods in both face based and text prompt based speech synthesis, highlighting its effectiveness in generating high-quality speech.",
      "authors": [
        "Rui Niu",
        "Weihao Wu",
        "Jie Chen",
        "Long Ma",
        "Zhiyong Wu"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20945",
        "HTML": "https://arxiv.org/html/2506.20945",
        "PDF": "https://arxiv.org/pdf/2506.20945"
      },
      "subjects": [
        "Sound (cs.SD)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 02:23:42 GMT",
          "size": "549kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "A Multi-Stage Framework for Multimodal Controllable Speech Synthesis",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The study proposes a framework for speech synthesis focusing on multimodal inputs without addressing the processing or construction of training data for large language models."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.20946",
      "abstract": "Current texture synthesis methods, which generate textures from fixed viewpoints, suffer from inconsistencies due to the lack of global context and geometric understanding. Meanwhile, recent advancements in video generation models have demonstrated remarkable success in achieving temporally consistent videos. In this paper, we introduce VideoTex, a novel framework for seamless texture synthesis that leverages video generation models to address both spatial and temporal inconsistencies in 3D textures. Our approach incorporates geometry-aware conditions, enabling precise utilization of 3D mesh structures. Additionally, we propose a structure-wise UV diffusion strategy, which enhances the generation of occluded areas by preserving semantic information, resulting in smoother and more coherent textures. VideoTex not only achieves smoother transitions across UV boundaries but also ensures high-quality, temporally stable textures across video frames. Extensive experiments demonstrate that VideoTex outperforms existing methods in texture fidelity, seam blending, and stability, paving the way for dynamic real-time applications that demand both visual quality and temporal coherence.",
      "authors": [
        "Donggoo Kang",
        "Jangyeong Kim",
        "Dasol Jeong",
        "Junyoung Choi",
        "Jeonga Wi",
        "Hyunmin Lee",
        "Joonho Gwon",
        "Joonki Paik"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20946",
        "HTML": "https://arxiv.org/html/2506.20946",
        "PDF": "https://arxiv.org/pdf/2506.20946"
      },
      "subjects": [
        "Graphics (cs.GR)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 02:25:16 GMT",
          "size": "43735kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Consistent Zero-shot 3D Texture Synthesis Using Geometry-aware Diffusion and Temporal Video Models",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The work presents a method for texture synthesis employing video models, without any link to LLM training data stages like collection or preprocessing."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.20947",
      "abstract": "Continuous sign language recognition (CSLR) aims to transcribe untrimmed videos into glosses, which are typically textual words. Recent studies indicate that the lack of large datasets and precise annotations has become a bottleneck for CSLR due to insufficient training data. To address this, some works have developed cross-modal solutions to align visual and textual modalities. However, they typically extract textual features from glosses without fully utilizing their knowledge. In this paper, we propose the Hierarchical Sub-action Tree (HST), termed HST-CSLR, to efficiently combine gloss knowledge with visual representation learning. By incorporating gloss-specific knowledge from large language models, our approach leverages textual information more effectively. Specifically, we construct an HST for textual information representation, aligning visual and textual modalities step-by-step and benefiting from the tree structure to reduce computational complexity. Additionally, we impose a contrastive alignment enhancement to bridge the gap between the two modalities. Experiments on four datasets (PHOENIX-2014, PHOENIX-2014T, CSL-Daily, and Sign Language Gesture) demonstrate the effectiveness of our HST-CSLR.",
      "authors": [
        "Dejie Yang and Zhu Xu and Xinjie Gao and Yang Liu"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20947",
        "HTML": "https://arxiv.org/html/2506.20947",
        "PDF": "https://arxiv.org/pdf/2506.20947"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Multimedia (cs.MM)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 02:27:50 GMT",
          "size": "671kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Hierarchical Sub-action Tree for Continuous Sign Language Recognition",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper addresses sign language recognition using alignment of visual and textual modalities and does not delve into LLM training data engineering or data processing tasks."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.20952",
      "abstract": "Human crowd simulation in virtual reality (VR) is a powerful tool with potential applications including emergency evacuation training and assessment of building layout. While haptic feedback in VR enhances immersive experience, its effect on walking behavior in dense and dynamic pedestrian flows is unknown. Through a user study, we investigated how haptic feedback changes user walking motion in crowded pedestrian flows in VR. The results indicate that haptic feedback changed users' collision avoidance movements, as measured by increased walking trajectory length and change in pelvis angle. The displacements of users' lateral position and pelvis angle were also increased in the instantaneous response to a collision with a non-player character (NPC), even when the NPC was inside the field of view. Haptic feedback also enhanced users' awareness and visual exploration when an NPC approached from the side and back. Furthermore, variation in walking speed was increased by the haptic feedback. These results suggested that the haptic feedback enhanced users' sensitivity to a collision in VR environment.",
      "authors": [
        "Kyosuke Ishibashi",
        "Atsushi Saito",
        "Zin Y. Tun",
        "Lucas Ray",
        "Megan C. Coram",
        "Akihiro Sakurai",
        "Allison M. Okamura",
        "and Ko Yamamoto"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20952",
        "HTML": "https://arxiv.org/html/2506.20952",
        "PDF": "https://arxiv.org/pdf/2506.20952"
      },
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 02:37:46 GMT",
          "size": "9167kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Effect of Haptic Feedback on Avoidance Behavior and Visual Exploration in Dynamic VR Pedestrian Environment",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper focuses on virtual reality and haptic feedback in pedestrian environments, with no mention of language model training data."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.20954",
      "abstract": "A cooperative circumnavigation framework is proposed for multi-quadrotor systems to enclose and track a moving target without reliance on external localization systems. The distinct relationships between quadrotor-quadrotor and quadrotor-target interactions are evaluated using a heterogeneous perception strategy and corresponding state estimation algorithms. A modified Kalman filter is developed to fuse visual-inertial odometry with range measurements to enhance the accuracy of inter-quadrotor relative localization. An event-triggered distributed Kalman filter is designed to achieve robust target state estimation under visual occlusion by incorporating neighbor measurements and estimated inter-quadrotor relative positions. Using the estimation results, a cooperative circumnavigation controller is constructed, leveraging an oscillator-based autonomous formation flight strategy. We conduct extensive indoor and outdoor experiments to validate the efficiency of the proposed circumnavigation framework in occluded environments. Furthermore, a quadrotor failure experiment highlights the inherent fault tolerance property of the proposed framework, underscoring its potential for deployment in search-and-rescue operations.",
      "authors": [
        "Xueming Liu",
        "Lin Li",
        "Xiang Zhou",
        "Qingrui Zhang",
        "and Tianjiang Hu"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20954",
        "HTML": "https://arxiv.org/html/2506.20954",
        "PDF": "https://arxiv.org/pdf/2506.20954"
      },
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 02:41:55 GMT",
          "size": "936kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Cooperative Circumnavigation for Multi-Quadrotor Systems via Onboard Sensing",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The main focus is on multi-quadrotor systems and cooperative circumnavigation, unrelated to language model training data processing."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.20957",
      "abstract": "Antibody design remains a critical challenge in therapeutic and diagnostic development, particularly for complex antigens with diverse binding interfaces. Current computational methods face two main limitations: (1) capturing geometric features while preserving symmetries, and (2) generalizing novel antigen interfaces. Despite recent advancements, these methods often fail to accurately capture molecular interactions and maintain structural integrity. To address these challenges, we propose \\textbf{AbMEGD}, an end-to-end framework integrating \\textbf{M}ulti-scale \\textbf{E}quivariant \\textbf{G}raph \\textbf{D}iffusion for antibody sequence and structure co-design. Leveraging advanced geometric deep learning, AbMEGD combines atomic-level geometric features with residue-level embeddings, capturing local atomic details and global sequence-structure interactions. Its E(3)-equivariant diffusion method ensures geometric precision, computational efficiency, and robust generalizability for complex antigens. Furthermore, experiments using the SAbDab database demonstrate a 10.13\\% increase in amino acid recovery, 3.32\\% rise in improvement percentage, and a 0.062~\\AA\\ reduction in root mean square deviation within the critical CDR-H3 region compared to DiffAb, a leading antibody design model. These results highlight AbMEGD's ability to balance structural integrity with improved functionality, establishing a new benchmark for sequence-structure co-design and affinity optimization. The code is available at: https://github.com/Patrick221215/AbMEGD.",
      "authors": [
        "Jiameng Chen",
        "Xiantao Cai",
        "Jia Wu",
        "Wenbin Hu"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20957",
        "HTML": "https://arxiv.org/html/2506.20957",
        "PDF": "https://arxiv.org/pdf/2506.20957"
      },
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 02:45:38 GMT",
          "size": "2727kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Antibody Design and Optimization with Multi-scale Equivariant Graph Diffusion Models for Accurate Complex Antigen Binding",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper is about antibody design using graph diffusion models, with no connection to language models or their training data."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.20967",
      "abstract": "The advent of Video Diffusion Transformers (Video DiTs) marks a milestone in video generation. However, directly applying existing video editing methods to Video DiTs often incurs substantial computational overhead, due to resource-intensive attention modification or finetuning. To alleviate this problem, we present DFVEdit, an efficient zero-shot video editing method tailored for Video DiTs. DFVEdit eliminates the need for both attention modification and fine-tuning by directly operating on clean latents via flow transformation. To be more specific, we observe that editing and sampling can be unified under the continuous flow perspective. Building upon this foundation, we propose the Conditional Delta Flow Vector (CDFV) -- a theoretically unbiased estimation of DFV -- and integrate Implicit Cross Attention (ICA) guidance as well as Embedding Reinforcement (ER) to further enhance editing quality. DFVEdit excels in practical efficiency, offering at least 20x inference speed-up and 85\\% memory reduction on Video DiTs compared to attention-engineering-based editing methods. Extensive quantitative and qualitative experiments demonstrate that DFVEdit can be seamlessly applied to popular Video DiTs (e.g., CogVideoX and Wan2.1), attaining state-of-the-art performance on structural fidelity, spatial-temporal consistency, and editing quality.",
      "authors": [
        "Lingling Cai",
        "Kang Zhao",
        "Hangjie Yuan",
        "Xiang Wang",
        "Yingya Zhang",
        "Kejie Huang"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20967",
        "HTML": "https://arxiv.org/html/2506.20967",
        "PDF": "https://arxiv.org/pdf/2506.20967"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 03:10:13 GMT",
          "size": "12976kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "DFVEdit: Conditional Delta Flow Vector for Zero-shot Video Editing",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The research focuses on video editing techniques for Video DiTs and does not contribute to LLM training data processing or data engineering methods directly."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.20969",
      "abstract": "Autonomous systems rely on sensors to estimate the environment around them. However, cameras, LiDARs, and RADARs have their own limitations. In nighttime or degraded environments such as fog, mist, or dust, thermal cameras can provide valuable information regarding the presence of objects of interest due to their heat signature. They make it easy to identify humans and vehicles that are usually at higher temperatures compared to their surroundings. In this paper, we focus on the adaptation of thermal cameras for robotics and automation, where the biggest hurdle is the lack of data. Several multi-modal datasets are available for driving robotics research in tasks such as scene segmentation, object detection, and depth estimation, which are the cornerstone of autonomous systems. However, they are found to be lacking in thermal imagery. Our paper proposes a solution to augment these datasets with synthetic thermal data to enable widespread and rapid adaptation of thermal cameras. We explore the use of conditional diffusion models to convert existing RGB images to thermal images using self-attention to learn the thermal properties of real-world objects.",
      "authors": [
        "Shruti Bansal",
        "Wenshan Wang",
        "Yifei Liu",
        "Parv Maheshwari"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20969",
        "HTML": "https://arxiv.org/html/2506.20969",
        "PDF": "https://arxiv.org/pdf/2506.20969"
      },
      "subjects": [
        "Robotics (cs.RO)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 03:18:22 GMT",
          "size": "31082kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "ThermalDiffusion: Visual-to-Thermal Image-to-Image Translation for Autonomous Navigation",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on using visual-to-thermal image translation to augment datasets for autonomous navigation, which involves generating synthetic thermal data but does not address large language model training data processing."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.20977",
      "abstract": "Face aging has become a crucial task in computer vision, with applications ranging from entertainment to healthcare. However, existing methods struggle with achieving a realistic and seamless transformation across the entire lifespan, especially when handling large age gaps or extreme head poses. The core challenge lies in balancing age accuracy and identity preservation--what we refer to as the Age-ID trade-off. Most prior methods either prioritize age transformation at the expense of identity consistency or vice versa. In this work, we address this issue by proposing a two-pass face aging framework, named Cradle2Cane, based on few-step text-to-image (T2I) diffusion models. The first pass focuses on solving age accuracy by introducing an adaptive noise injection (AdaNI) mechanism. This mechanism is guided by including prompt descriptions of age and gender for the given person as the textual condition. Also, by adjusting the noise level, we can control the strength of aging while allowing more flexibility in transforming the face. However, identity preservation is weakly ensured here to facilitate stronger age transformations. In the second pass, we enhance identity preservation while maintaining age-specific features by conditioning the model on two identity-aware embeddings (IDEmb): SVR-ArcFace and Rotate-CLIP. This pass allows for denoising the transformed image from the first pass, ensuring stronger identity preservation without compromising the aging accuracy. Both passes are jointly trained in an end-to-end way. Extensive experiments on the CelebA-HQ test dataset, evaluated through Face++ and Qwen-VL protocols, show that our Cradle2Cane outperforms existing face aging methods in age accuracy and identity consistency.",
      "authors": [
        "Tao Liu",
        "Dafeng Zhang",
        "Gengchen Li",
        "Shizhuo Liu",
        "Yongqi Song",
        "Senmao Li",
        "Shiqi Yang",
        "Boqian Li",
        "Kai Wang",
        "Yaxing Wang"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20977",
        "HTML": "https://arxiv.org/html/2506.20977",
        "PDF": "https://arxiv.org/pdf/2506.20977"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 03:48:28 GMT",
          "size": "5749kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "From Cradle to Cane: A Two-Pass Framework for High-Fidelity Lifespan Face Aging",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The work presents a framework for face aging using diffusion models, concentrating on image processing and identity preservation rather than LLM training data processing."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.20978",
      "abstract": "Existing research on Retrieval-Augmented Generation (RAG) primarily focuses on improving overall question-answering accuracy, often overlooking the quality of sub-claims within generated responses. Recent methods that attempt to improve RAG trustworthiness, such as through auto-evaluation metrics, lack probabilistic guarantees or require ground truth answers. To address these limitations, we propose Conformal-RAG, a novel framework inspired by recent applications of conformal prediction (CP) on large language models (LLMs). Conformal-RAG leverages CP and internal information from the RAG mechanism to offer statistical guarantees on response quality. It ensures group-conditional coverage spanning multiple sub-domains without requiring manual labelling of conformal sets, making it suitable for complex RAG applications. Compared to existing RAG auto-evaluation methods, Conformal-RAG offers statistical guarantees on the quality of refined sub-claims, ensuring response reliability without the need for ground truth answers. Additionally, our experiments demonstrate that by leveraging information from the RAG system, Conformal-RAG retains up to 60\\% more high-quality sub-claims from the response compared to direct applications of CP to LLMs, while maintaining the same reliability guarantee.",
      "authors": [
        "Naihe Feng",
        "Yi Sui",
        "Shiyi Hou",
        "Jesse C. Cresswell",
        "Ga Wu"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20978",
        "HTML": "https://arxiv.org/html/2506.20978",
        "PDF": "https://arxiv.org/pdf/2506.20978"
      },
      "subjects": [
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 03:52:56 GMT",
          "size": "248kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Response Quality Assessment for Retrieval-Augmented Generation via Conditional Conformal Factuality",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper proposes a RAG framework to improve response quality assessment using conformal prediction techniques, primarily focusing on reliability and trustworthiness rather than on LLM training data."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.20979",
      "abstract": "Representing scenes from multi-view images is a crucial task in computer vision with extensive applications. However, inherent photometric distortions in the camera imaging can significantly degrade image quality. Without accounting for these distortions, the 3D scene representation may inadvertently incorporate erroneous information unrelated to the scene, diminishing the quality of the representation. In this paper, we propose a novel 3D scene-camera representation with joint camera photometric optimization. By introducing internal and external photometric model, we propose a full photometric model and corresponding camera representation. Based on simultaneously optimizing the parameters of the camera representation, the proposed method effectively separates scene-unrelated information from the 3D scene representation. Additionally, during the optimization of the photometric parameters, we introduce a depth regularization to prevent the 3D scene representation from fitting scene-unrelated information. By incorporating the camera model as part of the mapping process, the proposed method constructs a complete map that includes both the scene radiance field and the camera photometric model. Experimental results demonstrate that the proposed method can achieve high-quality 3D scene representations, even under conditions of imaging degradation, such as vignetting and dirt.",
      "authors": [
        "Weichen Dai",
        "Kangcheng Ma",
        "Jiaxin Wang",
        "Kecen Pan",
        "Yuhang Ming",
        "Hua Zhang",
        "Wanzeng Kong"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20979",
        "HTML": "https://arxiv.org/html/2506.20979",
        "PDF": "https://arxiv.org/pdf/2506.20979"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 03:53:38 GMT",
          "size": "2999kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "3D Scene-Camera Representation with Joint Camera Photometric Optimization",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This study addresses optimization in 3D scene representation from images with a focus on camera photometric modeling and does not relate to LLM training data engineering or processing."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.20980",
      "abstract": "Real-world networks usually have a property of node heterophily, that is, the connected nodes usually have different features or different labels. This heterophily issue has been extensively studied in homogeneous graphs but remains under-explored in heterogeneous graphs, where there are multiple types of nodes and edges. Capturing node heterophily in heterogeneous graphs is very challenging since both node/edge heterogeneity and node heterophily should be carefully taken into consideration. Existing methods typically convert heterogeneous graphs into homogeneous ones to learn node heterophily, which will inevitably lose the potential heterophily conveyed by heterogeneous relations. To bridge this gap, we propose Relation-Aware Separation of Homophily and Heterophily (RASH), a novel contrastive learning framework that explicitly models high-order semantics of heterogeneous interactions and adaptively separates homophilic and heterophilic patterns. Particularly, RASH introduces dual heterogeneous hypergraphs to encode multi-relational bipartite subgraphs and dynamically constructs homophilic graphs and heterophilic graphs based on relation importance. A multi-relation contrastive loss is designed to align heterogeneous and homophilic/heterophilic views by maximizing mutual information. In this way, RASH simultaneously resolves the challenges of heterogeneity and heterophily in heterogeneous graphs. Extensive experiments on benchmark datasets demonstrate the effectiveness of RASH across various downstream tasks. The code is available at: https://github.com/zhengziyu77/RASH.",
      "authors": [
        "Ziyu Zheng",
        "Yaming Yang",
        "Ziyu Guan",
        "Wei Zhao",
        "Weigang Lu"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20980",
        "HTML": "https://arxiv.org/html/2506.20980",
        "PDF": "https://arxiv.org/pdf/2506.20980"
      },
      "subjects": [
        "Social and Information Networks (cs.SI)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 03:54:06 GMT",
          "size": "1347kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Enhancing Homophily-Heterophily Separation: Relation-Aware Learning in Heterogeneous Graphs",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on improving contrastive learning for heterogeneous graphs, specifically with respect to node heterophily and homophily. It does not address LLM training data processing or data engineering tasks."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.20981",
      "abstract": "This paper tackles the challenging and practical problem of multi-identifier private user profile matching for privacy-preserving ad measurement, a cornerstone of modern advertising analytics. We introduce a comprehensive cryptographic framework leveraging reversed Oblivious Pseudorandom Functions (OPRF) and novel blind key rotation techniques to support secure matching across multiple identifiers. Our design prevents cross-identifier linkages and includes a differentially private mechanism to obfuscate intersection sizes, mitigating risks such as membership inference attacks.\n  We present a concrete construction of our protocol that achieves both strong privacy guarantees and high efficiency. It scales to large datasets, offering a practical and scalable solution for privacy-centric applications like secure ad conversion tracking. By combining rigorous cryptographic principles with differential privacy, our work addresses a critical need in the advertising industry, setting a new standard for privacy-preserving ad measurement frameworks.",
      "authors": [
        "Jian Du",
        "Haohao Qian",
        "Shikun Zhang",
        "Wen-jie Lu",
        "Donghang Lu",
        "Yongchuan Niu",
        "Bo Jiang",
        "Yongjun Zhao",
        "and Qiang Yan"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20981",
        "HTML": "https://arxiv.org/html/2506.20981",
        "PDF": "https://arxiv.org/pdf/2506.20981"
      },
      "subjects": [
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 03:54:19 GMT",
          "size": "12111kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "PrivacyGo: Privacy-Preserving Ad Measurement with Multidimensional Intersection",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper is about privacy-preserving ad measurement and does not relate to LLM training data processing or data engineering. It focuses on cryptographic frameworks for secure data matching."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.20983",
      "abstract": "Recent works favored dense signals (e.g., depth, DensePose), as an alternative to sparse signals (e.g., OpenPose), to provide detailed spatial guidance for pose-guided text-to-image generation. However, dense representations raised new challenges, including editing difficulties and potential inconsistencies with textual prompts. This fact motivates us to revisit sparse signals for pose guidance, owing to their simplicity and shape-agnostic nature, which remains underexplored. This paper proposes a novel Spatial-Pose ControlNet(SP-Ctrl), equipping sparse signals with robust controllability for pose-guided image generation. Specifically, we extend OpenPose to a learnable spatial representation, making keypoint embeddings discriminative and expressive. Additionally, we introduce keypoint concept learning, which encourages keypoint tokens to attend to the spatial positions of each keypoint, thus improving pose alignment. Experiments on animal- and human-centric image generation tasks demonstrate that our method outperforms recent spatially controllable T2I generation approaches under sparse-pose guidance and even matches the performance of dense signal-based methods. Moreover, SP-Ctrl shows promising capabilities in diverse and cross-species generation through sparse signals. Codes will be available at https://github.com/DREAMXFAR/SP-Ctrl.",
      "authors": [
        "Wenjie Xuan",
        "Jing Zhang",
        "Juhua Liu",
        "Bo Du",
        "Dacheng Tao"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20983",
        "HTML": "https://arxiv.org/html/2506.20983",
        "PDF": "https://arxiv.org/pdf/2506.20983"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 03:57:44 GMT",
          "size": "43067kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Rethink Sparse Signals for Pose-guided Text-to-image Generation",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper proposes a control network for pose-guided image generation and does not involve the processing or engineering of training data for LLMs."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.20986",
      "abstract": "Compositional Zero-Shot Learning (CZSL) investigates compositional generalization capacity to recognize unknown state-object pairs based on learned primitive concepts. Existing CZSL methods typically derive primitives features through a simple composition-prototype mapping, which is suboptimal for a set of individuals that can be divided into distinct semantic subsets. Moreover, the all-to-one cross-modal primitives matching neglects compositional divergence within identical states or objects, limiting fine-grained image-composition alignment. In this study, we propose EVA, a Mixture-of-Experts Semantic Variant Alignment framework for CZSL. Specifically, we introduce domain-expert adaption, leveraging multiple experts to achieve token-aware learning and model high-quality primitive representations. To enable accurate compositional generalization, we further present semantic variant alignment to select semantically relevant representation for image-primitives matching. Our method significantly outperforms other state-of-the-art CZSL methods on three popular benchmarks in both closed- and open-world settings, demonstrating the efficacy of the proposed insight.",
      "authors": [
        "Xiao Zhang",
        "Yongqiang Ma",
        "Haodong Jing",
        "Nanning Zheng"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20986",
        "HTML": "https://arxiv.org/html/2506.20986",
        "PDF": "https://arxiv.org/pdf/2506.20986"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 04:00:55 GMT",
          "size": "763kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "EVA: Mixture-of-Experts Semantic Variant Alignment for Compositional Zero-Shot Learning",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The focus is on compositional zero-shot learning for enhancing cross-modal matching capabilities, which does not involve any LLM training data processing or engineering tasks."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.20987",
      "abstract": "The selection of optimal design for power electronic converter parameters involves balancing efficiency and thermal constraints to ensure high performance without compromising safety. This paper introduces a probabilistic-learning-based stochastic surrogate modeling framework to address this challenge and significantly reduce the time required during the design phase. The approach begins with a neural network classifier that evaluates the feasibility of parameter configurations, effectively filtering out unsafe and/or impractical inputs. Subsequently, a probabilistic prediction model estimates the converter's efficiency and temperature while quantifying prediction uncertainty, providing both performance insights and reliability metrics. Finally, a heuristic optimization-based model is employed to optimize a multi-objective function that maximizes efficiency while adhering to thermal constraints. The optimization process incorporates penalty terms to discourage solutions that violate practical thresholds, ensuring actionable and realistic recommendations. An advanced heuristic optimization method is used to find the optimal solution and is compared with several well-known search algorithms, including Genetic Algorithm (GA), Particle Swarm Optimization (PSO), Simulated Annealing (SA), Tabu-Search (TS), and Stochastic Hill Climbing (SHC). The results demonstrate significant improvements in predictive accuracy and optimization outcomes, offering a robust solution for advancing power electronics design.",
      "authors": [
        "Akash Mahajan",
        "Shivam Chaturvedi",
        "Srijita Das",
        "Wencong Su",
        "Van-Hai Bui"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20987",
        "HTML": "https://arxiv.org/html/2506.20987",
        "PDF": "https://arxiv.org/pdf/2506.20987"
      },
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 04:00:58 GMT",
          "size": "1353kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Optimal Parameter Design for Power Electronic Converters Using a Probabilistic Learning-Based Stochastic Surrogate Model",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on optimizing design parameters for power electronic converters using probabilistic learning-based stochastic surrogate models. It does not address LLM training data processing or data engineering."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.20990",
      "abstract": "Fine-tuning vision language models (VLMs) has achieved remarkable performance across various downstream tasks; yet, it requires access to model gradients through backpropagation (BP), making them unsuitable for memory-constrained, inference-only edge devices. To address this limitation, previous work has explored various BP-free fine-tuning methods. However, these approaches often rely on high-variance evolutionary strategies (ES) or zeroth-order (ZO) optimization, and often fail to achieve satisfactory performance. In this paper, we propose a hybrid Sharpness-aware Zeroth-order optimization (SharpZO) approach, specifically designed to enhance the performance of ZO VLM fine-tuning via a sharpness-aware warm-up training. SharpZO features a two-stage optimization process: a sharpness-aware ES stage that globally explores and smooths the loss landscape to construct a strong initialization, followed by a fine-grained local search via sparse ZO optimization. The entire optimization relies solely on forward passes. Detailed theoretical analysis and extensive experiments on CLIP models demonstrate that SharpZO significantly improves accuracy and convergence speed, achieving up to 7% average gain over state-of-the-art forward-only methods.",
      "authors": [
        "Yifan Yang",
        "Zhen Zhang",
        "Rupak Vignesh Swaminathan",
        "Jing Liu",
        "Nathan Susanj",
        "Zheng Zhang"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20990",
        "HTML": "https://arxiv.org/html/2506.20990",
        "PDF": "https://arxiv.org/pdf/2506.20990"
      },
      "subjects": [
        "Machine Learning (cs.LG)",
        "Computation and Language (cs.CL)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 04:07:14 GMT",
          "size": "2497kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "SharpZO: Hybrid Sharpness-Aware Vision Language Model Prompt Tuning via Forward-Only Passes",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper discusses fine-tuning vision language models using a novel zeroth-order optimization method, not addressing any aspect of LLM training data processing or data engineering."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.20991",
      "abstract": "The rapid advancement of 3D vision-language models (VLMs) has spurred significant interest in interactive point cloud processing tasks, particularly for real-world applications. However, existing methods often underperform in point-level tasks, such as segmentation, due to missing direct 3D-text alignment, limiting their ability to link local 3D features with textual context. To solve this problem, we propose TSDASeg, a Two-Stage model coupled with a Direct cross-modal Alignment module and memory module for interactive point cloud Segmentation. We introduce the direct cross-modal alignment module to establish explicit alignment between 3D point clouds and textual/2D image data. Within the memory module, we employ multiple dedicated memory banks to separately store text features, visual features, and their cross-modal correspondence mappings. These memory banks are dynamically leveraged through self-attention and cross-attention mechanisms to update scene-specific features based on prior stored data, effectively addressing inconsistencies in interactive segmentation results across diverse scenarios. Experiments conducted on multiple 3D instruction, reference, and semantic segmentation datasets demonstrate that the proposed method achieves state-of-the-art performance.",
      "authors": [
        "Chade Li",
        "Pengju Zhang",
        "Yihong Wu"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20991",
        "HTML": "https://arxiv.org/html/2506.20991",
        "PDF": "https://arxiv.org/pdf/2506.20991"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 04:10:33 GMT",
          "size": "6408kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "TSDASeg: A Two-Stage Model with Direct Alignment for Interactive Point Cloud Segmentation",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on 3D vision-language models for point cloud segmentation, involving cross-modal alignment techniques, without addressing LLM training data processing or data engineering aspects."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.20993",
      "abstract": "Large language models (LLMs) have gained significant traction across a wide range of fields in recent years. There is also a growing expectation for them to display human-like personalities during interactions. To meet this expectation, numerous studies have proposed methods for modelling LLM personalities through psychometric evaluations. However, most existing models face two major limitations: they rely on the Big Five (OCEAN) framework, which only provides coarse personality dimensions, and they lack mechanisms for controlling trait intensity. In this paper, we address this gap by extending the Machine Personality Inventory (MPI), which originally used the Big Five model, to incorporate the 16 Personality Factor (16PF) model, allowing expressive control over sixteen distinct traits. We also developed a structured framework known as Specific Attribute Control (SAC) for evaluating and dynamically inducing trait intensity in LLMs. Our method introduces adjective-based semantic anchoring to guide trait intensity expression and leverages behavioural questions across five intensity factors: \\textit{Frequency}, \\textit{Depth}, \\textit{Threshold}, \\textit{Effort}, and \\textit{Willingness}. Through experimentation, we find that modelling intensity as a continuous spectrum yields substantially more consistent and controllable personality expression compared to binary trait toggling. Moreover, we observe that changes in target trait intensity systematically influence closely related traits in psychologically coherent directions, suggesting that LLMs internalize multi-dimensional personality structures rather than treating traits in isolation. Our work opens new pathways for controlled and nuanced human-machine interactions in domains such as healthcare, education, and interviewing processes, bringing us one step closer to truly human-like social machines.",
      "authors": [
        "Adithya Chittem",
        "Aishna Shrivastava",
        "Sai Tarun Pendela",
        "Jagat Sesh Challa",
        "Dhruv Kumar"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20993",
        "HTML": "https://arxiv.org/html/2506.20993",
        "PDF": "https://arxiv.org/pdf/2506.20993"
      },
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 04:12:15 GMT",
          "size": "102kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "SAC: A Framework for Measuring and Inducing Personality Traits in LLMs with Dynamic Intensity Control",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper covers methods for measuring and inducing personality traits in LLMs, focusing on dynamic intensity control and not on processing or engineering training data for LLMs."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.20994",
      "abstract": "With the emergence of new high-performance computing (HPC) accelerators, such as Nvidia and AMD GPUs, efficiently targeting diverse hardware architectures has become a major challenge for HPC application developers. The increasing hardware diversity in HPC systems often necessitates the development of architecture-specific code, hindering the sustainability of large-scale scientific applications. In this work, we leverage DaCe, a data-centric parallel programming framework, to automate the generation of high-performance kernels. DaCe enables automatic code generation for multicore processors and various accelerators, reducing the burden on developers who would otherwise need to rewrite code for each new architecture. Our study demonstrates DaCe's capabilities by applying its automatic code generation to a critical computational kernel used in Computational Fluid Dynamics (CFD). Specifically, we focus on Neko, a Fortran-based solver that employs the spectral-element method, which relies on small tensor operations. We detail the formulation of this computational kernel using DaCe's Stateful Dataflow Multigraph (SDFG) representation and discuss how this approach facilitates high-performance code generation. Additionally, we outline the workflow for seamlessly integrating DaCe's generated code into the Neko solver. Our results highlight the portability and performance of the generated code across multiple platforms, including Nvidia GH200, Nvidia A100, and AMD MI250X GPUs, with competitive performance results. By demonstrating the potential of automatic code generation, we emphasise the feasibility of using portable solutions to ensure the long-term sustainability of large-scale scientific applications.",
      "authors": [
        "M{\\aa}ns I. Andersson",
        "Martin Karp",
        "Niclas Jansson and Stefano Markidis"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20994",
        "HTML": "https://arxiv.org/html/2506.20994",
        "PDF": "https://arxiv.org/pdf/2506.20994"
      },
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "Performance (cs.PF)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 04:17:38 GMT",
          "size": "296kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Portable High-Performance Kernel Generation for a Computational Fluid Dynamics Code with DaCe",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper discusses high-performance kernel generation for computational fluid dynamics using a data-centric parallel programming framework, unrelated to LLM training data processing."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.20995",
      "abstract": "We propose a novel step-by-step video-to-audio generation method that sequentially produces individual audio tracks, each corresponding to a specific sound event in the video. Our approach mirrors traditional Foley workflows, aiming to capture all sound events induced by a given video comprehensively. Each generation step is formulated as a guided video-to-audio synthesis task, conditioned on a target text prompt and previously generated audio tracks. This design is inspired by the idea of concept negation from prior compositional generation frameworks. To enable this guided generation, we introduce a training framework that leverages pre-trained video-to-audio models and eliminates the need for specialized paired datasets, allowing training on more accessible data. Experimental results demonstrate that our method generates multiple semantically distinct audio tracks for a single input video, leading to higher-quality composite audio synthesis than existing baselines.",
      "authors": [
        "Akio Hayakawa",
        "Masato Ishii",
        "Takashi Shibuya",
        "Yuki Mitsufuji"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20995",
        "HTML": "https://arxiv.org/html/2506.20995",
        "PDF": "https://arxiv.org/pdf/2506.20995"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)",
        "Sound (cs.SD)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 04:20:08 GMT",
          "size": "3285kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Step-by-Step Video-to-Audio Synthesis via Negative Audio Guidance",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper presents a video-to-audio synthesis method and does not address LLM training data processing or data engineering tasks."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.20998",
      "abstract": "Novel view synthesis is a task of generating scenes from unseen perspectives; however, synthesizing dynamic scenes from blurry monocular videos remains an unresolved challenge that has yet to be effectively addressed. Existing novel view synthesis methods are often constrained by their reliance on high-resolution images or strong assumptions about static geometry and rigid scene priors. Consequently, their approaches lack robustness in real-world environments with dynamic object and camera motion, leading to instability and degraded visual fidelity. To address this, we propose Motion-aware Dynamic View Synthesis from Blurry Monocular Video via Sparse-Controlled Gaussian Splatting (DBMovi-GS), a method designed for dynamic view synthesis from blurry monocular videos. Our model generates dense 3D Gaussians, restoring sharpness from blurry videos and reconstructing detailed 3D geometry of the scene affected by dynamic motion variations. Our model achieves robust performance in novel view synthesis under dynamic blurry scenes and sets a new benchmark in realistic novel view synthesis for blurry monocular video inputs.",
      "authors": [
        "Yeon-Ji Song",
        "Jaein Kim",
        "Byung-Ju Kim",
        "Byoung-Tak Zhang"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20998",
        "HTML": "https://arxiv.org/html/2506.20998",
        "PDF": "https://arxiv.org/pdf/2506.20998"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 04:28:48 GMT",
          "size": "17641kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "DBMovi-GS: Dynamic View Synthesis from Blurry Monocular Video via Sparse-Controlled Gaussian Splatting",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on novel view synthesis from blurry monocular video, not related to any aspect of LLM training data processing or data engineering."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21001",
      "abstract": "Challenges such as the lack of high-quality annotations, long-tailed data distributions, and inconsistent staining styles pose significant obstacles to training neural networks to detect abnormal cells in cytopathology robustly. This paper proposes a style-aligned image composition (SAIC) method that composes high-fidelity and style-preserved pathological images to enhance the effectiveness and robustness of detection models. Without additional training, SAIC first selects an appropriate candidate from the abnormal cell bank based on attribute guidance. Then, it employs a high-frequency feature reconstruction to achieve a style-aligned and high-fidelity composition of abnormal cells and pathological backgrounds. Finally, it introduces a large vision-language model to filter high-quality synthesis images. Experimental results demonstrate that incorporating SAIC-synthesized images effectively enhances the performance and robustness of abnormal cell detection for tail categories and styles, thereby improving overall detection performance. The comprehensive quality evaluation further confirms the generalizability and practicality of SAIC in clinical application scenarios. Our code will be released at https://github.com/Joey-Qi/SAIC.",
      "authors": [
        "Qiuyi Qi",
        "Xin Li",
        "Ming Kong",
        "Zikang Xu",
        "Bingdi Chen",
        "Qiang Zhu",
        "S Kevin Zhou"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21001",
        "HTML": "https://arxiv.org/html/2506.21001",
        "PDF": "https://arxiv.org/pdf/2506.21001"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 04:32:21 GMT",
          "size": "43732kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Style-Aligned Image Composition for Robust Detection of Abnormal Cells in Cytopathology",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper discusses a method for enhancing detection of abnormal cells in cytopathology using style-aligned image composition but does not address any aspects of LLM training data processing."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21002",
      "abstract": "Scene text removal (STR) aims to erase textual elements from images. It was originally intended for removing privacy-sensitiveor undesired texts from natural scene images, but is now also appliedto typographic images. STR typically detects text regions and theninpaints them. Although STR has advanced through neural networksand synthetic data, misuse risks have increased. This paper investi-gates Inverse STR (ISTR), which analyzes STR-processed images andfocuses on binary classification (detecting whether an image has un-dergone STR) and localizing removed text regions. We demonstrate inexperiments that these tasks are achievable with high accuracies, en-abling detection of potential misuse and improving STR. We also at-tempt to recover the removed text content by training a text recognizerto understand its difficulty.",
      "authors": [
        "Takumi Yoshimatsu",
        "Shumpei Takezaki and Seiichi Uchida"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21002",
        "HTML": "https://arxiv.org/html/2506.21002",
        "PDF": "https://arxiv.org/pdf/2506.21002"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 04:32:35 GMT",
          "size": "5282kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Inverse Scene Text Removal",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on detecting and localizing text regions in scene text removal, which is not related to the processing of training data for LLMs."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21003",
      "abstract": "Explicit density learners are becoming an increasingly popular technique for generative models because of their ability to better model probability distributions. They have advantages over Generative Adversarial Networks due to their ability to perform density estimation and having exact latent-variable inference. This has many advantages, including: being able to simply interpolate, calculate sample likelihood, and analyze the probability distribution. The downside of these models is that they are often more difficult to train and have lower sampling quality.\n  Normalizing flows are explicit density models, that use composable bijective functions to turn an intractable probability function into a tractable one. In this work, we present novel knowledge distillation techniques to increase sampling quality and density estimation of smaller student normalizing flows. We seek to study the capacity of knowledge distillation in Compositional Normalizing Flows to understand the benefits and weaknesses provided by these architectures. Normalizing flows have unique properties that allow for a non-traditional forms of knowledge transfer, where we can transfer that knowledge within intermediate layers. We find that through this distillation, we can make students significantly smaller while making substantial performance gains over a non-distilled student. With smaller models there is a proportionally increased throughput as this is dependent upon the number of bijectors, and thus parameters, in the network.",
      "authors": [
        "Steven Walton",
        "Valeriy Klyukin",
        "Maksim Artemev",
        "Denis Derkach",
        "Nikita Orlov",
        "Humphrey Shi"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21003",
        "HTML": "https://arxiv.org/html/2506.21003",
        "PDF": "https://arxiv.org/pdf/2506.21003"
      },
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 04:34:28 GMT",
          "size": "4213kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Distilling Normalizing Flows",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper deals with normalizing flows and knowledge distillation for improving generative models, with no mention of LLM training data processing."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21005",
      "abstract": "Enforcing helmet regulations among motorcyclists is essential for enhancing road safety and ensuring the effectiveness of traffic management systems. However, automatic detection of helmet violations faces significant challenges due to environmental variability, camera angles, and inconsistencies in the data. These factors hinder reliable detection of motorcycles and riders and disrupt consistent object classification. To address these challenges, we propose VisionGuard, a synergistic multi-stage framework designed to overcome the limitations of frame-wise detectors, especially in scenarios with class imbalance and inconsistent annotations. VisionGuard integrates two key components: Adaptive Labeling and Contextual Expander modules. The Adaptive Labeling module is a tracking-based refinement technique that enhances classification consistency by leveraging a tracking algorithm to assign persistent labels across frames and correct misclassifications. The Contextual Expander module improves recall for underrepresented classes by generating virtual bounding boxes with appropriate confidence scores, effectively addressing the impact of data imbalance. Experimental results show that VisionGuard improves overall mAP by 3.1% compared to baseline detectors, demonstrating its effectiveness and potential for real-world deployment in traffic surveillance systems, ultimately promoting safety and regulatory compliance.",
      "authors": [
        "Lam-Huy Nguyen and Thinh-Phuc Nguyen and Thanh-Hai Nguyen and Gia-Huy Dinh and Minh-Triet Tran and Trung-Nghia Le"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21005",
        "HTML": "https://arxiv.org/html/2506.21005",
        "PDF": "https://arxiv.org/pdf/2506.21005"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 04:45:18 GMT",
          "size": "9373kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "VisionGuard: Synergistic Framework for Helmet Violation Detection",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "VisionGuard is aimed at improving helmet violation detection in traffic surveillance, with no relation to LLM data engineering or processing."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21006",
      "abstract": "Complete removal of cancer tumors with a negative specimen margin during lumpectomy is essential in reducing breast cancer recurrence. However, 2D specimen radiography (SR), the current method used to assess intraoperative specimen margin status, has limited accuracy, resulting in nearly a quarter of patients requiring additional surgery. To address this, we propose a novel deep learning framework combining the Segment Anything Model (SAM) with Forward-Forward Contrastive Learning (FFCL), a pre-training strategy leveraging both local and global contrastive learning for patch-level classification of SR images. After annotating SR images with regions of known maligancy, non-malignant tissue, and pathology-confirmed margins, we pre-train a ResNet-18 backbone with FFCL to classify margin status, then reconstruct coarse binary masks to prompt SAM for refined tumor margin segmentation. Our approach achieved an AUC of 0.8455 for margin classification and segmented margins with a 27.4% improvement in Dice similarity over baseline models, while reducing inference time to 47 milliseconds per image. These results demonstrate that FFCL-SAM significantly enhances both the speed and accuracy of intraoperative margin assessment, with strong potential to reduce re-excision rates and improve surgical outcomes in breast cancer treatment. Our code is available at https://github.com/tbwa233/FFCL-SAM/.",
      "authors": [
        "Tyler Ward",
        "Xiaoqin Wang",
        "Braxton McFarland",
        "Md Atik Ahamed",
        "Sahar Nozad",
        "Talal Arshad",
        "Hafsa Nebbache",
        "Jin Chen",
        "Abdullah Imran"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21006",
        "HTML": "https://arxiv.org/html/2506.21006",
        "PDF": "https://arxiv.org/pdf/2506.21006"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 04:46:28 GMT",
          "size": "11236kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Detection of Breast Cancer Lumpectomy Margin with SAM-incorporated Forward-Forward Contrastive Learning",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper presents a deep learning framework for breast cancer margin detection, without discussing LLM training data processing."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21008",
      "abstract": "We introduce the Aging Multiverse, a framework for generating multiple plausible facial aging trajectories from a single image, each conditioned on external factors such as environment, health, and lifestyle. Unlike prior methods that model aging as a single deterministic path, our approach creates an aging tree that visualizes diverse futures. To enable this, we propose a training-free diffusion-based method that balances identity preservation, age accuracy, and condition control. Our key contributions include attention mixing to modulate editing strength and a Simulated Aging Regularization strategy to stabilize edits. Extensive experiments and user studies demonstrate state-of-the-art performance across identity preservation, aging realism, and conditional alignment, outperforming existing editing and age-progression models, which often fail to account for one or more of the editing criteria. By transforming aging into a multi-dimensional, controllable, and interpretable process, our approach opens up new creative and practical avenues in digital storytelling, health education, and personalized visualization.",
      "authors": [
        "Bang Gong",
        "Luchao Qi",
        "Jiaye Wu",
        "Zhicheng Fu",
        "Chunbo Song",
        "David W. Jacobs",
        "John Nicholson",
        "Roni Sengupta"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21008",
        "HTML": "https://arxiv.org/html/2506.21008",
        "PDF": "https://arxiv.org/pdf/2506.21008"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 04:57:47 GMT",
          "size": "10455kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "The Aging Multiverse: Generating Condition-Aware Facial Aging Tree via Training-Free Diffusion",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on generating facial aging trajectories using a diffusion-based method, primarily enhancing image editing techniques, without contributing to the processing of training data for LLMs."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21009",
      "abstract": "Augmented reality (AR) provides ways to visualize missing view samples for novel view synthesis. Existing approaches present 3D annotations for new view samples and task users with taking images by aligning the AR display. This data collection task is known to be mentally demanding and limits capture areas to pre-defined small areas due to the ideal but restrictive underlying sampling theory. To free users from 3D annotations and limited scene exploration, we propose using locally reconstructed light fields and visualizing errors to be removed by inserting new views. Our results show that the error-peaking visualization is less invasive, reduces disappointment in final results, and is satisfactory with fewer view samples in our mobile view synthesis system. We also show that our approach can contribute to recent radiance field reconstruction for larger scenes, such as 3D Gaussian splatting.",
      "authors": [
        "Ayaka Yasunaga",
        "Hideo Saito",
        "Shohei Mori"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21009",
        "HTML": "https://arxiv.org/html/2506.21009",
        "PDF": "https://arxiv.org/pdf/2506.21009"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 05:01:41 GMT",
          "size": "745kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "User-in-the-Loop View Sampling with Error Peaking Visualization",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper emphasizes augmented reality and novel view synthesis for data collection in 3D scenes, without touching upon data engineering or processing related to LLM training."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21012",
      "abstract": "Federated learning (FL) aims to train models collaboratively across clients without sharing data for privacy-preserving. However, one major challenge is the data heterogeneity issue, which refers to the biased labeling preferences at multiple clients. A number of existing FL methods attempt to tackle data heterogeneity locally (e.g., regularizing local models) or globally (e.g., fine-tuning global model), often neglecting inherent semantic information contained in each client. To explore the possibility of using intra-client semantically meaningful knowledge in handling data heterogeneity, in this paper, we propose Federated Learning with Semantic-Aware Collaboration (FedSC) to capture client-specific and class-relevant knowledge across heterogeneous clients. The core idea of FedSC is to construct relational prototypes and consistent prototypes at semantic-level, aiming to provide fruitful class underlying knowledge and stable convergence signals in a prototype-wise collaborative way. On the one hand, FedSC introduces an inter-contrastive learning strategy to bring instance-level embeddings closer to relational prototypes with the same semantics and away from distinct classes. On the other hand, FedSC devises consistent prototypes via a discrepancy aggregation manner, as a regularization penalty to constrain the optimization region of the local model. Moreover, a theoretical analysis for FedSC is provided to ensure a convergence guarantee. Experimental results on various challenging scenarios demonstrate the effectiveness of FedSC and the efficiency of crucial components.",
      "authors": [
        "Huan Wang",
        "Haoran Li",
        "Huaming Chen",
        "Jun Yan",
        "Jiahua Shi",
        "Jun Shen"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21012",
        "HTML": "https://arxiv.org/html/2506.21012",
        "PDF": "https://arxiv.org/pdf/2506.21012"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 05:04:55 GMT",
          "size": "6560kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "FedSC: Federated Learning with Semantic-Aware Collaboration",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper addresses federated learning challenges, specifically data heterogeneity, using semantic-aware techniques without relevance to LLM training data processing."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21014",
      "abstract": "Vulnerability detection is a crucial yet challenging technique for ensuring the security of software systems. Currently, most deep learning-based vulnerability detection methods focus on stand-alone functions, neglecting the complex inter-function interrelations, particularly the multilateral associations. This oversight can fail to detect vulnerabilities in these interrelations. To address this gap, we present an Inter-Function Multilateral Association analysis framework for Vulnerability Detection (IFMA-VD). The cornerstone of the IFMA-VD lies in constructing a code behavior hypergraph and utilizing hyperedge convolution to extract multilateral association features. Specifically, we first parse functions into a code property graph to generate intra-function features. Following this, we construct a code behavior hypergraph by segmenting the program dependency graph to isolate and encode behavioral features into hyperedges. Finally, we utilize a hypergraph network to capture the multilateral association knowledge for augmenting vulnerability detection. We evaluate IFMA-VD on three widely used vulnerability datasets and demonstrate improvements in F-measure and Recall compared to baseline methods. Additionally, we illustrate that multilateral association features can boost code feature representation and validate the effectiveness of IFMA-VD on real-world datasets.",
      "authors": [
        "Shaojian Qiu",
        "Mengyang Huang",
        "Jiahao Cheng"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21014",
        "HTML": "https://arxiv.org/html/2506.21014",
        "PDF": "https://arxiv.org/pdf/2506.21014"
      },
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 05:11:21 GMT",
          "size": "1511kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Boosting Vulnerability Detection with Inter-function Multilateral Association Insights",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper introduces a framework for vulnerability detection through multilateral association analysis in code features, unrelated to LLM training data processing."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21015",
      "abstract": "Machine learning-assisted diagnosis is gaining traction in skin disease detection, but training effective models requires large amounts of high-quality data. Skin disease datasets often suffer from class imbalance, privacy concerns, and object bias, making data augmentation essential. While classical generative models are widely used, they demand extensive computational resources and lengthy training time. Quantum computing offers a promising alternative, but existing quantum-based image generation methods can only yield grayscale low-quality images. Through a novel classical-quantum latent space fusion technique, our work overcomes this limitation and introduces the first classical-quantum generative adversarial network (GAN) capable of generating color medical images. Our model outperforms classical deep convolutional GANs and existing hybrid classical-quantum GANs in both image generation quality and classification performance boost when used as data augmentation. Moreover, the performance boost is comparable with that achieved using state-of-the-art classical generative models, yet with over 25 times fewer parameters and 10 times fewer training epochs. Such results suggest a promising future for quantum image generation as quantum hardware advances. Finally, we demonstrate the robust performance of our model on real IBM quantum machine with hardware noise.",
      "authors": [
        "Qingyue Jiao",
        "Kangyu Zheng",
        "Yiyu Shi",
        "Zhiding Liang"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21015",
        "HTML": "https://arxiv.org/html/2506.21015",
        "PDF": "https://arxiv.org/pdf/2506.21015"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)",
        "Quantum Physics (quant-ph)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 05:14:45 GMT",
          "size": "405kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "HybridQ: Hybrid Classical-Quantum Generative Adversarial Network for Skin Disease Image Generation",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on a hybrid classical-quantum GAN for image generation, specifically for skin disease images, but does not discuss LLM training data processing or data engineering related to LLMs."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21016",
      "abstract": "The extended and unscented Kalman filter, and the particle filter provide a robust framework for fault-tolerant attitude estimation on spacecraft. This paper explores how each filter performs for a large satellite in a low earth orbit. Additionally, various techniques, built on these filters, for fault detection, isolation and recovery from erroneous sensor measurements, are analyzed. Key results from this analysis include filter performance for various fault modes.",
      "authors": [
        "B. Chidambaram",
        "A. Hilbert",
        "M. Silva"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21016",
        "HTML": "https://arxiv.org/html/2506.21016",
        "PDF": "https://arxiv.org/pdf/2506.21016"
      },
      "subjects": [
        "Robotics (cs.RO)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 05:19:38 GMT",
          "size": "1706kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Fault-Tolerant Spacecraft Attitude Determination using State Estimation Techniques",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper is about fault-tolerant spacecraft attitude determination using state estimation techniques, without any mention of LLM training data or related processing tasks."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21018",
      "abstract": "Effective deep feature extraction via feature-level fusion is crucial for multimodal object detection. However, previous studies often involve complex training processes that integrate modality-specific features by stacking multiple feature-level fusion units, leading to significant computational overhead. To address this issue, we propose a new fusion detection baseline that uses a single feature-level fusion unit to enable high-performance detection, thereby simplifying the training process. Based on this approach, we propose a lightweight attention-guided self-modulation feature fusion network (LASFNet), which introduces a novel attention-guided self-modulation feature fusion (ASFF) module that adaptively adjusts the responses of fusion features at both global and local levels based on attention information from different modalities, thereby promoting comprehensive and enriched feature generation. Additionally, a lightweight feature attention transformation module (FATM) is designed at the neck of LASFNet to enhance the focus on fused features and minimize information loss. Extensive experiments on three representative datasets demonstrate that, compared to state-of-the-art methods, our approach achieves a favorable efficiency-accuracy trade-off, reducing the number of parameters and computational cost by as much as 90% and 85%, respectively, while improving detection accuracy (mAP) by 1%-3%. The code will be open-sourced at https://github.com/leileilei2000/LASFNet.",
      "authors": [
        "Lei Hao",
        "Lina Xu",
        "Chang Liu",
        "and Yanni Dong"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21018",
        "HTML": "https://arxiv.org/html/2506.21018",
        "PDF": "https://arxiv.org/pdf/2506.21018"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 05:32:33 GMT",
          "size": "41398kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "LASFNet: A Lightweight Attention-Guided Self-Modulation Feature Fusion Network for Multimodal Object Detection",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper introduces a lightweight attention-guided network for multimodal object detection, which is unrelated to training data processing for LLMs."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21022",
      "abstract": "Image tokenization plays a critical role in reducing the computational demands of modeling high-resolution images, significantly improving the efficiency of image and multimodal understanding and generation. Recent advances in 1D latent spaces have reduced the number of tokens required by eliminating the need for a 2D grid structure. In this paper, we further advance compact discrete image representation by introducing 1D binary image latents. By representing each image as a sequence of binary vectors, rather than using traditional one-hot codebook tokens, our approach preserves high-resolution details while maintaining the compactness of 1D latents. To the best of our knowledge, our text-to-image models are the first to achieve competitive performance in both diffusion and auto-regressive generation using just 128 discrete tokens for images up to 1024x1024, demonstrating up to a 32-fold reduction in token numbers compared to standard VQ-VAEs. The proposed 1D binary latent space, coupled with simple model architectures, achieves marked improvements in speed training and inference speed. Our text-to-image models allow for a global batch size of 4096 on a single GPU node with 8 AMD MI300X GPUs, and the training can be completed within 200 GPU days. Our models achieve competitive performance compared to modern image generation models without any in-house private training data or post-training refinements, offering a scalable and efficient alternative to conventional tokenization methods.",
      "authors": [
        "Ze Wang",
        "Hao Chen",
        "Benran Hu",
        "Jiang Liu",
        "Ximeng Sun",
        "Jialian Wu",
        "Yusheng Su",
        "Xiaodong Yu",
        "Emad Barsoum",
        "Zicheng Liu"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21022",
        "HTML": "https://arxiv.org/html/2506.21022",
        "PDF": "https://arxiv.org/pdf/2506.21022"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 05:48:36 GMT",
          "size": "4980kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Instella-T2I: Pushing the Limits of 1D Discrete Latent Space Image Generation",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "While the paper discusses advances in image tokenization for text-to-image generation, it does not address the processing of language training data for LLMs."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21025",
      "abstract": "This work develops novel energy-stable parametric finite element methods (ES-PFEM) for the Willmore flow and curvature-dependent geometric gradient flows of surfaces in three dimensions. The key to achieving the energy stability lies in the use of two novel geometric identities: (i) a reformulated variational form of the normal velocity field, and (ii) incorporation of the temporal evolution of the mean curvature into the governing equations. These identities enable the derivation of a new variational formulation. By using the parametric finite element method, an implicit fully discrete scheme is subsequently developed, which maintains the energy dissipative property at the fully discrete level. Based on the ES-PFEM, comprehensive insights into the design of ES-PFEM for general curvature-dependent geometric gradient flows and a new understanding of mesh quality improvement in PFEM are provided. In particular, we develop the first PFEM for the Gauss curvature flow of surfaces. Furthermore, a tangential velocity control methodology is applied to improve the mesh quality and enhance the robustness of the proposed numerical method. Extensive numerical experiments confirm that the proposed method preserves energy dissipation properties and maintain good mesh quality in the surface evolution under the Willmore flow.",
      "authors": [
        "Weizhu Bao",
        "Yifei Li",
        "and Dongmin Wang"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21025",
        "HTML": "https://arxiv.org/html/2506.21025",
        "PDF": "https://arxiv.org/pdf/2506.21025"
      },
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 06:06:34 GMT",
          "size": "4946kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "An energy-stable parametric finite element method for the Willmore flow in three dimensions",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on developing energy-stable finite element methods for geometric flows, which is unrelated to LLM training data processing or engineering."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21030",
      "abstract": "The ability to perform reliable long-horizon task planning is crucial for deploying robots in real-world environments. However, directly employing Large Language Models (LLMs) as action sequence generators often results in low success rates due to their limited reasoning ability for long-horizon embodied tasks. In the STEP framework, we construct a subgoal tree through a pair of closed-loop models: a subgoal decomposition model and a leaf node termination model. Within this framework, we develop a hierarchical tree structure that spans from coarse to fine resolutions. The subgoal decomposition model leverages a foundation LLM to break down complex goals into manageable subgoals, thereby spanning the subgoal tree. The leaf node termination model provides real-time feedback based on environmental states, determining when to terminate the tree spanning and ensuring each leaf node can be directly converted into a primitive action. Experiments conducted in both the VirtualHome WAH-NL benchmark and on real robots demonstrate that STEP achieves long-horizon embodied task completion with success rates up to 34% (WAH-NL) and 25% (real robot) outperforming SOTA methods.",
      "authors": [
        "Zhou Tianxing",
        "Wang Zhirui",
        "Ao Haojia",
        "Chen Guangyan",
        "Xing Boyang",
        "Cheng Jingwen",
        "Yang Yi",
        "Yue Yufeng"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21030",
        "HTML": "https://arxiv.org/html/2506.21030",
        "PDF": "https://arxiv.org/pdf/2506.21030"
      },
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 06:10:02 GMT",
          "size": "11815kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "STEP Planner: Constructing cross-hierarchical subgoal tree as an embodied long-horizon task planner",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper presents a task planning framework for robots using LLMs, focusing on action decomposition rather than on LLM training data collection or processing."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21032",
      "abstract": "In real-world applications, users always interact with items in multiple aspects, such as through implicit binary feedback (e.g., clicks, dislikes, long views) and explicit feedback (e.g., comments, reviews). Modern recommendation systems (RecSys) learn user-item collaborative signals from these implicit feedback signals as a large-scale binary data-streaming, subsequently recommending other highly similar items based on users' personalized historical interactions. However, from this collaborative-connection perspective, the RecSys does not focus on the actual content of the items themselves but instead prioritizes higher-probability signals of behavioral co-occurrence among items. Consequently, under this binary learning paradigm, the RecSys struggles to understand why a user likes or dislikes certain items. To alleviate it, some works attempt to utilize the content-based reviews to capture the semantic knowledge to enhance recommender models. However, most of these methods focus on predicting the ratings of reviews, but do not provide a human-understandable explanation.",
      "authors": [
        "Shuo Yang",
        "Jiangxia Cao",
        "Haipeng Li",
        "Yuqi Mao",
        "Shuchao Pang"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21032",
        "HTML": "https://arxiv.org/html/2506.21032",
        "PDF": "https://arxiv.org/pdf/2506.21032"
      },
      "subjects": [
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 06:14:42 GMT",
          "size": "358kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "RecCoT: Enhancing Recommendation via Chain-of-Thought",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper deals with enhancing recommendation systems through user feedback interpretations, not related to processing or engineering of LLM training data."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21034",
      "abstract": "Commercial RGB-D cameras often produce noisy, incomplete depth maps for non-Lambertian objects. Traditional depth completion methods struggle to generalize due to the limited diversity and scale of training data. Recent advances exploit visual priors from pre-trained text-to-image diffusion models to enhance generalization in dense prediction tasks. However, we find that biases arising from training-inference mismatches in the vanilla diffusion framework significantly impair depth completion performance. Additionally, the lack of distinct visual features in non-Lambertian regions further hinders precise prediction. To address these issues, we propose \\textbf{DidSee}, a diffusion-based framework for depth completion on non-Lambertian objects. First, we integrate a rescaled noise scheduler enforcing a zero terminal signal-to-noise ratio to eliminate signal leakage bias. Second, we devise a noise-agnostic single-step training formulation to alleviate error accumulation caused by exposure bias and optimize the model with a task-specific loss. Finally, we incorporate a semantic enhancer that enables joint depth completion and semantic segmentation, distinguishing objects from backgrounds and yielding precise, fine-grained depth maps. DidSee achieves state-of-the-art performance on multiple benchmarks, demonstrates robust real-world generalization, and effectively improves downstream tasks such as category-level pose estimation and robotic grasping.Project page: https://wenzhoulyu.github.io/DidSee/",
      "authors": [
        "Wenzhou Lyu",
        "Jialing Lin",
        "Wenqi Ren",
        "Ruihao Xia",
        "Feng Qian",
        "Yang Tang"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21034",
        "HTML": "https://arxiv.org/html/2506.21034",
        "PDF": "https://arxiv.org/pdf/2506.21034"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 06:18:42 GMT",
          "size": "5732kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "DidSee: Diffusion-Based Depth Completion for Material-Agnostic Robotic Perception and Manipulation",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper deals with depth completion for robotic perception using a diffusion-based framework, which does not relate to LLM training data processing or engineering."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21036",
      "abstract": "Recent studies in federated learning (FL) commonly train models on static datasets. However, real-world data often arrives as streams with shifting distributions, causing performance degradation known as concept drift. This paper analyzes FL performance under concept drift using information theory and proposes an algorithm to mitigate the performance degradation. We model concept drift as a Markov chain and introduce the \\emph{Stationary Generalization Error} to assess a model's capability to capture characteristics of future unseen data. Its upper bound is derived using KL divergence and mutual information. We study three drift patterns (periodic, gradual, and random) and their impact on FL performance. Inspired by this, we propose an algorithm that regularizes the empirical risk minimization approach with KL divergence and mutual information, thereby enhancing long-term performance. We also explore the performance-cost tradeoff by identifying a Pareto front. To validate our approach, we build an FL testbed using Raspberry Pi4 devices. Experimental results corroborate with theoretical findings, confirming that drift patterns significantly affect performance. Our method consistently outperforms existing approaches for these three patterns, demonstrating its effectiveness in adapting concept drift in FL.",
      "authors": [
        "Fu Peng",
        "Meng Zhang and Ming Tang"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21036",
        "HTML": "https://arxiv.org/html/2506.21036",
        "PDF": "https://arxiv.org/pdf/2506.21036"
      },
      "subjects": [
        "Machine Learning (cs.LG)",
        "Distributed, Parallel, and Cluster Computing (cs.DC)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 06:25:15 GMT",
          "size": "12941kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "An Information-Theoretic Analysis for Federated Learning under Concept Drift",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper focuses on federated learning and concept drift, analyzing model performance under varying data distributions, which is unrelated to LLM training data processing."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21039",
      "abstract": "Long-horizon goal-conditioned tasks pose fundamental challenges for reinforcement learning (RL), particularly when goals are distant and rewards are sparse. While hierarchical and graph-based methods offer partial solutions, they often suffer from subgoal infeasibility and inefficient planning. We introduce Strict Subgoal Execution (SSE), a graph-based hierarchical RL framework that enforces single-step subgoal reachability by structurally constraining high-level decision-making. To enhance exploration, SSE employs a decoupled exploration policy that systematically traverses underexplored regions of the goal space. Furthermore, a failure-aware path refinement, which refines graph-based planning by dynamically adjusting edge costs according to observed low-level success rates, thereby improving subgoal reliability. Experimental results across diverse long-horizon benchmarks demonstrate that SSE consistently outperforms existing goal-conditioned RL and hierarchical RL approaches in both efficiency and success rate.",
      "authors": [
        "Jaebak Hwang",
        "Sanghyeon Lee",
        "Jeongmo Kim",
        "Seungyul Han"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21039",
        "HTML": "https://arxiv.org/html/2506.21039",
        "PDF": "https://arxiv.org/pdf/2506.21039"
      },
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 06:35:42 GMT",
          "size": "3023kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Strict Subgoal Execution: Reliable Long-Horizon Planning in Hierarchical Reinforcement Learning",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on hierarchical reinforcement learning for long-horizon tasks without mentioning any processing of training data for large language models."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21042",
      "abstract": "Detectors often suffer from performance drop due to domain gap between training and testing data. Recent methods explore diffusion models applied to domain generalization (DG) and adaptation (DA) tasks, but still struggle with large inference costs and have not yet fully leveraged the capabilities of diffusion models. We propose to tackle these problems by extracting intermediate features from a single-step diffusion process, improving feature collection and fusion to reduce inference time by 75% while enhancing performance on source domains (i.e., Fitness). Then, we construct an object-centered auxiliary branch by applying box-masked images with class prompts to extract robust and domain-invariant features that focus on object. We also apply consistency loss to align the auxiliary and ordinary branch, balancing fitness and generalization while preventing overfitting and improving performance on target domains (i.e., Generalization). Furthermore, within a unified framework, standard detectors are guided by diffusion detectors through feature-level and object-level alignment on source domains (for DG) and unlabeled target domains (for DA), thereby improving cross-domain detection performance (i.e., Transferability). Our method achieves competitive results on 3 DA benchmarks and 5 DG benchmarks. Additionally, experiments on COCO generalization benchmark demonstrate that our method maintains significant advantages and show remarkable efficiency in large domain shifts and low-data scenarios. Our work shows the superiority of applying diffusion models to domain generalized and adaptive detection tasks and offers valuable insights for visual perception tasks across diverse domains. The code is available at \\href{https://github.com/heboyong/Fitness-Generalization-Transferability}{Fitness-Generalization-Transferability}.",
      "authors": [
        "Boyong He",
        "Yuxiang Ji",
        "Zhuoyue Tan and Liaoni Wu"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21042",
        "HTML": "https://arxiv.org/html/2506.21042",
        "PDF": "https://arxiv.org/pdf/2506.21042"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 06:42:23 GMT",
          "size": "36455kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Boosting Domain Generalized and Adaptive Detection with Diffusion Models: Fitness, Generalization, and Transferability",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper discusses improving domain generalization and adaptive detection using diffusion models and does not address any LLM training data processing aspects."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21044",
      "abstract": "Unsupervised skill discovery aims to learn diverse and distinguishable behaviors in open-ended reinforcement learning. For existing methods, they focus on improving diversity through pure exploration, mutual information optimization, and learning temporal representation. Despite that they perform well on exploration, they remain limited in terms of efficiency, especially for the high-dimensional situations. In this work, we frame skill discovery as a min-max game of skill generation and policy learning, proposing a regret-aware method on top of temporal representation learning that expands the discovered skill space along the direction of upgradable policy strength. The key insight behind the proposed method is that the skill discovery is adversarial to the policy learning, i.e., skills with weak strength should be further explored while less exploration for the skills with converged strength. As an implementation, we score the degree of strength convergence with regret, and guide the skill discovery with a learnable skill generator. To avoid degeneration, skill generation comes from an up-gradable population of skill generators. We conduct experiments on environments with varying complexities and dimension sizes. Empirical results show that our method outperforms baselines in both efficiency and diversity. Moreover, our method achieves a 15% zero shot improvement in high-dimensional environments, compared to existing methods.",
      "authors": [
        "He Zhang",
        "Ming Zhou",
        "Shaopeng Zhai",
        "Ying Sun",
        "Hui Xiong"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21044",
        "HTML": "https://arxiv.org/html/2506.21044",
        "PDF": "https://arxiv.org/pdf/2506.21044"
      },
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 06:45:59 GMT",
          "size": "3488kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Efficient Skill Discovery via Regret-Aware Optimization",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper focuses on skill discovery and policy learning in unsupervised learning settings within reinforcement learning environments, not relating to LLM training data processing."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21045",
      "abstract": "Text-guided diffusion models have become essential for high-quality image synthesis, enabling dynamic image editing. In image editing, two crucial aspects are editability, which determines the extent of modification, and faithfulness, which reflects how well unaltered elements are preserved. However, achieving optimal results is challenging because of the inherent trade-off between editability and faithfulness. To address this, we propose Faithfulness Guidance and Scheduling (FGS), which enhances faithfulness with minimal impact on editability. FGS incorporates faithfulness guidance to strengthen the preservation of input image information and introduces a scheduling strategy to resolve misalignment between editability and faithfulness. Experimental results demonstrate that FGS achieves superior faithfulness while maintaining editability. Moreover, its compatibility with various editing methods enables precise, high-quality image edits across diverse tasks.",
      "authors": [
        "Hansam Cho",
        "Seoung Bum Kim"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21045",
        "HTML": "https://arxiv.org/html/2506.21045",
        "PDF": "https://arxiv.org/pdf/2506.21045"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 06:46:03 GMT",
          "size": "4140kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Improving Diffusion-Based Image Editing Faithfulness via Guidance and Scheduling",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper discusses improving faithfulness in diffusion-based image editing, which is unrelated to the processing of training data for large language models."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21046",
      "abstract": "The ability of deep neural networks (DNNs) come from extracting and interpreting features from the data provided. By exploiting intermediate features in DNNs instead of relying on hard labels, we craft adversarial perturbation that generalize more effectively, boosting black-box transferability. These features ubiquitously come from supervised learning in previous work. Inspired by the exceptional synergy between self-supervised learning and the Transformer architecture, this paper explores whether exploiting self-supervised Vision Transformer (ViT) representations can improve adversarial transferability. We present dSVA -- a generative dual self-supervised ViT features attack, that exploits both global structural features from contrastive learning (CL) and local textural features from masked image modeling (MIM), the self-supervised learning paradigm duo for ViTs. We design a novel generative training framework that incorporates a generator to create black-box adversarial examples, and strategies to train the generator by exploiting joint features and the attention mechanism of self-supervised ViTs. Our findings show that CL and MIM enable ViTs to attend to distinct feature tendencies, which, when exploited in tandem, boast great adversarial generalizability. By disrupting dual deep features distilled by self-supervised ViTs, we are rewarded with remarkable black-box transferability to models of various architectures that outperform state-of-the-arts. Code available at https://github.com/spencerwooo/dSVA.",
      "authors": [
        "Shangbo Wu",
        "Yu-an Tan",
        "Ruinan Ma",
        "Wencong Ma",
        "Dehua Zhu",
        "Yuanzhang Li"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21046",
        "HTML": "https://arxiv.org/html/2506.21046",
        "PDF": "https://arxiv.org/pdf/2506.21046"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 06:47:51 GMT",
          "size": "6261kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Boosting Generative Adversarial Transferability with Self-supervised Vision Transformer Features",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on improving adversarial transferability using self-supervised Vision Transformer features, predominantly for crafting adversarial perturbations, rather than addressing any aspect of LLM training data processing."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21053",
      "abstract": "In the realm of contemporary social media, automatic stance detection is pivotal for opinion mining, as it synthesizes and examines user perspectives on contentious topics to uncover prevailing trends and sentiments. Traditional stance detection research often targets individual instances, thereby limiting its capacity to model multi-party discussions typical in real social media scenarios. This shortcoming largely stems from the scarcity of datasets that authentically capture the dynamics of social media interactions, hindering advancements in conversational stance detection. In this paper, we introduce MT2-CSD, a comprehensive dataset for multi-target, multi-turn conversational stance detection. To the best of our knowledge, MT2-CSD is the largest dataset available for this purpose, comprising 24,457 annotated instances and exhibiting the greatest conversational depth, thereby presenting new challenges for stance detection. To address these challenges, we propose the Large Language model enhanced Conversational Relational Attention Network (LLM-CRAN), which exploits the reasoning capabilities of LLMs to improve conversational understanding. We conduct extensive experiments to evaluate the efficacy of LLM-CRAN on the MT2-CSD dataset. The experimental results indicate that LLM-CRAN significantly outperforms strong baseline models in the task of conversational stance detection.",
      "authors": [
        "Fuqiang Niu",
        "Genan Dai",
        "Yisha Lu",
        "Jiayu Liao",
        "Xiang Li",
        "Hu Huang and Bowen Zhang"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21053",
        "HTML": "https://arxiv.org/html/2506.21053",
        "PDF": "https://arxiv.org/pdf/2506.21053"
      },
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 06:59:30 GMT",
          "size": "1392kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "MT2-CSD: A New Dataset and Multi-Semantic Knowledge Fusion Method for Conversational Stance Detection",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper introduces a dataset for conversational stance detection and presents a model to improve performance using LLMs, without addressing LLM training data processing tasks such as data engineering or preparation for LLMs."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21054",
      "abstract": "In federated learning (FL), the data distribution of each client may change over time, introducing both temporal and spatial data heterogeneity, known as concept drift. Data heterogeneity arises from three drift sources: real drift (a shift in the conditional distribution P(y|x)), virtual drift (a shift in the input distribution P(x)), and label drift (a shift in the label distribution P(y)). However, most existing FL methods addressing concept drift primarily focus on real drift. When clients experience virtual or label drift, these methods often fail to selectively retain useful historical knowledge, leading to catastrophic forgetting. A key challenge lies in distinguishing different sources of drift, as they require distinct adaptation strategies: real drift calls for discarding outdated data, while virtual or label drift benefits from retaining historical data. Without explicitly identifying the drift sources, a general adaptation strategy is suboptimal and may harm generalization. To address this challenge, we propose FedDAA, a dynamic clustered FL framework designed to adapt to multi-source concept drift while preserving valuable historical knowledge. Specifically, FedDAA integrates three modules: a cluster number determination module to find the optimal number of clusters; a real drift detection module to distinguish real drift from virtual/label drift; and a concept drift adaptation module to adapt to new data while retaining useful historical information. We provide theoretical convergence guarantees, and experiments show that FedDAA achieves 7.84% to 8.52% accuracy improvements over state-of-the-art methods on Fashion-MNIST, CIFAR-10, and CIFAR-100.",
      "authors": [
        "Fu Peng",
        "Ming Tang"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21054",
        "HTML": "https://arxiv.org/html/2506.21054",
        "PDF": "https://arxiv.org/pdf/2506.21054"
      },
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 07:09:08 GMT",
          "size": "580kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "FedDAA: Dynamic Client Clustering for Concept Drift Adaptation in Federated Learning",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper focuses on federated learning concept drift adaptation, which is outside the scope of LLM training data processing, as it does not involve data engineering or preparation tasks specific to LLMs."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21055",
      "abstract": "Document understanding and analysis have received a lot of attention due to their widespread application. However, existing document analysis solutions, such as document layout analysis and key information extraction, are only suitable for fixed category definitions and granularities, and cannot achieve flexible applications customized by users. Therefore, this paper defines a new task named ``Class-Agnostic Region-of-Interest Matching'' (``RoI-Matching'' for short), which aims to match the customized regions in a flexible, efficient, multi-granularity, and open-set manner. The visual prompt of the reference document and target document images are fed into our model, while the output is the corresponding bounding boxes in the target document images. To meet the above requirements, we construct a benchmark RoI-Matching-Bench, which sets three levels of difficulties following real-world conditions, and propose the macro and micro metrics to evaluate. Furthermore, we also propose a new framework RoI-Matcher, which employs a siamese network to extract multi-level features both in the reference and target domains, and cross-attention layers to integrate and align similar semantics in different domains. Experiments show that our method with a simple procedure is effective on RoI-Matching-Bench, and serves as the baseline for further research. The code is available at https://github.com/pd162/RoI-Matching.",
      "authors": [
        "Demin Zhang",
        "Jiahao Lyu",
        "Zhijie Shen",
        "Yu Zhou"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21055",
        "HTML": "https://arxiv.org/html/2506.21055",
        "PDF": "https://arxiv.org/pdf/2506.21055"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 07:09:19 GMT",
          "size": "405kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Class-Agnostic Region-of-Interest Matching in Document Images",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The work is centered around document image analysis through RoI-Matching and does not discuss processing of training data for LLMs or propose methods relevant to LLM data preparation."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21056",
      "abstract": "Retrieving 3D objects in complex indoor environments using only a masked 2D image and a natural language description presents significant challenges. The ROOMELSA challenge limits access to full 3D scene context, complicating reasoning about object appearance, geometry, and semantics. These challenges are intensified by distorted viewpoints, textureless masked regions, ambiguous language prompts, and noisy segmentation masks. To address this, we propose SAMURAI: Shape-Aware Multimodal Retrieval for 3D Object Identification. SAMURAI integrates CLIP-based semantic matching with shape-guided re-ranking derived from binary silhouettes of masked regions, alongside a robust majority voting strategy. A dedicated preprocessing pipeline enhances mask quality by extracting the largest connected component and removing background noise. Our hybrid retrieval framework leverages both language and shape cues, achieving competitive performance on the ROOMELSA private test set. These results highlight the importance of combining shape priors with language understanding for robust open-world 3D object retrieval.",
      "authors": [
        "Dinh-Khoi Vo and Van-Loc Nguyen and Minh-Triet Tran and Trung-Nghia Le"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21056",
        "HTML": "https://arxiv.org/html/2506.21056",
        "PDF": "https://arxiv.org/pdf/2506.21056"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 07:10:52 GMT",
          "size": "1678kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "SAMURAI: Shape-Aware Multimodal Retrieval for 3D Object Identification",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on 3D object retrieval using multimodal data and processing techniques like semantic matching and shape-guided re-ranking. It does not discuss any aspect of LLM training data processing or engineering."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21057",
      "abstract": "Imitation learning has emerged as a powerful paradigm in robot manipulation, yet its generalization capability remains constrained by object-specific dependencies in limited expert demonstrations. To address this challenge, we propose knowledge-driven imitation learning, a framework that leverages external structural semantic knowledge to abstract object representations within the same category. We introduce a novel semantic keypoint graph as a knowledge template and develop a coarse-to-fine template-matching algorithm that optimizes both structural consistency and semantic similarity. Evaluated on three real-world robotic manipulation tasks, our method achieves superior performance, surpassing image-based diffusion policies with only one-quarter of the expert demonstrations. Extensive experiments further demonstrate its robustness across novel objects, backgrounds, and lighting conditions. This work pioneers a knowledge-driven approach to data-efficient robotic learning in real-world settings. Code and more materials are available on https://knowledge-driven.github.io/.",
      "authors": [
        "Zhuochen Miao",
        "Jun Lv",
        "Hongjie Fang",
        "Yang Jin",
        "Cewu Lu"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21057",
        "HTML": "https://arxiv.org/html/2506.21057",
        "PDF": "https://arxiv.org/pdf/2506.21057"
      },
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 07:14:59 GMT",
          "size": "4579kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Knowledge-Driven Imitation Learning: Enabling Generalization Across Diverse Conditions",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper presents a knowledge-driven imitation learning framework for robotic manipulation, which does not involve any discussion of LLM training data processing or data engineering."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21063",
      "abstract": "The control of marine robots has long relied on model-based methods grounded in classical and modern control theory. However, the nonlinearity and uncertainties inherent in robot dynamics, coupled with the complexity of marine environments, have revealed the limitations of conventional control methods. The rapid evolution of machine learning has opened new avenues for incorporating data-driven intelligence into control strategies, prompting a paradigm shift in the control of marine robots. This paper provides a review of recent progress in marine robot control through the lens of this emerging paradigm. The review covers both individual and cooperative marine robotic systems, highlighting notable achievements in data-driven control of marine robots and summarizing open-source resources that support the development and validation of advanced control methods. Finally, several future perspectives are outlined to guide research toward achieving high-level autonomy for marine robots in real-world applications. This paper aims to serve as a roadmap toward the next-generation control framework of marine robots in the era of data-driven intelligence.",
      "authors": [
        "Lin Hong",
        "Lu Liu",
        "Zhouhua Peng",
        "and Fumin Zhang"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21063",
        "HTML": "https://arxiv.org/html/2506.21063",
        "PDF": "https://arxiv.org/pdf/2506.21063"
      },
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 07:28:03 GMT",
          "size": "42564kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Control of Marine Robots in the Era of Data-Driven Intelligence",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper reviews data-driven control strategies for marine robots without any reference to training data processing or engineering for LLMs."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21065",
      "abstract": "We propose inflow and outflow boundary conditions for the compressible Navier-Stokes equations and prove that they allow a priori estimates of the entropy, mass and total energy. Furthermore, we demonstrate how to approximate these boundary conditions in conjunction with an entropy-stable finite-volume scheme. The method is also applicable to other types of entropy-stable schemes. Finally, we carry out some numerical computations with the finite-volume scheme and demonstrate their robustness.",
      "authors": [
        "Magnus Sv\\\"ard",
        "Anita Gjesteland"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21065",
        "HTML": "https://arxiv.org/html/2506.21065",
        "PDF": "https://arxiv.org/pdf/2506.21065"
      },
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 07:34:21 GMT",
          "size": "590kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Entropy-stable in- and outflow boundary conditions for the compressible Navier-Stokes equations",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper is focused on boundary conditions for the compressible Navier-Stokes equations and does not pertain to training data processing for large language models."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21069",
      "abstract": "Electromagnetic (EM) covert channels pose significant threats to computer and communications security in air-gapped networks. Previous works exploit EM radiation from various components (e.g., video cables, memory buses, CPUs) to secretly send sensitive information. These approaches typically require the attacker to deploy highly specialized receivers near the victim, which limits their real-world impact. This paper reports a new EM covert channel, TEMPEST-LoRa, that builds on Cross-Technology Covert Communication (CTCC), which could allow attackers to covertly transmit EM-modulated secret data from air-gapped networks to widely deployed operational LoRa receivers from afar. We reveal the potential risk and demonstrate the feasibility of CTCC by tackling practical challenges involved in manipulating video cables to precisely generate the EM leakage that could readily be received by third-party commercial LoRa nodes/gateways. Experiment results show that attackers can reliably decode secret data modulated by the EM leakage from a video cable at a maximum distance of 87.5m or a rate of 21.6 kbps. We note that the secret data transmission can be performed with monitors turned off (therefore covertly).",
      "authors": [
        "Xieyang Sun",
        "Yuanqing Zheng",
        "Wei Xi",
        "Zuhao Chen",
        "Zhizhen Chen",
        "Han Hao",
        "Zhiping Jiang",
        "Sheng Zhong"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21069",
        "HTML": "https://arxiv.org/html/2506.21069",
        "PDF": "https://arxiv.org/pdf/2506.21069"
      },
      "subjects": [
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 07:39:50 GMT",
          "size": "4523kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "TEMPEST-LoRa: Cross-Technology Covert Communication",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper discusses EM covert channels and communications security, which are unrelated to the processing or engineering of LLM training data."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21070",
      "abstract": "This paper investigates an inverse source problem for space-time fractional diffusion equations from a posteriori interior measurements. The uniqueness result is established by the memory effect of fractional derivatives and the unique continuation property. For the numerical reconstruction, the inverse problem is reformulated as an optimization problem with the Tikhonov regularization. We use the Levenberg-Marquardt method to identity the unknown source from noisy measurements. Finally, we give some numerical examples to illustrate the efficiency and accuracy of the proposed algorithm.",
      "authors": [
        "Kai Yu",
        "Zhiyuan Li",
        "Yikan Liu"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21070",
        "HTML": "https://arxiv.org/html/2506.21070",
        "PDF": "https://arxiv.org/pdf/2506.21070"
      },
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 07:43:02 GMT",
          "size": "73kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Inverse source problem with a posteriori interior measurements for space-time fractional diffusion equations",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper addresses an inverse source problem in fractional diffusion equations, focusing on numerical methods like Tikhonov regularization for solving these equations. It is not related to the processing of training data for LLMs."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21072",
      "abstract": "The Operational Technology Platform as a Service (OTPaaS) initiative provides a structured framework for the efficient management and storage of data. It ensures excellent response times while improving security, reliability, data and technology sovereignty, robustness, and energy efficiency, which are crucial for industrial transformation and data sovereignty. This paper illustrates successful deployment, adaptable application management, and various integration components catering to Edge and Cloud environments. It leverages the advantages of the Platform as a Service model and highlights key challenges that have been addressed for specific use cases.",
      "authors": [
        "Carlos J Barrios (LIG",
        "UIS",
        "CITI)",
        "Yves Denneulin (LIG",
        "Grenoble INP)"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21072",
        "HTML": "https://arxiv.org/html/2506.21072",
        "PDF": "https://arxiv.org/pdf/2506.21072"
      },
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "Performance (cs.PF)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 07:52:30 GMT",
          "size": "3757kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Bridding OT and PaaS in Edge-to-Cloud Continuum",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper discusses Operational Technology PaaS for data management in Edge-to-Cloud environments, which is not related to training data processing for LLMs."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21073",
      "abstract": "The advent of 5G and beyond has brought increased performance networks, facilitating the deployment of services closer to the user. To meet performance requirements such services require specialized hardware, such as Field Programmable Gate Arrays (FPGAs). However, FPGAs are often deployed in unprotected environments, leaving the user's applications vulnerable to multiple attacks. With the rise of quantum computing, which threatens the integrity of widely-used cryptographic algorithms, the need for a robust security infrastructure is even more crucial. In this paper we introduce a hybrid hardware-software solution utilizing remote attestation to securely configure FPGAs, while integrating Post-Quantum Cryptographic (PQC) algorithms for enhanced security. Additionally, to enable trustworthiness across the whole edge computing continuum, our solution integrates a blockchain infrastructure, ensuring the secure storage of any security evidence. We evaluate the proposed secure configuration process under different PQC algorithms in two FPGA families, showcasing only 2% overheard compared to the non PQC approach.",
      "authors": [
        "Ilias Papalamprou",
        "Nikolaos Fotos",
        "Nikolaos Chatzivasileiadis",
        "Anna Angelogianni",
        "Dimosthenis Masouros",
        "Dimitrios Soudris"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21073",
        "HTML": "https://arxiv.org/html/2506.21073",
        "PDF": "https://arxiv.org/pdf/2506.21073"
      },
      "subjects": [
        "Hardware Architecture (cs.AR)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 07:58:22 GMT",
          "size": "280kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Post-Quantum and Blockchain-Based Attestation for Trusted FPGAs in B5G Networks",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper focuses on hardware-security solutions for FPGAs in network environments, unrelated to any aspect of training data processing for LLMs."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21076",
      "abstract": "3D characters play a crucial role in our daily entertainment. To improve the efficiency of 3D character modeling, recent image-based methods use two separate models to achieve pose standardization and 3D reconstruction of the A-pose character. However, these methods are prone to generating distorted and degraded images in the pose standardization stage due to self-occlusion and viewpoints, which further affects the geometric quality of the subsequent reconstruction process. To tackle these problems, we propose PoseMaster, an end-to-end controllable 3D character generation framework. Specifically, we unify pose transformation and 3D character generation into a flow-based 3D native generation framework. To achieve accurate arbitrary-pose control, we propose to leverage the 3D body bones existing in the skeleton of an animatable character as the pose condition. Furthermore, considering the specificity of multi-condition control, we randomly empty the pose condition and the image condition during training to improve the effectiveness and generalizability of pose control. Finally, we create a high-quality pose-control dataset derived from realistic character animation data to make the model learning the implicit relationships between skeleton and skinning weights. Extensive experiments show that PoseMaster outperforms current state-of-the-art techniques in both qualitative and quantitative evaluations for A-pose character generation while demonstrating its powerful ability to achieve precise control for arbitrary poses.",
      "authors": [
        "Hongyu Yan",
        "Kunming Luo",
        "Weiyu Li",
        "Yixun Liang",
        "Shengming Li",
        "Jingwei Huang",
        "Chunchao Guo",
        "Ping Tan"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21076",
        "HTML": "https://arxiv.org/html/2506.21076",
        "PDF": "https://arxiv.org/pdf/2506.21076"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 08:03:14 GMT",
          "size": "6870kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "PoseMaster: Generating 3D Characters in Arbitrary Poses from a Single Image",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on 3D character generation using pose transformation and does not relate to LLM training data processing or data engineering tasks."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21077",
      "abstract": "This paper studies 3D LiDAR mapping with a focus on developing an updatable and localizable map representation that enables continuity, compactness and consistency in 3D maps. Traditional LiDAR Simultaneous Localization and Mapping (SLAM) systems often rely on 3D point cloud maps, which typically require extensive storage to preserve structural details in large-scale environments. In this paper, we propose a novel paradigm for LiDAR SLAM by leveraging the Continuous and Ultra-compact Representation of LiDAR (CURL) introduced in [1]. Our proposed LiDAR mapping approach, CURL-SLAM, produces compact 3D maps capable of continuous reconstruction at variable densities using CURL's spherical harmonics implicit encoding, and achieves global map consistency after loop closure. Unlike popular Iterative Closest Point (ICP)-based LiDAR odometry techniques, CURL-SLAM formulates LiDAR pose estimation as a unique optimization problem tailored for CURL and extends it to local Bundle Adjustment (BA), enabling simultaneous pose refinement and map correction. Experimental results demonstrate that CURL-SLAM achieves state-of-the-art 3D mapping quality and competitive LiDAR trajectory accuracy, delivering sensor-rate real-time performance (10 Hz) on a CPU. We will release the CURL-SLAM implementation to the community.",
      "authors": [
        "Kaicheng Zhang",
        "Shida Xu",
        "Yining Ding",
        "Xianwen Kong",
        "Sen Wang"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21077",
        "HTML": "https://arxiv.org/html/2506.21077",
        "PDF": "https://arxiv.org/pdf/2506.21077"
      },
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 08:05:30 GMT",
          "size": "43414kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "CURL-SLAM: Continuous and Compact LiDAR Mapping",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The research centers on 3D LiDAR mapping and optimization for SLAM systems, which is not applicable to the processing of LLM training data."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21078",
      "abstract": "Integrated sensing and communications (ISAC) is considered a key enabler to support application scenarios such as the Internet-of-Things (IoT) in which both communications and sensing play significant roles. Multi-carrier waveforms, such as orthogonal frequency division multiplexing (OFDM), have been considered as good candidates for ISAC due to their high communications data rate and good time bandwidth property for sensing. Nevertheless, their high peak-to-average-power-ratio (PAPR) values lead to either performance degradation or an increase in system complexity. This can make OFDM unsuitable for IoT applications with insufficient resources in terms of power, system complexity, hardware size or cost. This article provides IoT-centric constant modulus waveform designs that leverage the advantage of unit PAPR and thus are more suitable in resource-limited scenarios. More specifically, several single-carrier frequency and/or phase-modulated waveforms are considered. A comprehensive discussion on their radar sensing and communications performance is conducted based on performance metrics, including the radar ambiguity function, the bandwidth property, the data rate, and the communications receiver complexity.",
      "authors": [
        "Tian Han",
        "Shalanika Dayarathna",
        "Rajitha Senanayake",
        "Peter Smith",
        "Aryan Kaushik",
        "Alain Mourad",
        "Richard A. Stirling-Gallacher",
        "Jamie Evans"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21078",
        "HTML": "https://arxiv.org/html/2506.21078",
        "PDF": "https://arxiv.org/pdf/2506.21078"
      },
      "subjects": [
        "Information Theory (cs.IT)",
        "Signal Processing (eess.SP)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 08:06:24 GMT",
          "size": "262kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Constant Modulus Waveforms for IoT-Centric Integrated Sensing and Communications",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper discusses waveform designs for IoT applications in the context of integrated sensing and communications, not LLM training data."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21080",
      "abstract": "Modern perception models, particularly those designed for multisensory egocentric tasks, have achieved remarkable performance but often come with substantial computational costs. These high demands pose challenges for real-world deployment, especially in resource-constrained environments. In this paper, we introduce EgoAdapt, a framework that adaptively performs cross-modal distillation and policy learning to enable efficient inference across different egocentric perception tasks, including egocentric action recognition, active speaker localization, and behavior anticipation. Our proposed policy module is adaptable to task-specific action spaces, making it broadly applicable. Experimental results on three challenging egocentric datasets EPIC-Kitchens, EasyCom, and Aria Everyday Activities demonstrate that our method significantly enhances efficiency, reducing GMACs by up to 89.09%, parameters up to 82.02%, and energy up to 9.6x, while still on-par and in many cases outperforming, the performance of corresponding state-of-the-art models.",
      "authors": [
        "Sanjoy Chowdhury",
        "Subrata Biswas",
        "Sayan Nag",
        "Tushar Nagarajan",
        "Calvin Murdock",
        "Ishwarya Ananthabhotla",
        "Yijun Qian",
        "Vamsi Krishna Ithapu",
        "Dinesh Manocha",
        "Ruohan Gao"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21080",
        "HTML": "https://arxiv.org/html/2506.21080",
        "PDF": "https://arxiv.org/pdf/2506.21080"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 08:09:16 GMT",
          "size": "23658kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "EgoAdapt: Adaptive Multisensory Distillation and Policy Learning for Efficient Egocentric Perception",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper introduces a framework for efficient perception tasks using multisensory distillation and policy learning, unrelated to LLM data processing."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21084",
      "abstract": "We investigate the computational complexity of the timed prediction problem in two-dimensional sandpile models. This question refines the classical prediction problem, which asks whether a cell q will eventually become unstable after adding a grain at cell p from a given configuration. The prediction problem has been shown to be P-complete in several settings, including for subsets of the Moore neighborhood, but its complexity for the von Neumann neighborhood remains open. In a previous work, we provided a complete characterization of crossover gates (a key to the implementation of non-planar monotone circuits) for these small neighborhoods, leading to P-completeness proofs with only 4 and 5 neighbors among the eight adjancent cells. In this paper, we introduce the timed setting, where the goal is to determine whether cell q becomes unstable exactly at time t. We distinguish several cases: some neighborhoods support complete timed toolkits (including timed crossover gates) and exhibit P-completeness; others admit timed crossovers but suffer from synchronization issues; planar neighborhoods provably do not admit any timed crossover; and finally, for some remaining neighborhoods, we conjecture that no timed crossover is possible.",
      "authors": [
        "Pablo Concha-Vega (AMU",
        "LIS)",
        "K\\'evin Perrot (AMU",
        "LIS)"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21084",
        "HTML": "https://arxiv.org/html/2506.21084",
        "PDF": "https://arxiv.org/pdf/2506.21084"
      },
      "subjects": [
        "Computational Complexity (cs.CC)",
        "Cellular Automata and Lattice Gases (nlin.CG)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 08:19:31 GMT",
          "size": "444kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Timed Prediction Problem for Sandpile Models",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on the computational complexity of a prediction problem in sandpile models and does not discuss any aspect of data processing for LLM training."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21086",
      "abstract": "This work introduces PeakNetFP, the first neural audio fingerprinting (AFP) system designed specifically around spectral peaks. This novel system is designed to leverage the sparse spectral coordinates typically computed by traditional peak-based AFP methods. PeakNetFP performs hierarchical point feature extraction techniques similar to the computer vision model PointNet++, and is trained using contrastive learning like in the state-of-the-art deep learning AFP, NeuralFP. This combination allows PeakNetFP to outperform conventional AFP systems and achieves comparable performance to NeuralFP when handling challenging time-stretched audio data. In extensive evaluation, PeakNetFP maintains a Top-1 hit rate of over 90% for stretching factors ranging from 50% to 200%. Moreover, PeakNetFP offers significant efficiency advantages: compared to NeuralFP, it has 100 times fewer parameters and uses 11 times smaller input data. These features make PeakNetFP a lightweight and efficient solution for AFP tasks where time stretching is involved. Overall, this system represents a promising direction for future AFP technologies, as it successfully merges the lightweight nature of peak-based AFP with the adaptability and pattern recognition capabilities of neural network-based approaches, paving the way for more scalable and efficient solutions in the field.",
      "authors": [
        "Guillem Cort\\`es-Sebasti\\`a and Benjamin Martin and Emilio Molina and Xavier Serra and Romain Hennequin"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21086",
        "HTML": "https://arxiv.org/html/2506.21086",
        "PDF": "https://arxiv.org/pdf/2506.21086"
      },
      "subjects": [
        "Sound (cs.SD)",
        "Information Retrieval (cs.IR)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 08:29:48 GMT",
          "size": "1031kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "PeakNetFP: Peak-based Neural Audio Fingerprinting Robust to Extreme Time Stretching",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The work is centered around audio fingerprinting and signal processing, specifically using neural network-based approaches, with no mention of LLM training data processing or engineering."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21091",
      "abstract": "Stereo matching has become an increasingly important component of modern autonomous systems. Developing deep learning-based stereo matching models that deliver high accuracy while operating in real-time continues to be a major challenge in computer vision. In the domain of cost-volume-based stereo matching, accurate disparity estimation depends heavily on large-scale cost volumes. However, such large volumes store substantial redundant information and also require computationally intensive aggregation units for processing and regression, making real-time performance unattainable. Conversely, small-scale cost volumes followed by lightweight aggregation units provide a promising route for real-time performance, but lack sufficient information to ensure highly accurate disparity estimation. To address this challenge, we propose the Enhanced Shuffle Mixer (ESM) to mitigate information loss associated with small-scale cost volumes. ESM restores critical details by integrating primary features into the disparity upsampling unit. It quickly extracts features from the initial disparity estimation and fuses them with image features. These features are mixed by shuffling and layer splitting then refined through a compact feature-guided hourglass network to recover more detailed scene geometry. The ESM focuses on local contextual connectivity with a large receptive field and low computational cost, leading to the reconstruction of a highly accurate disparity map at real-time. The compact version of ESMStereo achieves an inference speed of 116 FPS on high-end GPUs and 91 FPS on the AGX Orin.",
      "authors": [
        "Mahmoud Tahmasebi",
        "Saif Huq",
        "Kevin Meehan",
        "Marion McAfee"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21091",
        "HTML": "https://arxiv.org/html/2506.21091",
        "PDF": "https://arxiv.org/pdf/2506.21091"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 08:34:51 GMT",
          "size": "13549kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "ESMStereo: Enhanced ShuffleMixer Disparity Upsampling for Real-Time and Accurate Stereo Matching",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper deals with stereo matching for computer vision applications and does not address any LLM training data collection, construction, or processing tasks."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21093",
      "abstract": "Transformers have shown potential in solving wireless communication problems, particularly via in-context learning (ICL), where models adapt to new tasks through prompts without requiring model updates. However, prior ICL-based Transformer models rely on deep architectures with many layers to achieve satisfactory performance, resulting in substantial storage and computational costs. In this work, we propose CHain Of thOught Symbol dEtection (CHOOSE), a CoT-enhanced shallow Transformer framework for wireless symbol detection. By introducing autoregressive latent reasoning steps within the hidden space, CHOOSE significantly improves the reasoning capacity of shallow models (1-2 layers) without increasing model depth. This design enables lightweight Transformers to achieve detection performance comparable to much deeper models, making them well-suited for deployment on resource-constrained mobile devices. Experimental results demonstrate that our approach outperforms conventional shallow Transformers and achieves performance comparable to that of deep Transformers, while maintaining storage and computational efficiency. This represents a promising direction for implementing Transformer-based algorithms in wireless receivers with limited computational resources.",
      "authors": [
        "Li Fan",
        "Peng Wang",
        "Jing Yang",
        "Cong Shen"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21093",
        "HTML": "https://arxiv.org/html/2506.21093",
        "PDF": "https://arxiv.org/pdf/2506.21093"
      },
      "subjects": [
        "Machine Learning (cs.LG)",
        "Information Theory (cs.IT)",
        "Signal Processing (eess.SP)",
        "Information Theory (math.IT)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 08:41:45 GMT",
          "size": "2416kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Chain-of-Thought Enhanced Shallow Transformers for Wireless Symbol Detection",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper introduces a transformer framework for wireless symbol detection without discussing any training data processing or data engineering tasks related to LLMs."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21096",
      "abstract": "Previous multimodal sentence representation learning methods have achieved impressive performance. However, most approaches focus on aligning images and text at a coarse level, facing two critical challenges:cross-modal misalignment bias and intra-modal semantic divergence, which significantly degrade sentence representation quality. To address these challenges, we propose DALR (Dual-level Alignment Learning for Multimodal Sentence Representation). For cross-modal alignment, we propose a consistency learning module that softens negative samples and utilizes semantic similarity from an auxiliary task to achieve fine-grained cross-modal alignment. Additionally, we contend that sentence relationships go beyond binary positive-negative labels, exhibiting a more intricate ranking structure. To better capture these relationships and enhance representation quality, we integrate ranking distillation with global intra-modal alignment learning. Comprehensive experiments on semantic textual similarity (STS) and transfer (TR) tasks validate the effectiveness of our approach, consistently demonstrating its superiority over state-of-the-art baselines.",
      "authors": [
        "Kang He",
        "Yuzhe Ding. Haining Wang",
        "Fei Li",
        "Chong Teng",
        "Donghong Ji"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21096",
        "HTML": "https://arxiv.org/html/2506.21096",
        "PDF": "https://arxiv.org/pdf/2506.21096"
      },
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 08:45:14 GMT",
          "size": "2377kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "DALR: Dual-level Alignment Learning for Multimodal Sentence Representation Learning",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper discusses multimodal sentence representation learning with a focus on alignment techniques. It does not address aspects related to LLM training data processing or dataset engineering."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21098",
      "abstract": "Community Question Answering (CQA) platforms can be deemed as important knowledge bases in community, but effectively leveraging historical interactions and domain knowledge in real-time remains a challenge. Existing methods often underutilize external knowledge, fail to incorporate dynamic historical QA context, or lack memory mechanisms suited for industrial deployment. We propose ComRAG, a retrieval-augmented generation framework for real-time industrial CQA that integrates static knowledge with dynamic historical QA pairs via a centroid-based memory mechanism designed for retrieval, generation, and efficient storage. Evaluated on three industrial CQA datasets, ComRAG consistently outperforms all baselines--achieving up to 25.9% improvement in vector similarity, reducing latency by 8.7% to 23.3%, and lowering chunk growth from 20.23% to 2.06% over iterations.",
      "authors": [
        "Qinwen Chen",
        "Wenbiao Tao",
        "Zhiwei Zhu",
        "Mingfan Xi",
        "Liangzhong Guo",
        "Yuan Wang",
        "Wei Wang",
        "Yunshi Lan"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21098",
        "HTML": "https://arxiv.org/html/2506.21098",
        "PDF": "https://arxiv.org/pdf/2506.21098"
      },
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 08:48:16 GMT",
          "size": "675kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "ComRAG: Retrieval-Augmented Generation with Dynamic Vector Stores for Real-time Community Question Answering in Industry",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This research proposes a framework for community question answering using retrieval-augmented generation, focusing on memory mechanisms. It does not address the collection, processing, or engineering of training data for LLMs."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21101",
      "abstract": "As one of the earliest ancient languages, Oracle Bone Script (OBS) encapsulates the cultural records and intellectual expressions of ancient civilizations. Despite the discovery of approximately 4,500 OBS characters, only about 1,600 have been deciphered. The remaining undeciphered ones, with their complex structure and abstract imagery, pose significant challenges for interpretation. To address these challenges, this paper proposes a novel two-stage semantic typography framework, named OracleFusion. In the first stage, this approach leverages the Multimodal Large Language Model (MLLM) with enhanced Spatial Awareness Reasoning (SAR) to analyze the glyph structure of the OBS character and perform visual localization of key components. In the second stage, we introduce Oracle Structural Vector Fusion (OSVF), incorporating glyph structure constraints and glyph maintenance constraints to ensure the accurate generation of semantically enriched vector fonts. This approach preserves the objective integrity of the glyph structure, offering visually enhanced representations that assist experts in deciphering OBS. Extensive qualitative and quantitative experiments demonstrate that OracleFusion outperforms state-of-the-art baseline models in terms of semantics, visual appeal, and glyph maintenance, significantly enhancing both readability and aesthetic quality. Furthermore, OracleFusion provides expert-like insights on unseen oracle characters, making it a valuable tool for advancing the decipherment of OBS.",
      "authors": [
        "Caoshuo Li",
        "Zengmao Ding",
        "Xiaobin Hu",
        "Bang Li",
        "Donghao Luo",
        "AndyPian Wu",
        "Chaoyang Wang",
        "Chengjie Wang",
        "Taisong Jin",
        "SevenShu",
        "Yunsheng Wu",
        "Yongge Liu",
        "Rongrong Ji"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21101",
        "HTML": "https://arxiv.org/html/2506.21101",
        "PDF": "https://arxiv.org/pdf/2506.21101"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 08:56:07 GMT",
          "size": "28194kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "OracleFusion: Assisting the Decipherment of Oracle Bone Script with Structurally Constrained Semantic Typography",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper is about deciphering Oracle Bone Script using semantic typography and multimodal models, focusing on glyph structure. It does not pertain to the processing of LLM training data."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21102",
      "abstract": "Concept-Based Models (CBMs) are a class of deep learning models that provide interpretability by explaining predictions through high-level concepts. These models first predict concepts and then use them to perform a downstream task. However, current CBMs offer interpretability only for the final task prediction, while the concept predictions themselves are typically made via black-box neural networks. To address this limitation, we propose Hierarchical Concept Memory Reasoner (H-CMR), a new CBM that provides interpretability for both concept and task predictions. H-CMR models relationships between concepts using a learned directed acyclic graph, where edges represent logic rules that define concepts in terms of other concepts. During inference, H-CMR employs a neural attention mechanism to select a subset of these rules, which are then applied hierarchically to predict all concepts and the final task. Experimental results demonstrate that H-CMR matches state-of-the-art performance while enabling strong human interaction through concept and model interventions. The former can significantly improve accuracy at inference time, while the latter can enhance data efficiency during training when background knowledge is available.",
      "authors": [
        "David Debot",
        "Pietro Barbiero",
        "Gabriele Dominici",
        "Giuseppe Marra"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21102",
        "HTML": "https://arxiv.org/html/2506.21102",
        "PDF": "https://arxiv.org/pdf/2506.21102"
      },
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 08:56:55 GMT",
          "size": "104kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Interpretable Hierarchical Concept Reasoning through Attention-Guided Graph Learning",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This work focuses on interpretable models and concept reasoning with graph learning. It does not involve LLM training data processing or data engineering tasks relevant to LLMs."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21103",
      "abstract": "Conditional computation is a popular strategy to make Transformers more efficient. Existing methods often target individual modules (e.g., mixture-of-experts layers) or skip layers independently of one another. However, interpretability research has demonstrated that the middle layers of Transformers exhibit greater redundancy, and that early layers aggregate information into token positions. Guided by these insights, we propose a novel architecture that dynamically skips a variable number of layers from the middle outward. In particular, a learned gating mechanism determines whether to bypass a symmetric span of central blocks based on the input, and a gated attention mechanism prevents subsequent tokens from attending to skipped token positions. Residual norms are controlled with a 'sandwich' or 'perilayernorm' scheme and gate sparsity with an adaptive regularization loss. We had aimed to reduce compute requirements for 'simpler' tokens and potentially foster an emergent multi-level representational hierarchy but, at the scales investigated, our approach does not achieve improvements in the trade-off between validation cross-entropy and estimated FLOPs compared to dense baselines with fewer layers. We release our code at https://github.com/tim-lawson/skip-middle.",
      "authors": [
        "Tim Lawson",
        "Laurence Aitchison"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21103",
        "HTML": "https://arxiv.org/html/2506.21103",
        "PDF": "https://arxiv.org/pdf/2506.21103"
      },
      "subjects": [
        "Machine Learning (cs.LG)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 09:01:19 GMT",
          "size": "69kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Learning to Skip the Middle Layers of Transformers",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on a novel architecture for improving the efficiency of transformers by skipping middle layers. It does not discuss any aspects related to the training data processing or data engineering for LLMs."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21104",
      "abstract": "Time-evolving perforated domains arise in many engineering and geoscientific applications, including reactive transport, particle deposition, and structural degradation in porous media. Accurately capturing the macroscopic behavior of such systems poses significant computational challenges due to the dynamic fine-scale geometries. In this paper, we develop a robust and generalizable multiscale modeling framework based on multicontinuum homogenization to derive effective macroscopic equations in shrinking domains. The method distinguishes multiple continua according to the physical characteristics (e.g., channel widths), and couples them via space-time local cell problems formulated on representative volume elements. These local problems incorporate temporal derivatives and domain evolution, ensuring consistency with underlying fine-scale dynamics. The resulting upscaled system yields computable macroscopic coefficients and is suitable for large-scale simulations. Several numerical experiments are presented to validate the accuracy, efficiency, and potential applicability of the method to complex time-dependent engineering problems.",
      "authors": [
        "Wei Xie",
        "Viet Ha Hoang",
        "Yin Yang",
        "Yunqing Huang"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21104",
        "HTML": "https://arxiv.org/html/2506.21104",
        "PDF": "https://arxiv.org/pdf/2506.21104"
      },
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 09:01:53 GMT",
          "size": "933kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Robust space-time multiscale upscaling via multicontinuum homogenization for evolving perforated media",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper is about a multiscale modeling framework for evolving perforated media. There are no mentions of LLM training data processing, construction, or enhancement."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21106",
      "abstract": "Phishing attacks pose a significant cybersecurity threat, evolving rapidly to bypass detection mechanisms and exploit human vulnerabilities. This paper introduces PhishKey to address the challenges of adaptability, robustness, and efficiency. PhishKey is a novel phishing detection method using automatic feature extraction from hybrid sources. PhishKey combines character-level processing with Convolutional Neural Networks (CNN) for URL classification, and a Centroid-Based Key Component Phishing Extractor (CAPE) for HTML content at the word level. CAPE reduces noise and ensures complete sample processing avoiding crop operations on the input data. The predictions from both modules are integrated using a soft-voting ensemble to achieve more accurate and reliable classifications. Experimental evaluations on four state-of-the-art datasets demonstrate the effectiveness of PhishKey. It achieves up to 98.70% F1 Score and shows strong resistance to adversarial manipulations such as injection attacks with minimal performance degradation.",
      "authors": [
        "Felipe Casta\\~no",
        "Eduardo Fidalgo",
        "Enrique Alegre",
        "Rocio Alaiz-Rodr\\'iguez",
        "Raul Orduna and Francesco Zola"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21106",
        "HTML": "https://arxiv.org/html/2506.21106",
        "PDF": "https://arxiv.org/pdf/2506.21106"
      },
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 09:04:55 GMT",
          "size": "254kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "PhishKey: A Novel Centroid-Based Approach for Enhanced Phishing Detection Using Adaptive HTML Component Extraction",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The work introduces a phishing detection method using CNNs, focusing on feature extraction and classification. There is no discussion related to LLM or its training data processing."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21107",
      "abstract": "Estimating single-cell responses across various perturbations facilitates the identification of key genes and enhances drug screening, significantly boosting experimental efficiency. However, single-cell sequencing is a destructive process, making it impossible to capture the same cell's phenotype before and after perturbation. Consequently, data collected under perturbed and unperturbed conditions are inherently unpaired. Existing methods either attempt to forcibly pair unpaired data using random sampling, or neglect the inherent relationship between unperturbed and perturbed cells during the modeling. In this work, we propose a framework based on Dual Diffusion Implicit Bridges (DDIB) to learn the mapping between different data distributions, effectively addressing the challenge of unpaired data. We further interpret this framework as a form of data augmentation. We integrate gene regulatory network (GRN) information to propagate perturbation signals in a biologically meaningful way, and further incorporate a masking mechanism to predict silent genes, improving the quality of generated profiles. Moreover, gene expression under the same perturbation often varies significantly across cells, frequently exhibiting a bimodal distribution that reflects intrinsic heterogeneity. To capture this, we introduce a more suitable evaluation metric. We propose Unlasting, dual conditional diffusion models that overcome the problem of unpaired single-cell perturbation data and strengthen the model's insight into perturbations under the guidance of the GRN, with a dedicated mask model designed to improve generation quality by predicting silent genes. In addition, we introduce a biologically grounded evaluation metric that better reflects the inherent heterogeneity in single-cell responses.",
      "authors": [
        "Changxi Chi and Jun Xia and Yufei Huang and Jingbo Zhou and Siyuan Li and Yunfan Liu and Chang Yu and Stan Z. Li"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21107",
        "HTML": "https://arxiv.org/html/2506.21107",
        "PDF": "https://arxiv.org/pdf/2506.21107"
      },
      "subjects": [
        "Machine Learning (cs.LG)",
        "Molecular Networks (q-bio.MN)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 09:05:38 GMT",
          "size": "584kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Unlasting: Unpaired Single-Cell Multi-Perturbation Estimation by Dual Conditional Diffusion Implicit Bridges",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper proposes a framework for single-cell data estimation using dual diffusion models. It does not address any topics related to LLM training data or its processing."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21109",
      "abstract": "Remote sensing change detection is essential for monitoring urban expansion, disaster assessment, and resource management, offering timely, accurate, and large-scale insights into dynamic landscape transformations. While deep learning has revolutionized change detection, the increasing complexity and computational demands of modern models have not necessarily translated into significant accuracy gains. Instead of following this trend, this study explores a more efficient approach, focusing on lightweight models that maintain high accuracy while minimizing resource consumption, which is an essential requirement for on-satellite processing. To this end, we propose FlickCD, which means quick flick then get great results, pushing the boundaries of the performance-resource trade-off. FlickCD introduces an Enhanced Difference Module (EDM) to amplify critical feature differences between temporal phases while suppressing irrelevant variations such as lighting and weather changes, thereby reducing computational costs in the subsequent change decoder. Additionally, the FlickCD decoder incorporates Local-Global Fusion Blocks, leveraging Shifted Window Self-Attention (SWSA) and Enhanced Global Self-Attention (EGSA) to efficiently capture semantic information at multiple scales, preserving both coarse- and fine-grained changes. Extensive experiments on four benchmark datasets demonstrate that FlickCD reduces computational and storage overheads by more than an order of magnitude while achieving state-of-the-art (SOTA) performance or incurring only a minor (<1\\% F1) accuracy trade-off. The implementation code is publicly available at https://github.com/xulsh8/FlickCD.",
      "authors": [
        "Luosheng Xu",
        "Dalin Zhang",
        "Zhaohui Song"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21109",
        "HTML": "https://arxiv.org/html/2506.21109",
        "PDF": "https://arxiv.org/pdf/2506.21109"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 09:06:52 GMT",
          "size": "3609kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Pushing Trade-Off Boundaries: Compact yet Effective Remote Sensing Change Detection",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The research emphasizes efficient change detection in remote sensing using lightweight models. There is no content relevant to LLM training data processing."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21117",
      "abstract": "In dynamic 3D environments, accurately updating scene representations over time is crucial for applications in robotics, mixed reality, and embodied AI. As scenes evolve, efficient methods to incorporate changes are needed to maintain up-to-date, high-quality reconstructions without the computational overhead of re-optimizing the entire scene. This paper introduces CL-Splats, which incrementally updates Gaussian splatting-based 3D representations from sparse scene captures. CL-Splats integrates a robust change-detection module that segments updated and static components within the scene, enabling focused, local optimization that avoids unnecessary re-computation. Moreover, CL-Splats supports storing and recovering previous scene states, facilitating temporal segmentation and new scene-analysis applications. Our extensive experiments demonstrate that CL-Splats achieves efficient updates with improved reconstruction quality over the state-of-the-art. This establishes a robust foundation for future real-time adaptation in 3D scene reconstruction tasks.",
      "authors": [
        "Jan Ackermann",
        "Jonas Kulhanek",
        "Shengqu Cai",
        "Haofei Xu",
        "Marc Pollefeys",
        "Gordon Wetzstein",
        "Leonidas Guibas",
        "Songyou Peng"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21117",
        "HTML": "https://arxiv.org/html/2506.21117",
        "PDF": "https://arxiv.org/pdf/2506.21117"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 09:32:37 GMT",
          "size": "7070kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "CL-Splats: Continual Learning of Gaussian Splatting with Local Optimization",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on dynamic 3D scene representation and reconstruction using Gaussian splatting, which is unrelated to the collection or processing of training data for LLMs."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21118",
      "abstract": "Lipschitz continuity of algorithms, introduced by Kumabe and Yoshida (FOCS'23), measures the stability of an algorithm against small input perturbations. Algorithms with small Lipschitz continuity are desirable, as they ensure reliable decision-making and reproducible scientific research. Several studies have proposed Lipschitz continuous algorithms for various combinatorial optimization problems, but these algorithms are problem-specific, requiring a separate design for each problem.\n  To address this issue, we provide the first algorithmic meta-theorem in the field of Lipschitz continuous algorithms. Our result can be seen as a Lipschitz continuous analogue of Courcelle's theorem, which offers Lipschitz continuous algorithms for problems on bounded-treewidth graphs. Specifically, we consider the problem of finding a vertex set in a graph that maximizes or minimizes the total weight, subject to constraints expressed in monadic second-order logic (MSO_2). We show that for any $\\varepsilon>0$, there exists a $(1\\pm \\varepsilon)$-approximation algorithm for the problem with a polylogarithmic Lipschitz constant on bounded treewidth graphs. On such graphs, our result outperforms most existing Lipschitz continuous algorithms in terms of approximability and/or Lipschitz continuity. Further, we provide similar results for problems on bounded-clique-width graphs subject to constraints expressed in MSO_1. Additionally, we construct a Lipschitz continuous version of Baker's decomposition using our meta-theorem as a subroutine.",
      "authors": [
        "Tatsuya Gima",
        "Soh Kumabe",
        "and Yuichi Yoshida"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21118",
        "HTML": "https://arxiv.org/html/2506.21118",
        "PDF": "https://arxiv.org/pdf/2506.21118"
      },
      "subjects": [
        "Data Structures and Algorithms (cs.DS)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 09:34:09 GMT",
          "size": "254kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Courcelle's Theorem for Lipschitz Continuity",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This work is about developing an algorithmic framework for Lipschitz continuity within graph-theoretical problems and does not relate to LLM training data processing or collection."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21121",
      "abstract": "Trajectory prediction for surrounding agents is a challenging task in autonomous driving due to its inherent uncertainty and underlying multimodality. Unlike prevailing data-driven methods that primarily rely on supervised learning, in this paper, we introduce a novel Graph-oriented Inverse Reinforcement Learning (GoIRL) framework, which is an IRL-based predictor equipped with vectorized context representations. We develop a feature adaptor to effectively aggregate lane-graph features into grid space, enabling seamless integration with the maximum entropy IRL paradigm to infer the reward distribution and obtain the policy that can be sampled to induce multiple plausible plans. Furthermore, conditioned on the sampled plans, we implement a hierarchical parameterized trajectory generator with a refinement module to enhance prediction accuracy and a probability fusion strategy to boost prediction confidence. Extensive experimental results showcase our approach not only achieves state-of-the-art performance on the large-scale Argoverse & nuScenes motion forecasting benchmarks but also exhibits superior generalization abilities compared to existing supervised models.",
      "authors": [
        "Muleilan Pei",
        "Shaoshuai Shi",
        "Lu Zhang",
        "Peiliang Li",
        "Shaojie Shen"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21121",
        "HTML": "https://arxiv.org/html/2506.21121",
        "PDF": "https://arxiv.org/pdf/2506.21121"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 09:46:53 GMT",
          "size": "2270kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "GoIRL: Graph-Oriented Inverse Reinforcement Learning for Multimodal Trajectory Prediction",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The focus is on a novel method for trajectory prediction in autonomous driving, utilizing inverse reinforcement learning, without any mention of LLM training data collection or processing."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21126",
      "abstract": "Artificial intelligence (AI) substantially enhances channel state information (CSI) acquisition performance but is limited by its reliance on single-modality information and deployment challenges, particularly in dataset collection. This paper investigates the use of semantic-aware digital twin (DT) to enhance AI-based CSI acquisition. We first briefly introduce the motivation and recent advancements in AI-driven CSI acquisition and semantic-aware DT employment for air interfaces. Then, we thoroughly explore how semantic-aware DT can bolster AI-based CSI acquisition. We categorizes the semantic-aware DT for AI-based CSI acquisition into two classes: enhancing AI-based CSI acquisition through integration with DT and using DT to aid AI-based CSI deployment. Potential integration frameworks are introduced in detail. Finally, we conclude by outlining potential research directions within the semantic-aware DT-assisted AI-based CSI acquisition.",
      "authors": [
        "Jiajia Guo",
        "Yiming Cui",
        "Shi Jin"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21126",
        "HTML": "https://arxiv.org/html/2506.21126",
        "PDF": "https://arxiv.org/pdf/2506.21126"
      },
      "subjects": [
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 09:59:26 GMT",
          "size": "839kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Semantic-aware Digital Twin for AI-based CSI Acquisition",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper discusses enhancing AI-based CSI acquisition through semantic-aware digital twins, with no relevance to LLM training data processing or data engineering."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21127",
      "abstract": "The increasing automation of navigation for unmanned aerial vehicles (UAVs) has exposed them to adversarial attacks that exploit vulnerabilities in reinforcement learning (RL) through sensor manipulation. Although existing robust RL methods aim to mitigate such threats, their effectiveness has limited generalization to out-of-distribution shifts from the optimal value distribution, as they are primarily designed to handle fixed perturbation. To address this limitation, this paper introduces an antifragile RL framework that enhances adaptability to broader distributional shifts by incorporating a switching mechanism based on discounted Thompson sampling (DTS). This mechanism dynamically selects among multiple robust policies to minimize adversarially induced state-action-value distribution shifts. The proposed approach first derives a diverse ensemble of action robust policies by accounting for a range of perturbations in the policy space. These policies are then modeled as a multiarmed bandit (MAB) problem, where DTS optimally selects policies in response to nonstationary Bernoulli rewards, effectively adapting to evolving adversarial strategies. Theoretical framework has also been provided where by optimizing the DTS to minimize the overall regrets due to distributional shift, results in effective adaptation against unseen adversarial attacks thus inducing antifragility. Extensive numerical simulations validate the effectiveness of the proposed framework in complex navigation environments with multiple dynamic three-dimensional obstacles and with stronger projected gradient descent (PGD) and spoofing attacks. Compared to conventional robust, non-adaptive RL methods, the antifragile approach achieves superior performance, demonstrating shorter navigation path lengths and a higher rate of conflict-free navigation trajectories compared to existing robust RL techniques",
      "authors": [
        "Deepak Kumar Panda and Weisi Guo"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21127",
        "HTML": "https://arxiv.org/html/2506.21127",
        "PDF": "https://arxiv.org/pdf/2506.21127"
      },
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 10:06:29 GMT",
          "size": "792kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Robust Policy Switching for Antifragile Reinforcement Learning for UAV Deconfliction in Adversarial Environments",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper introduces an antifragile RL framework for UAV deconfliction in adversarial environments, which does not relate to LLM training data processing or data engineering."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21129",
      "abstract": "Reinforcement learning (RL) policies deployed in safety-critical systems, such as unmanned aerial vehicle (UAV) navigation in dynamic airspace, are vulnerable to out-ofdistribution (OOD) adversarial attacks in the observation space. These attacks induce distributional shifts that significantly degrade value estimation, leading to unsafe or suboptimal decision making rendering the existing policy fragile. To address this vulnerability, we propose an antifragile RL framework designed to adapt against curriculum of incremental adversarial perturbations. The framework introduces a simulated attacker which incrementally increases the strength of observation-space perturbations which enables the RL agent to adapt and generalize across a wider range of OOD observations and anticipate previously unseen attacks. We begin with a theoretical characterization of fragility, formally defining catastrophic forgetting as a monotonic divergence in value function distributions with increasing perturbation strength. Building on this, we define antifragility as the boundedness of such value shifts and derive adaptation conditions under which forgetting is stabilized. Our method enforces these bounds through iterative expert-guided critic alignment using Wasserstein distance minimization across incrementally perturbed observations. We empirically evaluate the approach in a UAV deconfliction scenario involving dynamic 3D obstacles. Results show that the antifragile policy consistently outperforms standard and robust RL baselines when subjected to both projected gradient descent (PGD) and GPS spoofing attacks, achieving up to 15% higher cumulative reward and over 30% fewer conflict events. These findings demonstrate the practical and theoretical viability of antifragile reinforcement learning for secure and resilient decision-making in environments with evolving threat scenarios.",
      "authors": [
        "Deepak Kumar Panda",
        "Adolfo Perrusquia and Weisi Guo"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21129",
        "HTML": "https://arxiv.org/html/2506.21129",
        "PDF": "https://arxiv.org/pdf/2506.21129"
      },
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 10:10:41 GMT",
          "size": "620kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Curriculum-Guided Antifragile Reinforcement Learning for Secure UAV Deconfliction under Observation-Space Attacks",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The research proposes an antifragile RL method for securing UAV navigation under observation-space attacks, with no connection to LLM training data processes."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21132",
      "abstract": "Learning-based methods have made promising advances in low-light RAW image enhancement, while their capability to extremely dark scenes where the environmental illuminance drops as low as 0.0001 lux remains to be explored due to the lack of corresponding datasets. To this end, we propose a paired-to-paired data synthesis pipeline capable of generating well-calibrated extremely low-light RAW images at three precise illuminance ranges of 0.01-0.1 lux, 0.001-0.01 lux, and 0.0001-0.001 lux, together with high-quality sRGB references to comprise a large-scale paired dataset named See-in-the-Extremely-Dark (SIED) to benchmark low-light RAW image enhancement approaches. Furthermore, we propose a diffusion-based framework that leverages the generative ability and intrinsic denoising property of diffusion models to restore visually pleasing results from extremely low-SNR RAW inputs, in which an Adaptive Illumination Correction Module (AICM) and a color consistency loss are introduced to ensure accurate exposure correction and color restoration. Extensive experiments on the proposed SIED and publicly available benchmarks demonstrate the effectiveness of our method. The code and dataset are available at https://github.com/JianghaiSCU/SIED.",
      "authors": [
        "Hai Jiang",
        "Binhao Guan",
        "Zhen Liu",
        "Xiaohong Liu",
        "Jian Yu",
        "Zheng Liu",
        "Songchen Han",
        "Shuaicheng Liu"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21132",
        "HTML": "https://arxiv.org/html/2506.21132",
        "PDF": "https://arxiv.org/pdf/2506.21132"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 10:24:07 GMT",
          "size": "10327kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Learning to See in the Extremely Dark",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This work presents a data synthesis pipeline for low-light RAW image enhancement, unrelated to LLM training data collection or processing methods."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21134",
      "abstract": "Kubernetes has emerged as the de facto standard for container orchestration. Unfortunately, its increasing popularity has also made it an attractive target for malicious actors. Despite extensive research on securing Kubernetes, little attention has been paid to the impact of network configuration on the security of application deployments. This paper addresses this gap by conducting a comprehensive analysis of network misconfigurations in a Kubernetes cluster with specific reference to lateral movement. Accordingly, we carried out an extensive evaluation of 287 open-source applications belonging to six different organizations, ranging from IT companies and public entities to non-profits. As a result, we identified 634 misconfigurations, well beyond what could be found by solutions in the state of the art. We responsibly disclosed our findings to the concerned organizations and engaged in a discussion to assess their severity. As of now, misconfigurations affecting more than thirty applications have been fixed with the mitigations we proposed.",
      "authors": [
        "Jacopo Bufalino",
        "Jose Luis Martin-Navarro",
        "Mario Di Francesco and Tuomas Aura"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21134",
        "HTML": "https://arxiv.org/html/2506.21134",
        "PDF": "https://arxiv.org/pdf/2506.21134"
      },
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Networking and Internet Architecture (cs.NI)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 10:31:44 GMT",
          "size": "1463kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Inside Job: Defending Kubernetes Clusters Against Network Misconfigurations",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on network misconfigurations in Kubernetes clusters, which is unrelated to training data processing for large language models."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21135",
      "abstract": "Surface defect detection in industrial scenarios is both crucial and technically demanding due to the wide variability in defect types, irregular shapes and sizes, fine-grained requirements, and complex material textures. Although recent advances in AI-based detectors have improved performance, existing methods often suffer from redundant features, limited detail sensitivity, and weak robustness under multiscale conditions. To address these challenges, we propose YOLO-FDA, a novel YOLO-based detection framework that integrates fine-grained detail enhancement and attention-guided feature fusion. Specifically, we adopt a BiFPN-style architecture to strengthen bidirectional multilevel feature aggregation within the YOLOv5 backbone. To better capture fine structural changes, we introduce a Detail-directional Fusion Module (DDFM) that introduces a directional asymmetric convolution in the second-lowest layer to enrich spatial details and fuses the second-lowest layer with low-level features to enhance semantic consistency. Furthermore, we propose two novel attention-based fusion strategies, Attention-weighted Concatenation (AC) and Cross-layer Attention Fusion (CAF) to improve contextual representation and reduce feature noise. Extensive experiments on benchmark datasets demonstrate that YOLO-FDA consistently outperforms existing state-of-the-art methods in terms of both accuracy and robustness across diverse types of defects and scales.",
      "authors": [
        "Jiawei Hu"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21135",
        "HTML": "https://arxiv.org/html/2506.21135",
        "PDF": "https://arxiv.org/pdf/2506.21135"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 10:32:37 GMT",
          "size": "899kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "YOLO-FDA: Integrating Hierarchical Attention and Detail Enhancement for Surface Defect Detection",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper addresses surface defect detection using a novel detection framework, which does not involve processing training data for large language models."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21137",
      "abstract": "Linear attention has emerged as a viable alternative to softmax attention by reducing complexity from quadratic to linear in sequence length. To preserve two fundamental properties of softmax, non-negativity and entropy reduction, current works employ various linearly separatable kernel functions with $L1$ normalization instead of softmax operator. However, query norms are neglected by the normalization operation in linear attention, such degradation heavily leads to an entropy gap. Meanwhile, existing works inhibit negative values of query and key vectors resulting in a missing inner-product interactions after being mapped. To address these dual challenges, we propose a novel Norm-Aware Linear Attention mechanism serving to restore norm-guided dynamic spikiness and recover kernel-perturbed norm distributions. Specifically, we first decouple query and key matrices into two components: norm and direction, to achieve norm-aware spikiness control and norm consistency, respectively. We mathematically reveal that the extent of entropy reduction varies with the query norm in softmax normalization, motivating a query-norm aware kernel function for dynamic control over entropy reduction. Furthermore, to ensure norm consistency and enforce non-negativity constraints, we employ a norm-preserving mapping to project all elements of the angular matrix into positive values, leveraging cosine similarity to inhibit dimensions with opposite directions. We conduct extensive experiments demonstrating that the NaLaFormer improves performance on vision and language tasks, enhancing both expressiveness and efficiency by up to 4.2\\%.",
      "authors": [
        "Weikang Meng",
        "Yadan Luo",
        "Liangyu Huo",
        "Yaowei Wang",
        "Xin Li",
        "Zheng Zhang"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21137",
        "HTML": "https://arxiv.org/html/2506.21137",
        "PDF": "https://arxiv.org/pdf/2506.21137"
      },
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 10:47:39 GMT",
          "size": "2192kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "NaLaFormer: Norm-Aware Linear Attention for Transformer Models",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper discusses improvements in transformer model architecture through linear attention, not involving the processing of training data for LLMs."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21140",
      "abstract": "Electroencephalography (EEG)-based brain-computer interfaces (BCIs) transform spontaneous/evoked neural activity into control commands for external communication. While convolutional neural networks (CNNs) remain the mainstream backbone for EEG decoding, their inherently short receptive field makes it difficult to capture long-range temporal dependencies and global inter-channel relationships. Recent CNN-Transformer (Conformers) hybrids partially address this issue, but most adopt a serial design, resulting in suboptimal integration of local and global features, and often overlook explicit channel-wise modeling. To address these limitations, we propose DBConformer, a dual-branch convolutional Transformer network tailored for EEG decoding. It integrates a temporal Conformer to model long-range temporal dependencies and a spatial Conformer to extract inter-channel interactions, capturing both temporal dynamics and spatial patterns in EEG signals. A lightweight channel attention module further refines spatial representations by assigning data-driven importance to EEG channels. Extensive experiments on five motor imagery (MI) datasets and two seizure detection datasets under three evaluation settings demonstrate that DBConformer consistently outperforms 10 competitive baseline models, with over eight times fewer parameters than the high-capacity EEG Conformer baseline. Further, the visualization results confirm that the features extracted by DBConformer are physiologically interpretable and aligned with sensorimotor priors in MI. The superior performance and interpretability of DBConformer make it reliable for robust and explainable EEG decoding. Code is publicized at https://github.com/wzwvv/DBConformer.",
      "authors": [
        "Ziwei Wang",
        "Hongbin Wang",
        "Tianwang Jia",
        "Xingyi He",
        "Siyang Li",
        "and Dongrui Wu"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21140",
        "HTML": "https://arxiv.org/html/2506.21140",
        "PDF": "https://arxiv.org/pdf/2506.21140"
      },
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 10:53:24 GMT",
          "size": "10938kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "DBConformer: Dual-Branch Convolutional Transformer for EEG Decoding",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper proposes a model for EEG decoding, focusing on architecture design, without addressing aspects of LLM training data collection or processing."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21142",
      "abstract": "The growing integration of UAVs into civilian airspace underscores the need for resilient and intelligent intrusion detection systems (IDS), as traditional anomaly detection methods often fail to identify novel threats. A common approach treats unfamiliar attacks as out-of-distribution (OOD) samples; however, this leaves systems vulnerable when mitigation is inadequate. Moreover, conventional OOD detectors struggle to distinguish stealthy adversarial attacks from genuine OOD events. This paper introduces a conditional generative adversarial network (cGAN)-based framework for crafting stealthy adversarial attacks that evade IDS mechanisms. We first design a robust multi-class IDS classifier trained on benign UAV telemetry and known cyber-attacks, including Denial of Service (DoS), false data injection (FDI), man-in-the-middle (MiTM), and replay attacks. Using this classifier, our cGAN perturbs known attacks to generate adversarial samples that misclassify as benign while retaining statistical resemblance to OOD distributions. These adversarial samples are iteratively refined to achieve high stealth and success rates. To detect such perturbations, we implement a conditional variational autoencoder (CVAE), leveraging negative log-likelihood to separate adversarial inputs from authentic OOD samples. Comparative evaluation shows that CVAE-based regret scores significantly outperform traditional Mahalanobis distance-based detectors in identifying stealthy adversarial threats. Our findings emphasize the importance of advanced probabilistic modeling to strengthen IDS capabilities against adaptive, generative-model-based cyber intrusions.",
      "authors": [
        "Deepak Kumar Panda and Weisi Guo"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21142",
        "HTML": "https://arxiv.org/html/2506.21142",
        "PDF": "https://arxiv.org/pdf/2506.21142"
      },
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 10:56:34 GMT",
          "size": "2094kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Generative Adversarial Evasion and Out-of-Distribution Detection for UAV Cyber-Attacks",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper primarily focuses on UAV intrusion detection systems using adversarial attack generation. It does not address the processing of training data for large language models."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21144",
      "abstract": "Federated learning (FL) enables collaborative model training across decentralized clients without sharing local data, but is challenged by heterogeneity in data, computation, and communication. Pretrained vision-language models (VLMs), with their strong generalization and lightweight tuning via prompts, offer a promising solution. However, existing federated prompt-learning methods rely only on text prompts and overlook joint label-domain distribution shifts. In this paper, we propose a personalized FL framework based on dual-prompt learning and cross fusion, termed pFedDC. Specifically, each client maintains both global and local prompts across vision and language modalities: global prompts capture common knowledge shared across the federation, while local prompts encode client-specific semantics and domain characteristics. Meanwhile, a cross-fusion module is designed to adaptively integrate prompts from different levels, enabling the model to generate personalized representations aligned with each client's unique data distribution. Extensive experiments across nine datasets with various types of heterogeneity show that pFedDC consistently outperforms state-of-the-art methods.",
      "authors": [
        "Yuguang Zhang",
        "Kuangpu Guo",
        "Zhihe Lu",
        "Yunbo Wang and Jian Liang"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21144",
        "HTML": "https://arxiv.org/html/2506.21144",
        "PDF": "https://arxiv.org/pdf/2506.21144"
      },
      "subjects": [
        "Machine Learning (cs.LG)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 10:59:14 GMT",
          "size": "254kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Personalized Federated Learning via Dual-Prompt Optimization and Cross Fusion",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper discusses federated learning with vision-language models and prompt learning, but does not contribute specifically to LLM data processing or training data."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21146",
      "abstract": "In neural network compression, most current methods reduce unnecessary parameters by measuring importance and redundancy. To augment already highly optimized existing solutions, we propose linearity-based compression as a novel way to reduce weights in a neural network. It is based on the intuition that with ReLU-like activation functions, neurons that are almost always activated behave linearly, allowing for merging of subsequent layers. We introduce the theory underlying this compression and evaluate our approach experimentally. Our novel method achieves a lossless compression down to 1/4 of the original model size in over the majority of tested models. Applying our method on already importance-based pruned models shows very little interference between different types of compression, demonstrating the option of successful combination of techniques. Overall, our work lays the foundation for a new type of compression method that enables smaller and ultimately more efficient neural network models.",
      "authors": [
        "Silas Dobler",
        "Florian Lemmerich"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21146",
        "HTML": "https://arxiv.org/html/2506.21146",
        "PDF": "https://arxiv.org/pdf/2506.21146"
      },
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 11:04:12 GMT",
          "size": "806kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Linearity-based neural network compression",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper deals with neural network compression techniques and does not address training data processing for large language models."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21149",
      "abstract": "Analyzing refutations of the well known 0pebbling formulas Peb$(G)$ we prove some new strong connections between pebble games and algebraic proof system, showing that there is a parallelism between the reversible, black and black-white pebbling games on one side, and the three algebraic proof systems Nullstellensatz, Monomial Calculus and Polynomial Calculus on the other side. In particular we prove that for any DAG $G$ with a single sink, if there is a Monomial Calculus refutation for Peb$(G)$ having simultaneously degree $s$ and size $t$ then there is a black pebbling strategy on $G$ with space $s$ and time $t+s$. Also if there is a black pebbling strategy for $G$ with space $s$ and time $t$ it is possible to extract from it a MC refutation for Peb$(G)$ having simultaneously degree $s$ and size $ts$. These results are analogous to those proven in {deRezende et al.21} for the case of reversible pebbling and Nullstellensatz. Using them we prove degree separations between NS, MC and PC, as well as strong degree-size tradeoffs for MC.\n  We also notice that for any directed acyclic graph $G$ the space needed in a pebbling strategy on $G$, for the three versions of the game, reversible, black and black-white, exactly matches the variable space complexity of a refutation of the corresponding pebbling formula Peb$(G)$ in each of the algebraic proof systems NS, MC and PC. Using known pebbling bounds on graphs, this connection implies separations between the corresponding variable space measures.",
      "authors": [
        "Lisa-Marie Jaser and Jacobo Toran"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21149",
        "HTML": "https://arxiv.org/html/2506.21149",
        "PDF": "https://arxiv.org/pdf/2506.21149"
      },
      "subjects": [
        "Logic in Computer Science (cs.LO)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 11:10:45 GMT",
          "size": "21kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Pebble Games and Algebraic Proof Systems",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The focus is on pebble games and algebraic proof systems, with no connection to LLM training data or processing methods mentioned."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21150",
      "abstract": "Hyperspectral imaging (HSI) shows great promise for surgical applications, offering detailed insights into biological tissue differences beyond what the naked eye can perceive. Refined labelling efforts are underway to train vision systems to distinguish large numbers of subtly varying classes. However, commonly used learning methods for biomedical segmentation tasks penalise all errors equivalently and thus fail to exploit any inter-class semantics in the label space. In this work, we introduce two tree-based semantic loss functions which take advantage of a hierarchical organisation of the labels. We further incorporate our losses in a recently proposed approach for training with sparse, background-free annotations. Extensive experiments demonstrate that our proposed method reaches state-of-the-art performance on a sparsely annotated HSI dataset comprising $107$ classes organised in a clinically-defined semantic tree structure. Furthermore, our method enables effective detection of out-of-distribution (OOD) pixels without compromising segmentation performance on in-distribution (ID) pixels.",
      "authors": [
        "Junwen Wang",
        "Oscar Maccormac",
        "William Rochford",
        "Aaron Kujawa",
        "Jonathan Shapey",
        "Tom Vercauteren"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21150",
        "HTML": "https://arxiv.org/html/2506.21150",
        "PDF": "https://arxiv.org/pdf/2506.21150"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 11:20:46 GMT",
          "size": "14736kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Tree-based Semantic Losses: Application to Sparsely-supervised Large Multi-class Hyperspectral Segmentation",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper applies tree-based semantic losses to hyperspectral segmentation but does not involve LLM data processing or training data construction."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21152",
      "abstract": "Generating realistic 3D objects from single-view images requires natural appearance, 3D consistency, and the ability to capture multiple plausible interpretations of unseen regions. Existing approaches often rely on fine-tuning pretrained 2D diffusion models or directly generating 3D information through fast network inference or 3D Gaussian Splatting, but their results generally suffer from poor multiview consistency and lack geometric detail. To takle these issues, we present a novel method that seamlessly integrates geometry and perception priors without requiring additional model training to reconstruct detailed 3D objects from a single image. Specifically, we train three different Gaussian branches initialized from the geometry prior, perception prior and Gaussian noise, respectively. The geometry prior captures the rough 3D shapes, while the perception prior utilizes the 2D pretrained diffusion model to enhance multiview information. Subsequently, we refine 3D Gaussian branches through mutual interaction between geometry and perception priors, further enhanced by a reprojection-based strategy that enforces depth consistency. Experiments demonstrate the higher-fidelity reconstruction results of our method, outperforming existing methods on novel view synthesis and 3D reconstruction, demonstrating robust and consistent 3D object generation.",
      "authors": [
        "Pufan Li",
        "Bi'an Du and Wei Hu"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21152",
        "HTML": "https://arxiv.org/html/2506.21152",
        "PDF": "https://arxiv.org/pdf/2506.21152"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 11:22:06 GMT",
          "size": "4643kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Geometry and Perception Guided Gaussians for Multiview-consistent 3D Generation from a Single Image",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper discusses methods for 3D object generation from images using Gaussians and perception priors, but does not address LLM training data processing or engineering."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21158",
      "abstract": "In many real-world applications, evaluating the goodness of instances is often costly and time-consuming, e.g., human feedback and physics simulations, in contrast to proposing new instances. In particular, this is even more critical in reinforcement learning, as new interactions with the environment (i.e., new instances) need to be evaluated to provide a reward signal to learn from. As sufficient exploration is crucial, learning from a diverse mini-batch can have a large impact and help mitigate mode collapse. In this paper, we introduce diverse mini-batch selection for reinforcement learning and propose to use determinantal point processes for this task. We study this framework in the context of a real-world problem, namely drug discovery. We experimentally study how our proposed framework can improve the effectiveness of chemical exploration in de novo drug design, where finding diverse and high-quality solutions is essential. We conduct a comprehensive evaluation with three well-established molecular generation oracles over numerous generative steps. Our experiments conclude that our diverse mini-batch selection framework can substantially improve the diversity of the solutions, while still obtaining solutions of high quality. In drug discovery, such outcome can potentially lead to fulfilling unmet medication needs faster.",
      "authors": [
        "Hampus Gummesson Svensson",
        "Ola Engkvist",
        "Jon Paul Janet",
        "Christian Tyrchan",
        "Morteza Haghir Chehreghani"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21158",
        "HTML": "https://arxiv.org/html/2506.21158",
        "PDF": "https://arxiv.org/pdf/2506.21158"
      },
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 11:31:30 GMT",
          "size": "14939kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Diverse Mini-Batch Selection in Reinforcement Learning for Efficient Chemical Exploration in de novo Drug Design",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The research focuses on reinforcement learning and diverse mini-batch selection for drug design, with no relation to LLM training data processing or data engineering."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21165",
      "abstract": "Learning semantic representations from point sets of 3D object shapes is often challenged by significant geometric variations, primarily due to differences in data acquisition methods. Typically, training data is generated using point simulators, while testing data is collected with distinct 3D sensors, leading to a simulation-to-reality (Sim2Real) domain gap that limits the generalization ability of point classifiers. Current unsupervised domain adaptation (UDA) techniques struggle with this gap, as they often lack robust, domain-insensitive descriptors capable of capturing global topological information, resulting in overfitting to the limited semantic patterns of the source domain. To address this issue, we introduce a novel Topology-Aware Modeling (TAM) framework for Sim2Real UDA on object point clouds. Our approach mitigates the domain gap by leveraging global spatial topology, characterized by low-level, high-frequency 3D structures, and by modeling the topological relations of local geometric features through a novel self-supervised learning task. Additionally, we propose an advanced self-training strategy that combines cross-domain contrastive learning with self-training, effectively reducing the impact of noisy pseudo-labels and enhancing the robustness of the adaptation process. Experimental results on three public Sim2Real benchmarks validate the effectiveness of our TAM framework, showing consistent improvements over state-of-the-art methods across all evaluated tasks. The source code of this work will be available at https://github.com/zou-longkun/TAG.git.",
      "authors": [
        "Longkun Zou",
        "Kangjun Liu",
        "Ke Chen",
        "Kailing Guo",
        "Kui Jia",
        "Yaowei Wang"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21165",
        "HTML": "https://arxiv.org/html/2506.21165",
        "PDF": "https://arxiv.org/pdf/2506.21165"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 11:53:59 GMT",
          "size": "5894kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Topology-Aware Modeling for Unsupervised Simulation-to-Reality Point Cloud Recognition",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on unsupervised domain adaptation for point cloud recognition, specifically addressing the simulation-to-reality gap. It does not discuss LLM training data, data engineering, or training-stage data processing."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21167",
      "abstract": "Identifying instrument activities within audio excerpts is vital in music information retrieval, with significant implications for music cataloging and discovery. Prior deep learning endeavors in musical instrument recognition have predominantly emphasized instrument classes with ample data availability. Recent studies have demonstrated the applicability of hierarchical classification in detecting instrument activities in orchestral music, even with limited fine-grained annotations at the instrument level. Based on the Hornbostel-Sachs classification, such a hierarchical classification system is evaluated using the MedleyDB dataset, renowned for its diversity and richness concerning various instruments and music genres. This work presents various strategies to integrate hierarchical structures into models and tests a new class of models for hierarchical music prediction. This study showcases more reliable coarse-level instrument detection by bridging the gap between detailed instrument identification and group-level recognition, paving the way for further advancements in this domain.",
      "authors": [
        "Dylan Sechet",
        "Francesca Bugiotti",
        "Matthieu Kowalski",
        "Edouard d'H\\'erouville",
        "Filip Langiewicz"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21167",
        "HTML": "https://arxiv.org/html/2506.21167",
        "PDF": "https://arxiv.org/pdf/2506.21167"
      },
      "subjects": [
        "Sound (cs.SD)",
        "Artificial Intelligence (cs.AI)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 11:56:11 GMT",
          "size": "689kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "A Hierarchical Deep Learning Approach for Minority Instrument Detection",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper addresses hierarchical deep learning for minority instrument detection in music data. It does not relate to LLM training data processing or any aspects of data engineering for LLMs."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21175",
      "abstract": "Stacked area charts are a widely used visualization technique for numerical time series. The x-axis represents time, and the time series are displayed as horizontal, variable-height layers stacked on top of each other. The height of each layer corresponds to the time series values at each time point. The main aesthetic criterion for optimizing the readability of stacked area charts is the amount of vertical change of the borders between the time series in the visualization, called wiggle. While many heuristic algorithms have been developed to minimize wiggle, the computational complexity of minimizing wiggle has not been formally analyzed. In this paper, we show that different variants of wiggle minimization are NP-hard and even hard to approximate. We also present an exact mixed-integer linear programming formulation and compare its performance with a state-of-the-art heuristic in an experimental evaluation. Lastly, we consider a special case of wiggle minimization that corresponds to the fundamentally interesting and natural problem of ordering a set of numbers as to minimize their sum of absolute prefix sums. We show several complexity results for this problem that imply some of the mentioned hardness results for wiggle minimization.",
      "authors": [
        "Alexander Dobler",
        "Martin N\\\"ollenburg"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21175",
        "HTML": "https://arxiv.org/html/2506.21175",
        "PDF": "https://arxiv.org/pdf/2506.21175"
      },
      "subjects": [
        "Data Structures and Algorithms (cs.DS)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 12:28:04 GMT",
          "size": "642kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "On Minimizing Wiggle in Stacked Area Charts",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on optimizing the visualization of stacked area charts by minimizing wiggle, with no mention of LLM training data processing or related data engineering tasks."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21178",
      "abstract": "This paper presents UAIbot, a free and open-source web-based robotics simulator designed to address the educational and research challenges conventional simulation platforms generally face. The Python and JavaScript interfaces of UAIbot enable accessible hands-on learning experiences without cumbersome installations. By allowing users to explore fundamental mathematical and physical principles interactively, ranging from manipulator kinematics to pedestrian flow dynamics, UAIbot provides an effective tool for deepening student understanding, facilitating rapid experimentation, and enhancing research dissemination.",
      "authors": [
        "Johnata Brayan",
        "Armando Alves Neto",
        "Pavel Petrovi\\v{c}",
        "Gustavo M Freitas",
        "Vinicius Mariano Gon\\c{c}alves"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21178",
        "HTML": "https://arxiv.org/html/2506.21178",
        "PDF": "https://arxiv.org/pdf/2506.21178"
      },
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 12:31:32 GMT",
          "size": "1753kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "UAIbot: Beginner-friendly web-based simulator for interactive robotics learning and research",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper discusses UAIbot, a web-based robotics simulator designed for learning and research, without any reference to LLM training data processing or data engineering."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21185",
      "abstract": "3D Semantic Occupancy Prediction is crucial for autonomous driving, providing a dense, semantically rich environmental representation. However, existing methods focus on in-distribution scenes, making them susceptible to Out-of-Distribution (OoD) objects and long-tail distributions, which increases the risk of undetected anomalies and misinterpretations, posing safety hazards. To address these challenges, we introduce Out-of-Distribution Semantic Occupancy Prediction, targeting OoD detection in 3D voxel space. To fill the gaps in the dataset, we propose a Synthetic Anomaly Integration Pipeline that injects synthetic anomalies while preserving realistic spatial and occlusion patterns, enabling the creation of two datasets: VAA-KITTI and VAA-KITTI-360. We introduce OccOoD, a novel framework integrating OoD detection into 3D semantic occupancy prediction, with Voxel-BEV Progressive Fusion (VBPF) leveraging an RWKV-based branch to enhance OoD detection via geometry-semantic fusion. Experimental results demonstrate that OccOoD achieves state-of-the-art OoD detection with an AuROC of 67.34% and an AuPRCr of 29.21% within a 1.2m region, while maintaining competitive occupancy prediction performance. The established datasets and source code will be made publicly available at https://github.com/7uHeng/OccOoD.",
      "authors": [
        "Yuheng Zhang",
        "Mengfei Duan",
        "Kunyu Peng",
        "Yuhang Wang",
        "Ruiping Liu",
        "Fei Teng",
        "Kai Luo",
        "Zhiyong Li",
        "Kailun Yang"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21185",
        "HTML": "https://arxiv.org/html/2506.21185",
        "PDF": "https://arxiv.org/pdf/2506.21185"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Robotics (cs.RO)",
        "Image and Video Processing (eess.IV)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 12:44:29 GMT",
          "size": "20164kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Out-of-Distribution Semantic Occupancy Prediction",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper introduces a framework for Out-of-Distribution Semantic Occupancy Prediction in autonomous driving, which includes dataset creation but is unrelated to LLM training data processing or data engineering."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21186",
      "abstract": "Perpetual voting addresses fairness in sequential collective decision-making by evaluating representational equity over time. However, existing perpetual voting rules rely on full participation and complete approval information, assumptions that rarely hold in practice, where partial turnout is the norm. In this work, we study the integration of Artificial Delegates, preference-learning agents trained to represent absent voters, into perpetual voting systems. We examine how absenteeism affects fairness and representativeness under various voting methods and evaluate the extent to which Artificial Delegates can compensate for missing participation. Our findings indicate that while absenteeism significantly affects fairness, Artificial Delegates reliably mitigate these effects and enhance robustness across diverse scenarios.",
      "authors": [
        "Apurva Shah",
        "Axel Abels",
        "Ann Now\\'e",
        "Tom Lenaerts"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21186",
        "HTML": "https://arxiv.org/html/2506.21186",
        "PDF": "https://arxiv.org/pdf/2506.21186"
      },
      "subjects": [
        "Machine Learning (cs.LG)",
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 12:44:50 GMT",
          "size": "3566kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Artificial Delegates Resolve Fairness Issues in Perpetual Voting with Partial Turnout",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on fairness in voting systems and the integration of Artificial Delegates to address absenteeism. It does not address any aspect of LLM training data processes or improvements."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21188",
      "abstract": "Sequential grounding in 3D point clouds (SG3D) refers to locating sequences of objects by following text instructions for a daily activity with detailed steps. Current 3D visual grounding (3DVG) methods treat text instructions with multiple steps as a whole, without extracting useful temporal information from each step. However, the instructions in SG3D often contain pronouns such as \"it\", \"here\" and \"the same\" to make language expressions concise. This requires grounding methods to understand the context and retrieve relevant information from previous steps to correctly locate object sequences. Due to the lack of an effective module for collecting related historical information, state-of-the-art 3DVG methods face significant challenges in adapting to the SG3D task. To fill this gap, we propose GroundFlow -- a plug-in module for temporal reasoning on 3D point cloud sequential grounding. Firstly, we demonstrate that integrating GroundFlow improves the task accuracy of 3DVG baseline methods by a large margin (+7.5\\% and +10.2\\%) in the SG3D benchmark, even outperforming a 3D large language model pre-trained on various datasets. Furthermore, we selectively extract both short-term and long-term step information based on its relevance to the current instruction, enabling GroundFlow to take a comprehensive view of historical information and maintain its temporal understanding advantage as step counts increase. Overall, our work introduces temporal reasoning capabilities to existing 3DVG models and achieves state-of-the-art performance in the SG3D benchmark across five datasets.",
      "authors": [
        "Zijun Lin",
        "Shuting He",
        "Cheston Tan",
        "Bihan Wen"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21188",
        "HTML": "https://arxiv.org/html/2506.21188",
        "PDF": "https://arxiv.org/pdf/2506.21188"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 12:47:33 GMT",
          "size": "1865kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "GroundFlow: A Plug-in Module for Temporal Reasoning on 3D Point Cloud Sequential Grounding",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper presents a plug-in module for temporal reasoning on 3D point cloud grounding. It does not involve the design, construction, or processing of LLM training data."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21195",
      "abstract": "Have you wondered how cross-functional teams balance between maximizing value that users derive and business growth leading to win-win situations? This case study shows how User Experience Research (UXR) and Data Science teams used mixed methods research to strategically influence Product Led Growth (PLG) for a Password Manager used by million+ users, thus allowing our users, internal teams, and business to win. The audience will take away practical lessons/techniques related to leveraging mixed methods to: a. Maximize user value while meeting business growth goals b. Influence cross-functional teams c. Measure user and business impact This case study can be easily tied to the UXR Point of view pyramid (POV) [2] that represents a methodological approach to construct a POV and further dives into actioning POV to create measurable user and business impact.",
      "authors": [
        "Neha Raghuvanshi"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21195",
        "HTML": "https://arxiv.org/html/2506.21195",
        "PDF": "https://arxiv.org/pdf/2506.21195"
      },
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 12:54:41 GMT",
          "size": "232kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Follow the user meaningfully and product growth will follow: A mixed methods case study tying UX Point of View & Growth leading to measurable impact",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This case study is about the intersection of user experience research and product growth strategies. It does not cover topics related to LLM training data processing or enhancement."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21198",
      "abstract": "Panoramic image processing is essential for omni-context perception, yet faces constraints like distortions, perspective occlusions, and limited annotations. Previous unsupervised domain adaptation methods transfer knowledge from labeled pinhole data to unlabeled panoramic images, but they require access to source pinhole data. To address these, we introduce a more practical task, i.e., Source-Free Occlusion-Aware Seamless Segmentation (SFOASS), and propose its first solution, called UNconstrained Learning Omni-Context Knowledge (UNLOCK). Specifically, UNLOCK includes two key modules: Omni Pseudo-Labeling Learning and Amodal-Driven Context Learning. While adapting without relying on source data or target labels, this framework enhances models to achieve segmentation with 360{\\deg} viewpoint coverage and occlusion-aware reasoning. Furthermore, we benchmark the proposed SFOASS task through both real-to-real and synthetic-to-real adaptation settings. Experimental results show that our source-free method achieves performance comparable to source-dependent methods, yielding state-of-the-art scores of 10.9 in mAAP and 11.6 in mAP, along with an absolute improvement of +4.3 in mAPQ over the source-only method. All data and code will be made publicly available at https://github.com/yihong-97/UNLOCK.",
      "authors": [
        "Yihong Cao",
        "Jiaming Zhang",
        "Xu Zheng",
        "Hao Shi",
        "Kunyu Peng",
        "Hang Liu",
        "Kailun Yang",
        "Hui Zhang"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21198",
        "HTML": "https://arxiv.org/html/2506.21198",
        "PDF": "https://arxiv.org/pdf/2506.21198"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Robotics (cs.RO)",
        "Image and Video Processing (eess.IV)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 12:55:36 GMT",
          "size": "7964kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Unlocking Constraints: Source-Free Occlusion-Aware Seamless Segmentation",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper introduces a method for seamless segmentation in panoramic image processing, which is unrelated to LLM training data processing or enhancement."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21199",
      "abstract": "Current medical image analysis systems are typically task-specific, requiring separate models for classification and segmentation, and lack the flexibility to support user-defined workflows. To address these challenges, we introduce MedPrompt, a unified framework that combines a few-shot prompted Large Language Model (Llama-4-17B) for high-level task planning with a modular Convolutional Neural Network (DeepFusionLab) for low-level image processing. The LLM interprets user instructions and generates structured output to dynamically route task-specific pretrained weights. This weight routing approach avoids retraining the entire framework when adding new tasks-only task-specific weights are required, enhancing scalability and deployment. We evaluated MedPrompt across 19 public datasets, covering 12 tasks spanning 5 imaging modalities. The system achieves a 97% end-to-end correctness in interpreting and executing prompt-driven instructions, with an average inference latency of 2.5 seconds, making it suitable for near real-time applications. DeepFusionLab achieves competitive segmentation accuracy (e.g., Dice 0.9856 on lungs) and strong classification performance (F1 0.9744 on tuberculosis). Overall, MedPrompt enables scalable, prompt-driven medical imaging by combining the interpretability of LLMs with the efficiency of modular CNNs.",
      "authors": [
        "Shadman Sobhan",
        "Kazi Abrar Mahmud",
        "Abduz Zami"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21199",
        "HTML": "https://arxiv.org/html/2506.21199",
        "PDF": "https://arxiv.org/pdf/2506.21199"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Signal Processing (eess.SP)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 12:57:41 GMT",
          "size": "2326kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "MedPrompt: LLM-CNN Fusion with Weight Routing for Medical Image Segmentation and Classification",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on integrating LLMs with CNNs for medical image analysis but does not address any aspect of training data processing or enhancement for LLMs specifically."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21201",
      "abstract": "The consumption of subtitles via TVs, laptops and smartphones has the potential to marginalize people based on their complex accessibility needs. The current one-size-fits-all approach to this accessibility aid is no longer fit for purpose and work is required to look at how it can be adapted to be personalised for individual users based on individual context, content, and consumption habits. People with Aphasia, for example, encounter significant challenges in understanding subtitle texts.\n  We see our work as a call to action for more inclusive practices, focusing on how the thoughts and opinions of people with aphasia can be included in media research. Our work investigates how to develop future media solutions for people with aphasia to create a more inclusive media viewing environment. We believe the key to this is appropriate prototyping tools and methods to allow equitable inclusion in the system design process.",
      "authors": [
        "Zihao You and Michael Crabb"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21201",
        "HTML": "https://arxiv.org/html/2506.21201",
        "PDF": "https://arxiv.org/pdf/2506.21201"
      },
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 12:59:25 GMT",
          "size": "266kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Subtitled Media Adaptations for People with Aphasia: Ongoing Accessibility Barriers and Emerging Design Practices",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper discusses the design of media solutions for people with aphasia and does not involve any LLM data collection, construction, or processing tasks."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21203",
      "abstract": "The study of the evolving phenomena in a domain helps to understand the relationships between entities at different points in time and predict future trends. These phenomena, often complex, can be represented using knowledge graphs, which have the capability to model heterogeneous data from multiple sources. Nowadays, a considerable amount of sources delivering periodic updates to knowledge graphs in various domains is openly available. The evolution of data is of interest to knowledge graph management systems, and therefore it is crucial to organize these constantly evolving data to make them easily accessible and exploitable for analyzes. In this article, we will present and formalize the condensed representation of these evolving graphs.",
      "authors": [
        "Jey Puget Gil",
        "Emmanuel Coquery",
        "John Samuel",
        "Gilles Gesquiere"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21203",
        "HTML": "https://arxiv.org/html/2506.21203",
        "PDF": "https://arxiv.org/pdf/2506.21203"
      },
      "subjects": [
        "Databases (cs.DB)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 13:00:09 GMT",
          "size": "242kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Condensed Representation of RDF and its Application on Graph Versioning",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper is centered around knowledge graph representation and versioning, with no direct focus on LLM training data or its processing."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21205",
      "abstract": "Deploying mobile robots safely among humans requires the motion planner to account for the uncertainty in the other agents' predicted trajectories. This remains challenging in traditional approaches, especially with arbitrarily shaped predictions and real-time constraints. To address these challenges, we propose a Dynamic Risk-Aware Model Predictive Path Integral control (DRA-MPPI), a motion planner that incorporates uncertain future motions modelled with potentially non-Gaussian stochastic predictions. By leveraging MPPI's gradient-free nature, we propose a method that efficiently approximates the joint Collision Probability (CP) among multiple dynamic obstacles for several hundred sampled trajectories in real-time via a Monte Carlo (MC) approach. This enables the rejection of samples exceeding a predefined CP threshold or the integration of CP as a weighted objective within the navigation cost function. Consequently, DRA-MPPI mitigates the freezing robot problem while enhancing safety. Real-world and simulated experiments with multiple dynamic obstacles demonstrate DRA-MPPI's superior performance compared to state-of-the-art approaches, including Scenario-based Model Predictive Control (S-MPC), Frenet planner, and vanilla MPPI.",
      "authors": [
        "Elia Trevisan",
        "Khaled A. Mustafa",
        "Godert Notten",
        "Xinwei Wang and Javier Alonso-Mora"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21205",
        "HTML": "https://arxiv.org/html/2506.21205",
        "PDF": "https://arxiv.org/pdf/2506.21205"
      },
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 13:01:32 GMT",
          "size": "5777kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Dynamic Risk-Aware MPPI for Mobile Robots in Crowds via Efficient Monte Carlo Approximations",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The research presents a motion planning algorithm for mobile robots and does not discuss any aspect of training data processing for LLMs."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21206",
      "abstract": "Obtaining high-quality particle distributions for stable and accurate particle-based simulations poses significant challenges, especially for complex geometries. We introduce a preprocessing technique for 2D and 3D geometries, optimized for smoothed particle hydrodynamics (SPH) and other particle-based methods. Our pipeline begins with the generation of a resolution-adaptive point cloud near the geometry's surface employing a face-based neighborhood search. This point cloud forms the basis for a signed distance field, enabling efficient, localized computations near surface regions. To create an initial particle configuration, we apply a hierarchical winding number method for fast and accurate inside-outside segmentation. Particle positions are then relaxed using an SPH-inspired scheme, which also serves to pack boundary particles. This ensures full kernel support and promotes isotropic distributions while preserving the geometry interface. By leveraging the meshless nature of particle-based methods, our approach does not require connectivity information and is thus straightforward to integrate into existing particle-based frameworks. It is robust to imperfect input geometries and memory-efficient without compromising performance. Moreover, our experiments demonstrate that with increasingly higher resolution, the resulting particle distribution converges to the exact geometry.",
      "authors": [
        "Niklas S. Neher",
        "Erik Faulhaber",
        "Sven Berger",
        "Christian Wei{\\ss}enfels",
        "Gregor J. Gassner",
        "Michael Schlottke-Lakemper"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21206",
        "HTML": "https://arxiv.org/html/2506.21206",
        "PDF": "https://arxiv.org/pdf/2506.21206"
      },
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 13:02:10 GMT",
          "size": "28938kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Robust and efficient pre-processing techniques for particle-based methods including dynamic boundary generation",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The work introduces pre-processing techniques for particle-based simulations, unrelated to LLM training data processing or procedures."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21211",
      "abstract": "Automatic Program Repair (APR) is a core technology in software development and maintenance, with aims to enable automated defect repair with minimal human intervention. In recent years, the substantial advancements in Large Language Models (LLMs) and the Chain-of-Thought (CoT) techniques have significantly enhanced the reasoning capabilities of these models. However, due to the complex logic and multi-step reasoning ability needed, the application of CoT techniques in the APR domain remains insufficient. This study systematically evaluates the performance of several common CoT techniques in APR tasks and proposes an innovative framework $T^3$, which integrates the powerful reasoning capabilities of LLMs with tree search, effectively improving the precision of generating candidate repair solutions. Furthermore, $T^3$ provides valuable guidance for optimizing sample selection and repair strategies in APR tasks, establishing a robust framework for achieving efficient automated debugging.",
      "authors": [
        "Quanming Liu",
        "Xupeng Bu",
        "Zhichao Yan",
        "Ru Li"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21211",
        "HTML": "https://arxiv.org/html/2506.21211",
        "PDF": "https://arxiv.org/pdf/2506.21211"
      },
      "subjects": [
        "Software Engineering (cs.SE)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 13:04:28 GMT",
          "size": "710kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "$T^3$: Multi-level Tree-based Automatic Program Repair with Large Language Models",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper is concerned with automatic program repair and LLMs' reasoning capabilities, with no focus on training data processing for LLMs."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21215",
      "abstract": "Causal reasoning capability is critical in advancing large language models (LLMs) toward strong artificial intelligence. While versatile LLMs appear to have demonstrated capabilities in understanding contextual causality and providing responses that obey the laws of causality, it remains unclear whether they perform genuine causal reasoning akin to humans. However, current evidence indicates the contrary. Specifically, LLMs are only capable of performing shallow (level-1) causal reasoning, primarily attributed to the causal knowledge embedded in their parameters, but they lack the capacity for genuine human-like (level-2) causal reasoning. To support this hypothesis, methodologically, we delve into the autoregression mechanism of transformer-based LLMs, revealing that it is not inherently causal. Empirically, we introduce a new causal Q&A benchmark called CausalProbe-2024, whose corpora are fresh and nearly unseen for the studied LLMs. The LLMs exhibit a significant performance drop on CausalProbe-2024 compared to earlier benchmarks, indicating the fact that they primarily engage in level-1 causal reasoning. To bridge the gap towards level-2 causal reasoning, we draw inspiration from the fact that human reasoning is usually facilitated by general knowledge and intended goals. We propose G^2-Reasoner, a method that incorporates general knowledge and goal-oriented prompts into LLMs' causal reasoning processes. Experiments demonstrate that G^2-Reasoner significantly enhances LLMs' causal reasoning capability, particularly in fresh and counterfactual contexts. This work sheds light on a new path for LLMs to advance towards genuine causal reasoning, going beyond level-1 and making strides towards level-2.",
      "authors": [
        "Haoang Chi",
        "He Li",
        "Wenjing Yang",
        "Feng Liu",
        "Long Lan",
        "Xiaoguang Ren",
        "Tongliang Liu",
        "Bo Han"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21215",
        "HTML": "https://arxiv.org/html/2506.21215",
        "PDF": "https://arxiv.org/pdf/2506.21215"
      },
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 13:11:01 GMT",
          "size": "1040kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Unveiling Causal Reasoning in Large Language Models: Reality or Mirage?",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper explores causal reasoning in LLMs but does not address training data processing, focusing instead on reasoning capabilities and benchmarks."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21216",
      "abstract": "Covering and partitioning the edges of a graph into cliques are classical problems at the intersection of combinatorial optimization and graph theory, having been studied through a range of algorithmic and complexity-theoretic lenses. Despite the well-known fixed-parameter tractability of these problems when parameterized by the total number of cliques, such a parameterization often fails to be meaningful for sparse graphs. In many real-world instances, on the other hand, the minimum number of cliques in an edge cover or partition can be very close to the size of a maximum independent set \\alpha(G).\n  Motivated by this observation, we investigate above \\alpha parameterizations of the edge clique cover and partition problems. Concretely, we introduce and study Edge Clique Cover Above Independent Set (ECC/\\alpha) and Edge Clique Partition Above Independent Set (ECP/\\alpha), where the goal is to cover or partition all edges of a graph using at most \\alpha(G) + k cliques, and k is the parameter. Our main results reveal a distinct complexity landscape for the two variants. We show that ECP/\\alpha is fixed-parameter tractable, whereas ECC/\\alpha is NP-complete for all k \\geq 2, yet can be solved in polynomial time for k \\in {0,1}. These findings highlight intriguing differences between the two problems when viewed through the lens of parameterization above a natural lower bound.\n  Finally, we demonstrate that ECC/\\alpha becomes fixed-parameter tractable when parameterized by k + \\omega(G), where \\omega(G) is the size of a maximum clique of the graph G. This result is particularly relevant for sparse graphs, in which \\omega is typically small. For H-minor free graphs, we design a subexponential algorithm of running time f(H)^{\\sqrt{k}}n^{O(1)}.",
      "authors": [
        "Fedor V. Fomin",
        "Petr A. Golovach",
        "Danil Sagunov",
        "and Kirill Simonov"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21216",
        "HTML": "https://arxiv.org/html/2506.21216",
        "PDF": "https://arxiv.org/pdf/2506.21216"
      },
      "subjects": [
        "Data Structures and Algorithms (cs.DS)",
        "Discrete Mathematics (cs.DM)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 13:11:12 GMT",
          "size": "33kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Edge Clique Partition and Cover Beyond Independence",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper is centered on graph theory and combinatorial optimization concerning edge clique partition and cover, without discussing LLM training data processing."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21222",
      "abstract": "Automatic Term Extraction (ATE) identifies domain-specific expressions that are crucial for downstream tasks such as machine translation and information retrieval. Although large language models (LLMs) have significantly advanced various NLP tasks, their potential for ATE has scarcely been examined. We propose a retrieval-based prompting strategy that, in the few-shot setting, selects demonstrations according to \\emph{syntactic} rather than semantic similarity. This syntactic retrieval method is domain-agnostic and provides more reliable guidance for capturing term boundaries. We evaluate the approach in both in-domain and cross-domain settings, analyzing how lexical overlap between the query sentence and its retrieved examples affects performance. Experiments on three specialized ATE benchmarks show that syntactic retrieval improves F1-score. These findings highlight the importance of syntactic cues when adapting LLMs to terminology-extraction tasks.",
      "authors": [
        "Yongchan Chun",
        "Minhyuk Kim",
        "Dongjun Kim",
        "Chanjun Park",
        "Heuiseok Lim"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21222",
        "HTML": "https://arxiv.org/html/2506.21222",
        "PDF": "https://arxiv.org/pdf/2506.21222"
      },
      "subjects": [
        "Computation and Language (cs.CL)",
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 13:14:52 GMT",
          "size": "611kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Enhancing Automatic Term Extraction with Large Language Models via Syntactic Retrieval",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on a retrieval-based prompting strategy for Automatic Term Extraction with LLMs and does not address any aspects of LLM training data processing or engineering."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21230",
      "abstract": "Large Vision-Language Models (LVLMs) show promise for embodied planning tasks but struggle with complex scenarios involving unfamiliar environments and multi-step goals. Current approaches rely on environment-agnostic imitation learning that disconnects instructions from environmental contexts, causing models to struggle with context-sensitive instructions and rely on supplementary cues rather than visual reasoning during long-horizon interactions. In this work, we propose World-Aware Planning Narrative Enhancement (WAP), a framework that infuses LVLMs with comprehensive environmental understanding through four cognitive capabilities (visual appearance modeling, spatial reasoning, functional abstraction, and syntactic grounding) while developing and evaluating models using only raw visual observations through curriculum learning. Evaluations on the EB-ALFRED benchmark demonstrate substantial improvements, with Qwen2.5-VL achieving a 60.7 absolute improvement in task success rates, particularly in commonsense reasoning (+60.0) and long-horizon planning (+70.0). Notably, our enhanced open-source models outperform proprietary systems like GPT-4o and Claude-3.5-Sonnet by a large margin.",
      "authors": [
        "Junhao Shi",
        "Zhaoye Fei",
        "Siyin Wang",
        "Qipeng Guo",
        "Jingjing Gong",
        "Xipeng QIu"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21230",
        "HTML": "https://arxiv.org/html/2506.21230",
        "PDF": "https://arxiv.org/pdf/2506.21230"
      },
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 13:20:55 GMT",
          "size": "2239kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "World-aware Planning Narratives Enhance Large Vision-Language Model Planner",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper discusses enhancing LVLMs for planning tasks through world-aware narratives but does not focus on LLM training data processing or engineering."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21232",
      "abstract": "A 20-year analysis of CrossRef metadata demonstrates that global scholarly output -- encompassing publications, retractions, and preprints -- exhibits strikingly inertial growth, well-described by exponential, quadratic, and logistic models with nearly indistinguishable goodness-of-fit. Retraction dynamics, in particular, remain stable and minimally affected by the COVID-19 shock, which contributed less than 1% to total notices. Since 2004, publications doubled every 9.8 years, retractions every 11.4 years, and preprints at the fastest rate, every 5.6 years. The findings underscore a system primed for ongoing stress at unchanged structural bottlenecks. Although model forecasts diverge beyond 2024, the evidence suggests that the future trajectory of scholarly communication will be determined by persistent systemic inertia rather than episodic disruptions -- unless intentionally redirected by policy or AI-driven reform.",
      "authors": [
        "Khalid M. Saqr"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21232",
        "HTML": "https://arxiv.org/html/2506.21232",
        "PDF": "https://arxiv.org/pdf/2506.21232"
      },
      "subjects": [
        "Digital Libraries (cs.DL)",
        "Physics and Society (physics.soc-ph)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 13:21:25 GMT",
          "size": "193kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "The State of Papers, Retractions, and Preprints: Evidence from the CrossRef Database (2004-2024)",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper provides an analysis of scholarly publications, retractions, and preprints, unrelated to LLM training data processing or engineering."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21234",
      "abstract": "This paper presents ESFP, an end-to-end pipeline that converts monocular RGB video into executable joint trajectories for a low-cost 4-DoF desktop arm. ESFP comprises four sequential modules. (1) Estimating: ROMP lifts each frame to a 24-joint 3-D skeleton. (2) Smoothing: the proposed HPSTM-a sequence-to-sequence Transformer with self-attention-combines long-range temporal context with a differentiable forward-kinematics decoder, enforcing constant bone lengths and anatomical plausibility while jointly predicting joint means and full covariances. (3) Filtering: root-normalized trajectories are variance-weighted according to HPSTM's uncertainty estimates, suppressing residual noise. (4) Pose-Mapping: a geometric retargeting layer transforms shoulder-elbow-wrist triples into the uArm's polar workspace, preserving wrist orientation.",
      "authors": [
        "Qifei Cui",
        "Yuang Zhou",
        "Ruichen Deng"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21234",
        "HTML": "https://arxiv.org/html/2506.21234",
        "PDF": "https://arxiv.org/pdf/2506.21234"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 13:22:12 GMT",
          "size": "4629kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Real-Time ESFP: Estimating, Smoothing, Filtering, and Pose-Mapping",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on a pipeline (ESFP) for converting video data into motion trajectories for robotics. It does not involve LLM training data or processing related to natural language models."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21237",
      "abstract": "We introduce DiMPLe (Disentangled Multi-Modal Prompt Learning), a novel approach to disentangle invariant and spurious features across vision and language modalities in multi-modal learning. Spurious correlations in visual data often hinder out-of-distribution (OOD) performance. Unlike prior methods focusing solely on image features, DiMPLe disentangles features within and across modalities while maintaining consistent alignment, enabling better generalization to novel classes and robustness to distribution shifts. Our method combines three key objectives: (1) mutual information minimization between invariant and spurious features, (2) spurious feature regularization, and (3) contrastive learning on invariant features. Extensive experiments demonstrate DiMPLe demonstrates superior performance compared to CoOp-OOD, when averaged across 11 diverse datasets, and achieves absolute gains of 15.27 in base class accuracy and 44.31 in novel class accuracy.",
      "authors": [
        "Umaima Rahman",
        "Mohammad Yaqub",
        "Dwarikanath Mahapatra"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21237",
        "HTML": "https://arxiv.org/html/2506.21237",
        "PDF": "https://arxiv.org/pdf/2506.21237"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 13:22:44 GMT",
          "size": "4530kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "DiMPLe -- Disentangled Multi-Modal Prompt Learning: Enhancing Out-Of-Distribution Alignment with Invariant and Spurious Feature Separation",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper introduces a multi-modal learning approach (DiMPLe) for disentangling features across vision and language modalities to improve out-of-distribution performance. It does not discuss training data processing for LLMs specifically."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21241",
      "abstract": "Symplectic numerical methods have become a widely-used choice for the accurate simulation of Hamiltonian systems in various fields, including celestial mechanics, molecular dynamics and robotics. Even though their characteristics are well-understood mathematically, relatively little attention has been paid in general to the practical aspect of how the choice of coordinates affects the accuracy of the numerical results, even though the consequences can be computationally significant. The present article aims to fill this gap by giving a systematic overview of how coordinate transformations can influence the results of simulations performed using symplectic methods. We give a derivation for the non-invariance of the modified Hamiltonian of symplectic methods under coordinate transformations, as well as a sufficient condition for the non-preservation of a first integral corresponding to a cyclic coordinate for the symplectic Euler method. We also consider the possibility of finding order-compensating coordinate transformations that improve the order of accuracy of a numerical method. Various numerical examples are presented throughout.",
      "authors": [
        "Don\\'at M. Tak\\'acs",
        "Tam\\'as F\\\"ul\\\"op"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21241",
        "HTML": "https://arxiv.org/html/2506.21241",
        "PDF": "https://arxiv.org/pdf/2506.21241"
      },
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)",
        "Classical Physics (physics.class-ph)",
        "Computational Physics (physics.comp-ph)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 13:24:54 GMT",
          "size": "1501kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "On the coordinate system-dependence of the accuracy of symplectic numerical methods",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper investigates the effects of coordinate systems on symplectic numerical methods. It does not relate to LLM training data engineering or processing."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21242",
      "abstract": "We study the application of the generalized convolution quadrature (gCQ) based on Runge--Kutta methods to approximate the solution of an important class of sectorial problems. The gCQ generalizes Lubich's original convolution quadrature (CQ) to variable steps. High-order versions of the gCQ have been developed in the last decade, relying on certain Runge--Kutta methods. The Runge--Kutta based gCQ has been studied so far in a rather general setting, which includes applications to boundary integral formulations of wave problems. The available stability and convergence results for these new methods are suboptimal compared to those known for the uniform-step CQ, both in terms of convergence order and regularity requirements of the data. Here we focus on a special class of sectorial problems and prove that in these important applications it is possible to achieve the same order of convergence as for the original CQ, under the same regularity hypotheses on the data, and for very general time meshes. In the particular case of data with some known algebraic type of singularity, we also show how to choose an optimally graded time mesh to achieve convergence with maximal order, overcoming the well-known order reduction of the original CQ in these situations. An important advantage of the gCQ method is that it allows for a fast and memory-efficient implementation. We describe how the fast and oblivious Runge--Kutta based gCQ can be implemented and illustrate our theoretical results with several numerical experiments. The codes implementing the examples in this article are available in [13].",
      "authors": [
        "Jing Guo",
        "Maria Lopez-Fernandez"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21242",
        "HTML": "https://arxiv.org/html/2506.21242",
        "PDF": "https://arxiv.org/pdf/2506.21242"
      },
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 13:26:33 GMT",
          "size": "1083kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Runge--Kutta generalized Convolution Quadrature for sectorial problems",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on generalized convolution quadrature methods for sectorial problems, which are mathematical techniques not connected to the domain of LLM training data processing."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21249",
      "abstract": "Human Motion Segmentation (HMS), which aims to partition videos into non-overlapping human motions, has attracted increasing research attention recently. Existing approaches for HMS are mainly dominated by subspace clustering methods, which are grounded on the assumption that high-dimensional temporal data align with a Union-of-Subspaces (UoS) distribution. However, the frames in video capturing complex human motions with cluttered backgrounds may not align well with the UoS distribution. In this paper, we propose a novel approach for HMS, named Temporal Rate Reduction Clustering ($\\text{TR}^2\\text{C}$), which jointly learns structured representations and affinity to segment the frame sequences in video. Specifically, the structured representations learned by $\\text{TR}^2\\text{C}$ maintain temporally consistent and align well with a UoS structure, which is favorable for the HMS task. We conduct extensive experiments on five benchmark HMS datasets and achieve state-of-the-art performances with different feature extractors.",
      "authors": [
        "Xianghan Meng",
        "Zhengyu Tong",
        "Zhiyuan Huang",
        "Chun-Guang Li"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21249",
        "HTML": "https://arxiv.org/html/2506.21249",
        "PDF": "https://arxiv.org/pdf/2506.21249"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 13:35:07 GMT",
          "size": "2636kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Temporal Rate Reduction Clustering for Human Motion Segmentation",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper proposes a clustering method for human motion video segmentation, which involves temporal data but does not address LLM training data processing."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21250",
      "abstract": "This paper introduces ACTLLM (Action Consistency Tuned Large Language Model), a novel approach for robot manipulation in dynamic environments. Traditional vision-based systems often struggle to learn visual representations that excel in both task execution and spatial reasoning, thereby limiting their adaptability in dynamic environments. ACTLLM addresses these challenges by harnessing language to craft structured scene descriptors, providing a uniform interface for both spatial understanding and task performance through flexible language instructions. Moreover, we introduce a novel action consistency constraint that aligns visual perception with corresponding actions, thereby enhancing the learning of actionable visual representations. Additionally, we have reformulated the Markov decision process for manipulation tasks into a multi-turn visual dialogue framework. This approach enables the modeling of long-term task execution with enhanced contextual relevance derived from the history of task execution. During our evaluation, ACTLLM excels in diverse scenarios, proving its effectiveness on challenging vision-based robot manipulation tasks.",
      "authors": [
        "Jing Bi",
        "Lianggong Bruce Wen",
        "Zhang Liu",
        "Chenliang Xu"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21250",
        "HTML": "https://arxiv.org/html/2506.21250",
        "PDF": "https://arxiv.org/pdf/2506.21250"
      },
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 13:35:53 GMT",
          "size": "2467kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "ACTLLM: Action Consistency Tuned Large Language Model",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "Describes a model for robot manipulation using visual data and language but does not propose novel methods or processes related to the training data of LLMs."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21254",
      "abstract": "The 1-2-3 Conjecture, introduced by Karo\\'nski, {\\L}uczak, and Thomason in 2004, was recently solved by Keusch. This implies that, for any connected graph $G$ different from $K_2$, we can turn $G$ into a locally irregular multigraph $M(G)$, i.e., in which no two adjacent vertices have the same degree, by replacing some of its edges with at most three parallel edges. In this work, we introduce and study a restriction of this problem under the additional constraint that edges added to $G$ to reach $M(G)$ must form a walk (i.e., a path with possibly repeated edges and vertices) of $G$. We investigate the general consequences of having this additional constraint, and provide several results of different natures (structural, combinatorial, algorithmic) on the length of the shortest irregularising walks, for general graphs and more restricted classes.",
      "authors": [
        "Julien Bensmail",
        "Romain Bourneuf",
        "Paul Colinot",
        "Samuel Humeau",
        "Timoth\\'ee Martinod"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21254",
        "HTML": "https://arxiv.org/html/2506.21254",
        "PDF": "https://arxiv.org/pdf/2506.21254"
      },
      "subjects": [
        "Discrete Mathematics (cs.DM)",
        "Combinatorics (math.CO)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 13:37:01 GMT",
          "size": "76kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Making Graphs Irregular through Irregularising Walks",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on graph theory and the problem of turning a graph into a locally irregular multigraph. It does not relate to LLM training data processing or data engineering."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21260",
      "abstract": "Real-world object detection systems, such as those in autonomous driving and surveillance, must continuously learn new object categories and simultaneously adapt to changing environmental conditions. Existing approaches, Class Incremental Object Detection (CIOD) and Domain Incremental Object Detection (DIOD) only address one aspect of this challenge. CIOD struggles in unseen domains, while DIOD suffers from catastrophic forgetting when learning new classes, limiting their real-world applicability. To overcome these limitations, we introduce Dual Incremental Object Detection (DuIOD), a more practical setting that simultaneously handles class and domain shifts in an exemplar-free manner. We propose DuET, a Task Arithmetic-based model merging framework that enables stable incremental learning while mitigating sign conflicts through a novel Directional Consistency Loss. Unlike prior methods, DuET is detector-agnostic, allowing models like YOLO11 and RT-DETR to function as real-time incremental object detectors. To comprehensively evaluate both retention and adaptation, we introduce the Retention-Adaptability Index (RAI), which combines the Average Retention Index (Avg RI) for catastrophic forgetting and the Average Generalization Index for domain adaptability into a common ground. Extensive experiments on the Pascal Series and Diverse Weather Series demonstrate DuET's effectiveness, achieving a +13.12% RAI improvement while preserving 89.3% Avg RI on the Pascal Series (4 tasks), as well as a +11.39% RAI improvement with 88.57% Avg RI on the Diverse Weather Series (3 tasks), outperforming existing methods.",
      "authors": [
        "Munish Monga",
        "Vishal Chudasama",
        "Pankaj Wasnik",
        "Biplab Banerjee"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21260",
        "HTML": "https://arxiv.org/html/2506.21260",
        "PDF": "https://arxiv.org/pdf/2506.21260"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 13:41:47 GMT",
          "size": "23932kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "DuET: Dual Incremental Object Detection via Exemplar-Free Task Arithmetic",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper discusses object detection and incremental learning in the context of computer vision without connection to training data processing specifically for LLMs."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21263",
      "abstract": "The distributed training of foundation models, particularly large language models (LLMs), demands a high level of communication. Consequently, it is highly dependent on a centralized cluster with fast and reliable interconnects. Can we conduct training on slow networks and thereby unleash the power of decentralized clusters when dealing with models exceeding 100 billion parameters? In this paper, we propose DiLoCoX, a low-communication large-scale decentralized cluster training framework. It combines Pipeline Parallelism with Dual Optimizer Policy, One-Step-Delay Overlap of Communication and Local Training, and an Adaptive Gradient Compression Scheme. This combination significantly improves the scale of parameters and the speed of model pre-training. We justify the benefits of one-step-delay overlap of communication and local training, as well as the adaptive gradient compression scheme, through a theoretical analysis of convergence. Empirically, we demonstrate that DiLoCoX is capable of pre-training a 107B foundation model over a 1Gbps network. Compared to vanilla AllReduce, DiLoCoX can achieve a 357x speedup in distributed training while maintaining negligible degradation in model convergence. To the best of our knowledge, this is the first decentralized training framework successfully applied to models with over 100 billion parameters.",
      "authors": [
        "Ji Qi",
        "WenPeng Zhu",
        "Li Li",
        "Ming Wu",
        "YingJun Wu",
        "Wu He",
        "Xun Gao",
        "Jason Zeng",
        "Michael Heinrich"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21263",
        "HTML": "https://arxiv.org/html/2506.21263",
        "PDF": "https://arxiv.org/pdf/2506.21263"
      },
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 13:45:04 GMT",
          "size": "319kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "DiLoCoX: A Low-Communication Large-Scale Training Framework for Decentralized Cluster",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper describes a framework for decentralized training in distributed systems. It does not discuss the processing of training data for LLMs but rather focuses on training architecture and efficiency."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21265",
      "abstract": "Unmanned Surface Vessels (USVs) face significant control challenges due to uncertain environmental disturbances like waves and currents. This paper proposes a trajectory tracking controller based on Active Disturbance Rejection Control (ADRC) implemented on the DUS V2500. A custom simulation incorporating realistic waves and current disturbances is developed to validate the controller's performance, supported by further validation through field tests in the harbour of Scheveningen, the Netherlands, and at sea. Simulation results demonstrate that ADRC significantly reduces cross-track error across all tested conditions compared to a baseline PID controller but increases control effort and energy consumption. Field trials confirm these findings while revealing a further increase in energy consumption during sea trials compared to the baseline.",
      "authors": [
        "Jelmer van der Saag",
        "Elia Trevisan",
        "Wouter Falkena and Javier Alonso-Mora"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21265",
        "HTML": "https://arxiv.org/html/2506.21265",
        "PDF": "https://arxiv.org/pdf/2506.21265"
      },
      "subjects": [
        "Robotics (cs.RO)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 13:48:13 GMT",
          "size": "7227kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Active Disturbance Rejection Control for Trajectory Tracking of a Seagoing USV: Design, Simulation, and Field Experiments",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper offers a control strategy for trajectory tracking of USVs. It does not relate to LLMs or their training data processing."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21266",
      "abstract": "Collecting data of students solving programming tasks is incredibly valuable for researchers and educators. It allows verifying that the students correctly apply the features and concepts they are taught, or finding students' misconceptions. However, existing data collection tools have limitations, e.g., no control over the granularity of the collected code, not collecting the specific events of the programming environment used, and overall being hard to configure.\n  To overcome these limitations, we propose KOALA, a convenient and highly configurable tool for collecting code snapshots and feature usage from students solving programming tasks in JetBrains IDEs. The plugin can be installed in IDEs and configured to provide the students with the necessary tasks, enable or disable certain IDE features like code completion, and run surveys. During problem solving, the plugin collects code snapshots at the configured granularity, all IDE actions like running and debugging, as well as some data not collected in prior works, like employed hotkeys and switching focus between files. The collected data is sent to the server that comes with the tool, where it is stored and can be converted to the standardized ProgSnap2 format. To showcase the tool, we collected data from 28 students solving tasks in two courses within the IDE, highlighting some insights from this data.",
      "authors": [
        "Daniil Karol",
        "Elizaveta Artser",
        "Ilya Vlasov",
        "Yaroslav Golubev",
        "Hieke Keuning",
        "Anastasiia Birillo"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21266",
        "HTML": "https://arxiv.org/html/2506.21266",
        "PDF": "https://arxiv.org/pdf/2506.21266"
      },
      "subjects": [
        "Software Engineering (cs.SE)",
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 13:48:38 GMT",
          "size": "962kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "KOALA: a Configurable Tool for Collecting IDE Data When Solving Programming Tasks",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on a tool named KOALA for collecting IDE data from students solving programming tasks. It discusses data collection within educational settings and code snapshots but does not relate to LLM training data processing or data engineering."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21269",
      "abstract": "This study presents and publicly releases the Suzhou Urban Road Acoustic Dataset (SZUR-Acoustic Dataset), which is accompanied by comprehensive data-acquisition protocols and annotation guidelines to ensure transparency and reproducibility of the experimental workflow. To model the coupling between vehicular noise and driving speed, we propose a bimodal-feature-fusion deep convolutional neural network (BMCNN). During preprocessing, an adaptive denoising and normalization strategy is applied to suppress environmental background interference; in the network architecture, parallel branches extract Mel-frequency cepstral coefficients (MFCCs) and wavelet-packet energy features, which are subsequently fused via a cross-modal attention mechanism in the intermediate feature space to fully exploit time-frequency information. Experimental results demonstrate that BMCNN achieves a classification accuracy of 87.56% on the SZUR-Acoustic Dataset and 96.28% on the public IDMT-Traffic dataset. Ablation studies and robustness tests on the Suzhou dataset further validate the contributions of each module to performance improvement and overfitting mitigation. The proposed acoustics-based speed classification method can be integrated into smart-city traffic management systems for real-time noise monitoring and speed estimation, thereby optimizing traffic flow control, reducing roadside noise pollution, and supporting sustainable urban planning.",
      "authors": [
        "Pengfei Fan",
        "Yuli Zhang",
        "Xinheng Wang",
        "Ruiyuan Jiang",
        "Hankang Gu",
        "Dongyao Jia",
        "Shangbo Wang"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21269",
        "HTML": "https://arxiv.org/html/2506.21269",
        "PDF": "https://arxiv.org/pdf/2506.21269"
      },
      "subjects": [
        "Sound (cs.SD)",
        "Artificial Intelligence (cs.AI)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 13:53:22 GMT",
          "size": "2780kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Integrating Vehicle Acoustic Data for Enhanced Urban Traffic Management: A Study on Speed Classification in Suzhou",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This study introduces an acoustic dataset for urban traffic management and proposes a deep learning model for speed classification. The focus is on traffic data processing and vehicle acoustics, without any mention of LLM training data."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21270",
      "abstract": "Video virtual try-on aims to naturally fit a garment to a target person in consecutive video frames. It is a challenging task, on the one hand, the output video should be in good spatial-temporal consistency, on the other hand, the details of the given garment need to be preserved well in all the frames. Naively using image-based try-on methods frame by frame can get poor results due to severe inconsistency. Recent diffusion-based video try-on methods, though very few, happen to coincide with a similar solution: inserting temporal attention into image-based try-on model to adapt it for video try-on task, which have shown improvements but there still exist inconsistency problems. In this paper, we propose ViTI (Video Try-on Inpainter), formulate and implement video virtual try-on as a conditional video inpainting task, which is different from previous methods. In this way, we start with a video generation problem instead of an image-based try-on problem, which from the beginning has a better spatial-temporal consistency. Specifically, at first we build a video inpainting framework based on Diffusion Transformer with full 3D spatial-temporal attention, and then we progressively adapt it for video garment inpainting, with a collection of masking strategies and multi-stage training. After these steps, the model can inpaint the masked garment area with appropriate garment pixels according to the prompt with good spatial-temporal consistency. Finally, as other try-on methods, garment condition is added to the model to make sure the inpainted garment appearance and details are as expected. Both quantitative and qualitative experimental results show that ViTI is superior to previous works.",
      "authors": [
        "Cheng Zou",
        "Senlin Cheng",
        "Bolei Xu",
        "Dandan Zheng",
        "Xiaobo Li",
        "Jingdong Chen",
        "Ming Yang"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21270",
        "HTML": "https://arxiv.org/html/2506.21270",
        "PDF": "https://arxiv.org/pdf/2506.21270"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 13:56:27 GMT",
          "size": "5740kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Video Virtual Try-on with Conditional Diffusion Transformer Inpainter",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper addresses video virtual try-on using a conditional diffusion transformer. It is centered around video processing and virtual try-on technology, without reference to LLM training data or data processing methodologies."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21272",
      "abstract": "We propose FairyGen, an automatic system for generating story-driven cartoon videos from a single child's drawing, while faithfully preserving its unique artistic style. Unlike previous storytelling methods that primarily focus on character consistency and basic motion, FairyGen explicitly disentangles character modeling from stylized background generation and incorporates cinematic shot design to support expressive and coherent storytelling. Given a single character sketch, we first employ an MLLM to generate a structured storyboard with shot-level descriptions that specify environment settings, character actions, and camera perspectives. To ensure visual consistency, we introduce a style propagation adapter that captures the character's visual style and applies it to the background, faithfully retaining the character's full visual identity while synthesizing style-consistent scenes. A shot design module further enhances visual diversity and cinematic quality through frame cropping and multi-view synthesis based on the storyboard. To animate the story, we reconstruct a 3D proxy of the character to derive physically plausible motion sequences, which are then used to fine-tune an MMDiT-based image-to-video diffusion model. We further propose a two-stage motion customization adapter: the first stage learns appearance features from temporally unordered frames, disentangling identity from motion; the second stage models temporal dynamics using a timestep-shift strategy with frozen identity weights. Once trained, FairyGen directly renders diverse and coherent video scenes aligned with the storyboard. Extensive experiments demonstrate that our system produces animations that are stylistically faithful, narratively structured natural motion, highlighting its potential for personalized and engaging story animation. The code will be available at https://github.com/GVCLab/FairyGen",
      "authors": [
        "Jiayi Zheng and Xiaodong Cun"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21272",
        "HTML": "https://arxiv.org/html/2506.21272",
        "PDF": "https://arxiv.org/pdf/2506.21272"
      },
      "subjects": [
        "Graphics (cs.GR)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Multimedia (cs.MM)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 13:58:16 GMT",
          "size": "14794kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "FairyGen: Storied Cartoon Video from a Single Child-Drawn Character",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "FairyGen generates storied cartoon videos from a child's drawing, focusing on artistic style preservation and animation. The emphasis is on video and animation technology rather than LLM training data processing."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21276",
      "abstract": "Achieving precise word-level typography control within generated images remains a persistent challenge. To address it, we newly construct a word-level controlled scene text dataset and introduce the Text-Image Alignment (TIA) framework. This framework leverages cross-modal correspondence between text and local image regions provided by grounding models to enhance the Text-to-Image (T2I) model training. Furthermore, we propose WordCon, a hybrid parameter-efficient fine-tuning (PEFT) method. WordCon reparameterizes selective key parameters, improving both efficiency and portability. This allows seamless integration into diverse pipelines, including artistic text rendering, text editing, and image-conditioned text rendering. To further enhance controllability, the masked loss at the latent level is applied to guide the model to concentrate on learning the text region in the image, and the joint-attention loss provides feature-level supervision to promote disentanglement between different words. Both qualitative and quantitative results demonstrate the superiority of our method to the state of the art. The datasets and source code will be available for academic use.",
      "authors": [
        "Wenda Shi",
        "Yiren Song",
        "Zihan Rao",
        "Dengming Zhang",
        "Jiaming Liu",
        "Xingxing Zou"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21276",
        "HTML": "https://arxiv.org/html/2506.21276",
        "PDF": "https://arxiv.org/pdf/2506.21276"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 14:00:38 GMT",
          "size": "17885kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "WordCon: Word-level Typography Control in Scene Text Rendering",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper discusses a method for enhancing scene text rendering using a newly constructed dataset, which is unrelated to the training data processing stages for LLMs."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21277",
      "abstract": "With the rapid evolution of multimodal large language models, the capacity to deeply understand and interpret human intentions has emerged as a critical capability, which demands detailed and thoughtful reasoning. In recent studies, Reinforcement Learning (RL) has demonstrated potential in enhancing the reasoning capabilities of Large Language Models (LLMs). Nonetheless, the challenges associated with adapting RL to multimodal data and formats remain largely unaddressed. In this paper, we identify two issues in existing multimodal reasoning models: insufficient global context understanding and shortcut problems. Insufficient context understanding can happen when a model misinterprets multimodal context, resulting in incorrect answers. The shortcut problem occurs when the model overlooks crucial clues in multimodal inputs, directly addressing the query without considering the multimodal information. To tackle these issues, we emphasize the necessity for the model to reason with a clear understanding of the global context within multimodal inputs. This global context understanding can effectively prevent the model from overlooking key multimodal cues and ensure a thorough reasoning process. To ensure the accurate interpretation of multimodal context information, we implement a context reward judged by a large language model, alongside format and accuracy rewards. Additionally, to improve complex reasoning capability, we employ the LLM to assess the logical reward, determining whether the reasoning process successfully integrates multimodal information with logical methods. We also introduce a reasoning omni-modal benchmark, IntentBench, aimed at evaluating models in understanding complex human intentions and emotions. Our proposed method demonstrates advanced performance across multiple omni-modal benchmarks compared to other open-source omni-modal models.",
      "authors": [
        "Qize Yang",
        "Shimin Yao",
        "Weixuan Chen",
        "Shenghao Fu",
        "Detao Bai",
        "Jiaxing Zhao",
        "Boyuan Sun",
        "Bowen Yin",
        "Xihan Wei",
        "Jingren Zhou"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21277",
        "HTML": "https://arxiv.org/html/2506.21277",
        "PDF": "https://arxiv.org/pdf/2506.21277"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 14:01:03 GMT",
          "size": "3911kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "HumanOmniV2: From Understanding to Omni-Modal Reasoning with Context",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper is centered on enhancing multimodal reasoning in LLMs using reinforcement learning, focusing on reasoning processes rather than data engineering or processing for LLM training."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21281",
      "abstract": "Snake is a classic computer game, which has been around for decades. Based on this game, we study the game of Snake on arbitrary undirected graphs. A snake forms a simple path that has to move to an apple while avoiding colliding with itself. When the snake reaches the apple, it grows longer, and a new apple appears. A graph on which the snake has a strategy to keep eating apples until it covers all the vertices of the graph is called snake-winnable. We prove that determining whether a graph is snake-winnable is NP-hard, even when restricted to grid graphs. We fully characterize snake-winnable graphs for odd-sized bipartite graphs and graphs with vertex-connectivity 1. While Hamiltonian graphs are always snake-winnable, we show that non-Hamiltonian snake-winnable graphs have a girth of at most 6 and that this bound is tight.",
      "authors": [
        "Denise Graafsma",
        "Bodo Manthey",
        "Alexander Skopalik"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21281",
        "HTML": "https://arxiv.org/html/2506.21281",
        "PDF": "https://arxiv.org/pdf/2506.21281"
      },
      "subjects": [
        "Discrete Mathematics (cs.DM)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 14:02:34 GMT",
          "size": "179kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Playing Snake on a Graph",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper addresses the combinatorial problem of snake games on graphs and does not cover topics related to LLM training data processing or engineering."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21287",
      "abstract": "Surgical Video Synthesis has emerged as a promising research direction following the success of diffusion models in general-domain video generation. Although existing approaches achieve high-quality video generation, most are unconditional and fail to maintain consistency with surgical actions and phases, lacking the surgical understanding and fine-grained guidance necessary for factual simulation. We address these challenges by proposing HieraSurg, a hierarchy-aware surgical video generation framework consisting of two specialized diffusion models. Given a surgical phase and an initial frame, HieraSurg first predicts future coarse-grained semantic changes through a segmentation prediction model. The final video is then generated by a second-stage model that augments these temporal segmentation maps with fine-grained visual features, leading to effective texture rendering and integration of semantic information in the video space. Our approach leverages surgical information at multiple levels of abstraction, including surgical phase, action triplets, and panoptic segmentation maps. The experimental results on Cholecystectomy Surgical Video Generation demonstrate that the model significantly outperforms prior work both quantitatively and qualitatively, showing strong generalization capabilities and the ability to generate higher frame-rate videos. The model exhibits particularly fine-grained adherence when provided with existing segmentation maps, suggesting its potential for practical surgical applications.",
      "authors": [
        "Diego Biagini",
        "Nassir Navab",
        "Azade Farshad"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21287",
        "HTML": "https://arxiv.org/html/2506.21287",
        "PDF": "https://arxiv.org/pdf/2506.21287"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 14:07:23 GMT",
          "size": "8592kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "HieraSurg: Hierarchy-Aware Diffusion Model for Surgical Video Generation",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper addresses a hierarchy-aware diffusion model for video generation, specifically in surgical contexts, and does not include any discussion relevant to LLM training data processing."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21291",
      "abstract": "We revisit the randomized seeding techniques for k-means clustering and k-GMM (Gaussian Mixture model fitting with Expectation-Maximization), formalizing their three key ingredients: the metric used for seed sampling, the number of candidate seeds, and the metric used for seed selection. This analysis yields novel families of initialization methods exploiting a lookahead principle--conditioning the seed selection to an enhanced coherence with the final metric used to assess the algorithm, and a multipass strategy to tame down the effect of randomization.\n  Experiments show a consistent constant factor improvement over classical contenders in terms of the final metric (SSE for k-means, log-likelihood for k-GMM), at a modest overhead. In particular, for k-means, our methods improve on the recently designed multi-swap strategy, which was the first one to outperform the greedy k-means++ seeding.\n  Our experimental analysis also shed light on subtle properties of k-means often overlooked, including the (lack of) correlations between the SSE upon seeding and the final SSE, the variance reduction phenomena observed in iterative seeding methods, and the sensitivity of the final SSE to the pool size for greedy methods.\n  Practically, our most effective seeding methods are strong candidates to become one of the--if not the--standard techniques. From a theoretical perspective, our formalization of seeding opens the door to a new line of analytical approaches.",
      "authors": [
        "Guillaume Carri\\`ere and Fr\\'ed\\'eric Cazals"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21291",
        "HTML": "https://arxiv.org/html/2506.21291",
        "PDF": "https://arxiv.org/pdf/2506.21291"
      },
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 14:10:40 GMT",
          "size": "3037kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Improved seeding strategies for k-means and k-GMM",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on improved seeding strategies for k-means and k-GMM clustering, which is unrelated to LLM training data processing."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21297",
      "abstract": "In the micro frontends architectural style, the frontend is divided into smaller components, which can range from a simple button to an entire page. The goal is to improve scalability, resilience, and team independence, albeit at the cost of increased complexity and infrastructure demands. This paper seeks to understand when it is worth adopting micro frontends, particularly in the context of industry. To achieve this, we conducted an investigation into the state of the art of micro frontends, based on both academic and gray literature. We then implemented this architectural style in a marketplace for handcrafted products, which already used microservices. Finally, we evaluated the implementation through a semi-open questionnaire with the developers. At the studied marketplace company, the need for architectural change arose due to the tight coupling between their main system (a Java monolith) and a dedicated frontend system. Additionally, there were deprecated technologies and poor developer experience. To address these issues, the micro frontends architecture was adopted, along with the API Gateway and Backend for Frontend patterns, and technologies such as Svelte and Fastify. Although the adoption of Micro Frontends was successful, it was not strictly necessary to meet the company's needs. According to the analysis of the mixed questionnaire responses, other alternatives, such as a monolithic frontend, could have achieved comparable results. What made adopting micro frontends the most convenient choice in the company's context was the monolith strangulation and microservices adoption, which facilitated implementation through infrastructure reuse and knowledge sharing between teams.",
      "authors": [
        "Ricardo Hideki Hangai Kojo (1)",
        "Luiz Fernando Corte Real (1)",
        "Renato Cordeiro Ferreira (1,2,3,4)",
        "Thatiane de Oliveira Rosa (1,5)",
        "Alfredo Goldman (1) ((1) University of S\\~ao Paulo",
        "(2) Jheronimus Academy of Data Science",
        "(3) Technical University of Eindhoven",
        "(4) Tilburg University",
        "(5) Federal Institute of Tocantins)"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21297",
        "HTML": "https://arxiv.org/html/2506.21297",
        "PDF": "https://arxiv.org/pdf/2506.21297"
      },
      "subjects": [
        "Software Engineering (cs.SE)",
        "Distributed, Parallel, and Cluster Computing (cs.DC)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 14:17:22 GMT",
          "size": "138kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Exploring Micro Frontends: A Case Study Application in E-Commerce",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on micro frontend architectural design and its application in e-commerce systems, with no mention of LLM training data processing."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21300",
      "abstract": "Advances in Internet-of-Things (IoT) technologies have prompted the integration of IoT devices with business processes (BPs) in many organizations across various sectors, such as manufacturing, healthcare and smart spaces. The proliferation of IoT devices leads to the generation of large amounts of IoT data providing a window on the physical context of BPs, which facilitates the discovery of new insights about BPs using process mining (PM) techniques. However, to achieve these benefits, IoT data need to be combined with traditional process (event) data, which is challenging due to the very different characteristics of IoT and process data, for instance in terms of granularity levels. Recently, several data models were proposed to integrate IoT data with process data, each focusing on different aspects of data integration based on different assumptions and requirements. This fragmentation hampers data exchange and collaboration in the field of PM, e.g., making it tedious for researchers to share data. In this paper, we present a core model synthesizing the most important features of existing data models. As the core model is based on common requirements, it greatly facilitates data sharing and collaboration in the field. A prototypical Python implementation is used to evaluate the model against various use cases and demonstrate that it satisfies these common requirements.",
      "authors": [
        "Yannis Bertrand",
        "Christian Imenkamp",
        "Lukas Malburg",
        "Matthias Ehrendorfer",
        "Marco Franceschetti",
        "Joscha Gr\\\"uger",
        "Francesco Leotta",
        "J\\\"urgen Mangler",
        "Ronny Seiger",
        "Agnes Koschmider",
        "Stefanie Rinderle-Ma",
        "Barbara Weber and Estefania Serral"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21300",
        "HTML": "https://arxiv.org/html/2506.21300",
        "PDF": "https://arxiv.org/pdf/2506.21300"
      },
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 14:19:44 GMT",
          "size": "706kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "An object-centric core metamodel for IoT-enhanced event logs",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper discusses integrating IoT data with business process event data for process mining, without addressing any aspects of LLM training data processing."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21302",
      "abstract": "The effective and safe management of traffic is a key issue due to the rapid advancement of the urban transportation system. Connected autonomous vehicles (CAVs) possess the capability to connect with each other and adjacent infrastructure, presenting novel opportunities for enhancing traffic flow and coordination. This work proposes a dual-mode model predictive control (MPC) architecture that tackles two interrelated issues: mitigating traffic density at signalized junctions and facilitating seamless, cooperative lane changes in high-density traffic conditions. The objective of this work is to facilitate responsive decision-making for CAVs, thereby enhancing the efficiency and safety of urban mobility. Moreover, we ensure recursive feasibility and convergence of the proposed MPC scheme by the integration of an online-calculated maximal control invariant terminal set. Finally, the efficacy of the proposed approach is validated through numerical simulation.",
      "authors": [
        "Rudra Sen and Subashish Datta"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21302",
        "HTML": "https://arxiv.org/html/2506.21302",
        "PDF": "https://arxiv.org/pdf/2506.21302"
      },
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 14:21:41 GMT",
          "size": "681kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Coordinated Control of Autonomous Vehicles for Traffic Density Reduction at a Signalized Junction: An MPC Approach",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper deals with traffic management using autonomous vehicles and model predictive control, not related to LLM training data processing."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21306",
      "abstract": "It is a classical result in rational approximation theory that certain non-smooth or singular functions, such as $|x|$ and $x^{1/p}$, can be efficiently approximated using rational functions with root-exponential convergence in terms of degrees of freedom \\cite{Sta, GN}. In contrast, polynomial approximations admit only algebraic convergence by Jackson's theorem \\cite{Lub2}. Recent work shows that composite polynomial architectures can recover exponential approximation rates even without smoothness \\cite{KY}. In this work, we introduce and analyze a class of weighted deep polynomial approximants tailored for functions with asymmetric behavior-growing unbounded on one side and decaying on the other. By multiplying a learnable deep polynomial with a one-sided weight, we capture both local non-smoothness and global growth. We show numerically that this framework outperforms Taylor, Chebyshev, and standard deep polynomial approximants, even when all use the same number of parameters. To optimize these approximants in practice, we propose a stable graph-based parameterization strategy building on \\cite{Jar}.",
      "authors": [
        "Kingsley Yeon",
        "Steven B. Damelin"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21306",
        "HTML": "https://arxiv.org/html/2506.21306",
        "PDF": "https://arxiv.org/pdf/2506.21306"
      },
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)",
        "Numerical Analysis (cs.NA)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 14:25:32 GMT",
          "size": "1124kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "On Uniform Weighted Deep Polynomial approximation",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on deep polynomial approximation for non-smooth or singular functions without addressing LLM training data processing."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21307",
      "abstract": "We investigate the Dispersive Art Gallery Problem with vertex guards and rectangular visibility ($r$-visibility) for a class of orthogonal polygons that reflect the properties of real-world floor plans: these office-like polygons consist of rectangular rooms and corridors. In the dispersive variant of the Art Gallery Problem, the objective is not to minimize the number of guards but to maximize the minimum geodesic $L_1$-distance between any two guards, called the dispersion distance.\n  Our main contributions are as follows. We prove that determining whether a vertex guard set can achieve a dispersion distance of $4$ in office-like polygons is NP-complete, where vertices of the polygon are restricted to integer coordinates. Additionally, we present a simple worst-case optimal algorithm that guarantees a dispersion distance of $3$ in polynomial time. Our complexity result extends to polyominoes, resolving an open question posed by Rieck and Scheffer (CGTA 2024). When vertex coordinates are allowed to be rational, we establish analogous results, proving that achieving a dispersion distance of $2+\\varepsilon$ is NP-hard for any $\\varepsilon > 0$, while the classic Art Gallery Problem remains solvable in polynomial time for this class of polygons. Furthermore, we give a straightforward polynomial-time algorithm that computes worst-case optimal solutions with a dispersion distance of $2$.\n  On the other hand, for the more restricted class of hole-free independent office-like polygons, we propose a dynamic programming approach that computes optimal solutions. Moreover, we demonstrate that the problem is practically tractable for arbitrary orthogonal polygons. To this end, we compare solvers based on SAT, CP, and MIP formulations. Notably, SAT solvers efficiently compute optimal solutions for randomly generated instances with up to $1600$ vertices in under $15$s.",
      "authors": [
        "S\\'andor P. Fekete and Kai Kobbe and Dominik Krupke and Joseph S. B. Mitchell and Christian Rieck and Christian Scheffer"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21307",
        "HTML": "https://arxiv.org/html/2506.21307",
        "PDF": "https://arxiv.org/pdf/2506.21307"
      },
      "subjects": [
        "Computational Geometry (cs.CG)",
        "Data Structures and Algorithms (cs.DS)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 14:25:35 GMT",
          "size": "1131kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Guarding Offices with Maximum Dispersion",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on the Dispersive Art Gallery Problem, specifically related to maximizing dispersion distance in polygonal environments and does not address any aspect of LLM training data processing or data engineering."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21310",
      "abstract": "Although several post-hoc methods for explainable AI have been developed, most are static and neglect the user perspective, limiting their effectiveness for the target audience. In response, we developed the interactive explainable intelligent system called IXAII that offers explanations from four explainable AI methods: LIME, SHAP, Anchors, and DiCE. Our prototype provides tailored views for five user groups and gives users agency over the explanations' content and their format. We evaluated IXAII through interviews with experts and lay users. Our results indicate that IXAII, which provides different explanations with multiple visualization options, is perceived as helpful to increase transparency. By bridging the gaps between explainable AI methods, interactivity, and practical implementation, we provide a novel perspective on AI explanation practices and human-AI interaction.",
      "authors": [
        "Pauline Speckmann and Mario Nadj and Christian Janiesch"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21310",
        "HTML": "https://arxiv.org/html/2506.21310",
        "PDF": "https://arxiv.org/pdf/2506.21310"
      },
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 14:28:13 GMT",
          "size": "261kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "IXAII: An Interactive Explainable Artificial Intelligence Interface for Decision Support Systems",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The focus of the paper is on developing an interactive explainable AI interface. It does not address LLM training data processing or data engineering."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21311",
      "abstract": "Electric grids in low- and middle-income countries (LMICs) across the world face an acute challenge. To support global decarbonisation efforts and raise millions from energy poverty, these grids must shoulder substantial load growth while integrating distributed renewable generation. However, decades of rapid and poorly funded infrastructure expansions have led to national grids in many LMICs that are strained and weak, composed of aging, faulty, and undersized infrastructure. A cause and symptom of this weakness is excessive technical loss within the grid infrastructure during energy delivery, particularly at the distribution level; network losses are regularly estimated to be well over 20 percent, compared to a baseline of 5 percent in higher-income nations. Addressing technical loss through targeted interventions is essential for bolstering grids' physical and economic strength. Unfortunately, current approaches for estimating and localizing technical loss require expensive, extensive power flow sensing, which is essentially absent in LMIC distribution systems. We present a novel approach to technical loss estimation without power flows, which leverages more readily available voltage magnitude measurements at sparse locations in the grid. This estimator puts loss estimation and localization within reach for LMIC grids globally, and provides a critical tool for the effective design, implementation, and evaluation of loss-reduction interventions.",
      "authors": [
        "Mohini Bariya and Genevieve Flaspohler"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21311",
        "HTML": "https://arxiv.org/html/2506.21311",
        "PDF": "https://arxiv.org/pdf/2506.21311"
      },
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 14:28:37 GMT",
          "size": "1113kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Estimating Technical Loss without Power Flows: A Practical, Data-Driven Approach for Loss Estimation in Distribution Grids",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper introduces a method for estimating technical loss in electric distribution grids, unrelated to LLM training data processing or engineering."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21312",
      "abstract": "The development of continual learning (CL) methods, which aim to learn new tasks in a sequential manner from the training data acquired continuously, has gained great attention in remote sensing (RS). The existing CL methods in RS, while learning new tasks, enhance robustness towards catastrophic forgetting. This is achieved by using a large number of labeled training samples, which is costly and not always feasible to gather in RS. To address this problem, we propose a novel continual self-supervised learning method in the context of masked autoencoders (denoted as CoSMAE). The proposed CoSMAE consists of two components: i) data mixup; and ii) model mixup knowledge distillation. Data mixup is associated with retaining information on previous data distributions by interpolating images from the current task with those from the previous tasks. Model mixup knowledge distillation is associated with distilling knowledge from past models and the current model simultaneously by interpolating their model weights to form a teacher for the knowledge distillation. The two components complement each other to regularize the MAE at the data and model levels to facilitate better generalization across tasks and reduce the risk of catastrophic forgetting. Experimental results show that CoSMAE achieves significant improvements of up to 4.94% over state-of-the-art CL methods applied to MAE. Our code is publicly available at: https://git.tu-berlin.de/rsim/CoSMAE.",
      "authors": [
        "Lars M\\\"ollenbrok",
        "Behnood Rasti",
        "Beg\\\"um Demir"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21312",
        "HTML": "https://arxiv.org/html/2506.21312",
        "PDF": "https://arxiv.org/pdf/2506.21312"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 14:28:59 GMT",
          "size": "1337kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Continual Self-Supervised Learning with Masked Autoencoders in Remote Sensing",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on a continual self-supervised learning method for remote sensing using masked autoencoders, particularly addressing catastrophic forgetting. It does not discuss processing of training data for LLMs or related tasks."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21314",
      "abstract": "We develop a mass-conserving, adaptive-rank solver for the 1D1V Wigner-Poisson system. Our work is motivated by applications to the study of the stopping power of $\\alpha$ particles at the National Ignition Facility (NIF). In this regime, electrons are in a warm dense state, requiring more than a standard kinetic model. They are hot enough to neglect Pauli exclusion, yet quantum enough to require accounting for uncertainty. The Wigner-Poisson system captures these effects but presents challenges due to its nonlocal nature. Based on a second-order Strang splitting method, we first design a full-rank solver with a structure-preserving Fourier update that ensures the intermediate solutions remain real-valued (up to machine precision), improving upon previous methods. Simulations demonstrate that the solutions exhibit a low rank structure for moderate to high dimensionless Planck constants ($H \\ge 0.1$). This observed low rank structure motivates the development of an adaptive-rank solver, built on a Semi-Lagrangian adaptive-rank (SLAR) scheme for advection and an adaptive-rank, structure-preserving Fourier update for the Wigner integral terms, with a rigorous proof of structure-preserving property provided. Our solver achieves $O(N)$ complexity in both storage and computation time, while preserving mass and maintaining momentum accuracy up to the truncation error. The adaptive rank simulations are visually indistinguishable from the full-rank simulations in capturing solution structures. These results highlight the potential of adaptive rank methods for high-dimensional Wigner-Poisson simulations, paving the way toward fully kinetic studies of stopping power in warm dense plasmas.",
      "authors": [
        "Andrew Christlieb",
        "Sining Gong",
        "Jing-Mei Qiu and Nanyi Zheng"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21314",
        "HTML": "https://arxiv.org/html/2506.21314",
        "PDF": "https://arxiv.org/pdf/2506.21314"
      },
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 14:29:12 GMT",
          "size": "8833kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "A Sampling-Based Adaptive Rank Approach to the Wigner-Poisson System",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper addresses the development of an adaptive-rank solver for the Wigner-Poisson system, motivated by physics applications. It does not discuss data processing related to LLMs."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21322",
      "abstract": "Advancements in robotic capabilities for providing physical assistance, psychological support, and daily health management are making the deployment of intelligent healthcare robots in home environments increasingly feasible in the near future. However, challenges arise when the information provided by these robots contradicts users' memory, raising concerns about user trust and decision-making. This paper presents a study that examines how varying a robot's level of transparency and sociability influences user interpretation, decision-making and perceived trust when faced with conflicting information from a robot. In a 2 x 2 between-subjects online study, 176 participants watched videos of a Furhat robot acting as a family healthcare assistant and suggesting a fictional user to take medication at a different time from that remembered by the user. Results indicate that robot transparency influenced users' interpretation of information discrepancies: with a low transparency robot, the most frequent assumption was that the user had not correctly remembered the time, while with the high transparency robot, participants were more likely to attribute the discrepancy to external factors, such as a partner or another household member modifying the robot's information. Additionally, participants exhibited a tendency toward overtrust, often prioritizing the robot's recommendations over the user's memory, even when suspecting system malfunctions or third-party interference. These findings highlight the impact of transparency mechanisms in robotic systems, the complexity and importance associated with system access control for multi-user robots deployed in home environments, and the potential risks of users' over reliance on robots in sensitive domains such as healthcare.",
      "authors": [
        "Hong Wang",
        "Natalia Calvo-Barajas",
        "Katie Winkle",
        "and Ginevra Castellano"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21322",
        "HTML": "https://arxiv.org/html/2506.21322",
        "PDF": "https://arxiv.org/pdf/2506.21322"
      },
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 14:37:54 GMT",
          "size": "5117kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "\"Who Should I Believe?\": User Interpretation and Decision-Making When a Family Healthcare Robot Contradicts Human Memory",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on user interpretation and decision-making when interacting with healthcare robots, without any discussion on LLM training data processing or data engineering."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21324",
      "abstract": "Neuromorphic and quantum computing have recently emerged as promising paradigms for advancing artificial intelligence, each offering complementary strengths. Neuromorphic systems built on spiking neurons excel at processing time-series data efficiently through sparse, event-driven computation, consuming energy only upon input events. Quantum computing, on the other hand, leverages superposition and entanglement to explore feature spaces that are exponentially large in the number of qubits. Hybrid approaches combining these paradigms have begun to show potential, but existing quantum spiking models have important limitations. Notably, prior quantum spiking neuron implementations rely on classical memory mechanisms on single qubits, requiring repeated measurements to estimate firing probabilities, and they use conventional backpropagation on classical simulators for training. Here we propose a stochastic quantum spiking (SQS) neuron model that addresses these challenges. The SQS neuron uses multi-qubit quantum circuits to realize a spiking unit with internal quantum memory, enabling event-driven probabilistic spike generation in a single shot. Furthermore, we outline how networks of SQS neurons -- dubbed SQS neural networks (SQSNNs) -- can be trained via a hardware-friendly local learning rule, eliminating the need for global classical backpropagation. The proposed SQSNN model fuses the time-series efficiency of neuromorphic computing with the exponentially large inner state space of quantum computing, paving the way for quantum spiking neural networks that are modular, scalable, and trainable on quantum hardware.",
      "authors": [
        "Jiechen Chen",
        "Bipin Rajendran",
        "Osvaldo Simeone"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21324",
        "HTML": "https://arxiv.org/html/2506.21324",
        "PDF": "https://arxiv.org/pdf/2506.21324"
      },
      "subjects": [
        "Neural and Evolutionary Computing (cs.NE)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 14:39:14 GMT",
          "size": "1044kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Stochastic Quantum Spiking Neural Networks with Quantum Memory and Local Learning",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper introduces a quantum spiking neuron model, concentrating on quantum and neuromorphic computation without addressing LLM training data or processing."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21326",
      "abstract": "We present a first numerical study of transport phenomena involving chemically reactive species, modeled by advection-diffusion-reaction systems with flow fields governed by Darcy's law. Among the various discretisation approaches, we consider the Streamline Diffusion method. Both the velocity field and the species concentrations are computed using the Virtual Element Method using a Discontinuous Galerkin scheme for time. An abstract error estimate has been derived using a special technique that utilizes Gauss-Radau interpolation in conjunction with numerical integration. These theoretical findings are supported by numerical experiments with arbitrary-order accuracy in both space and time.",
      "authors": [
        "R A Caraballo Diaz",
        "F Dassi"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21326",
        "HTML": "https://arxiv.org/html/2506.21326",
        "PDF": "https://arxiv.org/pdf/2506.21326"
      },
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 14:40:29 GMT",
          "size": "2967kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "A discontinuous in time Streamline Diffusion Virtual Element Method for Darcy-transport problem",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The research involves numerical analysis of chemical transport phenomena and does not relate to the collection, construction, or processing of LLM training data."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21327",
      "abstract": "There is growing interest in providing programmatic access to the value locked in Bitcoin, which famously offers limited programmability itself. Various approaches have been put forth in recent years, with the vast majority of proposed mechanisms either building new functionality on top of Bitcoin or leveraging a bridging mechanism to enable smart contracts that make use of ``wrapped'' bitcoins on entirely different platforms.\n  In this work, an architecture is presented that follows a different approach. The architecture enables the execution of Turing-complete Bitcoin smart contracts on the Internet Computer (IC), a blockchain platform for hosting and executing decentralized applications. Instead of using a bridge, IC and Bitcoin nodes interact directly, eliminating potential security risks that the use of a bridge entails. This integration requires novel concepts, in particular to reconcile the probabilistic nature of Bitcoin with the irreversibility of finalized state changes on the IC, which may be of independent interest.\n  In addition to the presentation of the architecture, we provide evaluation results based on measurements of the Bitcoin integration running on mainnet. The evaluation results demonstrate that, with finalization in a few seconds and low execution costs, this integration enables complex Bitcoin-based decentralized applications that were not practically feasible or economically viable before.",
      "authors": [
        "Ryan Croote",
        "Islam El-Ashi",
        "Thomas Locher",
        "Yvonne-Anne Pignolet"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21327",
        "HTML": "https://arxiv.org/html/2506.21327",
        "PDF": "https://arxiv.org/pdf/2506.21327"
      },
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 14:41:01 GMT",
          "size": "411kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Enabling Bitcoin Smart Contracts on the Internet Computer",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper discusses enabling Bitcoin smart contracts on different platforms, unrelated to LLM training data processing or data engineering."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21328",
      "abstract": "Mixture-of-Experts (MoE) architectures have emerged as a key strategy for scaling large language models (LLMs) efficiently. However, current MoE systems suffer from severe load imbalance, where only a small subset of experts is consistently activated during training and inference, leading to significant underutilization of model capacity and computational resources. In this work, we revisit expert routing through a clustering perspective and propose Latent Prototype Routing (LPR), a novel routing framework that generalizes existing approaches while promoting balanced expert utilization without compromising downstream performance. Extensive experiments across multiple open-source MoE models -- including DeepSeek-V3, Qwen3-MoE, and Mixtral -- demonstrate that LPR reduces the Gini coefficient of expert load from 0.70 to 0.035 on average, improves the min-max expert load ratio from 1e-6 to 0.70, achieving near-perfect load balancing.",
      "authors": [
        "Jiajie Yang"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21328",
        "HTML": "https://arxiv.org/html/2506.21328",
        "PDF": "https://arxiv.org/pdf/2506.21328"
      },
      "subjects": [
        "Machine Learning (cs.LG)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 14:41:18 GMT",
          "size": "156kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Latent Prototype Routing: Achieving Near-Perfect Load Balancing in Mixture-of-Experts",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "While the paper discusses model architecture for large language models (LLMs), it focuses on improving computational efficiency without discussing specific stages of data processing or engineering for LLM training."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21329",
      "abstract": "The rapid evolution of artificial intelligence has led to expectations of transformative scientific discovery, yet current systems remain fundamentally limited by their operational architectures, brittle reasoning mechanisms, and their separation from experimental reality. Building on earlier work, we contend that progress in AI-driven science now depends on closing three fundamental gaps -- the abstraction gap, the reasoning gap, and the reality gap -- rather than on model size/data/test time compute. Scientific reasoning demands internal representations that support simulation of actions and response, causal structures that distinguish correlation from mechanism, and continuous calibration. We define active inference AI systems for scientific discovery as those that (i) maintain long-lived research memories grounded in causal self-supervised foundation models, (ii) symbolic or neuro-symbolic planners equipped with Bayesian guardrails, (iii) grow persistent knowledge graphs where thinking generates novel conceptual nodes, reasoning establishes causal edges, and real-world interaction prunes false connections while strengthening verified pathways, and (iv) refine their internal representations through closed-loop interaction with both high-fidelity simulators and automated laboratories - an operational loop where mental simulation guides action and empirical surprise reshapes understanding. In essence, we outline an architecture where discovery arises from the interplay between internal models that enable counterfactual reasoning and external validation that grounds hypotheses in reality. It is also argued that the inherent ambiguity in feedback from simulations and experiments, and underlying uncertainties makes human judgment indispensable, not as a temporary scaffold but as a permanent architectural component.",
      "authors": [
        "Karthik Duraisamy"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21329",
        "HTML": "https://arxiv.org/html/2506.21329",
        "PDF": "https://arxiv.org/pdf/2506.21329"
      },
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Physics and Society (physics.soc-ph)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 14:43:04 GMT",
          "size": "186kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Active Inference AI Systems for Scientific Discovery",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on architectures for scientific discovery using active inference, with no mention of LLM training data, processing, collection, or enhancement related to LLMs."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21330",
      "abstract": "Surgical workflow analysis is essential in robot-assisted surgeries, yet the long duration of such procedures poses significant challenges for comprehensive video analysis. Recent approaches have predominantly relied on transformer models; however, their quadratic attention mechanism restricts efficient processing of lengthy surgical videos. In this paper, we propose a novel hierarchical input-dependent state space model that leverages the linear scaling property of state space models to enable decision making on full-length videos while capturing both local and global dynamics. Our framework incorporates a temporally consistent visual feature extractor, which appends a state space model head to a visual feature extractor to propagate temporal information. The proposed model consists of two key modules: a local-aggregation state space model block that effectively captures intricate local dynamics, and a global-relation state space model block that models temporal dependencies across the entire video. The model is trained using a hybrid discrete-continuous supervision strategy, where both signals of discrete phase labels and continuous phase progresses are propagated through the network. Experiments have shown that our method outperforms the current state-of-the-art methods by a large margin (+2.8% on Cholec80, +4.3% on MICCAI2016, and +12.9% on Heichole datasets). Code will be publicly available after paper acceptance.",
      "authors": [
        "Haoyang Wu",
        "Tsun-Hsuan Wang",
        "Mathias Lechner",
        "Ramin Hasani",
        "Jennifer A. Eckhoff",
        "Paul Pak",
        "Ozanan R. Meireles",
        "Guy Rosman",
        "Yutong Ban",
        "Daniela Rus"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21330",
        "HTML": "https://arxiv.org/html/2506.21330",
        "PDF": "https://arxiv.org/pdf/2506.21330"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 14:43:57 GMT",
          "size": "3154kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Holistic Surgical Phase Recognition with Hierarchical Input Dependent State Space Models",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper presents a model for surgical phase recognition and does not discuss data engineering or processing related to LLMs."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21331",
      "abstract": "Everyday, a vast stream of research documents is submitted to conferences, anthologies, journals, newsletters, annual reports, daily papers, and various periodicals. Many such publications use independent external specialists to review submissions. This process is called peer review, and the reviewers are called referees. However, it is not always possible to pick the best referee for reviewing. Moreover, new research fields are emerging in every sector, and the number of research papers is increasing dramatically. To review all these papers, every journal assigns a small team of referees who may not be experts in all areas. For example, a research paper in communication technology should be reviewed by an expert from the same field. Thus, efficiently selecting the best reviewer or referee for a research paper is a big challenge.\n  In this research, we propose and implement program that uses a new strategy to automatically select the best reviewers for a research paper. Every research paper contains references at the end, usually from the same area. First, we collect the references and count authors who have at least one paper in the references. Then, we automatically browse the web to extract research topic keywords. Next, we search for top researchers in the specific topic and count their h-index, i10-index, and citations for the first n authors. Afterward, we rank the top n authors based on a score and automatically browse their homepages to retrieve email addresses. We also check their co-authors and colleagues online and discard them from the list. The remaining top n authors, generally professors, are likely the best referees for reviewing the research paper.",
      "authors": [
        "Tamim Al Mahmud",
        "B M Mainul Hossain and Dilshad Ara"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21331",
        "HTML": "https://arxiv.org/html/2506.21331",
        "PDF": "https://arxiv.org/pdf/2506.21331"
      },
      "subjects": [
        "Digital Libraries (cs.DL)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 14:44:06 GMT",
          "size": "144kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Automatic Reviewers Assignment to a Research Paper Based on Allied References and Publications Weight",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper describes a method for automatic reviewer assignment and does not involve LLM training data processing or enhancement."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21333",
      "abstract": "The co creativity community is making significant progress in developing more sophisticated and tailored systems to support and enhance human creativity. Design considerations from prior work can serve as a valuable and efficient foundation for future systems. To support this effort, we conducted a systematic literature review of 62 papers on co-creative systems. These papers cover a diverse range of applications, including visual arts, design, and writing, where the AI acts not just as a tool but as an active collaborator in the creative process. From this review, we identified several key dimensions relevant to system design: phase of the creative process, creative task, proactive behavior of the system, user control, system embodiment, and AI model type. Our findings suggest that systems offering high user control lead to greater satisfaction, trust, and a stronger sense of ownership over creative outcomes. Furthermore, proactive systems, when adaptive and context sensitive, can enhance collaboration. We also extracted 24 design considerations, highlighting the value of encouraging users to externalize their thoughts and of increasing the system's social presence and transparency to foster trust. Despite recent advancements, important gaps remain, such as limited support for early creative phases like problem clarification, and challenges related to user adaptation to AI systems.",
      "authors": [
        "Saloni Singh",
        "Koen Hndriks",
        "Drik Heylen",
        "Kim Baraka"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21333",
        "HTML": "https://arxiv.org/html/2506.21333",
        "PDF": "https://arxiv.org/pdf/2506.21333"
      },
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 14:44:52 GMT",
          "size": "1851kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "A Systematic Review of Human-AI Co-Creativity",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper provides a review of human-AI co-creativity systems and does not discuss training data formulation or processing for LLMs."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21338",
      "abstract": "Brain-computer interface (BCI) technology utilizing electroencephalography (EEG) marks a transformative innovation, empowering motor-impaired individuals to engage with their environment on equal footing. Despite its promising potential, developing subject-invariant and session-invariant BCI systems remains a significant challenge due to the inherent complexity and variability of neural activity across individuals and over time, compounded by EEG hardware constraints. While prior studies have sought to develop robust BCI systems, existing approaches remain ineffective in capturing the intricate spatiotemporal dependencies within multichannel EEG signals. This study addresses this gap by introducing the attentive graph-temporal convolutional network (AGTCNet), a novel graph-temporal model for motor imagery EEG (MI-EEG) classification. Specifically, AGTCNet leverages the topographic configuration of EEG electrodes as an inductive bias and integrates graph convolutional attention network (GCAT) to jointly learn expressive spatiotemporal EEG representations. The proposed model significantly outperformed existing MI-EEG classifiers, achieving state-of-the-art performance while utilizing a compact architecture, underscoring its effectiveness and practicality for BCI deployment. With a 49.87% reduction in model size, 64.65% faster inference time, and shorter input EEG signal, AGTCNet achieved a moving average accuracy of 66.82% for subject-independent classification on the BCI Competition IV Dataset 2a, which further improved to 82.88% when fine-tuned for subject-specific classification. On the EEG Motor Movement/Imagery Dataset, AGTCNet achieved moving average accuracies of 64.14% and 85.22% for 4-class and 2-class subject-independent classifications, respectively, with further improvements to 72.13% and 90.54% for subject-specific classifications.",
      "authors": [
        "Galvin Brice S. Lim",
        "Brian Godwin S. Lim",
        "Argel A. Bandala",
        "John Anthony C. Jose",
        "Timothy Scott C. Chu",
        "Edwin Sybingco"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21338",
        "HTML": "https://arxiv.org/html/2506.21338",
        "PDF": "https://arxiv.org/pdf/2506.21338"
      },
      "subjects": [
        "Machine Learning (cs.LG)",
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 14:49:10 GMT",
          "size": "8661kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "AGTCNet: A Graph-Temporal Approach for Principled Motor Imagery EEG Classification",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on a novel model for motor imagery EEG classification and does not mention any contributions related to LLM training data processing, construction, or enhancement."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21347",
      "abstract": "This research addresses critical autonomous vehicle control challenges arising from road roughness variation, which induces course deviations and potential loss of road contact during steering operations. We present a novel real-time road roughness estimation system employing Bayesian calibration methodology that processes axle accelerations to predict terrain roughness with quantifiable confidence measures. The technical framework integrates a Gaussian process surrogate model with a simulated half-vehicle model, systematically processing vehicle velocity and road surface roughness parameters to generate corresponding axle acceleration responses. The Bayesian calibration routine performs inverse estimation of road roughness from observed accelerations and velocities, yielding posterior distributions that quantify prediction uncertainty for adaptive risk management. Training data generation utilizes Latin Hypercube sampling across comprehensive velocity and roughness parameter spaces, while the calibrated model integrates seamlessly with a Simplex controller architecture to dynamically adjust velocity limits based on real-time roughness predictions. Experimental validation on stochastically generated surfaces featuring varying roughness regions demonstrates robust real-time characterization capabilities, with the integrated Simplex control strategy effectively enhancing autonomous vehicle operational safety through proactive surface condition response. This innovative Bayesian framework establishes a comprehensive foundation for mitigating roughness-related operational risks while simultaneously improving efficiency and safety margins in autonomous vehicle systems.",
      "authors": [
        "Edwina Lewis",
        "Aditya Parameshwaran",
        "Laura Redmond and Yue Wang"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21347",
        "HTML": "https://arxiv.org/html/2506.21347",
        "PDF": "https://arxiv.org/pdf/2506.21347"
      },
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 14:59:50 GMT",
          "size": "947kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Real-time Terrain Analysis for Off-road Autonomous Vehicles",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The research deals with terrain analysis for autonomous vehicles using a Bayesian calibration method and does not discuss any aspects of data processing for LLM training."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21348",
      "abstract": "Panoptic segmentation of 3D scenes, involving the segmentation and classification of object instances in a dense 3D reconstruction of a scene, is a challenging problem, especially when relying solely on unposed 2D images. Existing approaches typically leverage off-the-shelf models to extract per-frame 2D panoptic segmentations, before optimizing an implicit geometric representation (often based on NeRF) to integrate and fuse the 2D predictions. We argue that relying on 2D panoptic segmentation for a problem inherently 3D and multi-view is likely suboptimal as it fails to leverage the full potential of spatial relationships across views. In addition to requiring camera parameters, these approaches also necessitate computationally expensive test-time optimization for each scene. Instead, in this work, we propose a unified and integrated approach PanSt3R, which eliminates the need for test-time optimization by jointly predicting 3D geometry and multi-view panoptic segmentation in a single forward pass. Our approach builds upon recent advances in 3D reconstruction, specifically upon MUSt3R, a scalable multi-view version of DUSt3R, and enhances it with semantic awareness and multi-view panoptic segmentation capabilities. We additionally revisit the standard post-processing mask merging procedure and introduce a more principled approach for multi-view segmentation. We also introduce a simple method for generating novel-view predictions based on the predictions of PanSt3R and vanilla 3DGS. Overall, the proposed PanSt3R is conceptually simple, yet fast and scalable, and achieves state-of-the-art performance on several benchmarks, while being orders of magnitude faster than existing methods.",
      "authors": [
        "Lojze Zust",
        "Yohann Cabon",
        "Juliette Marrie",
        "Leonid Antsfeld",
        "Boris Chidlovskii",
        "Jerome Revaud",
        "Gabriela Csurka"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21348",
        "HTML": "https://arxiv.org/html/2506.21348",
        "PDF": "https://arxiv.org/pdf/2506.21348"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 15:02:00 GMT",
          "size": "32480kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "PanSt3R: Multi-view Consistent Panoptic Segmentation",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper focuses on a method for panoptic segmentation of 3D scenes and does not involve contributions related to LLM training data processing or construction."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21349",
      "abstract": "Solving Electromagnetic Inverse Scattering Problems (EISP) is fundamental in applications such as medical imaging, where the goal is to reconstruct the relative permittivity from scattered electromagnetic field. This inverse process is inherently ill-posed and highly nonlinear, making it particularly challenging. A recent machine learning-based approach, Img-Interiors, shows promising results by leveraging continuous implicit functions. However, it requires case-specific optimization, lacks generalization to unseen data, and fails under sparse transmitter setups (e.g., with only one transmitter). To address these limitations, we revisit EISP from a physics-informed perspective, reformulating it as a two stage inverse transmission-scattering process. This formulation reveals the induced current as a generalizable intermediate representation, effectively decoupling the nonlinear scattering process from the ill-posed inverse problem. Built on this insight, we propose the first generalizable physics-driven framework for EISP, comprising a current estimator and a permittivity solver, working in an end-to-end manner. The current estimator explicitly learns the induced current as a physical bridge between the incident and scattered field, while the permittivity solver computes the relative permittivity directly from the estimated induced current. This design enables data-driven training and generalizable feed-forward prediction of relative permittivity on unseen data while maintaining strong robustness to transmitter sparsity. Extensive experiments show that our method outperforms state-of-the-art approaches in reconstruction accuracy, generalization, and robustness. This work offers a fundamentally new perspective on electromagnetic inverse scattering and represents a major step toward cost-effective practical solutions for electromagnetic imaging.",
      "authors": [
        "Yizhe Cheng",
        "Chunxun Tian",
        "Haoru Wang",
        "Wentao Zhu",
        "Xiaoxuan Ma",
        "Yizhou Wang"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21349",
        "HTML": "https://arxiv.org/html/2506.21349",
        "PDF": "https://arxiv.org/pdf/2506.21349"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Image and Video Processing (eess.IV)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 15:02:50 GMT",
          "size": "4189kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Generalizable Neural Electromagnetic Inverse Scattering",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on solving electromagnetic inverse scattering problems using a physics-driven framework but does not address any aspect of LLM training data processing or construction."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21352",
      "abstract": "Persistent Laplacians are matrix operators that track how the shape and structure of data transform across scales and are popularly adopted in biology, physics, and machine learning. Their eigenvalues are concise descriptors of geometric and topological features in a filtration. Although earlier work established global algebraic stability for these operators, the precise change in a single eigenvalue when one simplex, such as a vertex, edge, or triangle, is added has remained unknown. This is important because downstream tools, including heat-kernel signatures and spectral neural networks, depend directly on these eigenvalues. We close this gap by proving a uniform Lipschitz bound: after inserting one simplex, every up-persistent Laplacian eigenvalue can vary by at most twice the Euclidean norm of that simplex's boundary, independent of filtration scale and complex size. This result delivers the first eigenvalue-level robustness guarantee for spectral topological data analysis. It guarantees that spectral features remain stable under local updates and enables reliable error control in dynamic data settings.",
      "authors": [
        "Le Vu Anh",
        "Mehmet Dik",
        "Nguyen Viet Anh"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21352",
        "HTML": "https://arxiv.org/html/2506.21352",
        "PDF": "https://arxiv.org/pdf/2506.21352"
      },
      "subjects": [
        "Machine Learning (cs.LG)",
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)",
        "Metric Geometry (math.MG)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 15:03:54 GMT",
          "size": "161kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Lipschitz Bounds for Persistent Laplacian Eigenvalues under One-Simplex Insertions",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper centers on providing a robustness guarantee for persistent Laplacian eigenvalues, which is unrelated to the processing or collection of LLM training data."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21357",
      "abstract": "2D scene graphs provide a structural and explainable framework for scene understanding. However, current work still struggles with the lack of accurate scene graph data. To overcome this data bottleneck, we present CoPa-SG, a synthetic scene graph dataset with highly precise ground truth and exhaustive relation annotations between all objects. Moreover, we introduce parametric and proto-relations, two new fundamental concepts for scene graphs. The former provides a much more fine-grained representation than its traditional counterpart by enriching relations with additional parameters such as angles or distances. The latter encodes hypothetical relations in a scene graph and describes how relations would form if new objects are placed in the scene. Using CoPa-SG, we compare the performance of various scene graph generation models. We demonstrate how our new relation types can be integrated in downstream applications to enhance planning and reasoning capabilities.",
      "authors": [
        "Julian Lorenz",
        "Mrunmai Phatak",
        "Robin Sch\\\"on",
        "Katja Ludwig",
        "Nico H\\\"ormann",
        "Annemarie Friedrich",
        "Rainer Lienhart"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21357",
        "HTML": "https://arxiv.org/html/2506.21357",
        "PDF": "https://arxiv.org/pdf/2506.21357"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 15:09:23 GMT",
          "size": "6842kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "CoPa-SG: Dense Scene Graphs with Parametric and Proto-Relations",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper is concerned with generating scene graphs and overcoming data limitations in this context, but it does not discuss LLM training data collection or processing."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21358",
      "abstract": "Many existing methods for 3D cuboid annotation of vehicles rely on expensive and carefully calibrated camera-LiDAR or stereo setups, limiting their accessibility for large-scale data collection. We introduce ToosiCubix, a simple yet powerful approach for annotating ground-truth cuboids using only monocular images and intrinsic camera parameters. Our method requires only about 10 user clicks per vehicle, making it highly practical for adding 3D annotations to existing datasets originally collected without specialized equipment. By annotating specific features (e.g., wheels, car badge, symmetries) across different vehicle parts, we accurately estimate each vehicle's position, orientation, and dimensions up to a scale ambiguity (8 DoF). The geometric constraints are formulated as an optimization problem, which we solve using a coordinate descent strategy, alternating between Perspective-n-Points (PnP) and least-squares subproblems. To handle common ambiguities such as scale and unobserved dimensions, we incorporate probabilistic size priors, enabling 9 DoF cuboid placements. We validate our annotations against the KITTI and Cityscapes3D datasets, demonstrating that our method offers a cost-effective and scalable solution for high-quality 3D cuboid annotation.",
      "authors": [
        "Behrooz Nasihatkon",
        "Hossein Resani",
        "Amirreza Mehrzadian"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21358",
        "HTML": "https://arxiv.org/html/2506.21358",
        "PDF": "https://arxiv.org/pdf/2506.21358"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 15:09:33 GMT",
          "size": "37144kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "ToosiCubix: Monocular 3D Cuboid Labeling via Vehicle Part Annotations",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on a technique for 3D cuboid annotation of vehicles in monocular images. It discusses annotation methods that improve vehicle feature estimation but does not address LLM training data processing or engineering."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21360",
      "abstract": "Large Language Models (LLMs) excel in understanding and generating text but struggle with providing professional literary criticism for works with profound thoughts and complex narratives. This paper proposes GLASS (Greimas Literary Analysis via Semiotic Square), a structured analytical framework based on Greimas Semiotic Square (GSS), to enhance LLMs' ability to conduct in-depth literary analysis. GLASS facilitates the rapid dissection of narrative structures and deep meanings in narrative works. We propose the first dataset for GSS-based literary criticism, featuring detailed analyses of 48 works. Then we propose quantitative metrics for GSS-based literary criticism using the LLM-as-a-judge paradigm. Our framework's results, compared with expert criticism across multiple works and LLMs, show high performance. Finally, we applied GLASS to 39 classic works, producing original and high-quality analyses that address existing research gaps. This research provides an AI-based tool for literary research and education, offering insights into the cognitive mechanisms underlying literary engagement.",
      "authors": [
        "Fangzhou Dong and Yifan Zeng and Yingpeng Sang and Hong Shen"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21360",
        "HTML": "https://arxiv.org/html/2506.21360",
        "PDF": "https://arxiv.org/pdf/2506.21360"
      },
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 15:10:24 GMT",
          "size": "1177kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Structuralist Approach to AI Literary Criticism: Leveraging Greimas Semiotic Square for Large Language Models",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper introduces a literary criticism framework using LLMs but does not contribute directly to LLM training data processing or data engineering aspects like data collection or quality enhancement."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21361",
      "abstract": "Poroelasticity problems play an important role in various engineering, geophysical, and biological applications. Their full discretization results in a large-scale saddle-point system at each time step that is becoming singular for locking cases and needs effective preconditioners for its fast iterative solution. Instead of constructing spectrally equivalent ones, we develop nonsingular preconditioners so that the eigenvalues of the preconditioned system consist of a cluster around $1$ and an outlier in the order of $1/\\lambda$, where $\\lambda$ is a Lam\\'{e} constant that is large for locking cases. It is known that the convergence factor of GMRES is bounded by the radius of the cluster for this type of systems. Both two- and three-field block triangular Schur complement preconditioners are studied. Upper bounds of the radius of the eigenvalue cluster for those systems are obtained and shown to be related to the inf-sup condition but independent of mesh size, time step, and locking parameters, which reflects the robustness of the preconditioners with respect to parameter variations. Moreover, the developed preconditioners do not need to compute the Schur complement and neither require exact inversion of diagonal blocks except the leading one. A locking-free weak Galerkin finite element method and the implicit Euler scheme are used for the discretization of the governing equation. Both two- and three-dimensional numerical results are presented to confirm the effectiveness and parameter-robustness of the developed preconditioners.",
      "authors": [
        "Weizhang Huang and Zhuoran Wang"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21361",
        "HTML": "https://arxiv.org/html/2506.21361",
        "PDF": "https://arxiv.org/pdf/2506.21361"
      },
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 15:13:16 GMT",
          "size": "28kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Efficient parameter-robust preconditioners for linear poroelasticity and elasticity in the primal formulation",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper deals with numerical methods for solving poroelasticity and elasticity problems, focusing on preconditioners for linear algebra problems, and is unrelated to LLM training data processing."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21362",
      "abstract": "Efficient access to high-quality information is vital for online platforms. To promote more useful information, users not only create new content but also evaluate existing content, often through helpfulness voting. Although aggregated votes help service providers rank their user content, these votes are often biased by disparate accessibility per position and the cascaded influence of prior votes. For a fairer assessment of information quality, we propose the Counterfactual Voting Adjustment (CVA), a causal framework that accounts for the context in which individual votes are cast. Through preliminary and semi-synthetic experiments, we show that CVA effectively models the position and herding biases, accurately recovering the predefined content quality. In a real experiment, we demonstrate that reranking content based on the learned quality by CVA exhibits stronger alignment with both user sentiment and quality evaluation assessed by GPT-4o, outperforming system rankings based on aggregated votes and model-based rerankings without causal inference. Beyond the individual quality inference, our embeddings offer comparative insights into the behavioral dynamics of expert user groups across 120 major StackExchange communities.",
      "authors": [
        "Chang Liu",
        "Yixin Wang",
        "Moontae Lee"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21362",
        "HTML": "https://arxiv.org/html/2506.21362",
        "PDF": "https://arxiv.org/pdf/2506.21362"
      },
      "subjects": [
        "Computational Engineering, Finance, and Science (cs.CE)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 15:13:35 GMT",
          "size": "2724kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Counterfactual Voting Adjustment for Quality Assessment and Fairer Voting in Online Platforms with Helpfulness Evaluation",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The focus is on developing a causal framework for improving fairness in online content voting systems, unrelated to collecting or processing LLM training data."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21364",
      "abstract": "Detection-free methods typically follow a coarse-to-fine pipeline, extracting image and point cloud features for patch-level matching and refining dense pixel-to-point correspondences. However, differences in feature channel attention between images and point clouds may lead to degraded matching results, ultimately impairing registration accuracy. Furthermore, similar structures in the scene could lead to redundant correspondences in cross-modal matching. To address these issues, we propose Channel Adaptive Adjustment Module (CAA) and Global Optimal Selection Module (GOS). CAA enhances intra-modal features and suppresses cross-modal sensitivity, while GOS replaces local selection with global optimization. Experiments on RGB-D Scenes V2 and 7-Scenes demonstrate the superiority of our method, achieving state-of-the-art performance in image-to-point cloud registration.",
      "authors": [
        "Zhixin Cheng",
        "Jiacheng Deng",
        "Xinjun Li",
        "Xiaotian Yin",
        "Bohao Liao",
        "Baoqun Yin",
        "Wenfei Yang",
        "Tianzhu Zhang"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21364",
        "HTML": "https://arxiv.org/html/2506.21364",
        "PDF": "https://arxiv.org/pdf/2506.21364"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 15:15:18 GMT",
          "size": "4224kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "CA-I2P: Channel-Adaptive Registration Network with Global Optimal Selection",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The research addresses image-to-point cloud registration techniques, particularly enhancing feature extraction and matching accuracy. It does not involve LLM training data processing or data engineering."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21367",
      "abstract": "rQdia regularizes Q-value distributions with augmented images in pixel-based deep reinforcement learning. With a simple auxiliary loss, that equalizes these distributions via MSE, rQdia boosts DrQ and SAC on 9/12 and 10/12 tasks respectively in the MuJoCo Continuous Control Suite from pixels, and Data-Efficient Rainbow on 18/26 Atari Arcade environments. Gains are measured in both sample efficiency and longer-term training. Moreover, the addition of rQdia finally propels model-free continuous control from pixels over the state encoding baseline.",
      "authors": [
        "Sam Lerman",
        "Jing Bi"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21367",
        "HTML": "https://arxiv.org/html/2506.21367",
        "PDF": "https://arxiv.org/pdf/2506.21367"
      },
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 15:16:35 GMT",
          "size": "3301kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "rQdia: Regularizing Q-Value Distributions With Image Augmentation",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on regularizing Q-values in deep reinforcement learning using image augmentation. It does not address any aspect of LLM training data collection, construction, or processing."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21368",
      "abstract": "We present a methodology to provide real-time and personalized product recommendations for large e-commerce platforms, specifically focusing on fashion retail. Our approach aims to achieve accurate and scalable recommendations with minimal response times, ensuring user satisfaction, leveraging Graph Neural Networks and parsimonious learning methodologies. Extensive experimentation with datasets from one of the largest e-commerce platforms demonstrates the effectiveness of our approach in forecasting purchase sequences and handling multi-interaction scenarios, achieving efficient personalized recommendations under real-world constraints.",
      "authors": [
        "Matteo Tolloso",
        "Davide Bacciu",
        "Shahab Mokarizadeh",
        "Marco Varesi"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21368",
        "HTML": "https://arxiv.org/html/2506.21368",
        "PDF": "https://arxiv.org/pdf/2506.21368"
      },
      "subjects": [
        "Information Retrieval (cs.IR)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 15:16:44 GMT",
          "size": "664kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Real-time and personalized product recommendations for large e-commerce platforms",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper discusses real-time and personalized product recommendations for e-commerce platforms using graph neural networks. It does not involve LLM training data processing or engineering."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21369",
      "abstract": "Generative art unlocks boundless creative possibilities, yet its full potential remains untapped due to the technical expertise required for advanced architectural concepts and computational workflows. To bridge this gap, we present GenFlow, a novel modular framework that empowers users of all skill levels to generate images with precision and ease. Featuring a node-based editor for seamless customization and an intelligent assistant powered by natural language processing, GenFlow transforms the complexity of workflow creation into an intuitive and accessible experience. By automating deployment processes and minimizing technical barriers, our framework makes cutting-edge generative art tools available to everyone. A user study demonstrated GenFlow's ability to optimize workflows, reduce task completion times, and enhance user understanding through its intuitive interface and adaptive features. These results position GenFlow as a groundbreaking solution that redefines accessibility and efficiency in the realm of generative art.",
      "authors": [
        "Duc-Hung Nguyen and Huu-Phuc Huynh and Minh-Triet Tran and Trung-Nghia Le"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21369",
        "HTML": "https://arxiv.org/html/2506.21369",
        "PDF": "https://arxiv.org/pdf/2506.21369"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 15:18:00 GMT",
          "size": "5363kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "GenFlow: Interactive Modular System for Image Generation",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper introduces GenFlow, a system for interactive image generation in generative art. It does not pertain to LLM training data processing or improvement."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21370",
      "abstract": "In this paper, a cluster-aware two-stage multiple-input multiple-output (MIMO) detection method is proposed for direct-to-cell satellite communications. The method achieves computational efficiency by exploiting a distinctive property of satellite MIMO channels: users within the same geographical cluster exhibit highly correlated channel characteristics due to their physical proximity, which typically impedes convergence in conventional iterative MIMO detectors. The proposed method implements a two-stage strategy that first eliminates intra-cluster interference using computationally efficient small matrix inversions, then utilizes these pre-computed matrices to accelerate standard iterative MIMO detectors such as Gauss-Seidel (GS) and symmetric successive over-relaxation (SSOR) for effective inter-cluster interference cancellation. Computer simulations demonstrate that the proposed method achieves more than 12 times faster convergence under perfect channel state information. Even when accounting for channel estimation errors, the method maintains 9 times faster convergence, demonstrating its robustness and effectiveness for next-generation satellite MIMO communications.",
      "authors": [
        "Jiuyu Liu and Yi Ma and Qihao Peng and Rahim Tafazolli"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21370",
        "HTML": "https://arxiv.org/html/2506.21370",
        "PDF": "https://arxiv.org/pdf/2506.21370"
      },
      "subjects": [
        "Information Theory (cs.IT)",
        "Signal Processing (eess.SP)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 15:18:49 GMT",
          "size": "424kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Cluster-Aware Two-Stage Method for Fast Iterative MIMO Detection in LEO Satellite Communications",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper presents a MIMO detection method for satellite communications. It does not deal with any LLM training data processing or engineering tasks."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21371",
      "abstract": "Nowadays, the rapid growth of Deep Neural Network (DNN) architectures has established them as the defacto approach for providing advanced Machine Learning tasks with excellent accuracy. Targeting low-power DNN computing, this paper examines the interplay of fine-grained error resilience of DNN workloads in collaboration with hardware approximation techniques, to achieve higher levels of energy efficiency. Utilizing the state-of-the-art ROUP approximate multipliers, we systematically explore their fine-grained distribution across the network according to our layer-, filter-, and kernel-level approaches, and examine their impact on accuracy and energy. We use the ResNet-8 model on the CIFAR-10 dataset to evaluate our approximations. The proposed solution delivers up to 54% energy gains in exchange for up to 4% accuracy loss, compared to the baseline quantized model, while it provides 2x energy gains with better accuracy versus the state-of-the-art DNN approximations.",
      "authors": [
        "Vasileios Leon",
        "Georgios Makris",
        "Sotirios Xydis",
        "Kiamal Pekmestzi",
        "Dimitrios Soudris"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21371",
        "HTML": "https://arxiv.org/html/2506.21371",
        "PDF": "https://arxiv.org/pdf/2506.21371"
      },
      "subjects": [
        "Machine Learning (cs.LG)",
        "Hardware Architecture (cs.AR)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 15:21:12 GMT",
          "size": "388kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "MAx-DNN: Multi-Level Arithmetic Approximation for Energy-Efficient DNN Hardware Accelerators",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The research is centered on energy-efficient DNN hardware accelerators and approximation techniques. There's no mention of LLM training data processing or engineering."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21382",
      "abstract": "Cryptocurrency transaction fraud detection faces the dual challenges of increasingly complex transaction patterns and severe class imbalance. Traditional methods rely on manual feature engineering and struggle to capture temporal and structural dependencies in transaction networks. This paper proposes an Augmented Temporal-aware Graph Attention Network (ATGAT) that enhances detection performance through three modules: (1) designing an advanced temporal embedding module that fuses multi-scale time difference features with periodic position encoding; (2) constructing a temporal-aware triple attention mechanism that jointly optimizes structural, temporal, and global context attention; (3) employing weighted BCE loss to address class imbalance. Experiments on the Elliptic++ cryptocurrency dataset demonstrate that ATGAT achieves an AUC of 0.9130, representing a 9.2% improvement over the best traditional method XGBoost, 12.0% over GCN, and 10.0% over standard GAT. This method not only validates the enhancement effect of temporal awareness and triple attention mechanisms on graph neural networks, but also provides financial institutions with more reliable fraud detection tools, with its design principles generalizable to other temporal graph anomaly detection tasks.",
      "authors": [
        "Zhi Zheng",
        "Bochuan Zhou",
        "Yuping Song"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21382",
        "HTML": "https://arxiv.org/html/2506.21382",
        "PDF": "https://arxiv.org/pdf/2506.21382"
      },
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 15:34:06 GMT",
          "size": "172kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Temporal-Aware Graph Attention Network for Cryptocurrency Transaction Fraud Detection",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper is focused on graph attention networks for cryptocurrency fraud detection and does not address LLM training data processing or any stage of data preparation for language models."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21387",
      "abstract": "Tabular foundation models have shown strong performance across various tabular learning tasks via in-context learning, offering robust generalization without any downstream finetuning. However, their inference-time costs remain high, particularly for larger datasets. To address this, we propose early-stopping the in-context learning process. We achieve this by dynamically evaluating whether to stop in-context learning after each Transformer encoder layer. Once stopped, we decode the embedding using a pre-trained layer-wise decoder. Experiments across 34 small classification tasks size show that early stopping in-context learning accelerates inference by up to x1.3 with negligible degradation in predictive performance. To assess scalability, we further evaluate our method on five larger classification tasks, achieving speedups of up to x2.2. Our results demonstrate the potential of early exiting as an effective and practical strategy for improving the efficiency of tabular in-context learning.",
      "authors": [
        "Jaris K\\\"uken",
        "Lennart Purucker",
        "Frank Hutter"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21387",
        "HTML": "https://arxiv.org/html/2506.21387",
        "PDF": "https://arxiv.org/pdf/2506.21387"
      },
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 15:36:37 GMT",
          "size": "106kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Early Stopping Tabular In-Context Learning",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper proposes early stopping in tabular in-context learning to improve efficiency, which is related to model inference rather than the processing of training data for LLMs."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21395",
      "abstract": "This work presents a nonlinear extension of the high-order discretisation framework based on the Variational Multiscale (VMS) method previously introduced for steady linear problems. Building on the concept of an optimal projector defined via the symmetric part of the governing operator, we generalise the formulation to treat the 2D incompressible Navier-Stokes equations. The arroach maintains a clear separation between the resolved and unresolved scales, with the fine-scale contributions approximated through the approximate Fine-Scale Greens' function of the associated symmetric operator. This enables a consistent variational treatment of the nonlinearity while preserving high-order accuracy. We show that the method yields numerical solutions that closely approximate the optimal projection of the continuous/highly resolved solution and inherits desirable conservation properties. Numerical results confirm the framework's robustness, accuracy, and its potential for application to a broad class of nonlinear multiscale problems.",
      "authors": [
        "Suyash Shrestha",
        "Marc Gerritsma",
        "Gonzalo Rubio",
        "Steven Hulshoff",
        "Esteban Ferrer"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21395",
        "HTML": "https://arxiv.org/html/2506.21395",
        "PDF": "https://arxiv.org/pdf/2506.21395"
      },
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 15:41:52 GMT",
          "size": "12058kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Optimal solutions employing an algebraic Variational Multiscale approach Part II: Application to Navier-Stokes",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on a nonlinear extension of the Variational Multiscale method for Navier-Stokes equations and does not address topics related to LLM training data processing."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21398",
      "abstract": "Few-shot industrial anomaly detection (FS-IAD) presents a critical challenge for practical automated inspection systems operating in data-scarce environments. While existing approaches predominantly focus on deriving prototypes from limited normal samples, they typically neglect to systematically incorporate query image statistics to enhance prototype representativeness. To address this issue, we propose FastRef, a novel and efficient prototype refinement framework for FS-IAD. Our method operates through an iterative two-stage process: (1) characteristic transfer from query features to prototypes via an optimizable transformation matrix, and (2) anomaly suppression through prototype alignment. The characteristic transfer is achieved through linear reconstruction of query features from prototypes, while the anomaly suppression addresses a key observation in FS-IAD that unlike conventional IAD with abundant normal prototypes, the limited-sample setting makes anomaly reconstruction more probable. Therefore, we employ optimal transport (OT) for non-Gaussian sampled features to measure and minimize the gap between prototypes and their refined counterparts for anomaly suppression. For comprehensive evaluation, we integrate FastRef with three competitive prototype-based FS-IAD methods: PatchCore, FastRecon, WinCLIP, and AnomalyDINO. Extensive experiments across four benchmark datasets of MVTec, ViSA, MPDD and RealIAD demonstrate both the effectiveness and computational efficiency of our approach under 1/2/4-shots.",
      "authors": [
        "Long Tian",
        "Yufei Li",
        "Yuyang Dai",
        "Wenchao Chen",
        "Xiyang Liu",
        "Bo Chen"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21398",
        "HTML": "https://arxiv.org/html/2506.21398",
        "PDF": "https://arxiv.org/pdf/2506.21398"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 15:46:28 GMT",
          "size": "5774kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "FastRef:Fast Prototype Refinement for Few-Shot Industrial Anomaly Detection",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper addresses few-shot industrial anomaly detection techniques and does not involve any collection, construction, or processing of LLM training data."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21401",
      "abstract": "This paper presents an end-to-end framework for reconstructing 3D parametric curves directly from multi-view edge maps. Contrasting with existing two-stage methods that follow a sequential ``edge point cloud reconstruction and parametric curve fitting'' pipeline, our one-stage approach optimizes 3D parametric curves directly from 2D edge maps, eliminating error accumulation caused by the inherent optimization gap between disconnected stages. However, parametric curves inherently lack suitability for rendering-based multi-view optimization, necessitating a complementary representation that preserves their geometric properties while enabling differentiable rendering. We propose a novel bi-directional coupling mechanism between parametric curves and edge-oriented Gaussian components. This tight correspondence formulates a curve-aware Gaussian representation, \\textbf{CurveGaussian}, that enables differentiable rendering of 3D curves, allowing direct optimization guided by multi-view evidence. Furthermore, we introduce a dynamically adaptive topology optimization framework during training to refine curve structures through linearization, merging, splitting, and pruning operations. Comprehensive evaluations on the ABC dataset and real-world benchmarks demonstrate our one-stage method's superiority over two-stage alternatives, particularly in producing cleaner and more robust reconstructions. Additionally, by directly optimizing parametric curves, our method significantly reduces the parameter count during training, achieving both higher efficiency and superior performance compared to existing approaches.",
      "authors": [
        "Zhirui Gao. Renjiao Yi",
        "Yaqiao Dai",
        "Xuening Zhu",
        "Wei Chen",
        "Chenyang Zhu",
        "Kai Xu"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21401",
        "HTML": "https://arxiv.org/html/2506.21401",
        "PDF": "https://arxiv.org/pdf/2506.21401"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 15:48:08 GMT",
          "size": "16958kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Curve-Aware Gaussian Splatting for 3D Parametric Curve Reconstruction",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The research is focused on a framework for 3D parametric curve reconstruction using multi-view edge maps, with no connection to LLM training data processing or engineering."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21405",
      "abstract": "The numerical solution of parameter identification inverse problems for kinetic equations can exhibit high computational and memory costs. In this paper, we propose a dynamical low-rank scheme for the reconstruction of the scattering parameter in the radiative transfer equation from a number of macroscopic time-independent measurements. We first work through the PDE constrained optimization procedure in a continuous setting and derive the adjoint equations using a Lagrangian reformulation. For the scattering coefficient, a periodic B-spline approximation is introduced and a gradient descent step for updating its coefficients is formulated. After the discretization, a dynamical low-rank approximation (DLRA) is applied. We make use of the rank-adaptive basis update & Galerkin integrator and a line search approach for the adaptive refinement of the gradient descent step size and the DLRA tolerance. We show that the proposed scheme significantly reduces both memory and computational cost. Numerical results computed with different initial conditions validate the accuracy and efficiency of the proposed DLRA scheme compared to solutions computed with a full solver.",
      "authors": [
        "Lena Baumann and Lukas Einkemmer and Christian Klingenberg and Jonas Kusch"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21405",
        "HTML": "https://arxiv.org/html/2506.21405",
        "PDF": "https://arxiv.org/pdf/2506.21405"
      },
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 15:53:05 GMT",
          "size": "2103kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "An adaptive dynamical low-rank optimizer for solving kinetic parameter identification inverse problems",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper proposes a numerical solution for kinetic parameter identification inverse problems, with no focus on LLM training data processing or engineering."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21406",
      "abstract": "Network latency severely impacts the performance of applications running on supercomputers. Adaptive routing algorithms route packets over different available paths to reduce latency and improve network utilization. However, if a switch routes packets belonging to the same network flow on different paths, they might arrive at the destination out-of-order due to differences in the latency of these paths. For some transport protocols like TCP, QUIC, and RoCE, out-of-order (OOO) packets might cause large performance drops or significantly increase CPU utilization. In this work, we propose flowcut switching, a new adaptive routing algorithm that provides high-performance in-order packet delivery. Differently from existing solutions like flowlet switching, which are based on the assumption of bursty traffic and that might still reorder packets, flowcut switching guarantees in-order delivery under any network conditions, and is effective also for non-bursty traffic, as it is often the case for RDMA.",
      "authors": [
        "Tommaso Bonato",
        "Daniele De Sensi",
        "Salvatore Di Girolamo",
        "Abdulla Bataineh",
        "David Hewson",
        "Duncan Roweth",
        "Torsten Hoefler"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21406",
        "HTML": "https://arxiv.org/html/2506.21406",
        "PDF": "https://arxiv.org/pdf/2506.21406"
      },
      "subjects": [
        "Networking and Internet Architecture (cs.NI)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 15:54:26 GMT",
          "size": "1137kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Flowcut Switching: High-Performance Adaptive Routing with In-Order Delivery Guarantees",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper discusses adaptive routing algorithms in high-performance computing networks, which is unrelated to the processing of training data for large language models."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21411",
      "abstract": "Vision-based scientific foundation models hold significant promise for advancing scientific discovery and innovation. This potential stems from their ability to aggregate images from diverse sources such as varying physical groundings or data acquisition systems and to learn spatio-temporal correlations using transformer architectures. However, tokenizing and aggregating images can be compute-intensive, a challenge not fully addressed by current distributed methods. In this work, we introduce the Distributed Cross-Channel Hierarchical Aggregation (D-CHAG) approach designed for datasets with a large number of channels across image modalities. Our method is compatible with any model-parallel strategy and any type of vision transformer architecture, significantly improving computational efficiency. We evaluated D-CHAG on hyperspectral imaging and weather forecasting tasks. When integrated with tensor parallelism and model sharding, our approach achieved up to a 75% reduction in memory usage and more than doubled sustained throughput on up to 1,024 AMD GPUs on the Frontier Supercomputer.",
      "authors": [
        "Aristeidis Tsaris",
        "Isaac Lyngaas",
        "John Lagregren",
        "Mohamed Wahib",
        "Larry York",
        "Prasanna Balaprakash",
        "Dan Lu",
        "Feiyi Wang",
        "Xiao Wang"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21411",
        "HTML": "https://arxiv.org/html/2506.21411",
        "PDF": "https://arxiv.org/pdf/2506.21411"
      },
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 15:58:14 GMT",
          "size": "3892kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Distributed Cross-Channel Hierarchical Aggregation for Foundation Models",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper is about improving computational efficiency in processing vision-based scientific models using distributed methods and hierarchical aggregation, which are not related to LLM training data processing."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21414",
      "abstract": "Graph Neural Networks (GNNs) have demonstrated significant success in graph learning and are widely adopted across various critical domains. However, the irregular connectivity between vertices leads to inefficient neighbor aggregation, resulting in substantial irregular and coarse-grained DRAM accesses. This lack of data locality presents significant challenges for execution platforms, ultimately degrading performance. While previous accelerator designs have leveraged on-chip memory and data access scheduling strategies to address this issue, they still inevitably access features at irregular addresses from DRAM. In this work, we propose LiGNN, a hardware-based solution that improves data locality by applying dropout and merge techniques during neighbor aggregation to accelerate GNN training. Unlike conventional algorithm-level dropout methods that primarily aim to improve accuracy while overlooking hardware costs, LiGNN introduces a locality-aware feature dropout mechanism. This approach selectively drops node features with data locality awareness, effectively reducing irregular DRAM accesses without compromising model accuracy. Moreover, by leveraging detailed knowledge of memory layout and organization-including critical alignment constraints-LiGNN strategically merges memory accesses during neighbor aggregation at the DRAM row level, guided by GNN-level semantics. This optimization significantly improves data locality with minimal additional cost. Under the commonly adopted 0.5 dropout rate, LiGNN outperforms state-of-the-art methods, delivering a 1.48~3.02x speedup, reducing DRAM accesses by 34%~55%, and lowering DRAM row activations by 59%~82%, all while maintaining model accuracy.",
      "authors": [
        "Gongjian Sun",
        "Mingyu Yan",
        "Dengke Han",
        "Runzhen Xue",
        "Duo Wang",
        "Xiaochun Ye",
        "Dongrui Fan"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21414",
        "HTML": "https://arxiv.org/html/2506.21414",
        "PDF": "https://arxiv.org/pdf/2506.21414"
      },
      "subjects": [
        "Hardware Architecture (cs.AR)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 16:01:28 GMT",
          "size": "1769kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Accelerating GNN Training through Locality-aware Dropout and Merge",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper proposes hardware optimization techniques for accelerating Graph Neural Network training, which do not involve LLM training data processing."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21416",
      "abstract": "Achieving fine-grained control over subject identity and semantic attributes (pose, style, lighting) in text-to-image generation, particularly for multiple subjects, often undermines the editability and coherence of Diffusion Transformers (DiTs). Many approaches introduce artifacts or suffer from attribute entanglement. To overcome these challenges, we propose a novel multi-subject controlled generation model XVerse. By transforming reference images into offsets for token-specific text-stream modulation, XVerse allows for precise and independent control for specific subject without disrupting image latents or features. Consequently, XVerse offers high-fidelity, editable multi-subject image synthesis with robust control over individual subject characteristics and semantic attributes. This advancement significantly improves personalized and complex scene generation capabilities.",
      "authors": [
        "Bowen Chen",
        "Mengyi Zhao",
        "Haomiao Sun",
        "Li Chen",
        "Xu Wang",
        "Kang Du",
        "Xinglong Wu"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21416",
        "HTML": "https://arxiv.org/html/2506.21416",
        "PDF": "https://arxiv.org/pdf/2506.21416"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 16:04:16 GMT",
          "size": "16513kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "XVerse: Consistent Multi-Subject Control of Identity and Semantic Attributes via DiT Modulation",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper primarily addresses image synthesis techniques for text-to-image generation models, focusing on control over identity and semantic attributes. It does not contribute to LLM training data processing."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21417",
      "abstract": "This study presents a lightweight, wearable fingertip haptic device that provides physics-based haptic feedback for dexterous manipulation in virtual environments without hindering real-world interactions. The device, designed with thin strings and actuators attached to the fingernails, ensures minimal weight (1.55 g per finger) and preserves finger flexibility. Integrating the software with a physics engine renders multiple types of haptic feedback (grip force, collision, and sliding vibration feedback). We evaluated the device's performance in pressure perception, slip feedback, typical dexterous manipulation tasks, and daily operations, and we gathered user experience through subjective assessments. Our results show that participants could perceive and respond to pressure and vibration feedback. Through dexterous manipulation experiments, we further demonstrated that these minimal haptic cues significantly improved virtual task efficiency, showcasing how lightweight haptic feedback can enhance manipulation performance without complex mechanisms. The device's ability to preserve tactile sensations and minimize hindrance to real-world operations is a key advantage over glove-type haptic devices. This research offers a potential solution for designing haptic interfaces that balance lightweight construction, haptic feedback for dexterous manipulation, and daily wearability.",
      "authors": [
        "Yunxiu Xu",
        "Siyu Wang",
        "and Shoichi Hasegawa"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21417",
        "HTML": "https://arxiv.org/html/2506.21417",
        "PDF": "https://arxiv.org/pdf/2506.21417"
      },
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 16:06:04 GMT",
          "size": "11847kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Lightweight Fingernail Haptic Device: Unobstructed Fingerpad Force and Vibration Feedback for Enhanced Virtual Dexterous Manipulation",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper presents a haptic device for virtual reality and does not relate to LLM training data processing or any element related to language models."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21418",
      "abstract": "Motivated by the problem of estimating bottleneck capacities on the Internet, we formulate and study the problem of vantage point selection. We are given a graph $G=(V, E)$ whose edges $E$ have unknown capacity values that are to be discovered. Probes from a vantage point, i.e, a vertex $v \\in V$, along shortest paths from $v$ to all other vertices, reveal bottleneck edge capacities along each path. Our goal is to select $k$ vantage points from $V$ that reveal the maximum number of bottleneck edge capacities.\n  We consider both a non-adaptive setting where all $k$ vantage points are selected before any bottleneck capacity is revealed, and an adaptive setting where each vantage point selection instantly reveals bottleneck capacities along all shortest paths starting from that point. In the non-adaptive setting, by considering a relaxed model where edge capacities are drawn from a random permutation (which still leaves the problem of maximizing the expected number of revealed edges NP-hard), we are able to give a $1-1/e$ approximate algorithm. In the adaptive setting we work with the least permissive model where edge capacities are arbitrarily fixed but unknown. We compare with the best solution for the particular input instance (i.e. by enumerating all choices of $k$ tuples), and provide both lower bounds on instance optimal approximation algorithms and upper bounds for trees and planar graphs.",
      "authors": [
        "Vikrant Ashvinkumar",
        "Rezaul Chowdhury",
        "Jie Gao",
        "Mayank Goswami",
        "Joseph S. B. Mitchell",
        "Valentin Polishchuk"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21418",
        "HTML": "https://arxiv.org/html/2506.21418",
        "PDF": "https://arxiv.org/pdf/2506.21418"
      },
      "subjects": [
        "Data Structures and Algorithms (cs.DS)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 16:06:29 GMT",
          "size": "127kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Vantage Point Selection Algorithms for Bottleneck Capacity Estimation",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on algorithms for selecting vantage points for network capacity estimation, unrelated to LLM training data processing or language models."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21420",
      "abstract": "Efficient three-dimensional reconstruction and real-time visualization are critical in surgical scenarios such as endoscopy. In recent years, 3D Gaussian Splatting (3DGS) has demonstrated remarkable performance in efficient 3D reconstruction and rendering. Most 3DGS-based Simultaneous Localization and Mapping (SLAM) methods only rely on the appearance constraints for optimizing both 3DGS and camera poses. However, in endoscopic scenarios, the challenges include photometric inconsistencies caused by non-Lambertian surfaces and dynamic motion from breathing affects the performance of SLAM systems. To address these issues, we additionally introduce optical flow loss as a geometric constraint, which effectively constrains both the 3D structure of the scene and the camera motion. Furthermore, we propose a depth regularisation strategy to mitigate the problem of photometric inconsistencies and ensure the validity of 3DGS depth rendering in endoscopic scenes. In addition, to improve scene representation in the SLAM system, we improve the 3DGS refinement strategy by focusing on viewpoints corresponding to Keyframes with suboptimal rendering quality frames, achieving better rendering results. Extensive experiments on the C3VD static dataset and the StereoMIS dynamic dataset demonstrate that our method outperforms existing state-of-the-art methods in novel view synthesis and pose estimation, exhibiting high performance in both static and dynamic surgical scenes. The source code will be publicly available upon paper acceptance.",
      "authors": [
        "Taoyu Wu",
        "Yiyi Miao",
        "Zhuoxiao Li",
        "Haocheng Zhao",
        "Kang Dang",
        "Jionglong Su",
        "Limin Yu",
        "Haoang Li"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21420",
        "HTML": "https://arxiv.org/html/2506.21420",
        "PDF": "https://arxiv.org/pdf/2506.21420"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 16:06:46 GMT",
          "size": "883kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "EndoFlow-SLAM: Real-Time Endoscopic SLAM with Flow-Constrained Gaussian Splatting",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper discusses 3D reconstruction in endoscopic surgery. It does not involve any aspects of LLM training data processing or language model refinement."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21422",
      "abstract": "The carbon footprint of data centers has recently become a critical concern. So far, most carbon-aware strategies have focused on leveraging the flexibility of scheduling decisions for batch processing by shifting the time and location of workload executions. However, such approaches cannot be applied to service-oriented cloud applications, since they have to be reachable at every point in time and often at low latencies. We propose a carbon-aware approach for operating microservices under hourly carbon budgets. By choosing the most appropriate version and horizontal scaleout for each microservice, our strategy maximizes user experience and revenue while staying within budget constraints. Experiments across various application configurations and carbon budgets demonstrate that the approach adapts properly to changing workloads and carbon intensities.",
      "authors": [
        "Kevin Kreutz and Philipp Wiesner and Monica Vitali"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21422",
        "HTML": "https://arxiv.org/html/2506.21422",
        "PDF": "https://arxiv.org/pdf/2506.21422"
      },
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 16:07:07 GMT",
          "size": "285kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Carbon-Aware Microservice Deployment for Optimal User Experience on a Budget",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper deals with carbon-aware strategies for microservices in data centers and does not discuss LLM training data processing."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21425",
      "abstract": "Traffic anomalies and attacks are commonplace in today's networks and identifying them rapidly and accurately is critical for large network operators. For a statistical intrusion detection system (IDS), it is crucial to detect at the flow-level for accurate detection and mitigation. However, existing IDS systems offer only limited support for 1) interactively examining detected intrusions and anomalies, 2) analyzing worm propagation patterns, 3) and discovering correlated attacks. These problems are becoming even more acute as the traffic on today's high-speed routers continues to grow.\n  IDGraphs is an interactive visualization system for intrusion detection that addresses these challenges. The central visualization in the system is a flow-level trace plotted with time on the horizontal axis and aggregated number of unsuccessful connections on the vertical axis. We then summarize a stack of tens or hundreds of thousands of these traces using the Histographs [RW05] technique, which maps data frequency at each pixel to brightness. Users may then interactively query the summary view, performing analysis by highlighting subsets of the traces. For example, brushing a linked correlation matrix view highlights traces with similar patterns, revealing distributed attacks that are difficult to detect using standard statistical analysis.\n  We apply IDGraphs system to a real network router data-set with 179M flow-level records representing a total traffic of 1.16TB. The system successfully detects and analyzes a variety of attacks and anomalies, including port scanning, worm outbreaks, stealthy TCP SYN floodings, and some distributed attacks.",
      "authors": [
        "Pin Ren",
        "Yan Gao",
        "Zhichun Li",
        "Yan Chen and Benjamin Watson"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21425",
        "HTML": "https://arxiv.org/html/2506.21425",
        "PDF": "https://arxiv.org/pdf/2506.21425"
      },
      "subjects": [
        "Graphics (cs.GR)",
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 16:08:20 GMT",
          "size": "2353kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "IDGraphs: Intrusion Detection and Analysis Using Stream Compositing",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on intrusion detection using an interactive visualization system for analyzing network traffic. It does not discuss any aspect related to LLM training data processing or any stages of data collection and cleaning for LLMs."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21427",
      "abstract": "Generative models such as diffusion and flow-matching offer expressive policies for offline reinforcement learning (RL) by capturing rich, multimodal action distributions, but their iterative sampling introduces high inference costs and training instability due to gradient propagation across sampling steps. We propose the \\textit{Single-Step Completion Policy} (SSCP), a generative policy trained with an augmented flow-matching objective to predict direct completion vectors from intermediate flow samples, enabling accurate, one-shot action generation. In an off-policy actor-critic framework, SSCP combines the expressiveness of generative models with the training and inference efficiency of unimodal policies, without requiring long backpropagation chains. Our method scales effectively to offline, offline-to-online, and online RL settings, offering substantial gains in speed and adaptability over diffusion-based baselines. We further extend SSCP to goal-conditioned RL, enabling flat policies to exploit subgoal structures without explicit hierarchical inference. SSCP achieves strong results across standard offline RL and behavior cloning benchmarks, positioning it as a versatile, expressive, and efficient framework for deep RL and sequential decision-making.",
      "authors": [
        "Prajwal Koirala",
        "Cody Fleming"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21427",
        "HTML": "https://arxiv.org/html/2506.21427",
        "PDF": "https://arxiv.org/pdf/2506.21427"
      },
      "subjects": [
        "Machine Learning (cs.LG)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 16:09:53 GMT",
          "size": "5229kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Flow-Based Single-Step Completion for Efficient and Expressive Policy Learning",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper proposes a method for policy learning in reinforcement learning using generative models. It does not address any LLM training data processing tasks nor contributes to data engineering for LLMs."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21429",
      "abstract": "This study investigates the efficacy of using multimodal machine learning techniques to detect deception in dyadic interactions, focusing on the integration of data from both the deceiver and the deceived. We compare early and late fusion approaches, utilizing audio and video data - specifically, Action Units and gaze information - across all possible combinations of modalities and participants. Our dataset, newly collected from Swedish native speakers engaged in truth or lie scenarios on emotionally relevant topics, serves as the basis for our analysis. The results demonstrate that incorporating both speech and facial information yields superior performance compared to single-modality approaches. Moreover, including data from both participants significantly enhances deception detection accuracy, with the best performance (71%) achieved using a late fusion strategy applied to both modalities and participants. These findings align with psychological theories suggesting differential control of facial and vocal expressions during initial interactions. As the first study of its kind on a Scandinavian cohort, this research lays the groundwork for future investigations into dyadic interactions, particularly within psychotherapy settings.",
      "authors": [
        "Franco Rugolon",
        "Thomas Jack Samuels",
        "Stephan Hau",
        "Lennart H\\\"ogman"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21429",
        "HTML": "https://arxiv.org/html/2506.21429",
        "PDF": "https://arxiv.org/pdf/2506.21429"
      },
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 16:11:42 GMT",
          "size": "5146kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Deception Detection in Dyadic Exchanges Using Multimodal Machine Learning: A Study on a Swedish Cohort",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This study focuses on deception detection using multimodal machine learning within dyadic interactions. There is no mention of LLM training data processing or any contributions to the preparation or processing of LLM-training datasets."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21430",
      "abstract": "Medical imaging datasets often contain heterogeneous biases ranging from erroneous labels to inconsistent labeling styles. Such biases can negatively impact deep segmentation networks performance. Yet, the identification and characterization of such biases is a particularly tedious and challenging task. In this paper, we introduce HyperSORT, a framework using a hyper-network predicting UNets' parameters from latent vectors representing both the image and annotation variability. The hyper-network parameters and the latent vector collection corresponding to each data sample from the training set are jointly learned. Hence, instead of optimizing a single neural network to fit a dataset, HyperSORT learns a complex distribution of UNet parameters where low density areas can capture noise-specific patterns while larger modes robustly segment organs in differentiated but meaningful manners. We validate our method on two 3D abdominal CT public datasets: first a synthetically perturbed version of the AMOS dataset, and TotalSegmentator, a large scale dataset containing real unknown biases and errors. Our experiments show that HyperSORT creates a structured mapping of the dataset allowing the identification of relevant systematic biases and erroneous samples. Latent space clusters yield UNet parameters performing the segmentation task in accordance with the underlying learned systematic bias. The code and our analysis of the TotalSegmentator dataset are made available: https://github.com/ImFusionGmbH/HyperSORT",
      "authors": [
        "Samuel Joutard",
        "Marijn Stollenga",
        "Marc Balle Sanchez",
        "Mohammad Farid Azampour",
        "Raphael Prevost"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21430",
        "HTML": "https://arxiv.org/html/2506.21430",
        "PDF": "https://arxiv.org/pdf/2506.21430"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 16:12:34 GMT",
          "size": "7735kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "HyperSORT: Self-Organising Robust Training with hyper-networks",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper introduces a framework for handling biases in medical imaging datasets using a hyper-network. It does not relate to LLM training data processing or present any techniques for preparing or engineering data specifically for LLMs."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21436",
      "abstract": "Computing over compressed data combines the space saving of data compression with efficient support for queries directly on the compressed representation. Such data structures are widely applied in text indexing and have been successfully generalised to trees. For graphs, support for computing over compressed data remains patchy; typical results in the area of succinct data structures are restricted to a specific class of graphs and use the same, worst-case amount of space for any graph from this class.\n  In this work, we design a data structure whose space usage automatically improves with the compressibility of the graph at hand, while efficiently supporting navigational operations (simulating adjacency-list access). Specifically, we show that the space usage approaches the instance-optimal space when the graph is drawn according to the classic Barab\\'asi-Albert model of preferential-attachment graphs. Our data-structure techniques also work for arbitrary graphs, guaranteeing a size asymptotically no larger than an entropy-compressed edge list. A key technical contribution is the careful analysis of the instance-optimal space usage.",
      "authors": [
        "Ziad Ismaili Alaoui and Namrata and Sebastian Wild"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21436",
        "HTML": "https://arxiv.org/html/2506.21436",
        "PDF": "https://arxiv.org/pdf/2506.21436"
      },
      "subjects": [
        "Data Structures and Algorithms (cs.DS)",
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)",
        "Probability (math.PR)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 16:20:31 GMT",
          "size": "52kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Succinct Preferential Attachment Graphs",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper discusses data structures for compressing graphs and supporting navigational operations, which is unrelated to LLM training data processing or engineering."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21440",
      "abstract": "The short-time Fourier transform (STFT) is widely used for analyzing non-stationary signals. However, its performance is highly sensitive to its parameters, and manual or heuristic tuning often yields suboptimal results. To overcome this limitation, we propose a unified differentiable formulation of the STFT that enables gradient-based optimization of its parameters. This approach addresses the limitations of traditional STFT parameter tuning methods, which often rely on computationally intensive discrete searches. It enables fine-tuning of the time-frequency representation (TFR) based on any desired criterion. Moreover, our approach integrates seamlessly with neural networks, allowing joint optimization of the STFT parameters and network weights. The efficacy of the proposed differentiable STFT in enhancing TFRs and improving performance in downstream tasks is demonstrated through experiments on both simulated and real-world data.",
      "authors": [
        "Maxime Leiber",
        "Yosra Marnissi",
        "Axel Barrau",
        "Sylvain Meignen",
        "Laurent Massouli\\'e"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21440",
        "HTML": "https://arxiv.org/html/2506.21440",
        "PDF": "https://arxiv.org/pdf/2506.21440"
      },
      "subjects": [
        "Sound (cs.SD)",
        "Machine Learning (cs.LG)",
        "Audio and Speech Processing (eess.AS)",
        "Signal Processing (eess.SP)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 16:24:27 GMT",
          "size": "3025kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Learnable Adaptive Time-Frequency Representation via Differentiable Short-Time Fourier Transform",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper focuses on a learnable representation for time-frequency analysis via STFT, which is not related to the processing or engineering of training data for LLMs."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21441",
      "abstract": "A paradigm for the design of systems that manage level of detail in virtual environments is proposed. As an example of the prototyping step in this paradigm, a user study was performed to evaluate the effectiveness of high detail insets used with head-mounted displays. Ten subjects were given a simple search task that required the location and identification of a single target object. All subjects used seven different displays (the independent variable), varying in inset size and peripheral detail, to perform this task. Frame rate, target location, subject input method, and order of display use were all controlled. Primary dependent measures were search time on trials with correct identification, and the percentage of all trials correctly identified. ANOVAs of the results showed that insetless, high detail displays did not lead to significantly different search times or accuracies than displays with insets. In fact, only the insetless, low detail display returned significantly different results. Further research is being performed to examine the effect of varying task complexity, inset size, and level of detail.",
      "authors": [
        "Benjamin Watson",
        "Neff Walker",
        "Larry F Hodges",
        "Martin Reddy"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21441",
        "HTML": "https://arxiv.org/html/2506.21441",
        "PDF": "https://arxiv.org/pdf/2506.21441"
      },
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Graphics (cs.GR)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 16:26:36 GMT",
          "size": "100kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "An evaluation of level of detail degradation in head-mounted display peripheries",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper evaluates display designs for virtual environments using user studies, with no discussion on LLM training data processing or engineering."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21444",
      "abstract": "Atypical mitoses mark a deviation in the cell division process that can be an independent prognostically relevant marker for tumor malignancy. However, their identification remains challenging due to low prevalence, at times subtle morphological differences from normal mitoses, low inter-rater agreement among pathologists, and class imbalance in datasets. Building on the Atypical Mitosis dataset for Breast Cancer (AMi-Br), this study presents a comprehensive benchmark comparing deep learning approaches for automated atypical mitotic figure (AMF) classification, including baseline models, foundation models with linear probing, and foundation models fine-tuned with low-rank adaptation (LoRA). For rigorous evaluation, we further introduce two new hold-out AMF datasets - AtNorM-Br, a dataset of mitoses from the The TCGA breast cancer cohort, and AtNorM-MD, a multi-domain dataset of mitoses from the MIDOG++ training set. We found average balanced accuracy values of up to 0.8135, 0.7696, and 0.7705 on the in-domain AMi-Br and the out-of-domain AtNorm-Br and AtNorM-MD datasets, respectively, with the results being particularly good for LoRA-based adaptation of the Virchow-line of foundation models. Our work shows that atypical mitosis classification, while being a challenging problem, can be effectively addressed through the use of recent advances in transfer learning and model fine-tuning techniques. We make available all code and data used in this paper in this github repository: https://github.com/DeepMicroscopy/AMi-Br_Benchmark.",
      "authors": [
        "Sweta Banerjee",
        "Viktoria Weiss",
        "Taryn A. Donovan",
        "Rutger A. Fick",
        "Thomas Conrad",
        "Jonas Ammeling",
        "Nils Porsche",
        "Robert Klopfleisch",
        "Christopher Kaltenecker",
        "Katharina Breininger",
        "Marc Aubreville",
        "Christof A. Bertram"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21444",
        "HTML": "https://arxiv.org/html/2506.21444",
        "PDF": "https://arxiv.org/pdf/2506.21444"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 16:30:42 GMT",
          "size": "997kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Benchmarking Deep Learning and Vision Foundation Models for Atypical vs. Normal Mitosis Classification with Cross-Dataset Evaluation",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This study benchmarks deep learning models for mitosis classification and does not propose any methods related to LLM training data processing or engineering."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21446",
      "abstract": "Image editing approaches have become more powerful and flexible with the advent of powerful text-conditioned generative models. However, placing objects in an environment with a precise location and orientation still remains a challenge, as this typically requires carefully crafted inpainting masks or prompts. In this work, we show that a carefully designed visual map, combined with coarse object masks, is sufficient for high quality object placement. We design a conditioning signal that resolves ambiguities, while being flexible enough to allow for changing of shapes or object orientations. By building on an inpainting model, we leave the background intact by design, in contrast to methods that model objects and background jointly. We demonstrate the effectiveness of our method in the automotive setting, where we compare different conditioning signals in novel object placement tasks. These tasks are designed to measure edit quality not only in terms of appearance, but also in terms of pose and location accuracy, including cases that require non-trivial shape changes. Lastly, we show that fine location control can be combined with appearance control to place existing objects in precise locations in a scene.",
      "authors": [
        "Mohamed Omran and Dimitris Kalatzis and Jens Petersen and Amirhossein Habibian and Auke Wiggers"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21446",
        "HTML": "https://arxiv.org/html/2506.21446",
        "PDF": "https://arxiv.org/pdf/2506.21446"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 16:31:39 GMT",
          "size": "40423kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Controllable 3D Placement of Objects with Scene-Aware Diffusion Models",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on image editing and object placement using scene-aware diffusion models, which is unrelated to the processing of training data for LLMs."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21449",
      "abstract": "exa-AMD is a Python-based application designed to accelerate the discovery and design of functional materials by integrating AI/ML tools, materials databases, and quantum mechanical calculations into scalable, high-performance workflows. The execution model of exa-AMD relies on Parsl, a task-parallel programming library that enables a flexible execution of tasks on any computing resource from laptops to supercomputers. By using Parsl, exa-AMD is able to decouple the workflow logic from execution configuration, thereby empowering researchers to scale their workflows without having to reimplement them for each system.",
      "authors": [
        "Maxim Moraru",
        "Weiyi Xia",
        "Zhuo Ye",
        "Feng Zhang",
        "Yongxin Yao",
        "Ying Wai Li",
        "Cai-Zhuang Wang"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21449",
        "HTML": "https://arxiv.org/html/2506.21449",
        "PDF": "https://arxiv.org/pdf/2506.21449"
      },
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 16:32:12 GMT",
          "size": "758kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "exa-AMD: A Scalable Workflow for Accelerating AI-Assisted Materials Discovery and Design",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper is about AI-assisted materials discovery using scalable workflows, without focus on training data processing or construction for LLMs."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21451",
      "abstract": "Underground mining operations face significant safety challenges that make emergency response capabilities crucial. While robots have shown promise in assisting with search and rescue operations, their effectiveness depends on reliable miner detection capabilities. Deep learning algorithms offer potential solutions for automated miner detection, but require comprehensive training datasets, which are currently lacking for underground mining environments. This paper presents a novel thermal imaging dataset specifically designed to enable the development and validation of miner detection systems for potential emergency applications. We systematically captured thermal imagery of various mining activities and scenarios to create a robust foundation for detection algorithms. To establish baseline performance metrics, we evaluated several state-of-the-art object detection algorithms including YOLOv8, YOLOv10, YOLO11, and RT-DETR on our dataset. While not exhaustive of all possible emergency situations, this dataset serves as a crucial first step toward developing reliable thermal-based miner detection systems that could eventually be deployed in real emergency scenarios. This work demonstrates the feasibility of using thermal imaging for miner detection and establishes a foundation for future research in this critical safety application.",
      "authors": [
        "Cyrus Addy",
        "Ajay Kumar Gurumadaiah",
        "Yixiang Gao and Kwame Awuah-Offei"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21451",
        "HTML": "https://arxiv.org/html/2506.21451",
        "PDF": "https://arxiv.org/pdf/2506.21451"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 16:33:49 GMT",
          "size": "585kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "A Comprehensive Dataset for Underground Miner Detection in Diverse Scenario",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper presents a thermal imaging dataset for miner detection but this does not pertain to LLM training data processing or engineering."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21452",
      "abstract": "Classifier-free guidance (CFG) succeeds in condition diffusion models that use a guidance scale to balance the influence of conditional and unconditional terms. A high guidance scale is used to enhance the performance of the conditional term. However, the high guidance scale often results in oversaturation and unrealistic artifacts. In this paper, we introduce a new perspective based on low-frequency signals, identifying the accumulation of redundant information in these signals as the key factor behind oversaturation and unrealistic artifacts. Building on this insight, we propose low-frequency improved classifier-free guidance (LF-CFG) to mitigate these issues. Specifically, we introduce an adaptive threshold-based measurement to pinpoint the locations of redundant information. We determine a reasonable threshold by analyzing the change rate of low-frequency information between prior and current steps. We then apply a down-weight strategy to reduce the impact of redundant information in the low-frequency signals. Experimental results demonstrate that LF-CFG effectively alleviates oversaturation and unrealistic artifacts across various diffusion models, including Stable Diffusion-XL, Stable Diffusion 2.1, 3.0, 3.5, and SiT-XL.",
      "authors": [
        "Kaiyu Song",
        "Hanjiang Lai"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21452",
        "HTML": "https://arxiv.org/html/2506.21452",
        "PDF": "https://arxiv.org/pdf/2506.21452"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 16:34:00 GMT",
          "size": "11009kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Rethinking Oversaturation in Classifier-Free Guidance via Low Frequency",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on improving classifier-free guidance in diffusion models by addressing issues like oversaturation and artifact generation, which are unrelated to the processing of LLM training data."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21453",
      "abstract": "We propose a training formulation for ResNets reflecting an optimal control problem that is applicable for standard architectures and general loss functions. We suggest bridging both worlds via penalizing intermediate outputs of hidden states corresponding to stage cost terms in optimal control. For standard ResNets, we obtain intermediate outputs by propagating the state through the subsequent skip connections and the output layer. We demonstrate that our training dynamic biases the weights of the unnecessary deeper residual layers to vanish. This indicates the potential for a theory-grounded layer pruning strategy.",
      "authors": [
        "Jens P\\\"uttschneider",
        "Simon Heilig",
        "Asja Fischer",
        "Timm Faulwasser"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21453",
        "HTML": "https://arxiv.org/html/2506.21453",
        "PDF": "https://arxiv.org/pdf/2506.21453"
      },
      "subjects": [
        "Machine Learning (cs.LG)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)",
        "Optimization and Control (math.OC)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 16:34:47 GMT",
          "size": "404kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Towards an Optimal Control Perspective of ResNet Training",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper proposes a new training formulation for ResNets based on optimal control theory, without any focus on LLM training data or data processing methods."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21455",
      "abstract": "In this paper, we propose an iterative algorithm using polar decomposition to approximate a channel characterized by a single unitary matrix based on input-output quantum state pairs. In limited data, we state and prove that the optimal solution obtained from our method using one pair with a specific structure will generate an equivalent class, significantly reducing the dimension of the searching space. Furthermore, we prove that the unitary matrices describing the same channel differ by a complex number with modulus 1. We rigorously prove our proposed algorithm can ultimately identify a critical point, which is also a local minimum of the established objective function.",
      "authors": [
        "Matthew M. Lin",
        "Hao-Wei Huang",
        "Bing-Ze Lu"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21455",
        "HTML": "https://arxiv.org/html/2506.21455",
        "PDF": "https://arxiv.org/pdf/2506.21455"
      },
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)",
        "Quantum Physics (quant-ph)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 16:35:28 GMT",
          "size": "196kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "An Iterative Methodology for Unitary Quantum Channel Search",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper presents an algorithm for unitary quantum channel approximation, with no discussion on LLM training data processing or related methodologies."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21456",
      "abstract": "Previous work has demonstrated the utility of reductions in the level of detail (LOD) in the periphery of head-tracked, large field of view displays. This paper provides a psychophysically based model, centered around an eye/head movement tradeoff, that explains the effectiveness of peripheral degradation and suggests how peripherally degraded displays should be designed. An experiment evaluating the effect on search performance of the shape and area of the high detail central area (inset) in peripherally degraded displays was performed, results indicated that inset shape is not a significant factor in performance. Inset area, however, was significant: performance with displays subtending at least 30 degrees of horizontal and vertical angle was not significantly different from performance with an undegraded display. These results agreed with the proposed model.",
      "authors": [
        "Benjamin Watson",
        "Neff Walker",
        "Larry F Hodges"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21456",
        "HTML": "https://arxiv.org/html/2506.21456",
        "PDF": "https://arxiv.org/pdf/2506.21456"
      },
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Graphics (cs.GR)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 16:35:38 GMT",
          "size": "74kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Managing level of detail through head-tracked peripheral degradation: a model and resulting design principles",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This research involves an experiment on perception in head-tracked displays and does not involve any aspect of LLM training data processing."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21458",
      "abstract": "Can Vision Language Models (VLMs) imagine the full scene from just a few views, like humans do? Humans form spatial mental models, internal representations of unseen space, to reason about layout, perspective, and motion. Our new MindCube benchmark with 21,154 questions across 3,268 images exposes this critical gap, where existing VLMs exhibit near-random performance. Using MindCube, we systematically evaluate how well VLMs build robust spatial mental models through representing positions (cognitive mapping), orientations (perspective-taking), and dynamics (mental simulation for \"what-if\" movements). We then explore three approaches to help VLMs approximate spatial mental models, including unseen intermediate views, natural language reasoning chains, and cognitive maps. The significant improvement comes from a synergistic approach, \"map-then-reason\", that jointly trains the model to first generate a cognitive map and then reason upon it. By training models to reason over these internal maps, we boosted accuracy from 37.8% to 60.8% (+23.0%). Adding reinforcement learning pushed performance even further to 70.7% (+32.9%). Our key insight is that such scaffolding of spatial mental models, actively constructing and utilizing internal structured spatial representations with flexible reasoning processes, significantly improves understanding of unobservable space.",
      "authors": [
        "Baiqiao Yin",
        "Qineng Wang",
        "Pingyue Zhang",
        "Jianshu Zhang",
        "Kangrui Wang",
        "Zihan Wang",
        "Jieyu Zhang",
        "Keshigeyan Chandrasegaran",
        "Han Liu",
        "Ranjay Krishna",
        "Saining Xie",
        "Manling Li",
        "Jiajun Wu",
        "Li Fei-Fei"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21458",
        "HTML": "https://arxiv.org/html/2506.21458",
        "PDF": "https://arxiv.org/pdf/2506.21458"
      },
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 16:38:19 GMT",
          "size": "29451kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Spatial Mental Modeling from Limited Views",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper addresses VLMs generating spatial mental models from limited views, which does not pertain to LLM training data processing."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21461",
      "abstract": "Evaluation is the method of assessing and determining the educational system through various techniques such as verbal or viva-voice test, subjective or objective written test. This paper presents an efficient solution to evaluate the subjective answer script electronically. In this paper, we proposed and implemented an integrated system that examines and evaluates the written answer script. This article focuses on finding the keywords from the answer script and then compares them with the keywords that have been parsed from both open and closed domain. The system also checks the grammatical and spelling errors in the answer script. Our proposed system tested with answer scripts of 100 students and gives precision score 0.91.",
      "authors": [
        "Tamim Al Mahmud",
        "Md Gulzar Hussain",
        "Sumaiya Kabir",
        "Hasnain Ahmad and Mahmudus Sobhan"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21461",
        "HTML": "https://arxiv.org/html/2506.21461",
        "PDF": "https://arxiv.org/pdf/2506.21461"
      },
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 16:42:49 GMT",
          "size": "666kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "A Keyword-Based Technique to Evaluate Broad Question Answer Script",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on evaluating written answer scripts using a keyword-based approach, which does not involve any aspects of LLM training data processing."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21465",
      "abstract": "Extended Stability Runge-Kutta (ESRK) methods are crucial for solving large-scale computational problems in science and engineering, including weather forecasting, aerodynamic analysis, and complex biological modelling. However, balancing accuracy, stability, and computational efficiency remains challenging, particularly for high-order, low-storage schemes. This study introduces a hybrid Genetic Algorithm (GA) and Reinforcement Learning (RL) approach for automated heuristic discovery, optimising low-storage ESRK methods. Unlike traditional approaches that rely on manually designed heuristics or exhaustive numerical searches, our method leverages GA-driven mutations for search-space exploration and an RL-inspired state transition mechanism to refine heuristic selection dynamically. This enables systematic parameter reduction, preserving fourth-order accuracy while significantly improving computational efficiency.The proposed GA-RL heuristic optimisation framework is validated through rigorous testing on benchmark problems, including the 1D and 2D Brusselator systems and the steady-state Navier-Stokes equations. The best-performing heuristic achieves a 25\\% reduction in IPOPT runtime compared to traditional ESRK optimisation processes while maintaining numerical stability and accuracy. These findings demonstrate the potential of adaptive heuristic discovery to improve resource efficiency in high-fidelity simulations and broaden the applicability of low-storage Runge-Kutta methods in real-world computational fluid dynamics, physics simulations, and other demanding fields. This work establishes a new paradigm in heuristic optimisation for numerical methods, opening pathways for further exploration using Deep RL and AutoML-based heuristic search",
      "authors": [
        "Gavin Lee Goodship",
        "Luis Miralles-Pechuan",
        "Stephen O'Sullivan"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21465",
        "HTML": "https://arxiv.org/html/2506.21465",
        "PDF": "https://arxiv.org/pdf/2506.21465"
      },
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 16:51:22 GMT",
          "size": "612kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Optimising 4th-Order Runge-Kutta Methods: A Dynamic Heuristic Approach for Efficiency and Low Storage",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This study introduces a heuristic optimization approach for Runge-Kutta methods used for simulations in science and engineering, without any discussion on LLM training data processing."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21468",
      "abstract": "Sparse autoencoders (SAEs) have become an important tool for analyzing and interpreting the activation space of transformer-based language models (LMs). However, SAEs suffer several shortcomings that diminish their utility and internal validity. Since SAEs are trained post-hoc, it is unclear if the failure to discover a particular concept is a failure on the SAE's side or due to the underlying LM not representing this concept. This problem is exacerbated by training conditions and architecture choices affecting which features an SAE learns. When tracing how LMs learn concepts during training, the lack of feature stability also makes it difficult to compare SAEs features across different checkpoints. To address these limitations, we introduce a modification to the transformer architecture that incorporates a TopK activation function at chosen layers, making the model's hidden states equivalent to the latent features of a TopK SAE. This approach eliminates the need for post-hoc training while providing interpretability comparable to SAEs. The resulting TopK LMs offer a favorable trade-off between model size, computational efficiency, and interpretability. Despite this simple architectural change, TopK LMs maintain their original capabilities while providing robust interpretability benefits. Our experiments demonstrate that the sparse representations learned by TopK LMs enable successful steering through targeted neuron interventions and facilitate detailed analysis of neuron formation processes across checkpoints and layers. These features make TopK LMs stable and reliable tools for understanding how language models learn and represent concepts, which we believe will significantly advance future research on model interpretability and controllability.",
      "authors": [
        "Ryosuke Takahashi",
        "Tatsuro Inaba",
        "Kentaro Inui",
        "Benjamin Heinzerling"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21468",
        "HTML": "https://arxiv.org/html/2506.21468",
        "PDF": "https://arxiv.org/pdf/2506.21468"
      },
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 16:56:43 GMT",
          "size": "205kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "TopK Language Models",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on the interpretability of LMs by modifying transformer architectures using TopK activation functions rather than addressing any training data processing-related aspects."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21469",
      "abstract": "The turning movement count data is crucial for traffic signal design, intersection geometry planning, traffic flow, and congestion analysis. This work proposes three methods called dynamic, static, and hybrid configuration for TMC-based traffic signals. A vision-based tracking system is developed to estimate the TMC of six intersections in Las Vegas using traffic cameras. The intersection design, route (e.g. vehicle movement directions), and signal configuration files with compatible formats are synthesized and imported into Simulation of Urban MObility for signal evaluation with realistic data. The initial experimental results based on estimated waiting times indicate that the cycle time of 90 and 120 seconds works best for all intersections. In addition, four intersections show better performance for dynamic signal timing configuration, and the other two with lower performance have a lower ratio of total vehicle count to total lanes of the intersection leg. Since daily traffic flow often exhibits a bimodal pattern, we propose a hybrid signal method that switches between dynamic and static methods, adapting to peak and off-peak traffic conditions for improved flow management. So, a built-in traffic generator module creates vehicle routes for 4 hours, including peak hours, and a signal design module produces signal schedule cycles according to static, dynamic, and hybrid methods. Vehicle count distributions are weighted differently for each zone (i.e., West, North, East, South) to generate diverse traffic patterns. The extended experimental results for 6 intersections with 4 hours of simulation time imply that zone-based traffic pattern distributions affect signal design selection. Although the static method works great for evenly zone-based traffic distribution, the hybrid method works well for highly weighted traffic at intersection pairs of the West-East and North-South zones.",
      "authors": [
        "Mohammad Shokrolah Shirazi",
        "Hung-Fu Chang"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21469",
        "HTML": "https://arxiv.org/html/2506.21469",
        "PDF": "https://arxiv.org/pdf/2506.21469"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 16:56:59 GMT",
          "size": "560kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Evaluation of Traffic Signals for Daily Traffic Pattern",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper discusses traffic signal evaluation and traffic pattern analysis using vision-based tracking systems but does not address LLM training data processing."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21474",
      "abstract": "In this paper, we present an Optical Character Recognition (OCR) system specifically designed for the accurate recognition and digitization of Greek polytonic texts. By leveraging the combined strengths of convolutional layers for feature extraction and recurrent layers for sequence learning, our system addresses the unique challenges posed by Greek polytonic scripts. This approach aims to overcome the limitations of traditional OCR methods, offering significant improvements in accuracy and efficiency. We release the underlying model as an open-source library and make our OCR platform available for academic use.",
      "authors": [
        "Perifanos Konstantinos and Goutsos Dionisis"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21474",
        "HTML": "https://arxiv.org/html/2506.21474",
        "PDF": "https://arxiv.org/pdf/2506.21474"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 17:04:27 GMT",
          "size": "4115kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Logios : An open source Greek Polytonic Optical Character Recognition system",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "Discusses the development of an OCR system specifically for Greek polytonic texts; the content does not relate to LLM training data processing."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21476",
      "abstract": "Learning the hierarchical structure of data in vision-language models is a significant challenge. Previous works have attempted to address this challenge by employing entailment learning. However, these approaches fail to model the transitive nature of entailment explicitly, which establishes the relationship between order and semantics within a representation space. In this work, we introduce Radial Cross-Modal Embeddings (RCME), a framework that enables the explicit modeling of transitivity-enforced entailment. Our proposed framework optimizes for the partial order of concepts within vision-language models. By leveraging our framework, we develop a hierarchical vision-language foundation model capable of representing the hierarchy in the Tree of Life. Our experiments on hierarchical species classification and hierarchical retrieval tasks demonstrate the enhanced performance of our models compared to the existing state-of-the-art models. Our code and models are open-sourced at https://vishu26.github.io/RCME/index.html.",
      "authors": [
        "Srikumar Sastry",
        "Aayush Dhakal",
        "Eric Xing",
        "Subash Khanal",
        "Nathan Jacobs"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21476",
        "HTML": "https://arxiv.org/html/2506.21476",
        "PDF": "https://arxiv.org/pdf/2506.21476"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 17:05:06 GMT",
          "size": "3804kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Global and Local Entailment Learning for Natural World Imagery",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper introduces a vision-language model framework for hierarchical entailment learning, but does not cover LLM training data processing aspects."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21478",
      "abstract": "Singing voice synthesis (SVS) aims to generate expressive and high-quality vocals from musical scores, requiring precise modeling of pitch, duration, and articulation. While diffusion-based models have achieved remarkable success in image and video generation, their application to SVS remains challenging due to the complex acoustic and musical characteristics of singing, often resulting in artifacts that degrade naturalness. In this work, we propose SmoothSinger, a conditional diffusion model designed to synthesize high quality and natural singing voices. Unlike prior methods that depend on vocoders as a final stage and often introduce distortion, SmoothSinger refines low-quality synthesized audio directly in a unified framework, mitigating the degradation associated with two-stage pipelines. The model adopts a reference-guided dual-branch architecture, using low-quality audio from any baseline system as a reference to guide the denoising process, enabling more expressive and context-aware synthesis. Furthermore, it enhances the conventional U-Net with a parallel low-frequency upsampling path, allowing the model to better capture pitch contours and long term spectral dependencies. To improve alignment during training, we replace reference audio with degraded ground truth audio, addressing temporal mismatch between reference and target signals. Experiments on the Opencpop dataset, a large-scale Chinese singing corpus, demonstrate that SmoothSinger achieves state-of-the-art results in both objective and subjective evaluations. Extensive ablation studies confirm its effectiveness in reducing artifacts and improving the naturalness of synthesized voices.",
      "authors": [
        "Kehan Sui",
        "Jinxu Xiang",
        "Fang Jin"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21478",
        "HTML": "https://arxiv.org/html/2506.21478",
        "PDF": "https://arxiv.org/pdf/2506.21478"
      },
      "subjects": [
        "Sound (cs.SD)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 17:07:45 GMT",
          "size": "125kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "SmoothSinger: A Conditional Diffusion Model for Singing Voice Synthesis with Multi-Resolution Architecture",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "Focuses on singing voice synthesis using diffusion models; it does not touch on LLM training data collection, construction, or processing."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21481",
      "abstract": "We study the problem of deciding whether a point escapes a closed subset of $\\mathbb{R}^d$ under the iteration of a continuous map $f \\colon \\mathbb{R}^d \\to \\mathbb{R}^d$ in the bit-model of real computation. We give a sound partial decision method for this problem which is complete in the sense that its halting set contains the halting set of all sound partial decision methods for the problem. Equivalently, our decision method terminates on all problem instances whose answer is robust under all sufficiently small perturbations of the function. We further show that the halting set of our algorithm is dense in the set of all problem instances. While our algorithm applies to general continuous functions, we demonstrate that it also yields complete decision methods for much more rigid function families: affine linear systems and quadratic complex polynomials. In the latter case, completeness is subject to the density of hyperbolicity conjecture in complex dynamics. This in particular yields an alternative proof of Hertling's (2004) conditional answer to a question raised by Penrose (1989) regarding the computability of the Mandelbrot set.",
      "authors": [
        "Eike Neumann"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21481",
        "HTML": "https://arxiv.org/html/2506.21481",
        "PDF": "https://arxiv.org/pdf/2506.21481"
      },
      "subjects": [
        "Logic in Computer Science (cs.LO)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 17:10:46 GMT",
          "size": "249kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Deciding Robust Instances of an Escape Problem for Dynamical Systems in Euclidean Space",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on a computational problem regarding dynamical systems in Euclidean space, which does not relate to LLM training data processing."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21484",
      "abstract": "We focus on the source-free domain adaptive object detection (SF-DAOD) problem when source data is unavailable during adaptation and the model must adapt to an unlabeled target domain. The majority of approaches for the problem employ a self-supervised approach using a student-teacher (ST) framework where pseudo-labels are generated via a source-pretrained model for further fine-tuning. We observe that the performance of a student model often degrades drastically, due to the collapse of the teacher model, primarily caused by high noise in pseudo-labels, resulting from domain bias, discrepancies, and a significant domain shift across domains. To obtain reliable pseudo-labels, we propose a Target-based Iterative Query-Token Adversarial Network (TITAN), which separates the target images into two subsets: those similar to the source (easy) and those dissimilar (hard). We propose a strategy to estimate variance to partition the target domain. This approach leverages the insight that higher detection variances correspond to higher recall and greater similarity to the source domain. Also, we incorporate query-token-based adversarial modules into a student-teacher baseline framework to reduce the domain gaps between two feature representations. Experiments conducted on four natural imaging datasets and two challenging medical datasets have substantiated the superior performance of TITAN compared to existing state-of-the-art (SOTA) methodologies. We report an mAP improvement of +22.7, +22.2, +21.1, and +3.7 percent over the current SOTA on C2F, C2B, S2C, and K2C benchmarks, respectively.",
      "authors": [
        "Tajamul Ashraf",
        "Janibul Bashir"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21484",
        "HTML": "https://arxiv.org/html/2506.21484",
        "PDF": "https://arxiv.org/pdf/2506.21484"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 17:12:58 GMT",
          "size": "12260kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "TITAN: Query-Token based Domain Adaptive Adversarial Learning",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper discusses domain adaptive object detection using adversarial learning methods, focusing on self-supervised learning, which is unrelated to the training data processing for LLMs."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21486",
      "abstract": "Deep neural networks have set the state-of-the-art in computer vision tasks such as bounding box detection and semantic segmentation. Object detectors and segmentation models assign confidence scores to predictions, reflecting the model's uncertainty in object detection or pixel-wise classification. However, these confidence estimates are often miscalibrated, as their architectures and loss functions are tailored to task performance rather than probabilistic foundation. Even with well calibrated predictions, object detectors fail to quantify uncertainty outside detected bounding boxes, i.e., the model does not make a probability assessment of whether an area without detected objects is truly free of obstacles. This poses a safety risk in applications such as automated driving, where uncertainty in empty areas remains unexplored. In this work, we propose an object detection model grounded in spatial statistics. Bounding box data matches realizations of a marked point process, commonly used to describe the probabilistic occurrence of spatial point events identified as bounding box centers, where marks are used to describe the spatial extension of bounding boxes and classes. Our statistical framework enables a likelihood-based training and provides well-defined confidence estimates for whether a region is drivable, i.e., free of objects. We demonstrate the effectiveness of our method through calibration assessments and evaluation of performance.",
      "authors": [
        "Tobias J. Riedlinger",
        "Kira Maag",
        "Hanno Gottschalk"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21486",
        "HTML": "https://arxiv.org/html/2506.21486",
        "PDF": "https://arxiv.org/pdf/2506.21486"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)",
        "Probability (math.PR)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 17:14:37 GMT",
          "size": "10782kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Towards Reliable Detection of Empty Space: Conditional Marked Point Processes for Object Detection",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This research is concentrated on object detection and spatial statistics in vision models, not addressing any aspects of LLM training data processing."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21487",
      "abstract": "This paper presents OptGM, an optimized gate merging method designed to mitigate negative bias temperature instability (NBTI) in digital circuits. First, the proposed approach effectively identifies NBTI-critical internal nodes, defined as those with a signal probability exceeding a predefined threshold. Next, based on the proposed optimized algorithm, the sensitizer gate (which drives the critical node) and the sensitive gate (which is fed by it) are merged into a new complex gate. This complex gate preserves the original logic while eliminating NBTI-critical nodes. Finally, to evaluate the effectiveness of OptGM, we assess it on several combinational and sequential benchmark circuits. Simulation results demonstrate that, on average, the number of NBTI-critical transistors (i.e., PMOS transistors connected to critical nodes), NBTI-induced delay degradation, and the total transistor count are reduced by 89.29%, 23.87%, and 6.47%, respectively. Furthermore, OptGM enhances performance per cost (PPC) by 12.8% on average, with minimal area overhead.",
      "authors": [
        "Maryam Ghane",
        "Amir M. Hajisadeghi",
        "Hamid R. Zarandi"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21487",
        "HTML": "https://arxiv.org/html/2506.21487",
        "PDF": "https://arxiv.org/pdf/2506.21487"
      },
      "subjects": [
        "Hardware Architecture (cs.AR)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 17:15:55 GMT",
          "size": "4537kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "OptGM: An Optimized Gate Merging Method to Mitigate NBTI in Digital Circuits",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The study is about mitigating NBTI in digital circuits through gate merging, which does not involve any processing of training data for LLMs."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21493",
      "abstract": "We consider the problem of fair allocation of $m$ indivisible items to $n$ agents with monotone subadditive valuations. For integer $d \\ge 2$, a $d$-multi-allocation is an allocation in which each item is allocated to at most $d$ different agents. We show that $d$-multi-allocations can be transformed into allocations, while not losing much more than a factor of $d$ in the value that each agent receives. One consequence of this result is that for allocation instances with equal entitlements and subadditive valuations, if $\\rho$-MMS $d$-multi-allocations exist, then so do $\\frac{\\rho}{4d}$-MMS allocations. Combined with recent results of Seddighin and Seddighin [EC 2025], this implies the existence of $\\Omega(\\frac{1}{\\log\\log n})$-MMS allocations.",
      "authors": [
        "Uriel Feige"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21493",
        "HTML": "https://arxiv.org/html/2506.21493",
        "PDF": "https://arxiv.org/pdf/2506.21493"
      },
      "subjects": [
        "Computer Science and Game Theory (cs.GT)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 17:21:51 GMT",
          "size": "17kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "From multi-allocations to allocations, with subadditive valuations",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper primarily deals with fair allocation of indivisible items with subadditive valuations, which is not related to LLM training data processing."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21500",
      "abstract": "According to the data, the percent of women who underwent screening for cervical cancer, breast and oral cancer in Telangana in the year 2020 was 3.3 percent, 0.3 percent and 2.3 percent respectively. Although early detection is the only way to reduce morbidity and mortality, people have very low awareness about cervical and breast cancer signs and symptoms and screening practices. We developed an ML classification model to predict if a person is susceptible to breast or cervical cancer based on demographic factors. We devised a system to provide suggestions for the nearest hospital or Cancer treatment centres based on the users location or address. In addition to this, we can integrate the health card to maintain medical records of all individuals and conduct awareness drives and campaigns. For ML classification models, we used decision tree classification and support vector classification algorithms for cervical cancer susceptibility and breast cancer susceptibility respectively. Thus, by devising this solution we come one step closer to our goal which is spreading cancer awareness, thereby, decreasing the cancer mortality and increasing cancer literacy among the people of Telangana.",
      "authors": [
        "Priyanka Avhad",
        "Vedanti Kshirsagar",
        "Urvi Ranjan",
        "Mahek Nakhua"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21500",
        "HTML": "https://arxiv.org/html/2506.21500",
        "PDF": "https://arxiv.org/pdf/2506.21500"
      },
      "subjects": [
        "Machine Learning (cs.LG)",
        "Computers and Society (cs.CY)",
        "Quantitative Methods (q-bio.QM)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 17:29:00 GMT",
          "size": "2054kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Devising a solution to the problems of Cancer awareness in Telangana",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper discusses an ML classification model to predict cancer susceptibility and a system for hospital suggestions, which does not involve LLM training data processing."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21502",
      "abstract": "Fault diagnosis in Cyber-Physical Systems (CPSs) is essential for ensuring system dependability and operational efficiency by accurately detecting anomalies and identifying their root causes. However, the manual modeling of faulty behaviors often demands extensive domain expertise and produces models that are complex, error-prone, and difficult to interpret. To address this challenge, we present a novel unsupervised fault diagnosis methodology that integrates collective anomaly detection in multivariate time series, process mining, and stochastic simulation. Initially, collective anomalies are detected from low-level sensor data using multivariate time-series analysis. These anomalies are then transformed into structured event logs, enabling the discovery of interpretable process models through process mining. By incorporating timing distributions into the extracted Petri nets, the approach supports stochastic simulation of faulty behaviors, thereby enhancing root cause analysis and behavioral understanding. The methodology is validated using the Robotic Arm Dataset (RoAD), a widely recognized benchmark in smart manufacturing. Experimental results demonstrate its effectiveness in modeling, simulating, and classifying faulty behaviors in CPSs. This enables the creation of comprehensive fault dictionaries that support predictive maintenance and the development of digital twins for industrial environments.",
      "authors": [
        "Francesco Vitale",
        "Nicola Dall'Ora",
        "Sebastiano Gaiardelli",
        "Enrico Fraccaroli",
        "Nicola Mazzocca",
        "Franco Fummi"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21502",
        "HTML": "https://arxiv.org/html/2506.21502",
        "PDF": "https://arxiv.org/pdf/2506.21502"
      },
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 17:29:37 GMT",
          "size": "16747kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Process mining-driven modeling and simulation to enhance fault diagnosis in cyber-physical systems",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on fault diagnosis in cyber-physical systems using process mining and stochastic simulation, which is unrelated to LLM training data processing."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21506",
      "abstract": "Agentic search such as Deep Research systems, where large language models autonomously browse the web, synthesize information, and return comprehensive citation-backed answers, represents a major shift in how users interact with web-scale information. While promising greater efficiency and cognitive offloading, the growing complexity and open-endedness of agentic search have outpaced existing evaluation benchmarks and methodologies, which largely assume short search horizons and static answers. In this paper, we introduce Mind2Web 2, a benchmark of 130 realistic, high-quality, and long-horizon tasks that require real-time web browsing and extensive information synthesis, constructed with over 1,000 hours of human labor. To address the challenge of evaluating time-varying and complex answers, we propose a novel Agent-as-a-Judge framework. Our method constructs task-specific judge agents based on a tree-structured rubric design to automatically assess both answer correctness and source attribution. We conduct a comprehensive evaluation of nine frontier agentic search systems and human performance, along with a detailed error analysis to draw insights for future development. The best-performing system, OpenAI Deep Research, can already achieve 50-70% of human performance while spending half the time, showing a great potential. Altogether, Mind2Web 2 provides a rigorous foundation for developing and benchmarking the next generation of agentic search systems.",
      "authors": [
        "Boyu Gou",
        "Zanming Huang",
        "Yuting Ning",
        "Yu Gu",
        "Michael Lin",
        "Weijian Qi",
        "Andrei Kopanev",
        "Botao Yu",
        "Bernal Jim\\'enez Guti\\'errez",
        "Yiheng Shu",
        "Chan Hee Song",
        "Jiaman Wu",
        "Shijie Chen",
        "Hanane Nour Moussa",
        "Tianshu Zhang",
        "Jian Xie",
        "Yifei Li",
        "Tianci Xue",
        "Zeyi Liao",
        "Kai Zhang",
        "Boyuan Zheng",
        "Zhaowei Cai",
        "Viktor Rozgic",
        "Morteza Ziyadi",
        "Huan Sun",
        "Yu Su"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21506",
        "HTML": "https://arxiv.org/html/2506.21506",
        "PDF": "https://arxiv.org/pdf/2506.21506"
      },
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 17:32:50 GMT",
          "size": "8157kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Mind2Web 2: Evaluating Agentic Search with Agent-as-a-Judge",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper is centered around evaluating agentic search systems and provides a benchmark for web browsing tasks, with no specific focus on LLM training data processing or engineering."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21509",
      "abstract": "Large Vision-Language Models (LVLMs) have demonstrated significant advancements in multimodal understanding, yet they are frequently hampered by hallucination-the generation of text that contradicts visual input. Existing training-free decoding strategies exhibit critical limitations, including the use of static constraints that do not adapt to semantic drift during generation, inefficiency stemming from the need for multiple forward passes, and degradation of detail due to overly rigid intervention rules. To overcome these challenges, this paper introduces Dynamic Logits Calibration (DLC), a novel training-free decoding framework designed to dynamically align text generation with visual evidence at inference time. At the decoding phase, DLC step-wise employs CLIP to assess the semantic alignment between the input image and the generated text sequence. Then, the Relative Visual Advantage (RVA) of candidate tokens is evaluated against a dynamically updated contextual baseline, adaptively adjusting output logits to favor tokens that are visually grounded. Furthermore, an adaptive weighting mechanism, informed by a real-time context alignment score, carefully balances the visual guidance while ensuring the overall quality of the textual output. Extensive experiments conducted across diverse benchmarks and various LVLM architectures (such as LLaVA, InstructBLIP, and MiniGPT-4) demonstrate that DLC significantly reduces hallucinations, outperforming current methods while maintaining high inference efficiency by avoiding multiple forward passes. Overall, we present an effective and efficient decoding-time solution to mitigate hallucinations, thereby enhancing the reliability of LVLMs for more practices. Code will be released on Github.",
      "authors": [
        "Jiahe Chen and Jiaying He and Qian Shao and Qiyuan Chen and Jiahe Ying and Hongxia Xu and Jintai Chen and Jianwei Zheng and Jian Wu"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21509",
        "HTML": "https://arxiv.org/html/2506.21509",
        "PDF": "https://arxiv.org/pdf/2506.21509"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 17:35:40 GMT",
          "size": "2507kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Mitigating Hallucination of Large Vision-Language Models via Dynamic Logits Calibration",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper discusses a decoding framework for vision-language models to mitigate hallucinations during inference, unrelated to tasks involved in processing training data for language models."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21510",
      "abstract": "We study the joint scheduling of behind-the-meter distributed energy resources (DERs), including flexible loads, renewable generation, and battery energy storage systems, under net energy metering frameworks with demand charges. The problem is formulated as a stochastic dynamic program aimed at maximizing expected operational surplus while accounting for renewable generation uncertainty. We analytically characterize the structure of the optimal control policy and show that it admits a threshold-based form. However, due to the strong temporal coupling of the storage and demand charge constraints, the number of conditional branches in the policy scales combinatorially with the scheduling horizon, as it requires a look-ahead over future states. To overcome the high computational complexity in the general formulation, an efficient approximation algorithm is proposed, which searches for the peak demand under a mildly relaxed problem. We show that the algorithm scales linearly with the scheduling horizon. Extensive simulations using two open-source datasets validate the proposed algorithm and compare its performance against different DER control strategies, including a reinforcement learning-based one. Under varying storage and tariff parameters, the results show that the proposed algorithm outperforms various benchmarks in achieving a relatively small solution gap compared to the theoretical upper bound.",
      "authors": [
        "Ruixiao Yang and Gulai Shen and Ahmed S. Alahmed and Chuchu Fan"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21510",
        "HTML": "https://arxiv.org/html/2506.21510",
        "PDF": "https://arxiv.org/pdf/2506.21510"
      },
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 17:35:55 GMT",
          "size": "316kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Joint Scheduling of DER under Demand Charges: Structure and Approximation",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This research addresses energy resource scheduling under demand charges, which is not connected to the creation or processing of LLM training data."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21513",
      "abstract": "Creating high-quality, generalizable speech-driven 3D talking heads remains a persistent challenge. Previous methods achieve satisfactory results for fixed viewpoints and small-scale audio variations, but they struggle with large head rotations and out-of-distribution (OOD) audio. Moreover, they are constrained by the need for time-consuming, identity-specific training. We believe the core issue lies in the lack of sufficient 3D priors, which limits the extrapolation capabilities of synthesized talking heads. To address this, we propose GGTalker, which synthesizes talking heads through a combination of generalizable priors and identity-specific adaptation. We introduce a two-stage Prior-Adaptation training strategy to learn Gaussian head priors and adapt to individual characteristics. We train Audio-Expression and Expression-Visual priors to capture the universal patterns of lip movements and the general distribution of head textures. During the Customized Adaptation, individual speaking styles and texture details are precisely modeled. Additionally, we introduce a color MLP to generate fine-grained, motion-aligned textures and a Body Inpainter to blend rendered results with the background, producing indistinguishable, photorealistic video frames. Comprehensive experiments show that GGTalker achieves state-of-the-art performance in rendering quality, 3D consistency, lip-sync accuracy, and training efficiency.",
      "authors": [
        "Wentao Hu",
        "Shunkai Li",
        "Ziqiao Peng",
        "Haoxian Zhang",
        "Fan Shi",
        "Xiaoqiang Liu",
        "Pengfei Wan",
        "Di Zhang",
        "Hui Tian"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21513",
        "HTML": "https://arxiv.org/html/2506.21513",
        "PDF": "https://arxiv.org/pdf/2506.21513"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 17:37:18 GMT",
          "size": "33502kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "GGTalker: Talking Head Systhesis with Generalizable Gaussian Priors and Identity-Specific Adaptation",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper addresses speech-driven 3D talking head synthesis and does not relate to the processing of training data for LLMs."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21514",
      "abstract": "Multimodal learning aims to leverage information from diverse data modalities to achieve more comprehensive performance. However, conventional multimodal models often suffer from modality imbalance, where one or a few modalities dominate model optimization, leading to suboptimal feature representation and underutilization of weak modalities. To address this challenge, we introduce Gradient-Guided Distillation (G$^{2}$D), a knowledge distillation framework that optimizes the multimodal model with a custom-built loss function that fuses both unimodal and multimodal objectives. G$^{2}$D further incorporates a dynamic sequential modality prioritization (SMP) technique in the learning process to ensure each modality leads the learning process, avoiding the pitfall of stronger modalities overshadowing weaker ones. We validate G$^{2}$D on multiple real-world datasets and show that G$^{2}$D amplifies the significance of weak modalities while training and outperforms state-of-the-art methods in classification and regression tasks. Our code is available at https://github.com/rAIson-Lab/G2D.",
      "authors": [
        "Mohammed Rakib",
        "Arunkumar Bagavathi"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21514",
        "HTML": "https://arxiv.org/html/2506.21514",
        "PDF": "https://arxiv.org/pdf/2506.21514"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 17:37:36 GMT",
          "size": "6068kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "G$^{2}$D: Boosting Multimodal Learning with Gradient-Guided Distillation",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The focus is on multimodal learning enhancements through gradient-guided distillation, without discussing training data processing specifically for LLMs."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21520",
      "abstract": "Recent advances in scene reconstruction have pushed toward highly realistic modeling of autonomous driving (AD) environments using 3D Gaussian splatting. However, the resulting reconstructions remain closely tied to the original observations and struggle to support photorealistic synthesis of significantly altered or novel driving scenarios. This work introduces MADrive, a memory-augmented reconstruction framework designed to extend the capabilities of existing scene reconstruction methods by replacing observed vehicles with visually similar 3D assets retrieved from a large-scale external memory bank. Specifically, we release MAD-Cars, a curated dataset of ${\\sim}70$K 360{\\deg} car videos captured in the wild and present a retrieval module that finds the most similar car instances in the memory bank, reconstructs the corresponding 3D assets from video, and integrates them into the target scene through orientation alignment and relighting. The resulting replacements provide complete multi-view representations of vehicles in the scene, enabling photorealistic synthesis of substantially altered configurations, as demonstrated in our experiments. Project page: https://yandex-research.github.io/madrive/",
      "authors": [
        "Polina Karpikova",
        "Daniil Selikhanovych",
        "Kirill Struminsky",
        "Ruslan Musaev",
        "Maria Golitsyna",
        "Dmitry Baranchuk"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21520",
        "HTML": "https://arxiv.org/html/2506.21520",
        "PDF": "https://arxiv.org/pdf/2506.21520"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 17:41:07 GMT",
          "size": "9206kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "MADrive: Memory-Augmented Driving Scene Modeling",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper introduces a memory-augmented framework for scene modeling in autonomous driving. It is not related to LLM training data processing and does not contribute to data engineering aspects specific to LLMs."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21521",
      "abstract": "Large language models (LLMs) are regularly evaluated using benchmark datasets. But what justifies making inferences about an LLM's capabilities based on its answers to a curated set of questions? This paper first introduces a formal framework to address this question. The key is to note that the benchmarks used to test LLMs -- such as AP exams -- are also those used to test people. However, this raises an implication: these benchmarks are only valid tests if LLMs misunderstand concepts in ways that mirror human misunderstandings. Otherwise, success on benchmarks only demonstrates potemkin understanding: the illusion of understanding driven by answers irreconcilable with how any human would interpret a concept. We present two procedures for quantifying the existence of potemkins: one using a specially designed benchmark in three domains, the other using a general procedure that provides a lower-bound on their prevalence. We find that potemkins are ubiquitous across models, tasks, and domains. We also find that these failures reflect not just incorrect understanding, but deeper internal incoherence in concept representations.",
      "authors": [
        "Marina Mancoridis",
        "Bec Weeks",
        "Keyon Vafa",
        "Sendhil Mullainathan"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21521",
        "HTML": "https://arxiv.org/html/2506.21521",
        "PDF": "https://arxiv.org/pdf/2506.21521"
      },
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 17:41:35 GMT",
          "size": "2402kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Potemkin Understanding in Large Language Models",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on evaluating LLMs using benchmark datasets, assessing model understanding versus human misunderstanding. It does not discuss processing or engineering of training data for LLMs."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21526",
      "abstract": "We introduce Warping-Alone Field Transforms (WAFT), a simple and effective method for optical flow. WAFT is similar to RAFT but replaces cost volume with high-resolution warping, achieving better accuracy with lower memory cost. This design challenges the conventional wisdom that constructing cost volumes is necessary for strong performance. WAFT is a simple and flexible meta-architecture with minimal inductive biases and reliance on custom designs. Compared with existing methods, WAFT ranks 1st on Spring and KITTI benchmarks, achieves the best zero-shot generalization on KITTI, while being up to 4.1x faster than methods with similar performance. Code and model weights are available at https://github.com/princeton-vl/WAFT.",
      "authors": [
        "Yihan Wang",
        "Jia Deng"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21526",
        "HTML": "https://arxiv.org/html/2506.21526",
        "PDF": "https://arxiv.org/pdf/2506.21526"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 17:47:59 GMT",
          "size": "24149kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "WAFT: Warping-Alone Field Transforms for Optical Flow",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper introduces WAFT for optical flow, focusing on accuracy and memory optimization in computer vision, without addressing LLM training data processing."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21538",
      "abstract": "Cross-modal image-text retrieval is challenging because of the diverse possible associations between content from different modalities. Traditional methods learn a single-vector embedding to represent semantics of each sample, but struggle to capture nuanced and diverse relationships that can exist across modalities. Set-based approaches, which represent each sample with multiple embeddings, offer a promising alternative, as they can capture richer and more diverse relationships. In this paper, we show that, despite their promise, these set-based representations continue to face issues including sparse supervision and set collapse, which limits their effectiveness. To address these challenges, we propose Maximal Pair Assignment Similarity to optimize one-to-one matching between embedding sets which preserve semantic diversity within the set. We also introduce two loss functions to further enhance the representations: Global Discriminative Loss to enhance distinction among embeddings, and Intra-Set Divergence Loss to prevent collapse within each set. Our method achieves state-of-the-art performance on MS-COCO and Flickr30k without relying on external data.",
      "authors": [
        "Hani Alomari",
        "Anushka Sivakumar",
        "Andrew Zhang",
        "Chris Thomas"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21538",
        "HTML": "https://arxiv.org/html/2506.21538",
        "PDF": "https://arxiv.org/pdf/2506.21538"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Information Retrieval (cs.IR)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 17:55:34 GMT",
          "size": "1309kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Maximal Matching Matters: Preventing Representation Collapse for Robust Cross-Modal Retrieval",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This work presents methods for cross-modal retrieval using image-text datasets, focusing on embedding techniques and loss functions. There is no connection to LLM training data processing or engineering."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21539",
      "abstract": "We present WorldVLA, an autoregressive action world model that unifies action and image understanding and generation. Our WorldVLA intergrates Vision-Language-Action (VLA) model and world model in one single framework. The world model predicts future images by leveraging both action and image understanding, with the purpose of learning the underlying physics of the environment to improve action generation. Meanwhile, the action model generates the subsequent actions based on image observations, aiding in visual understanding and in turn helps visual generation of the world model. We demonstrate that WorldVLA outperforms standalone action and world models, highlighting the mutual enhancement between the world model and the action model. In addition, we find that the performance of the action model deteriorates when generating sequences of actions in an autoregressive manner. This phenomenon can be attributed to the model's limited generalization capability for action prediction, leading to the propagation of errors from earlier actions to subsequent ones. To address this issue, we propose an attention mask strategy that selectively masks prior actions during the generation of the current action, which shows significant performance improvement in the action chunk generation task.",
      "authors": [
        "Jun Cen",
        "Chaohui Yu",
        "Hangjie Yuan",
        "Yuming Jiang",
        "Siteng Huang",
        "Jiayan Guo",
        "Xin Li",
        "Yibing Song",
        "Hao Luo",
        "Fan Wang",
        "Deli Zhao",
        "and Hao Chen"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21539",
        "HTML": "https://arxiv.org/html/2506.21539",
        "PDF": "https://arxiv.org/pdf/2506.21539"
      },
      "subjects": [
        "Robotics (cs.RO)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 17:55:40 GMT",
          "size": "2941kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "WorldVLA: Towards Autoregressive Action World Model",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "WorldVLA focuses on integrating vision-language-action models and enhancing performance through autoregressive methods and attention strategies. It does not address LLM training data collection or processing."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21541",
      "abstract": "Recently, Mamba-based methods have demonstrated impressive performance in point cloud representation learning by leveraging State Space Model (SSM) with the efficient context modeling ability and linear complexity. However, these methods still face two key issues that limit the potential of SSM: Destroying the adjacency of 3D points during SSM processing and failing to retain long-sequence memory as the input length increases in downstream tasks. To address these issues, we propose StruMamba3D, a novel paradigm for self-supervised point cloud representation learning. It enjoys several merits. First, we design spatial states and use them as proxies to preserve spatial dependencies among points. Second, we enhance the SSM with a state-wise update strategy and incorporate a lightweight convolution to facilitate interactions between spatial states for efficient structure modeling. Third, our method reduces the sensitivity of pre-trained Mamba-based models to varying input lengths by introducing a sequence length-adaptive strategy. Experimental results across four downstream tasks showcase the superior performance of our method. In addition, our method attains the SOTA 95.1% accuracy on ModelNet40 and 92.75% accuracy on the most challenging split of ScanObjectNN without voting strategy.",
      "authors": [
        "Chuxin Wang",
        "Yixin Zha",
        "Wenfei Yang",
        "Tianzhu Zhang"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21541",
        "HTML": "https://arxiv.org/html/2506.21541",
        "PDF": "https://arxiv.org/pdf/2506.21541"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 17:58:05 GMT",
          "size": "6854kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "StruMamba3D: Exploring Structural Mamba for Self-supervised Point Cloud Representation Learning",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper explores point cloud representation learning using Mamba-based methods for 3D models. There is no mention of LLM training data or related processing techniques."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21544",
      "abstract": "Reconstructing 3D objects from a single image is a long-standing challenge, especially under real-world occlusions. While recent diffusion-based view synthesis models can generate consistent novel views from a single RGB image, they generally assume fully visible inputs and fail when parts of the object are occluded. This leads to inconsistent views and degraded 3D reconstruction quality. To overcome this limitation, we propose an end-to-end framework for occlusion-aware multi-view generation. Our method directly synthesizes six structurally consistent novel views from a single partially occluded image, enabling downstream 3D reconstruction without requiring prior inpainting or manual annotations. We construct a self-supervised training pipeline using the Pix2Gestalt dataset, leveraging occluded-unoccluded image pairs and pseudo-ground-truth views to teach the model structure-aware completion and view consistency. Without modifying the original architecture, we fully fine-tune the view synthesis model to jointly learn completion and multi-view generation. Additionally, we introduce the first benchmark for occlusion-aware reconstruction, encompassing diverse occlusion levels, object categories, and mask patterns. This benchmark provides a standardized protocol for evaluating future methods under partial occlusions. Our code is available at https://github.com/Quyans/DeOcc123.",
      "authors": [
        "Yansong Qu",
        "Shaohui Dai",
        "Xinyang Li",
        "Yuze Wang",
        "You Shen",
        "Liujuan Cao",
        "Rongrong Ji"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21544",
        "HTML": "https://arxiv.org/html/2506.21544",
        "PDF": "https://arxiv.org/pdf/2506.21544"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 17:58:26 GMT",
          "size": "12771kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "DeOcc-1-to-3: 3D De-Occlusion from a Single Image via Self-Supervised Multi-View Diffusion",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper addresses 3D reconstruction from images using an occlusion-aware approach and does not contribute to the field of LLM training data processing or data engineering."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21546",
      "abstract": "Recent progress in vision-language segmentation has significantly advanced grounded visual understanding. However, these models often exhibit hallucinations by producing segmentation masks for objects not grounded in the image content or by incorrectly labeling irrelevant regions. Existing evaluation protocols for segmentation hallucination primarily focus on label or textual hallucinations without manipulating the visual context, limiting their capacity to diagnose critical failures. In response, we introduce HalluSegBench, the first benchmark specifically designed to evaluate hallucinations in visual grounding through the lens of counterfactual visual reasoning. Our benchmark consists of a novel dataset of 1340 counterfactual instance pairs spanning 281 unique object classes, and a set of newly introduced metrics that quantify hallucination sensitivity under visually coherent scene edits. Experiments on HalluSegBench with state-of-the-art vision-language segmentation models reveal that vision-driven hallucinations are significantly more prevalent than label-driven ones, with models often persisting in false segmentation, highlighting the need for counterfactual reasoning to diagnose grounding fidelity.",
      "authors": [
        "Xinzhuo Li",
        "Adheesh Juvekar",
        "Xingyou Liu",
        "Muntasir Wahed",
        "Kiet A. Nguyen",
        "Ismini Lourentzou"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21546",
        "HTML": "https://arxiv.org/html/2506.21546",
        "PDF": "https://arxiv.org/pdf/2506.21546"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 17:59:12 GMT",
          "size": "20977kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "HalluSegBench: Counterfactual Visual Reasoning for Segmentation Hallucination Evaluation",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper presents a benchmark for evaluating segmentation hallucination in vision-language models, which is not related to LLM training data processing or data engineering."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21552",
      "abstract": "We train models to Predict Ego-centric Video from human Actions (PEVA), given the past video and an action represented by the relative 3D body pose. By conditioning on kinematic pose trajectories, structured by the joint hierarchy of the body, our model learns to simulate how physical human actions shape the environment from a first-person point of view. We train an auto-regressive conditional diffusion transformer on Nymeria, a large-scale dataset of real-world egocentric video and body pose capture. We further design a hierarchical evaluation protocol with increasingly challenging tasks, enabling a comprehensive analysis of the model's embodied prediction and control abilities. Our work represents an initial attempt to tackle the challenges of modeling complex real-world environments and embodied agent behaviors with video prediction from the perspective of a human.",
      "authors": [
        "Yutong Bai",
        "Danny Tran",
        "Amir Bar",
        "Yann LeCun",
        "Trevor Darrell",
        "Jitendra Malik"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21552",
        "HTML": "https://arxiv.org/html/2506.21552",
        "PDF": "https://arxiv.org/pdf/2506.21552"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)",
        "Multimedia (cs.MM)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 17:59:59 GMT",
          "size": "44274kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Whole-Body Conditioned Egocentric Video Prediction",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This work focuses on egocentric video prediction based on human action data, utilizing a large-scale video dataset for model training. It does not contribute to LLM training data collection, construction, or processing."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.20672",
      "abstract": "A recent survey, nicknamed \"Hitchhiker's Guide\", J.J. Arias-Garc{\\i}a, R. Mesiar, and B. De Baets, A hitchhiker's guide to quasi-copulas, Fuzzy Sets and Systems 393 (2020) 1-28, has raised the rating of quasi-copula problems in the dependence modeling community in spite of the lack of statistical interpretation of quasi-copulas. In our previous work (arXiv:2410.19339, accepted in Fuzzy Sets and Systems), we addressed the question of extreme values of the mass distribution associated with multivariate quasi-copulas. Using a linear programming approach, we were able to solve Open Problem 5 of the \"Guide\" up to dimension d = 17 and disprove a recent conjecture on the solution to that problem. In this paper, we use an analytical approach to provide a complete answer to the original question.",
      "authors": [
        "Matja\\v{z} Omladi\\v{c}",
        "Martin Vuk and Alja\\v{z} Zalar"
      ],
      "last_revised_date": "2025/05/20",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20672",
        "HTML": "https://arxiv.org/html/2506.20672",
        "PDF": "https://arxiv.org/pdf/2506.20672"
      },
      "subjects": [
        "Machine Learning (stat.ML)",
        "Machine Learning (cs.LG)",
        "Optimization and Control (math.OC)",
        "Statistics Theory (math.ST)",
        "Statistics Theory (stat.TH)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 20 May 2025 14:56:53 GMT",
          "size": "21kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/05/20",
      "title": "The final solution of the Hitchhiker's problem #5",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This is a mathematical and analytical paper dealing with quasi-copulas and the Hitchhiker's problem, which lacks any connection to LLM training data or its processing."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.20683",
      "abstract": "An electrocardiogram (ECG) is a widely used, cost-effective tool for detecting electrical abnormalities in the heart. However, it cannot directly measure functional parameters, such as ventricular volumes and ejection fraction, which are crucial for assessing cardiac function. Cardiac magnetic resonance (CMR) is the gold standard for these measurements, providing detailed structural and functional insights, but is expensive and less accessible. To bridge this gap, we propose PTACL (Patient and Temporal Alignment Contrastive Learning), a multimodal contrastive learning framework that enhances ECG representations by integrating spatio-temporal information from CMR. PTACL uses global patient-level contrastive loss and local temporal-level contrastive loss. The global loss aligns patient-level representations by pulling ECG and CMR embeddings from the same patient closer together, while pushing apart embeddings from different patients. Local loss enforces fine-grained temporal alignment within each patient by contrasting encoded ECG segments with corresponding encoded CMR frames. This approach enriches ECG representations with diagnostic information beyond electrical activity and transfers more insights between modalities than global alignment alone, all without introducing new learnable weights. We evaluate PTACL on paired ECG-CMR data from 27,951 subjects in the UK Biobank. Compared to baseline approaches, PTACL achieves better performance in two clinically relevant tasks: (1) retrieving patients with similar cardiac phenotypes and (2) predicting CMR-derived cardiac function parameters, such as ventricular volumes and ejection fraction. Our results highlight the potential of PTACL to enhance non-invasive cardiac diagnostics using ECG. The code is available at: https://github.com/alsalivan/ecgcmr",
      "authors": [
        "Alexander Selivanov",
        "Philip M\\\"uller",
        "\\\"Ozg\\\"un Turgut",
        "Nil Stolt-Ans\\'o",
        "Daniel R\\\"uckert"
      ],
      "last_revised_date": "2025/06/24",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20683",
        "HTML": "https://arxiv.org/html/2506.20683",
        "PDF": "https://arxiv.org/pdf/2506.20683"
      },
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Signal Processing (eess.SP)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 24 Jun 2025 17:19:39 GMT",
          "size": "560kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/24",
      "title": "Global and Local Contrastive Learning for Joint Representations from Cardiac MRI and ECG",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The research focuses on enhancing ECG representations using CMR data via contrastive learning, not relating to the development or processing of training data for LLMs."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.20684",
      "abstract": "Mathematical oncology is an interdisciplinary research field where mathematics meets cancer research. The field's intention to study cancer makes it dynamic, as practicing researchers are incentivised to quickly adapt to both technical and medical research advances. Determining the scope of mathematical oncology is therefore not straightforward; however, it is important for purposes related to funding allocation, education, scientific communication, and community organisation. To address this issue, we here conduct a bibliometric analysis of mathematical oncology. We compare our results to the broader field of mathematical biology, and position our findings within theoretical science of science frameworks.\n  Based on article metadata and citation flows, our results provide evidence that mathematical oncology has undergone a significant evolution since the 1960s marked by increased interactions with other disciplines, geographical expansion, larger research teams, and greater diversity in studied topics. The latter finding contributes to the greater discussion on which models different research communities consider to be valuable in the era of big data and machine learning. Further, the results presented in this study quantitatively motivate that international collaboration networks should be supported to enable new countries to enter and remain in the field, and that mathematical oncology benefits both mathematics and the life sciences.",
      "authors": [
        "Kira Pugh",
        "Linn\\'ea Gyllingberg",
        "Stanislav Stratiev",
        "Sara Hamis"
      ],
      "last_revised_date": "2025/06/24",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20684",
        "HTML": "https://arxiv.org/html/2506.20684",
        "PDF": "https://arxiv.org/pdf/2506.20684"
      },
      "subjects": [
        "Physics and Society (physics.soc-ph)",
        "Digital Libraries (cs.DL)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 24 Jun 2025 17:59:59 GMT",
          "size": "11588kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/24",
      "title": "A bibliometric study on mathematical oncology: interdisciplinarity, internationality, collaboration and trending topics",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This is a bibliometric study on mathematical oncology and does not discuss any aspects of LLM training data processing or engineering."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.20686",
      "abstract": "Protein structure prediction models such as AlphaFold3 (AF3) push the frontier of biomolecular modeling by incorporating science-informed architectural changes to the transformer architecture. However, these advances come at a steep system cost, introducing: compute- and memory-intensive operators, 2D attention mechanisms, and retrieval-augmented data pipelines, which collectively hinder the scalability of AF3 training. In this work, we present MegaFold, a cross-platform system to accelerate AF3 training. MegaFold tackles key bottlenecks through ahead-of-time caching to eliminate GPU idle time from the retrieval-augmented data pipeline, Triton-based kernels for memory-efficient EvoAttention on heterogeneous devices, and deep fusion for common and critical small operators in AF3. Evaluation on both NVIDIA H200 and AMD MI250 GPUs shows that MegaFold reduces peak memory usage of AF3 training by up to 1.23$\\times$ and improves per-iteration training time by up-to 1.73$\\times$ and 1.62$\\times$ respectively. More importantly, MegaFold enables training on 1.35$\\times$ longer sequence lengths compared to PyTorch baselines without running out-of-memory, significantly improving the scalability of modern protein folding models. We open source our code at https://github.com/Supercomputing-System-AI-Lab/MegaFold/.",
      "authors": [
        "Hoa La",
        "Ahan Gupta",
        "Alex Morehead",
        "Jianlin Cheng",
        "Minjia Zhang"
      ],
      "last_revised_date": "2025/06/24",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20686",
        "HTML": "https://arxiv.org/html/2506.20686",
        "PDF": "https://arxiv.org/pdf/2506.20686"
      },
      "subjects": [
        "Biomolecules (q-bio.BM)",
        "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "Machine Learning (cs.LG)",
        "Performance (cs.PF)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 24 Jun 2025 23:30:49 GMT",
          "size": "423kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/24",
      "title": "MegaFold: System-Level Optimizations for Accelerating Protein Structure Prediction Models",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper details optimizations for protein structure prediction models, not LLMs. It does not discuss training data processing for language models."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.20689",
      "abstract": "Artificial intelligence, including deep learning models, will play a transformative role in automated medical image analysis for the diagnosis of cardiac disorders and their management. Automated accurate delineation of cardiac images is the first necessary initial step for the quantification and automated diagnosis of cardiac disorders. In this paper, we propose a deep learning based enhanced UNet model, U-R-Veda, which integrates convolution transformations, vision transformer, residual links, channel-attention, and spatial attention, together with edge-detection based skip-connections for an accurate fully-automated semantic segmentation of cardiac magnetic resonance (CMR) images. The model extracts local-features and their interrelationships using a stack of combination convolution blocks, with embedded channel and spatial attention in the convolution block, and vision transformers. Deep embedding of channel and spatial attention in the convolution block identifies important features and their spatial localization. The combined edge information with channel and spatial attention as skip connection reduces information-loss during convolution transformations. The overall model significantly improves the semantic segmentation of CMR images necessary for improved medical image analysis. An algorithm for the dual attention module (channel and spatial attention) has been presented. Performance results show that U-R-Veda achieves an average accuracy of 95.2%, based on DSC metrics. The model outperforms the accuracy attained by other models, based on DSC and HD metrics, especially for the delineation of right-ventricle and left-ventricle-myocardium.",
      "authors": [
        "Racheal Mukisa and Arvind K. Bansal"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20689",
        "HTML": "https://arxiv.org/html/2506.20689",
        "PDF": "https://arxiv.org/pdf/2506.20689"
      },
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 04:10:09 GMT",
          "size": "666kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "U-R-VEDA: Integrating UNET, Residual Links, Edge and Dual Attention, and Vision Transformer for Accurate Semantic Segmentation of CMRs",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper is focused on a deep learning model for semantic segmentation of medical images, not on LLM data processing."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.20691",
      "abstract": "St. Francis of Assisi (1181/82-1226) famously called money the devil's dung, and indeed money is often associated with greed, inequality, and corruption. Drawing on Nowak's five rules for the evolution of cooperation, we argue here that money promotes the formation of circuits of generalized reciprocity across human groups that are fundamental to social evolution. In an evolutionary tournament, we show that money exchange is an evolutionary stable strategy that promotes cooperation without relying on the cognitive demands of direct reciprocity or reputation mechanisms. However, we also find that excessive liquidity can be detrimental because it can distort the informational value of money as a signal of past cooperation, making defection more profitable. Our results suggest that, in addition to institutions that promoted trust and punishment, the emergence of institutions that regulated the money supply was key to maintaining generalized reciprocity within and across human groups.",
      "authors": [
        "Eduardo C. Ferraciolli",
        "Francesco Renzini",
        "Tanya V. Araujo",
        "Flaminio Squazzoni"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20691",
        "HTML": "https://arxiv.org/html/2506.20691",
        "PDF": "https://arxiv.org/pdf/2506.20691"
      },
      "subjects": [
        "Physics and Society (physics.soc-ph)",
        "Computer Science and Game Theory (cs.GT)",
        "Adaptation and Self-Organizing Systems (nlin.AO)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 07:21:50 GMT",
          "size": "1400kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "The Devil's Dung? Money as a mechanism of generalized reciprocity in human societies",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper discusses the role of money in human societies as an evolutionary mechanism, unrelated to LLM data processing."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.20694",
      "abstract": "Biological systems are non-linear, include unobserved variables and the physical principles that govern their dynamics are partly unknown. This makes the characterization of their behavior very challenging. Notably, their activity occurs on multiple interdependent spatial and temporal scales that require linking mechanisms across scales. To address the challenge of bridging gaps between scales, we leverage partial differential equations (PDE) discovery. PDE discovery suggests meso-scale dynamics characteristics from micro-scale data. In this article, we present our framework combining particle-based simulations and PDE discovery and conduct preliminary experiments to assess equation discovery in controlled settings. We evaluate five state-of-the-art PDE discovery methods on particle-based simulations of calcium diffusion in astrocytes. The performances of the methods are evaluated on both the form of the discovered equation and the forecasted temporal variations of calcium concentration. Our results show that several methods accurately recover the diffusion term, highlighting the potential of PDE discovery for capturing macroscopic dynamics in biological systems from microscopic data.",
      "authors": [
        "Andr\\'ea Ducos (AISTROSIGHT)",
        "Audrey Denizot (AISTROSIGHT)",
        "Thomas Guyet (AISTROSIGHT)",
        "Hugues Berry (AISTROSIGHT)"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20694",
        "HTML": "https://arxiv.org/html/2506.20694",
        "PDF": "https://arxiv.org/pdf/2506.20694"
      },
      "subjects": [
        "Quantitative Methods (q-bio.QM)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 08:43:37 GMT",
          "size": "1064kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Evaluating PDE discovery methods for multiscale modeling of biological signals",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper discusses PDE discovery for modeling biological signals, which is unrelated to the collection or processing of training data for large language models."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.20696",
      "abstract": "Elucidating the biomechanical behavior of the myocardium is crucial for understanding cardiac physiology, but cannot be directly inferred from clinical imaging and typically requires finite element (FE) simulations. However, conventional FE methods are computationally expensive and often fail to reproduce observed cardiac motions. We propose IMC-PINN-FE, a physics-informed neural network (PINN) framework that integrates imaged motion consistency (IMC) with FE modeling for patient-specific left ventricular (LV) biomechanics. Cardiac motion is first estimated from MRI or echocardiography using either a pre-trained attention-based network or an unsupervised cyclic-regularized network, followed by extraction of motion modes. IMC-PINN-FE then rapidly estimates myocardial stiffness and active tension by fitting clinical pressure measurements, accelerating computation from hours to seconds compared to traditional inverse FE. Based on these parameters, it performs FE modeling across the cardiac cycle at 75x speedup. Through motion constraints, it matches imaged displacements more accurately, improving average Dice from 0.849 to 0.927, while preserving realistic pressure-volume behavior. IMC-PINN-FE advances previous PINN-FE models by introducing back-computation of material properties and better motion fidelity. Using motion from a single subject to reconstruct shape modes also avoids the need for large datasets and improves patient specificity. IMC-PINN-FE offers a robust and efficient approach for rapid, personalized, and image-consistent cardiac biomechanical modeling.",
      "authors": [
        "Siyu Mu",
        "Wei Xuan Chan",
        "Choon Hwai Yap"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20696",
        "HTML": "https://arxiv.org/html/2506.20696",
        "PDF": "https://arxiv.org/pdf/2506.20696"
      },
      "subjects": [
        "Medical Physics (physics.med-ph)",
        "Artificial Intelligence (cs.AI)",
        "Image and Video Processing (eess.IV)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 11:37:34 GMT",
          "size": "1261kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "IMC-PINN-FE: A Physics-Informed Neural Network for Patient-Specific Left Ventricular Finite Element Modeling with Image Motion Consistency and Biomechanical Parameter Estimation",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper proposes a physics-informed neural network for biomechanical modeling, unrelated to training data processing for large language models."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.20697",
      "abstract": "The advent of single-cell multi-omics technologies has enabled the simultaneous profiling of diverse omics layers within individual cells. Integrating such multimodal data provides unprecedented insights into cellular identity, regulatory processes, and disease mechanisms. However, it remains challenging, as current methods often rely on selecting highly variable genes or peaks during preprocessing, which may inadvertently discard crucial biological information. Here, we present scMamba, a foundation model designed to integrate single-cell multi-omics data without the need for prior feature selection while preserving genomic positional information. scMamba introduces a patch-based cell tokenization strategy that treats genomics regions as words (tokens) and cells as sentences. Building upon the concept of state space duality, scMamba distills rich biological insights from high-dimensional, sparse single-cell multi-omics data. Additionally, our novel contrastive learning approach, enhanced with cosine similarity regularization, enables superior alignment across omics layers compared to traditional methods. Systematic benchmarking across multiple datasets demonstrates that scMamba significantly outperforms state-of-the-art methods in preserving biological variation, aligning omics layers, and enhancing key downstream tasks such as clustering, cell type annotation, and trajectory inference. Our findings position scMamba as a powerful tool for large-scale single-cell multi-omics integration, capable of handling large-scale atlases and advancing biological discovery.",
      "authors": [
        "Zhen Yuan",
        "Shaoqing Jiao",
        "Yihang Xiao",
        "Jiajie Peng"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20697",
        "HTML": "https://arxiv.org/html/2506.20697",
        "PDF": "https://arxiv.org/pdf/2506.20697"
      },
      "subjects": [
        "Cell Behavior (q-bio.CB)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 12:58:01 GMT",
          "size": "45836kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "scMamba: A Scalable Foundation Model for Single-Cell Multi-Omics Integration Beyond Highly Variable Feature Selection",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "While the paper involves data integration in biological multi-omics, it does not mention contributions to training data processing or engineering for large language models."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.20745",
      "abstract": "The exceptional adhesion properties of biological fibrillar structures -- such as those found in geckos -- have inspired the development of synthetic adhesive surfaces. Among these, mushroom-shaped fibrils have demonstrated superior pull-off strength compared to other geometries. In this study, we employ a computational approach based on a Dugdale cohesive zone model to analyze the detachment behavior of these fibrils when adhered to a rigid substrate. The results provide complete pull-off curves, revealing that the separation process is inherently unstable under load control, regardless of whether detachment initiates at the fibril edge or center. Our findings show that fibrils with a wide, thin mushroom cap effectively reduce stress concentrations and promote central detachment, leading to enhanced adhesion. However, detachment from the center is not observed in all geometries, whereas edge detachment can occur under certain conditions in all cases. Additionally, we investigate the impact of adhesion defects at the fibril center, showing that they can significantly reduce pull-off strength, particularly at high values of the dimensionless parameter \\c{hi}. These insights contribute to the optimization of bio-inspired adhesives and microstructured surfaces for various engineering applications.",
      "authors": [
        "C. Beteg\\'on",
        "C. Rodr\\'iguez",
        "E. Mart\\'inez-Pa\\~neda",
        "R.M. McMeeking"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20745",
        "HTML": "https://arxiv.org/html/2506.20745",
        "PDF": "https://arxiv.org/pdf/2506.20745"
      },
      "subjects": [
        "Soft Condensed Matter (cond-mat.soft)",
        "Materials Science (cond-mat.mtrl-sci)",
        "Computational Engineering, Finance, and Science (cs.CE)",
        "Applied Physics (physics.app-ph)",
        "Biological Physics (physics.bio-ph)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 18:13:20 GMT",
          "size": "1193kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Pull-off strength of mushroom-shaped fibrils adhered to rigid substrates",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on the adhesion properties of biological fibrillar structures and computational modeling of their detachment behavior. It has no relevance to LLM training data processing or data engineering."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.20753",
      "abstract": "We consider a variant of Cops and Robbers in which both the cops and the robber are allowed to traverse up to $s$ edges on each of their turns, where $s \\ge 2$. We give several general for this new model as well as establish bounds for the cop numbers for grids and hypercubes. We also determine the capture time of cop-win graphs when $s = 2$ up to a small additive constant.",
      "authors": [
        "William B. Kinnersley and Nikolas Townsend"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20753",
        "HTML": "https://arxiv.org/html/2506.20753",
        "PDF": "https://arxiv.org/pdf/2506.20753"
      },
      "subjects": [
        "Combinatorics (math.CO)",
        "Discrete Mathematics (cs.DM)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 18:26:32 GMT",
          "size": "50kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Accelerated Cops and Robbers",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on a game theoretic problem involving Cops and Robbers, analyzing movement dynamics and capture times on graphs. There is no mention or implication of training data processing for LLMs."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.20764",
      "abstract": "Although there is a substantial body of literature on control and optimization problems for parabolic and hyperbolic systems, the specific problem of controlling and optimizing the coefficients of the associated operators within such systems has not yet been thoroughly explored. In this work, we aim to initiate a line of research in control theory focused on optimizing and controlling the coefficients of these operators-a problem that naturally arises in the context of neural networks and supervised learning.\n  In supervised learning, the primary objective is to transport initial data toward target data through the layers of a neural network. We propose a novel perspective: neural networks can be interpreted as partial differential equations (PDEs). From this viewpoint, the control problem traditionally studied in the context of ordinary differential equations (ODEs) is reformulated as a control problem for PDEs, specifically targeting the optimization and control of coefficients in parabolic and hyperbolic operators. To the best of our knowledge, this specific problem has not yet been systematically addressed in the control theory of PDEs.\n  To this end, we propose a dual system formulation for the control and optimization problem associated with parabolic PDEs, laying the groundwork for the development of efficient numerical schemes in future research. We also provide a theoretical proof showing that the control and optimization problem for parabolic PDEs admits minimizers. Finally, we investigate the control problem associated with hyperbolic PDEs and prove the existence of solutions for a corresponding approximated control problem.",
      "authors": [
        "Alain Bensoussan",
        "Minh-Binh Tran",
        "Bangjie Wang"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20764",
        "HTML": "https://arxiv.org/html/2506.20764",
        "PDF": "https://arxiv.org/pdf/2506.20764"
      },
      "subjects": [
        "Optimization and Control (math.OC)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 18:54:48 GMT",
          "size": "43kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Control and optimization for Neural Partial Differential Equations in Supervised Learning",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper explores control and optimization of neural PDEs in supervised learning, with no specific focus on LLM training data processing or data engineering methods."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.20779",
      "abstract": "We study the implicit bias of flatness / low (loss) curvature and its effects on generalization in two-layer overparameterized ReLU networks with multivariate inputs -- a problem well motivated by the minima stability and edge-of-stability phenomena in gradient-descent training. Existing work either requires interpolation or focuses only on univariate inputs. This paper presents new and somewhat surprising theoretical results for multivariate inputs. On two natural settings (1) generalization gap for flat solutions, and (2) mean-squared error (MSE) in nonparametric function estimation by stable minima, we prove upper and lower bounds, which establish that while flatness does imply generalization, the resulting rates of convergence necessarily deteriorate exponentially as the input dimension grows. This gives an exponential separation between the flat solutions vis-\\`a-vis low-norm solutions (i.e., weight decay), which knowingly do not suffer from the curse of dimensionality. In particular, our minimax lower bound construction, based on a novel packing argument with boundary-localized ReLU neurons, reveals how flat solutions can exploit a kind of ''neural shattering'' where neurons rarely activate, but with high weight magnitudes. This leads to poor performance in high dimensions. We corroborate these theoretical findings with extensive numerical simulations. To the best of our knowledge, our analysis provides the first systematic explanation for why flat minima may fail to generalize in high dimensions.",
      "authors": [
        "Tongtong Liang",
        "Dan Qiao",
        "Yu-Xiang Wang",
        "Rahul Parhi"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20779",
        "HTML": "https://arxiv.org/html/2506.20779",
        "PDF": "https://arxiv.org/pdf/2506.20779"
      },
      "subjects": [
        "Machine Learning (stat.ML)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 19:10:03 GMT",
          "size": "4163kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Stable Minima of ReLU Neural Networks Suffer from the Curse of Dimensionality: The Neural Shattering Phenomenon",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper examines the generalization ability of ReLU neural networks in high-dimensional settings without discussing LLM or its training data processing."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.20799",
      "abstract": "Estimating the governing equation parameter values is essential for integrating experimental data with scientific theory to understand, validate, and predict the dynamics of complex systems. In this work, we propose a new method for structural system identification (SI), uncertainty quantification, and validation directly from data. Inspired by generative modeling frameworks, a neural network maps random noise to physically meaningful parameters. These parameters are then used in the known equation of motion to obtain fake accelerations, which are compared to real training data via a mean square error loss. To simultaneously validate the learned parameters, we use independent validation datasets. The generated accelerations from these datasets are evaluated by a discriminator network, which determines whether the output is real or fake, and guides the parameter-generator network. Analytical and real experiments show the parameter estimation accuracy and model validation for different nonlinear structural systems.",
      "authors": [
        "Cristian L\\'opez",
        "Keegan J. Moore"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20799",
        "HTML": "https://arxiv.org/html/2506.20799",
        "PDF": "https://arxiv.org/pdf/2506.20799"
      },
      "subjects": [
        "Dynamical Systems (math.DS)",
        "Machine Learning (cs.LG)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 19:43:23 GMT",
          "size": "4022kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Structural System Identification via Validation and Adaptation",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper discusses a method for structural system identification and validation using neural networks to estimate parameters from data. It does not address LLM training data or relevant data processing tasks for LLMs."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.20831",
      "abstract": "Combining attention with recurrence has shown to be valuable in sequence modeling, including hydrological predictions. Here, we explore the strength of Temporal Fusion Transformers (TFTs) over Long Short-Term Memory (LSTM) networks in rainfall-runoff modeling. We train ten randomly initialized models, TFT and LSTM, for 531 CAMELS catchments in the US. We repeat the experiment with five subsets of the Caravan dataset, each representing catchments in the US, Australia, Brazil, Great Britain, and Chile. Then, the performance of the models, their variability regarding the catchment attributes, and the difference according to the datasets are assessed. Our findings show that TFT slightly outperforms LSTM, especially in simulating the midsection and peak of hydrographs. Furthermore, we show the ability of TFT to handle longer sequences and why it can be a better candidate for higher or larger catchments. Being an explainable AI technique, TFT identifies the key dynamic and static variables, providing valuable scientific insights. However, both TFT and LSTM exhibit a considerable drop in performance with the Caravan dataset, indicating possible data quality issues. Overall, the study highlights the potential of TFT in improving hydrological modeling and understanding.",
      "authors": [
        "Sinan Rasiya Koya",
        "Tirthankar Roy"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20831",
        "HTML": "https://arxiv.org/html/2506.20831",
        "PDF": "https://arxiv.org/pdf/2506.20831"
      },
      "subjects": [
        "Geophysics (physics.geo-ph)",
        "Machine Learning (cs.LG)",
        "Applications (stat.AP)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 20:58:28 GMT",
          "size": "5618kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Efficacy of Temporal Fusion Transformers for Runoff Simulation",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper centers on the application of Temporal Fusion Transformers for hydrological modeling and does not address the processing or engineering of training data for large language models (LLMs)."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.20839",
      "abstract": "Machine learning has significantly advanced the understanding and application of structural materials, with an increasing emphasis on integrating existing data and quantifying uncertainties in predictive modeling. This study presents a comprehensive methodology utilizing a mixed density network (MDN) model, trained on extensive experimental data from literature. This approach uniquely predicts the distribution of dislocation density, inferred as a latent variable, and the resulting stress distribution at the grain level. The incorporation of statistical parameters of those predicted distributions into a dislocation-mediated plasticity model allows for accurate stress-strain predictions with explicit uncertainty quantification. This strategy not only improves the accuracy and reliability of mechanical property predictions but also plays a vital role in optimizing alloy design, thereby facilitating the development of new materials in a rapidly evolving industry.",
      "authors": [
        "Jing Luo",
        "Yejun Gu",
        "Yanfei Wang",
        "Xiaolong Ma",
        "Jaafar.A El-Awady"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20839",
        "HTML": "https://arxiv.org/html/2506.20839",
        "PDF": "https://arxiv.org/pdf/2506.20839"
      },
      "subjects": [
        "Materials Science (cond-mat.mtrl-sci)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 21:18:14 GMT",
          "size": "6465kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Uncertainty-Aware Machine-Learning Framework for Predicting Dislocation Plasticity and Stress-Strain Response in FCC Alloys",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This research pertains to machine learning models for predicting material properties and does not involve the processing of LLM training data."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.20897",
      "abstract": "Purpose:To develop a method that enhances the accuracy of spectral analysis in the presence of static magnetic field B0 inhomogeneity. Methods:The authors proposed a new spectral analysis method utilizing a deep learning model trained on modeled spectra that consistently represent the spectral variations induced by B0 inhomogeneity. These modeled spectra were generated from the B0 map and metabolite ratios of the healthy human brain. The B0 map was divided into a patch size of subregions, and the separately estimated metabolites and baseline components were averaged and then integrated. The quality of the modeled spectra was visually and quantitatively evaluated against the measured spectra. The analysis models were trained using measured, simulated, and modeled spectra. The performance of the proposed method was assessed using mean squared errors (MSEs) of metabolite ratios. The mean absolute percentage errors (MAPEs) of the metabolite ratios were also compared to LCModel when analyzing the phantom spectra acquired under two types of B0 inhomogeneity. Results:The modeled spectra exhibited broadened and narrowed spectral peaks depending on the B0 inhomogeneity and were quantitatively close to the measured spectra. The analysis model trained using measured spectra with modeled spectra improved MSEs by 49.89% compared to that trained using measured spectra alone, and by 26.66% compared to that trained using measured spectra with simulated spectra. The performance improved as the number of modeled spectra increased from 0 to 1,000. This model showed significantly lower MAPEs than LCModel under both types of B0 inhomogeneity. Conclusion:A new spectral analysis-trained deep learning model using the modeled spectra was developed. The results suggest that the proposed method has the potential to improve the accuracy of spectral analysis by increasing the training samples of spectra.",
      "authors": [
        "Shuki Maruyama and Hidenori Takeshima"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20897",
        "HTML": "https://arxiv.org/html/2506.20897",
        "PDF": "https://arxiv.org/pdf/2506.20897"
      },
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 00:03:25 GMT",
          "size": "1468kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Development of MR spectral analysis method robust against static magnetic field inhomogeneity",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on enhancing spectral analysis in MRI via deep learning, specifically in the context of magnetic field inhomogeneity, with no mention of LLM data processing or training data preparation."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.20909",
      "abstract": "This paper explores multiple closely related themes: bounding the complexity of Diophantine equations over the integers and developing mathematical proofs in parallel with formal theorem provers.\n  Hilbert's Tenth Problem (H10) asks about the decidability of Diophantine equations and has been answered negatively by Davis, Putnam, Robinson and Matiyasevich. It is natural to ask for which subclasses of Diophantine equations H10 remains undecidable. Such subclasses can be defined in terms of universal pairs: bounds on the number of variables $\\nu$ and degree $\\delta$ such that all Diophantine equations can be rewritten in at most this complexity. Our work develops explicit universal pairs $(\\nu, \\delta)$ for integer unknowns, achieving new bounds that cannot be obtained by naive translations from known results over $\\mathbb N$.\n  In parallel, we have conducted a formal verification of our results using the proof assistant Isabelle. While formal proof verification has traditionally been applied a posteriori to known results, this project integrates formalization into the discovery and development process. In a final section, we describe key insights gained from this unusual approach and its implications for mathematical practice. Our work contributes both to the study of Diophantine equations and to the broader question of how mathematics is conducted in the 21st century.",
      "authors": [
        "Jonas Bayer",
        "Marco David",
        "Malte Hassler",
        "Yuri Matiyasevich",
        "Dierk Schleicher"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20909",
        "HTML": "https://arxiv.org/html/2506.20909",
        "PDF": "https://arxiv.org/pdf/2506.20909"
      },
      "subjects": [
        "Number Theory (math.NT)",
        "Logic in Computer Science (cs.LO)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 00:30:24 GMT",
          "size": "58kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Diophantine Equations over $\\mathbb Z$: Universal Bounds and Parallel Formalization",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This work pertains to Diophantine equations and formal verification in mathematics, without addressing LLM training data engineering or processing."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.20910",
      "abstract": "We study value-iteration (VI) algorithms for solving general (a.k.a. multichain) Markov decision processes (MDPs) under the average-reward criterion, a fundamental but theoretically challenging setting. Beyond the difficulties inherent to all average-reward problems posed by the lack of contractivity and non-uniqueness of solutions to the Bellman operator, in the multichain setting an optimal policy must solve the navigation subproblem of steering towards the best connected component, in addition to optimizing long-run performance within each component. We develop algorithms which better solve this navigational subproblem in order to achieve faster convergence for multichain MDPs, obtaining improved rates of convergence and sharper measures of complexity relative to prior work. Many key components of our results are of potential independent interest, including novel connections between average-reward and discounted problems, optimal fixed-point methods for discounted VI which extend to general Banach spaces, new sublinear convergence rates for the discounted value error, and refined suboptimality decompositions for multichain MDPs. Overall our results yield faster convergence rates for discounted and average-reward problems and expand the theoretical foundations of VI approaches.",
      "authors": [
        "Matthew Zurek",
        "Yudong Chen"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20910",
        "HTML": "https://arxiv.org/html/2506.20910",
        "PDF": "https://arxiv.org/pdf/2506.20910"
      },
      "subjects": [
        "Optimization and Control (math.OC)",
        "Machine Learning (cs.LG)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 00:31:21 GMT",
          "size": "42kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Faster Fixed-Point Methods for Multichain MDPs",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper investigates numerical methods for Markov decision processes, without any connection to LLM training data or its processing methods."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.20928",
      "abstract": "This paper introduces an active learning framework for manifold Gaussian Process (GP) regression, combining manifold learning with strategic data selection to improve accuracy in high-dimensional spaces. Our method jointly optimizes a neural network for dimensionality reduction and a Gaussian process regressor in the latent space, supervised by an active learning criterion that minimizes global prediction error. Experiments on synthetic data demonstrate superior performance over randomly sequential learning. The framework efficiently handles complex, discontinuous functions while preserving computational tractability, offering practical value for scientific and engineering applications. Future work will focus on scalability and uncertainty-aware manifold learning.",
      "authors": [
        "Yuanxing Cheng",
        "Lulu Kang",
        "Yiwei Wang",
        "Chun Liu"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20928",
        "HTML": "https://arxiv.org/html/2506.20928",
        "PDF": "https://arxiv.org/pdf/2506.20928"
      },
      "subjects": [
        "Machine Learning (stat.ML)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 01:25:39 GMT",
          "size": "785kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Active Learning for Manifold Gaussian Process Regression",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on active learning for manifold Gaussian Process regression and does not address LLM training data processing. It discusses framework and algorithms for improving prediction accuracy in high-dimensional spaces."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.20932",
      "abstract": "The discrepancy between two independent samples \\(X_1,\\dots,X_n\\) and \\(Y_1,\\dots,Y_n\\) drawn from the same distribution on $\\mathbb{R}^d$ typically has order \\(O(\\sqrt{n})\\) even in one dimension. We give a simple online algorithm that reduces the discrepancy to \\(O(\\log^{2d} n)\\) by discarding a small fraction of the points.",
      "authors": [
        "Gleb Smirnov",
        "Roman Vershynin"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20932",
        "HTML": "https://arxiv.org/html/2506.20932",
        "PDF": "https://arxiv.org/pdf/2506.20932"
      },
      "subjects": [
        "Probability (math.PR)",
        "Data Structures and Algorithms (cs.DS)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 01:39:14 GMT",
          "size": "15kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Thinning to improve two-sample discrepancy",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The research develops an algorithm for reducing discrepancy between two independent samples, without any focus on LLM data collection, preparation, or processing methodologies."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.20933",
      "abstract": "Causal discovery algorithms typically recover causal graphs only up to their Markov equivalence classes unless additional parametric assumptions are made. The sizes of these equivalence classes reflect the limits of what can be learned about the underlying causal graph from purely observational data. Under the assumptions of acyclicity, causal sufficiency, and a uniform model prior, Markov equivalence classes are known to be small on average. In this paper, we show that this is no longer the case when any of these assumptions is relaxed. Specifically, we prove exponentially large lower bounds for the expected size of Markov equivalence classes in three settings: sparse random directed acyclic graphs, uniformly random acyclic directed mixed graphs, and uniformly random directed cyclic graphs.",
      "authors": [
        "Erik Jahn",
        "Frederick Eberhardt",
        "Leonard J. Schulman"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20933",
        "HTML": "https://arxiv.org/html/2506.20933",
        "PDF": "https://arxiv.org/pdf/2506.20933"
      },
      "subjects": [
        "Machine Learning (stat.ML)",
        "Machine Learning (cs.LG)",
        "Statistics Theory (math.ST)",
        "Statistics Theory (stat.TH)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 01:44:23 GMT",
          "size": "29kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Lower Bounds on the Size of Markov Equivalence Classes",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper deals with causal discovery and Markov equivalence classes, which does not relate to LLM training data engineering or training-stage data processing."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.20935",
      "abstract": "Forecasting geopolitical conflict from data sources like the Global Database of Events, Language, and Tone (GDELT) is a critical challenge for national security. The inherent sparsity, burstiness, and overdispersion of such data cause standard deep learning models, including the Temporal Fusion Transformer (TFT), to produce unreliable long-horizon predictions. We introduce STFT-VNNGP, a hybrid architecture that won the 2023 Algorithms for Threat Detection (ATD) competition by overcoming these limitations. Designed to bridge this gap, our model employs a two-stage process: first, a TFT captures complex temporal dynamics to generate multi-quantile forecasts. These quantiles then serve as informed inputs for a Variational Nearest Neighbor Gaussian Process (VNNGP), which performs principled spatiotemporal smoothing and uncertainty quantification. In a case study forecasting conflict dynamics in the Middle East and the U.S., STFT-VNNGP consistently outperforms a standalone TFT, showing a superior ability to predict the timing and magnitude of bursty event periods, particularly at long-range horizons. This work offers a robust framework for generating more reliable and actionable intelligence from challenging event data, with all code and workflows made publicly available to ensure reproducibility.",
      "authors": [
        "Hsin-Hsiung Huang and Hayden Hampton"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20935",
        "HTML": "https://arxiv.org/html/2506.20935",
        "PDF": "https://arxiv.org/pdf/2506.20935"
      },
      "subjects": [
        "Machine Learning (stat.ML)",
        "Machine Learning (cs.LG)",
        "Applications (stat.AP)",
        "Computation (stat.CO)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 01:53:25 GMT",
          "size": "4390kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Forecasting Geopolitical Events with a Sparse Temporal Fusion Transformer and Gaussian Process Hybrid: A Case Study in Middle Eastern and U.S. Conflict Dynamics",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on forecasting geopolitical events using a hybrid model architecture for temporal data processing but does not discuss LLM training data processing or data engineering for LLMs."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.20965",
      "abstract": "This paper integrates Austrian capital theory with repeated game theory to examine strategic miner behaviour under different institutional conditions in blockchain systems. It shows that when protocol rules are mutable, effective time preference rises, undermining rational long-term planning and cooperative equilibria. Using formal game-theoretic analysis and Austrian economic principles, the paper demonstrates how mutable protocols shift miner incentives from productive investment to political rent-seeking and influence games. The original Bitcoin protocol is interpreted as an institutional anchor: a fixed rule-set enabling calculability and low time preference. Drawing on the work of Bohm-Bawerk, Mises, and Hayek, the argument is made that protocol immutability is essential for restoring strategic coherence, entrepreneurial confidence, and sustainable network equilibrium.",
      "authors": [
        "Craig Steven Wright"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20965",
        "HTML": "https://arxiv.org/html/2506.20965",
        "PDF": "https://arxiv.org/pdf/2506.20965"
      },
      "subjects": [
        "General Economics (econ.GN)",
        "Cryptography and Security (cs.CR)",
        "Computer Science and Game Theory (cs.GT)",
        "Networking and Internet Architecture (cs.NI)",
        "Economics (q-fin.EC)",
        "General Finance (q-fin.GN)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 03:04:21 GMT",
          "size": "28kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Rational Miner Behaviour, Protocol Stability, and Time Preference: An Austrian and Game-Theoretic Analysis of Bitcoin's Incentive Environment",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper applies economic and game-theoretic analysis to blockchain protocols and miner behavior and does not address any aspects related to LLM training data processing or engineering."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.20992",
      "abstract": "This paper develops a formal game-theoretic model to examine how protocol mutability disrupts cooperative mining behaviour in blockchain systems. Using a repeated game framework with stochastic rule shocks, we show that even minor uncertainty in institutional rules increases time preference and induces strategic deviation. Fixed-rule environments support long-term investment and stable equilibrium strategies; in contrast, mutable protocols lead to short-termism, higher discounting, and collapse of coordinated engagement. Simulation results identify instability zones in the parameter space where rational mining gives way to extractive or arbitrage conduct. These findings support an Austrian economic interpretation: calculability requires rule stability. Institutional noise undermines the informational basis for productive action. We conclude that protocol design must be treated as a constitutional economic constraint, not a discretionary variable, if sustainable cooperation is to emerge in decentralised systems.",
      "authors": [
        "Craig Steven Wright"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20992",
        "HTML": "https://arxiv.org/html/2506.20992",
        "PDF": "https://arxiv.org/pdf/2506.20992"
      },
      "subjects": [
        "General Economics (econ.GN)",
        "Computational Engineering, Finance, and Science (cs.CE)",
        "Computers and Society (cs.CY)",
        "Computer Science and Game Theory (cs.GT)",
        "Social and Information Networks (cs.SI)",
        "Economics (q-fin.EC)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 04:12:06 GMT",
          "size": "31kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Institutional Noise, Strategic Deviation, and Intertemporal Collapse: A Formal Model of Miner Behaviour under Protocol Uncertainty",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on a game-theoretic model of miner behavior in blockchain systems, not related to LLM training data processing or data engineering."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21074",
      "abstract": "Neural speech codecs have been widely used in audio compression and various downstream tasks. Current mainstream codecs are fixed-frame-rate (FFR), which allocate the same number of tokens to every equal-duration slice. However, speech is inherently non-uniform in temporal information density. As a result, many tokens are wasted on steady-state segments like long vowels and silences. To address this mismatch, we present CodecSlime, a plugin-style method for compressing temporal redundancy through supporting dynamic frame rate (DFR) on neural speech codecs for the first time. Our method is unsupervised and architecture-agnostic, combining two key innovations, ScheDFR and Melt-and-Cool, for adapting inference and training, respectively. When integrated into a typical VQ-GAN codec backbone and operating at 40 Hz DFR ($\\approx$ 600 bps), the reconstruction WER of CodecSlime is reduced by up to 46% relative to conventional FFR baselines with the same model architecture and similar bitrates, while other metrics are also competitive. CodecSlime also enables flexible trade-offs between reconstruction quality and bitrate: a single model supports inference at multiple frame rates and consistently outperforms FFR models at the corresponding frame rates. Audio samples are available at https://acadarmeria.github.io/codecslime/.",
      "authors": [
        "Hankun Wang",
        "Yiwei Guo",
        "Chongtian Shao",
        "Bohan Li",
        "Xie Chen",
        "Kai Yu"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21074",
        "HTML": "https://arxiv.org/html/2506.21074",
        "PDF": "https://arxiv.org/pdf/2506.21074"
      },
      "subjects": [
        "Audio and Speech Processing (eess.AS)",
        "Sound (cs.SD)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 07:59:04 GMT",
          "size": "2955kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "CodecSlime: Temporal Redundancy Compression of Neural Speech Codec via Dynamic Frame Rate",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "CodecSlime addresses compression techniques for neural speech codecs and does not involve any aspect of LLM training data collection or processing."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21079",
      "abstract": "This paper introduces a new approach for approximating the learning dynamics of multiple reinforcement learning (RL) agents interacting in a finite-state Markov game. The idea is to rescale the learning process by simultaneously reducing the learning rate and increasing the update frequency, effectively treating the agent's parameters as a slow-evolving variable influenced by the fast-mixing game state. Under mild assumptions-ergodicity of the state process and continuity of the updates-we prove the convergence of this rescaled process to an ordinary differential equation (ODE). This ODE provides a tractable, deterministic approximation of the agent's learning dynamics. An implementation of the framework is available at\\,: https://github.com/yannKerzreho/MarkovGameApproximation",
      "authors": [
        "Yann Kerzreho (ENS Paris Saclay)"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21079",
        "HTML": "https://arxiv.org/html/2506.21079",
        "PDF": "https://arxiv.org/pdf/2506.21079"
      },
      "subjects": [
        "Machine Learning (stat.ML)",
        "Machine Learning (cs.LG)",
        "Probability (math.PR)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 08:08:49 GMT",
          "size": "24kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Homogenization of Multi-agent Learning Dynamics in Finite-state Markov Games",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper is about multi-agent learning dynamics in reinforcement learning contexts, without focus on LLM data processing or engineering."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21085",
      "abstract": "Molecular docking plays a crucial role in predicting the binding mode of ligands to target proteins, and covalent interactions, which involve the formation of a covalent bond between the ligand and the target, are particularly valuable due to their strong, enduring binding nature. However, most existing docking methods and deep learning approaches hardly account for the formation of covalent bonds and the associated structural changes. To address this gap, we introduce a comprehensive benchmark for covalent docking, CovDocker, which is designed to better capture the complexities of covalent binding. We decompose the covalent docking process into three main tasks: reactive location prediction, covalent reaction prediction, and covalent docking. By adapting state-of-the-art models, such as Uni-Mol and Chemformer, we establish baseline performances and demonstrate the effectiveness of the benchmark in accurately predicting interaction sites and modeling the molecular transformations involved in covalent binding. These results confirm the role of the benchmark as a rigorous framework for advancing research in covalent drug design. It underscores the potential of data-driven approaches to accelerate the discovery of selective covalent inhibitors and addresses critical challenges in therapeutic development.",
      "authors": [
        "Yangzhe Peng",
        "Kaiyuan Gao",
        "Liang He",
        "Yuheng Cong",
        "Haiguang Liu",
        "Kun He",
        "Lijun Wu"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21085",
        "HTML": "https://arxiv.org/html/2506.21085",
        "PDF": "https://arxiv.org/pdf/2506.21085"
      },
      "subjects": [
        "Biomolecules (q-bio.BM)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 08:28:07 GMT",
          "size": "3219kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "CovDocker: Benchmarking Covalent Drug Design with Tasks, Datasets, and Solutions",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper is related to covalent drug design and benchmarking molecular docking, which does not involve LLM training data processing or data engineering."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21124",
      "abstract": "This work presents Quantum Adaptive Search (QAGS), a hybrid quantum-classical algorithm for the global optimization of multivariate functions. The method employs an adaptive mechanism that dynamically narrows the search space based on a quantum-estimated probability distribution of the objective function. A quantum state encodes information about solution quality through an appropriate complex amplitude mapping, enabling the identification of the most promising regions, and thus progressively tightening the search bounds; then a classical optimizer performs local refinement of the solution. The analysis demonstrates that QAGS ensures a contraction of the search space toward global optima, with controlled computational complexity. The numerical results on the benchmark functions show that, compared to the classical methods, QAGS achieves higher accuracy while offering advantages in both time and space complexity.",
      "authors": [
        "G. Intoccia",
        "U. Chirico",
        "V. Schiano Di Cola",
        "G. Pepe",
        "S. Cuomo"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21124",
        "HTML": "https://arxiv.org/html/2506.21124",
        "PDF": "https://arxiv.org/pdf/2506.21124"
      },
      "subjects": [
        "Quantum Physics (quant-ph)",
        "Numerical Analysis (cs.NA)",
        "Numerical Analysis (math.NA)",
        "Optimization and Control (math.OC)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 09:55:36 GMT",
          "size": "554kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Quantum Adaptive Search: A Hybrid Quantum-Classical Algorithm for Global Optimization of Multivariate Functions",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on a quantum-classical algorithm for optimizing multivariate functions, with no mention of LLM training data processing or data engineering."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21154",
      "abstract": "The real world naturally has dimensions of time and space. Therefore, estimating the counterfactual outcomes with spatial-temporal attributes is a crucial problem. However, previous methods are based on classical statistical models, which still have limitations in performance and generalization. This paper proposes a novel framework for estimating counterfactual outcomes with spatial-temporal attributes using the Transformer, exhibiting stronger estimation ability. Under mild assumptions, the proposed estimator within this framework is consistent and asymptotically normal. To validate the effectiveness of our approach, we conduct simulation experiments and real data experiments. Simulation experiments show that our estimator has a stronger estimation capability than baseline methods. Real data experiments provide a valuable conclusion to the causal effect of conflicts on forest loss in Colombia. The source code is available at https://github.com/lihe-maxsize/DeppSTCI_Release_Version-master.",
      "authors": [
        "He Li",
        "Haoang Chi",
        "Mingyu Liu",
        "Wanrong Huang",
        "Liyang Xu",
        "Wenjing Yang"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21154",
        "HTML": "https://arxiv.org/html/2506.21154",
        "PDF": "https://arxiv.org/pdf/2506.21154"
      },
      "subjects": [
        "Methodology (stat.ME)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 11:24:46 GMT",
          "size": "2082kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Transformer-Based Spatial-Temporal Counterfactual Outcomes Estimation",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The focus is on estimating counterfactual outcomes with spatial-temporal attributes using Transformers, which does not relate to LLM training data processing or engineering."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21162",
      "abstract": "3D ultrasound (US) imaging has shown significant benefits in enhancing the outcomes of percutaneous liver tumour ablation. Its clinical integration is crucial for transitioning 3D US into the therapeutic domain. However, challenges of tumour identification in US images continue to hinder its broader adoption. In this work, we propose a novel framework for integrating 3D US into the standard ablation workflow. We present a key component, a clinically viable 2D US-CT/MRI registration approach, leveraging 3D US as an intermediary to reduce registration complexity. To facilitate efficient verification of the registration workflow, we also propose an intuitive multimodal image visualization technique. In our study, 2D US-CT/MRI registration achieved a landmark distance error of approximately 2-4 mm with a runtime of 0.22s per image pair. Additionally, non-rigid registration reduced the mean alignment error by approximately 40% compared to rigid registration. Results demonstrated the efficacy of the proposed 2D US-CT/MRI registration workflow. Our integration framework advanced the capabilities of 3D US imaging in improving percutaneous tumour ablation, demonstrating the potential to expand the therapeutic role of 3D US in clinical interventions.",
      "authors": [
        "Shuwei Xing",
        "Derek W. Cool",
        "David Tessier",
        "Elvis C.S. Chen",
        "Terry M. Peters",
        "Aaron Fenster"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21162",
        "HTML": "https://arxiv.org/html/2506.21162",
        "PDF": "https://arxiv.org/pdf/2506.21162"
      },
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 11:39:08 GMT",
          "size": "8423kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "A Novel Framework for Integrating 3D Ultrasound into Percutaneous Liver Tumour Ablation",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper proposes methods for integrating 3D ultrasound imaging into medical procedures, specifically liver tumor ablation, and does not address LLM training data processes."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21171",
      "abstract": "Joint Photographic Experts Group (JPEG) achieves data compression by quantizing Discrete Cosine Transform (DCT) coefficients, which inevitably introduces compression artifacts. Most existing JPEG quality enhancement methods operate in the pixel domain, suffering from the high computational costs of decoding. Consequently, direct enhancement of JPEG images in the DCT domain has gained increasing attention. However, current DCT-domain methods often exhibit limited performance. To address this challenge, we identify two critical types of correlations within the DCT coefficients of JPEG images. Building on this insight, we propose an Advanced DCT-domain JPEG Quality Enhancement (AJQE) method that fully exploits these correlations. The AJQE method enables the adaptation of numerous well-established pixel-domain models to the DCT domain, achieving superior performance with reduced computational complexity. Compared to the pixel-domain counterparts, the DCT-domain models derived by our method demonstrate a 0.35 dB improvement in PSNR and a 60.5% increase in enhancement throughput on average.",
      "authors": [
        "Jing Yang",
        "Qunliang Xing",
        "Mai Xu",
        "Minglang Qiao"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21171",
        "HTML": "https://arxiv.org/html/2506.21171",
        "PDF": "https://arxiv.org/pdf/2506.21171"
      },
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 12:08:18 GMT",
          "size": "2632kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Uncover Treasures in DCT: Advancing JPEG Quality Enhancement by Exploiting Latent Correlations",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper is centered on JPEG quality enhancement in the DCT domain, identifying latent correlations for improved image enhancement. There is no connection to LLM training data or associated data processing techniques."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21174",
      "abstract": "This technical report presents submission systems for Task 4 of the DCASE 2025 Challenge. This model incorporates additional audio features (spectral roll-off and chroma features) into the embedding feature extracted from the mel-spectral feature to im-prove the classification capabilities of an audio-tagging model in the spatial semantic segmentation of sound scenes (S5) system. This approach is motivated by the fact that mixed audio often contains subtle cues that are difficult to capture with mel-spectrograms alone. Thus, these additional features offer alterna-tive perspectives for the model. Second, an agent-based label correction system is applied to the outputs processed by the S5 system. This system reduces false positives, improving the final class-aware signal-to-distortion ratio improvement (CA-SDRi) metric. Finally, we refine the training dataset to enhance the classi-fication accuracy of low-performing classes by removing irrele-vant samples and incorporating external data. That is, audio mix-tures are generated from a limited number of data points; thus, even a small number of out-of-class data points could degrade model performance. The experiments demonstrate that the submit-ted systems employing these approaches relatively improve CA-SDRi by up to 14.7% compared to the baseline of DCASE 2025 Challenge Task 4.",
      "authors": [
        "Jongyeon Park",
        "Joonhee Lee",
        "Do-Hyeon Lim",
        "Hong Kook Kim",
        "Hyeongcheol Geum",
        "Jeong Eun Lim"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21174",
        "HTML": "https://arxiv.org/html/2506.21174",
        "PDF": "https://arxiv.org/pdf/2506.21174"
      },
      "subjects": [
        "Audio and Speech Processing (eess.AS)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 12:27:52 GMT",
          "size": "394kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Performance improvement of spatial semantic segmentation with enriched audio features and agent-based error correction for DCASE 2025 Challenge Task 4",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The report details methods to improve semantic segmentation in audio data for a specific challenge, emphasizing feature selection and error correction in audio processing, not related to LLM data engineering or processing."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21207",
      "abstract": "Enabled by progress in superconducting technology, several continuous wave linear accelerators are foreseen in the next decade. For these machines, it is of crucial importance to track the main cavity parameters, such as the resonator bandwidth and detuning. The bandwidth yields information on the superconducting state of the cavity. The detuning should be minimized to limit the required power to operate the cavity. The estimation of these parameters is commonly implemented in the digital electronics of the Low-Level RF control system to minimize the computation delay. In this proceeding, we present a way to compute the bandwidth and detuning using a Luenberger observer. In contrast to previous methods, a state observer yields estimations at the native control system sample rate without explicitly filtering the input signals. Additionally, the error convergence properties of the estimations can be controlled intuitively by adjusting gain parameters. Implementation considerations and test results on the derived observer are presented in the manuscript.",
      "authors": [
        "Bozo Richter",
        "Andrea Bellandi",
        "Julien Branlard",
        "Leon Speidel",
        "Annika Eichler"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21207",
        "HTML": "https://arxiv.org/html/2506.21207",
        "PDF": "https://arxiv.org/pdf/2506.21207"
      },
      "subjects": [
        "Accelerator Physics (physics.acc-ph)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 13:02:38 GMT",
          "size": "223kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Estimation of superconducting cavity bandwidth and detuning using a Luenberger observer",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on superconducting cavity bandwidth and detuning estimation using a Luenberger observer, which is unrelated to LLM training data processing."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21239",
      "abstract": "District heating networks (DHNs) are crucial for decarbonizing the heating sector. Yet, their efficient and reliable operation requires the coordination of multiple heat producers and the consideration of future demands. Predictive and optimization-based control is commonly used to address this task, but existing results for DHNs do not account for time-varying problem aspects. Since the turnpike phenomenon can serve as a basis for model predictive control design and analysis, this paper examines its role in DHN optimization by analyzing the underlying optimal control problem with time-varying prices and demands. That is, we derive conditions for the existence of a unique time-varying singular arc, which constitutes the time varying turnpike, and we provide its closed-form expression. Additionally, we present converse turnpike results showing a exact time-varying case implies strict dissipativity of the optimal control problem. A numerical example illustrates our findings.",
      "authors": [
        "Max Rose",
        "Hannes Gernandt",
        "Timm Faulwasser",
        "Johannes Schiffer"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21239",
        "HTML": "https://arxiv.org/html/2506.21239",
        "PDF": "https://arxiv.org/pdf/2506.21239"
      },
      "subjects": [
        "Optimization and Control (math.OC)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 13:23:21 GMT",
          "size": "368kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Exact Time-Varying Turnpikes for Dynamic Operation of District Heating Networks",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper addresses optimization in district heating networks and does not contain any content related to the processing of LLM training data."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21246",
      "abstract": "This study investigates the impact of data source diversity on the performance of cryptocurrency forecasting models by integrating various data categories, including technical indicators, on-chain metrics, sentiment and interest metrics, traditional market indices, and macroeconomic indicators. We introduce the Crypto100 index, representing the top 100 cryptocurrencies by market capitalization, and propose a novel feature reduction algorithm to identify the most impactful and resilient features from diverse data sources. Our comprehensive experiments demonstrate that data source diversity significantly enhances the predictive performance of forecasting models across different time horizons. Key findings include the paramount importance of on-chain metrics for both short-term and long-term predictions, the growing relevance of traditional market indices and macroeconomic indicators for longer-term forecasts, and substantial improvements in model accuracy when diverse data sources are utilized. These insights help demystify the short-term and long-term driving factors of the cryptocurrency market and lay the groundwork for developing more accurate and resilient forecasting models.",
      "authors": [
        "Giorgos Demosthenous",
        "Chryssis Georgiou",
        "Eliada Polydorou"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21246",
        "HTML": "https://arxiv.org/html/2506.21246",
        "PDF": "https://arxiv.org/pdf/2506.21246"
      },
      "subjects": [
        "Portfolio Management (q-fin.PM)",
        "Artificial Intelligence (cs.AI)",
        "Emerging Technologies (cs.ET)",
        "Machine Learning (cs.LG)",
        "Statistical Finance (q-fin.ST)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 13:29:19 GMT",
          "size": "2117kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "From On-chain to Macro: Assessing the Importance of Data Source Diversity in Cryptocurrency Market Forecasting",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This study is focused on forecasting models for cryptocurrency markets using diverse data sources and does not relate to training data processing for LLMs."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21275",
      "abstract": "Inspired by the Equation-Free multiscale modeling approach, we demonstrate how the embed-learn-lift framework enables the construction of surrogate normal-forms, namely minimal-dimensional reduced-order models (ROMs), from high-fidelity Navier-Stokes simulations. These surrogate models are then used for efficient and accurate bifurcation and stability analysis. The framework proceeds in four steps. First, manifold learning reveals the intrinsic latent dimension of the high-dimensional spatio-temporal Navier-Stokes dynamics across parameter space. Second, we construct low-dimensional \"normal-form\" like ROMs on this latent space using Gaussian Process Regression (GPR), capturing the emergent dynamics. Third, using these models, we apply numerical bifurcation tools to compute bifurcation diagrams and perform stability analysis in the latent space. This includes tracing branches of limit cycles arising from Andronov-Hopf bifurcations - tasks intractable in full space due to computational cost. Finally, solving the pre-image problem allows reconstruction of the bifurcation structure in the original high-dimensional space. We demonstrate the methodology on two canonical flows: wake flow past an infinite circular cylinder and planar sudden-expansion channel flow. These exhibit Andronov-Hopf and pitchfork bifurcations, respectively, as Reynolds number increases. Our method identifies the latent dimensionality and constructs GPR-based surrogate normal-forms that enable the tracing and stability analysis of bifurcating solutions, including limit cycles, their period, and stability via Floquet multipliers.",
      "authors": [
        "Alessandro Della Pia",
        "Dimitrios G. Patsatzis",
        "Gianluigi Rozza",
        "Lucia Russo",
        "Constantinos Siettos"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21275",
        "HTML": "https://arxiv.org/html/2506.21275",
        "PDF": "https://arxiv.org/pdf/2506.21275"
      },
      "subjects": [
        "Fluid Dynamics (physics.flu-dyn)",
        "Numerical Analysis (cs.NA)",
        "Numerical Analysis (math.NA)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 14:00:19 GMT",
          "size": "3251kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Surrogate normal-forms for the numerical bifurcation and stability analysis of navier-stokes flows via machine learning",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on surrogate normal-forms for the numerical bifurcation and stability analysis of Navier-Stokes flows using machine learning techniques, without addressing LLM training data processing."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21278",
      "abstract": "We propose a novel variational autoencoder (VAE) architecture that employs a spherical Cauchy (spCauchy) latent distribution. Unlike traditional Gaussian latent spaces or the widely used von Mises-Fisher (vMF) distribution, spCauchy provides a more natural hyperspherical representation of latent variables, better capturing directional data while maintaining flexibility. Its heavy-tailed nature prevents over-regularization, ensuring efficient latent space utilization while offering a more expressive representation. Additionally, spCauchy circumvents the numerical instabilities inherent to vMF, which arise from computing normalization constants involving Bessel functions. Instead, it enables a fully differentiable and efficient reparameterization trick via M\\\"obius transformations, allowing for stable and scalable training. The KL divergence can be computed through a rapidly converging power series, eliminating concerns of underflow or overflow associated with evaluation of ratios of hypergeometric functions. These properties make spCauchy a compelling alternative for VAEs, offering both theoretical advantages and practical efficiency in high-dimensional generative modeling.",
      "authors": [
        "Lukas Sablica",
        "Kurt Hornik"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21278",
        "HTML": "https://arxiv.org/html/2506.21278",
        "PDF": "https://arxiv.org/pdf/2506.21278"
      },
      "subjects": [
        "Machine Learning (stat.ML)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)",
        "Statistics Theory (math.ST)",
        "Statistics Theory (stat.TH)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 14:01:51 GMT",
          "size": "785kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Hyperspherical Variational Autoencoders Using Efficient Spherical Cauchy Distribution",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper introduces a novel VAE architecture with a spherical latent distribution for generative modeling, which does not involve LLM training data processing or engineering."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21309",
      "abstract": "Let $V$ be a vector space over the finite field $\\mathbb{F}_q$ with $q$ elements and $\\Lambda$ be the image of the Segre geometry $\\mathrm{PG}(V)\\otimes\\mathrm{PG}(V^*)$ in $\\mathrm{PG}(V\\otimes V^*)$. Consider the subvariety $\\Lambda_{1}$ of $\\Lambda$ represented by the pure tensors $x\\otimes \\xi$ with $x\\in V$ and $\\xi\\in V^*$ such that $\\xi(x)=0$. Regarding $\\Lambda_1$ as a projective system of $\\mathrm{PG}(V\\otimes V^*)$, we study the linear code $\\mathcal{C}(\\Lambda_1)$ arising from it. The code $\\mathcal{C}(\\Lambda_1)$ is minimal code and we determine its basic parameters, itsfull weight list and its linear automorphism group. We also give a geometrical characterization of its minimum and second lowest weight codewords as well as of some of the words of maximum weight.",
      "authors": [
        "Ilaria Cardinali and Luca Giuzzi"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21309",
        "HTML": "https://arxiv.org/html/2506.21309",
        "PDF": "https://arxiv.org/pdf/2506.21309"
      },
      "subjects": [
        "Combinatorics (math.CO)",
        "Discrete Mathematics (cs.DM)",
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 14:26:07 GMT",
          "size": "36kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Linear codes arising from the point-hyperplane geometry-Part I: the Segre embedding",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper investigates linear codes arising in finite geometry and does not relate to any LLM training data processing or methodologies."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21337",
      "abstract": "We initiate the study of Hamiltonian cycles up to symmetries of the underlying graph. Our focus lies on the extremal case of Hamiltonian-transitive graphs, i.e., Hamiltonian graphs where, for every pair of Hamiltonian cycles, there is a graph automorphism mapping one cycle to the other. This generalizes the extensively studied uniquely Hamiltonian graphs. In this paper, we show that Cayley graphs of abelian groups are not Hamiltonian-transitive (under some mild conditions and some non-surprising exceptions), i.e., they contain at least two structurally different Hamiltonian cycles. To show this, we reduce Hamiltonian-transitivity to properties of the prime factors of a Cartesian product decomposition, which we believe is interesting in its own right. We complement our results by constructing infinite families of regular Hamiltonian-transitive graphs and take a look at the opposite extremal case by constructing a family with many different Hamiltonian cycles up to symmetry.",
      "authors": [
        "Julia Baligacs (1)",
        "Sofia Brenner (2)",
        "Annette Lutz (1)",
        "Lena Volk (1) ((1) TU Darmstadt",
        "(2) Universit\\\"at Kassel)"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21337",
        "HTML": "https://arxiv.org/html/2506.21337",
        "PDF": "https://arxiv.org/pdf/2506.21337"
      },
      "subjects": [
        "Combinatorics (math.CO)",
        "Discrete Mathematics (cs.DM)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 14:48:24 GMT",
          "size": "240kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Symmetry classes of Hamiltonian cycles",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper investigates Hamiltonian cycles in graph theory and does not relate to LLM training data or its processing."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21345",
      "abstract": "We study the question of how much classical communication is needed when Alice is given a classical description of a quantum state $|\\psi\\rangle$ for Bob to recover any expectation value $\\langle \\psi | M |\\psi\\rangle$ given an observable $M$ with $M$ Hermitian and $||M||_{\\text{op}} \\leq 1$. This task, whose study was initiated by Raz (ACM 1999) and more recently investigated by Gosset and Smolin (TQC 2019), can be thought of as a fully classical version of the pure state case of the well-known classical shadows problem in quantum learning theory. We show how the hardness of these two seemingly distinct problems are connected.\n  We first consider the relative error version of the communication question and prove a lower bound of $\\Omega(\\sqrt{2^{n}}\\epsilon^{-2})$ on the one-way randomized classical communication, improving upon an additive error lower bound of $\\Omega(\\sqrt{2^{n}})$ as shown by Gosset and Smolin. Notably, we show that this lower bound holds not only for the set of all observables but also when restricted to just the class of Pauli observables. This fact implies a $\\Omega(\\sqrt{2^{n}})$ versus $O(\\text{poly}(n))$ separation in the compression size between the relative and additive error settings for non-adaptive Pauli classical shadows with classical memory.\n  Extending this framework, we prove randomized communication lower bounds for other relative error one-way classical communication tasks: an $\\Omega(2^{n}\\epsilon^{-2})$ lower bound when instead Alice is given an observable and Bob is given a quantum state and they are asked to estimate the expectation value, an $\\Omega(\\sqrt{n}\\epsilon^{-2})$ lower bound when restricted to Paulis, and an $\\Omega(\\sqrt{2^{n}}\\epsilon^{-2})$ lower bound when Alice and Bob are both given quantum states and asked to estimate the inner product.",
      "authors": [
        "Kaushik Sankar"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21345",
        "HTML": "https://arxiv.org/html/2506.21345",
        "PDF": "https://arxiv.org/pdf/2506.21345"
      },
      "subjects": [
        "Quantum Physics (quant-ph)",
        "Computational Complexity (cs.CC)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 14:58:23 GMT",
          "size": "17kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Lower Bounds on Relative Error Quantum Compression and Classical Shadows",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper is concerned with quantum communication and classical shadows, without discussing LLM training data processing or related data engineering tasks."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21386",
      "abstract": "Arabic dialect recognition presents a significant challenge in speech technology due to the linguistic diversity of Arabic and the scarcity of large annotated datasets, particularly for underrepresented dialects. This research investigates hybrid modeling strategies that integrate classical signal processing techniques with deep learning architectures to address this problem in low-resource scenarios. Two hybrid models were developed and evaluated: (1) Mel-Frequency Cepstral Coefficients (MFCC) combined with a Convolutional Neural Network (CNN), and (2) Discrete Wavelet Transform (DWT) features combined with a Recurrent Neural Network (RNN). The models were trained on a dialect-filtered subset of the Common Voice Arabic dataset, with dialect labels assigned based on speaker metadata. Experimental results demonstrate that the MFCC + CNN architecture achieved superior performance, with an accuracy of 91.2% and strong precision, recall, and F1-scores, significantly outperforming the Wavelet + RNN configuration, which achieved an accuracy of 66.5%. These findings highlight the effectiveness of leveraging spectral features with convolutional models for Arabic dialect recognition, especially when working with limited labeled data. The study also identifies limitations related to dataset size, potential regional overlaps in labeling, and model optimization, providing a roadmap for future research. Recommendations for further improvement include the adoption of larger annotated corpora, integration of self-supervised learning techniques, and exploration of advanced neural architectures such as Transformers. Overall, this research establishes a strong baseline for future developments in Arabic dialect recognition within resource-constrained environments.",
      "authors": [
        "Ghazal Al-Shwayyat",
        "Omer Nezih Gerek"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21386",
        "HTML": "https://arxiv.org/html/2506.21386",
        "PDF": "https://arxiv.org/pdf/2506.21386"
      },
      "subjects": [
        "Audio and Speech Processing (eess.AS)",
        "Computation and Language (cs.CL)",
        "Sound (cs.SD)",
        "Signal Processing (eess.SP)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 15:36:25 GMT",
          "size": "401kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Hybrid Deep Learning and Signal Processing for Arabic Dialect Recognition in Low-Resource Settings",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The research targets Arabic dialect recognition using hybrid models and does not involve any aspect of LLM training data collection, construction, or processing."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21412",
      "abstract": "This letter introduces a novel class of miniaturized, uncooled, and ultra-fast infrared (IR) resonant thermal detectors (RTDs) based on 30%-doped Aluminum Scandium Nitride (AlScN) nanoplates. Exploiting high electromechanical coupling, good thermal properties, and enhanced and selective IR absorption, the presented device aims to demonstrate significant advancements over the state-of-the-art IR RTDs. This single pixel combines compact footprint, high spectral selectivity and responsivity, reduced noise, and fast thermal response, allowing for the potential development of innovative IR thermal imagers through multi-pixel integration. The flexural nature of the actuated resonance mode eventually enables an interferometric optical readout, paving the way towards achieving extremely low Noise Equivalent Power levels. These results demonstrate a high IR responsivity of around 130 ppt/pW, a thermal time constant of around 330 us, and a large out-of-plane displacement. This work represents the first experimental integration on a resonating platform of plasmonic absorbers that utilize AlScN as dielectric layer.",
      "authors": [
        "Aurelio Venditti",
        "Walter Gubinelli",
        "Enise F. Altin",
        "Luca Colombo",
        "Pietro Simeoni",
        "Benyamin Davaji",
        "and Matteo Rinaldi"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21412",
        "HTML": "https://arxiv.org/html/2506.21412",
        "PDF": "https://arxiv.org/pdf/2506.21412"
      },
      "subjects": [
        "Instrumentation and Detectors (physics.ins-det)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)",
        "Applied Physics (physics.app-ph)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 16:00:10 GMT",
          "size": "2329kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Plasmonically Enhanced Flexural-Mode AlScN Nanoplate Resonator as Uncooled and Ultrafast IR Detector with High Responsivity",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper introduces a novel class of IR detectors using plasmonic absorbers and does not address any aspect of LLM training data processing."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21426",
      "abstract": "Recent crises like the COVID-19 pandemic and geopolitical tensions have exposed vulnerabilities and caused disruptions of supply chains, leading to product shortages, increased costs, and economic instability. This has prompted increasing efforts to assess systemic risk, namely the effects of firm disruptions on entire economies. However, the ability of firms to react to crises by rewiring their supply links has been largely overlooked, limiting our understanding of production networks resilience. Here we study dynamics and determinants of firm-level systemic risk in the Hungarian production network from 2015 to 2022. We use as benchmark a heuristic maximum entropy null model that generates an ensemble of production networks at equilibrium, by preserving the total input (demand) and output (supply) of each firm at the sector level. We show that the fairly stable set of firms with highest systemic risk undergoes a structural change during COVID-19, as those enabling economic exchanges become key players in the economy -- a result which is not reproduced by the null model. Although the empirical systemic risk aligns well with the null value until the onset of the pandemic, it becomes significantly smaller afterwards as the adaptive behavior of firms leads to a more resilient economy. Furthermore, firms' international trade volume (being a subject of disruption) becomes a significant predictor of their systemic risk. However, international links cannot provide an unequivocal explanation for the observed trends, as imports and exports have opposing effects on local systemic risk through the supply and demand channels.",
      "authors": [
        "Anna Mancini",
        "Bal\\'azs Lengyel",
        "Riccardo Di Clemente and Giulio Cimini"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21426",
        "HTML": "https://arxiv.org/html/2506.21426",
        "PDF": "https://arxiv.org/pdf/2506.21426"
      },
      "subjects": [
        "Physics and Society (physics.soc-ph)",
        "Social and Information Networks (cs.SI)",
        "General Economics (econ.GN)",
        "Data Analysis, Statistics and Probability (physics.data-an)",
        "Economics (q-fin.EC)",
        "Risk Management (q-fin.RM)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 16:08:22 GMT",
          "size": "42482kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Evolution and determinants of firm-level systemic risk in local production networks",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper examines the systemic risk in production networks, particularly in the context of supply chains and economic resilience. There is no mention of LLM training data processing or any contribution to data engineering for language models."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21460",
      "abstract": "We describe and analyze a computionally efficient refitting procedure for computing high-probability upper bounds on the instance-wise mean-squared prediction error of penalized nonparametric estimates based on least-squares minimization. Requiring only a single dataset and black box access to the prediction method, it consists of three steps: computing suitable residuals, symmetrizing and scaling them with a pre-factor $\\rho$, and using them to define and solve a modified prediction problem recentered at the current estimate. We refer to it as wild refitting, since it uses Rademacher residual symmetrization as in a wild bootstrap variant. Under relatively mild conditions allowing for noise heterogeneity, we establish a high probability guarantee on its performance, showing that the wild refit with a suitably chosen wild noise scale $\\rho$ gives an upper bound on prediction error. This theoretical analysis provides guidance into the design of such procedures, including how the residuals should be formed, the amount of noise rescaling in the wild sub-problem needed for upper bounds, and the local stability properties of the block-box procedure. We illustrate the applicability of this procedure to various problems, including non-rigid structure-from-motion recovery with structured matrix penalties; plug-and-play image restoration with deep neural network priors; and randomized sketching with kernel methods.",
      "authors": [
        "Martin J. Wainwright"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21460",
        "HTML": "https://arxiv.org/html/2506.21460",
        "PDF": "https://arxiv.org/pdf/2506.21460"
      },
      "subjects": [
        "Machine Learning (stat.ML)",
        "Machine Learning (cs.LG)",
        "Statistics Theory (math.ST)",
        "Statistics Theory (stat.TH)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 16:41:55 GMT",
          "size": "30554kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Wild refitting for black box prediction",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper discusses a refitting procedure for prediction error bounds in nonparametric estimates and applies it to various problems like image restoration and matrix penalties, but does not address LLM training data processing."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21499",
      "abstract": "Ultrasound Coherent Plane Wave Compounding (CPWC) enhances image contrast by combining echoes from multiple steered transmissions. While increasing the number of angles generally improves image quality, it drastically reduces the frame rate and can introduce blurring artifacts in fast-moving targets. Moreover, compounded images remain susceptible to noise, particularly when acquired with a limited number of transmissions. We propose a zero-shot denoising framework tailored for low-angle CPWC acquisitions, which enhances contrast without relying on a separate training dataset. The method divides the available transmission angles into two disjoint subsets, each used to form compound images that include higher noise levels. The new compounded images are then used to train a deep model via a self-supervised residual learning scheme, enabling it to suppress incoherent noise while preserving anatomical structures. Because angle-dependent artifacts vary between the subsets while the underlying tissue response is similar, this physics-informed pairing allows the network to learn to disentangle the inconsistent artifacts from the consistent tissue signal. Unlike supervised methods, our model requires no domain-specific fine-tuning or paired data, making it adaptable across anatomical regions and acquisition setups. The entire pipeline supports efficient training with low computational cost due to the use of a lightweight architecture, which comprises only two convolutional layers. Evaluations on simulation, phantom, and in vivo data demonstrate superior contrast enhancement and structure preservation compared to both classical and deep learning-based denoising methods.",
      "authors": [
        "Hojat Asgariandehkordi",
        "Mostafa Sharifzadeh and Hassan Rivaz"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21499",
        "HTML": "https://arxiv.org/html/2506.21499",
        "PDF": "https://arxiv.org/pdf/2506.21499"
      },
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 17:28:32 GMT",
          "size": "9567kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Lightweight Physics-Informed Zero-Shot Ultrasound Plane Wave Denoising",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper focuses on denoising ultrasound images using a self-supervised learning approach without the use of a separate training dataset, which is not related to LLM training data."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21511",
      "abstract": "We develop sampling methods, which consist of Gaussian invariant versions of random walk Metropolis (RWM), Metropolis adjusted Langevin algorithm (MALA) and second order Hessian or Manifold MALA. Unlike standard RWM and MALA we show that Gaussian invariant sampling can lead to ergodic estimators with improved statistical efficiency. This is due to a remarkable property of Gaussian invariance that allows us to obtain exact analytical solutions to the Poisson equation for Gaussian targets. These solutions can be used to construct efficient and easy to use control variates for variance reduction of estimators under any intractable target. We demonstrate the new samplers and estimators in several examples, including high dimensional targets in latent Gaussian models where we compare against several advanced methods and obtain state-of-the-art results. We also provide theoretical results regarding geometric ergodicity, and an optimal scaling analysis that shows the dependence of the optimal acceptance rate on the Gaussianity of the target.",
      "authors": [
        "Michalis K. Titsias",
        "Angelos Alexopoulos",
        "Siran Liu",
        "Petros Dellaportas"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21511",
        "HTML": "https://arxiv.org/html/2506.21511",
        "PDF": "https://arxiv.org/pdf/2506.21511"
      },
      "subjects": [
        "Machine Learning (stat.ML)",
        "Machine Learning (cs.LG)",
        "Methodology (stat.ME)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 17:36:10 GMT",
          "size": "449kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Gaussian Invariant Markov Chain Monte Carlo",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on sampling methods for Markov Chain Monte Carlo, particularly in relation to Gaussian targets, and does not discuss any aspect of LLM training data or its processing."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21524",
      "abstract": "The Particle-In-Cell (PIC) method for plasma simulation tracks particle phase space information using particle and grid data structures. High computational costs in 2D and 3D device-scale PIC simulations necessitate parallelization, with the Charge Deposition (CD) subroutine often becoming a bottleneck due to frequent particle-grid interactions. Conventional methods mitigate dependencies by generating private grids for each core, but this approach faces scalability issues. We propose a novel approach based on a particle-thread binding strategy that requires only four private grids per node in distributed memory systems or four private grids in shared memory systems, enhancing CD scalability and performance while maintaining conventional data structures and requiring minimal changes to existing PIC codes. This method ensures complete accessibility of grid data structure for concurrent threads and avoids simultaneous access to particles within the same cell using additional functions and flags. Performance evaluations using a PIC benchmark for low-temperature partially magnetized E x B discharge simulation on a shared memory as well as a distributed memory system (1000 cores) demonstrate the method's scalability, and additionally, we show the method has little hardware dependency.",
      "authors": [
        "Libn Varghese",
        "Bhaskar Chaudhury",
        "Miral Shah",
        "Mainak Bandyopadhyay"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21524",
        "HTML": "https://arxiv.org/html/2506.21524",
        "PDF": "https://arxiv.org/pdf/2506.21524"
      },
      "subjects": [
        "Computational Physics (physics.comp-ph)",
        "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "Plasma Physics (physics.plasm-ph)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 17:44:13 GMT",
          "size": "1256kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Benchmarking and Parallelization of Electrostatic Particle-In-Cell for low-temperature Plasma Simulation by particle-thread Binding",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper discusses parallelization techniques for plasma simulation using the Particle-In-Cell method, which is unrelated to the processing of training data for LLMs."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21537",
      "abstract": "Research in quantum machine learning has recently proliferated due to the potential of quantum computing to accelerate machine learning. An area of machine learning that has not yet been explored is neural ordinary differential equation (neural ODE) based residual neural networks (ResNets), which aim to improve the effectiveness of neural networks using the principles of ordinary differential equations. In this work, we present our insights about why analog Rydberg atom quantum computers are especially well-suited for ResNets. We also introduce ResQ, a novel framework to optimize the dynamics of Rydberg atom quantum computers to solve classification problems in machine learning using analog quantum neural ODEs.",
      "authors": [
        "Nicholas S. DiBrita",
        "Jason Han",
        "Tirthak Patel"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21537",
        "HTML": "https://arxiv.org/html/2506.21537",
        "PDF": "https://arxiv.org/pdf/2506.21537"
      },
      "subjects": [
        "Quantum Physics (quant-ph)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Emerging Technologies (cs.ET)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 17:55:12 GMT",
          "size": "1533kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "ResQ: A Novel Framework to Implement Residual Neural Networks on Analog Rydberg Atom Quantum Computers",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on quantum computing applications and introduces a framework (ResQ) for analog Rydberg atom quantum computers in machine learning tasks. It is not related to LLM training data processing."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21543",
      "abstract": "We study a generalization of the classical hidden clique problem to graphs with real-valued edge weights. Formally, we define a hypothesis testing problem. Under the null hypothesis, edges of a complete graph on $n$ vertices are associated with independent and identically distributed edge weights from a distribution $P$. Under the alternate hypothesis, $k$ vertices are chosen at random and the edge weights between them are drawn from a distribution $Q$, while the remaining are sampled from $P$. The goal is to decide, upon observing the edge weights, which of the two hypotheses they were generated from. We investigate the problem under two different scenarios: (1) when $P$ and $Q$ are completely known, and (2) when there is only partial information of $P$ and $Q$. In the first scenario, we obtain statistical limits on $k$ when the two hypotheses are distinguishable, and when they are not. Additionally, in each of the scenarios, we provide bounds on the minimal risk of the hypothesis testing problem when $Q$ is not absolutely continuous with respect to $P$. We also provide computationally efficient spectral tests that can distinguish the two hypotheses as long as $k=\\Omega(\\sqrt{n})$ in both the scenarios.",
      "authors": [
        "Urmisha Chatterjee",
        "Karissa Huang",
        "Ritabrata Karmakar",
        "B. R. Vinay Kumar",
        "G\\'abor Lugosi",
        "Nandan Malhotra",
        "Anirban Mandal",
        "Maruf Alam Tarafdar"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21543",
        "HTML": "https://arxiv.org/html/2506.21543",
        "PDF": "https://arxiv.org/pdf/2506.21543"
      },
      "subjects": [
        "Statistics Theory (math.ST)",
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)",
        "Probability (math.PR)",
        "Statistics Theory (stat.TH)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 17:58:22 GMT",
          "size": "16kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Detecting weighted hidden cliques",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on a hypothesis testing problem involving weighted cliques in graphs, which is unrelated to LLM training data processing or data engineering."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "1808.06258",
      "abstract": "In \\cite{Craig}, we introduced a syntactically defined and highly general class of calculi known as \\emph{semi-analytic}. We then demonstrated that any sufficiently strong (modal) substructural logic with a semi-analytic calculus must satisfy the Craig interpolation property. In this paper, we show that if the calculus is also terminating in a certain formal sense, then its logic has the Uniform Interpolation Property (UIP). This result has significant applications. On the positive side, it provides a uniform and modular method for proving UIP for various logics, including $\\mathsf{FL_e}$, $\\mathsf{FL_{ew}}$, $\\mathsf{CFL_e}$, $\\mathsf{CFL_{ew}}$, and their $K$, $D$, and $T$-type modal extensions, as well as $\\mathsf{CPC}$, $\\mathsf{K}$, and $\\mathsf{KD}$. However, its more striking consequence lies in the negative direction. It extends the negative results of \\cite{Craig} to logics with CIP but without UIP. In particular, it shows that the modal logics $\\mathsf{K4}$ and $\\mathsf{S4}$ do not have a terminating semi-analytic calculus.\n  \\textbf{keywords:} Uniform interpolation, Sequent calculi, Substructural logics, Modal logics, Subexponential modalities",
      "authors": [
        "Amirhossein Akbar Tabatabai",
        "Raheleh Jalali"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/1808.06258",
        "HTML": "https://arxiv.org/html/1808.06258",
        "PDF": "https://arxiv.org/pdf/1808.06258"
      },
      "subjects": [
        "Logic in Computer Science (cs.LO)",
        "Logic (math.LO)"
      ],
      "submission_historys": [
        {
          "date": "Sun, 19 Aug 2018 20:56:34 GMT",
          "size": "29kb",
          "version": "v1"
        },
        {
          "date": "Thu, 26 Jun 2025 15:38:38 GMT",
          "size": "44kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Universal Proof Theory: Semi-analytic Rules and Uniform Interpolation",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper deals with proof theory and uniform interpolation in logic systems. It does not discuss or relate to LLM training data processing or data engineering tasks."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2008.09253",
      "abstract": "We present a small, formal language for specifying the behavior of simple console I/O programs. The design is driven by the concrete application case of testing interactive Haskell programs written by students. Specifications are structurally similar to lexical analysis regular expressions, but are augmented with features like global variables that track state and history of program runs, enabling expression of an interesting range of dynamic behavior. We give a semantics for our specification language based on acceptance of execution traces. From this semantics we derive a definition of the set of all traces valid for a given specification. Sampling that set enables us to mechanically check program behavior against specifications in a probabilistic fashion. Beyond testing, other possible uses of the specification language in an education context include related activities like providing more helpful feedback, generating sample solutions, and even generating random exercise tasks.",
      "authors": [
        "Oliver Westphal",
        "Janis Voigtl\\\"ander"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2008.09253",
        "HTML": "https://arxiv.org/html/2008.09253",
        "PDF": "https://arxiv.org/pdf/2008.09253"
      },
      "subjects": [
        "Programming Languages (cs.PL)",
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "Fri, 21 Aug 2020 01:21:59 GMT",
          "size": "29kb",
          "version": "v1"
        },
        {
          "date": "Thu, 26 Jun 2025 13:12:32 GMT",
          "size": "34kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Describing Console I/O Behavior for Testing Student Submissions in Haskell",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper introduces a language for testing console I/O behavior in Haskell, which is unrelated to the processing of training data for LLMs or any data engineering stage relevant to LLMs."
      },
      "repo_urls": [
        "https://github.com/fmidue/IOTasks"
      ],
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2109.00972",
      "abstract": "Is there an algorithm that takes a game in normal form as input, and outputs a Nash equilibrium? If the payoffs are integers, the answer is yes, and lot of work has been done in its computational complexity. If the payoffs are permitted to be real numbers, the answer is no, for continuity reasons. It is worthwhile to investigate the precise degree of non-computability (the Weihrauch degree), since knowing the degree entails what other approaches are available (eg, is there a randomized algorithm with positive success change?). The two player case has already been fully classified, but the multiplayer case remains open and is addressed here. Our approach involves classifying the degree of finding roots of polynomials, and lifting this to systems of polynomial inequalities via cylindrical algebraic decomposition.",
      "authors": [
        "Tonicha Crook and Arno Pauly"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2109.00972",
        "HTML": "https://arxiv.org/html/2109.00972",
        "PDF": "https://arxiv.org/pdf/2109.00972"
      },
      "subjects": [
        "Logic in Computer Science (cs.LO)",
        "Computer Science and Game Theory (cs.GT)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 02 Sep 2021 14:17:29 GMT",
          "size": "33kb",
          "version": "v1"
        },
        {
          "date": "Fri, 09 Feb 2024 11:53:53 GMT",
          "size": "33kb",
          "version": "v2"
        },
        {
          "date": "Tue, 06 May 2025 16:31:04 GMT",
          "size": "34kb",
          "version": "v3"
        },
        {
          "date": "Thu, 26 Jun 2025 12:49:18 GMT",
          "size": "28kb",
          "version": "v4"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "The Weihrauch degree of finding Nash equilibria in multiplayer games",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper discusses the computational complexity of finding Nash equilibria in games, unrelated to any aspect of training data processing or engineering for LLMs."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2210.09394",
      "abstract": "When a deep learning model is trained sequentially on different datasets, it often forgets the knowledge learned from previous data, a problem known as catastrophic forgetting. This damages the model's performance on diverse datasets, which is critical in privacy-preserving deep learning (PPDL) applications based on transfer learning (TL). To overcome this, we introduce \"review learning\" (RevL), a low cost continual learning algorithm for diagnosis prediction using electronic health records (EHR) within a PPDL framework. RevL generates data samples from the model which are used to review knowledge from previous datasets. Six simulated institutional experiments and one real-world experiment involving three medical institutions were conducted to validate RevL, using three binary classification EHR data. In the real-world experiment with data from 106,508 patients, the mean global area under the receiver operating curve was 0.710 for RevL and 0.655 for TL. These results demonstrate RevL's ability to retain previously learned knowledge and its effectiveness in real-world PPDL scenarios. Our work establishes a realistic pipeline for PPDL research based on model transfers across institutions and highlights the practicality of continual learning in real-world medical settings using private EHR data.",
      "authors": [
        "Jaesung Yoo",
        "Sunghyuk Choi",
        "Ye Seul Yang",
        "Suhyeon Kim",
        "Jieun Choi",
        "Dongkyeong Lim",
        "Yaeji Lim",
        "Hyung Joon Joo",
        "Dae Jung Kim",
        "Rae Woong Park",
        "Hyeong-Jin Yoon",
        "Kwangsoo Kim"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2210.09394",
        "HTML": "https://arxiv.org/html/2210.09394",
        "PDF": "https://arxiv.org/pdf/2210.09394"
      },
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Mon, 17 Oct 2022 19:54:38 GMT",
          "size": "1555kb",
          "version": "v1"
        },
        {
          "date": "Thu, 26 Jun 2025 04:44:25 GMT",
          "size": "3999kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Review learning: Real world validation of privacy preserving continual learning across medical institutions",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper discusses a continual learning algorithm for electronic health records in a privacy-preserving context, without addressing LLM training data processing."
      },
      "tasks": [
        "Binary Classification",
        "Continual Learning",
        "Deep Learning",
        "Privacy Preserving",
        "Privacy Preserving Deep Learning",
        "Transfer Learning"
      ],
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2211.05770",
      "abstract": "While the integration of transformers in vision models have yielded significant improvements on vision tasks they still require significant amounts of computation for both training and inference. Restricted attention mechanisms significantly reduce these computational burdens but come at the cost of losing either global or local coherence. We propose a simple, yet powerful method to reduce these trade-offs: allow the attention heads of a single transformer to attend to multiple receptive fields.\n  We demonstrate our method utilizing Neighborhood Attention (NA) and integrate it into a StyleGAN based architecture for image generation. With this work, dubbed StyleNAT, we are able to achieve a FID of 2.05 on FFHQ, a 6% improvement over StyleGAN-XL, while utilizing 28% fewer parameters and with 4$\\times$ the throughput capacity. StyleNAT achieves the Pareto Frontier on FFHQ-256 and demonstrates powerful and efficient image generation on other datasets. Our code and model checkpoints are publicly available at: https://github.com/SHI-Labs/StyleNAT",
      "authors": [
        "Steven Walton",
        "Ali Hassani",
        "Xingqian Xu",
        "Zhangyang Wang",
        "Humphrey Shi"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2211.05770",
        "HTML": "https://arxiv.org/html/2211.05770",
        "PDF": "https://arxiv.org/pdf/2211.05770"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 10 Nov 2022 18:55:48 GMT",
          "size": "20378kb",
          "version": "v1"
        },
        {
          "date": "Sun, 13 Aug 2023 00:03:25 GMT",
          "size": "56184kb",
          "version": "v2"
        },
        {
          "date": "Thu, 26 Jun 2025 05:07:48 GMT",
          "size": "24955kb",
          "version": "v3"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Efficient Image Generation with Variadic Attention Heads",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper introduces a new attention mechanism for transformer models in image generation, without focusing on LLM training data processing."
      },
      "tasks": [
        "Face Generation",
        "Image Generation"
      ],
      "repo_urls": [
        "https://github.com/SHI-Labs/StyleNAT",
        "https://github.com/SHI-Labs/Neighborhood-Attention-Transformer"
      ],
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2307.04345",
      "abstract": "An agent that efficiently accumulates knowledge to develop increasingly sophisticated skills over a long lifetime could advance the frontier of artificial intelligence capabilities. The design of such agents, which remains a long-standing challenge of artificial intelligence, is addressed by the subject of continual learning. This monograph clarifies and formalizes concepts of continual learning, introducing a framework and set of tools to stimulate further research.",
      "authors": [
        "Saurabh Kumar",
        "Henrik Marklund",
        "Ashish Rao",
        "Yifan Zhu",
        "Hong Jun Jeon",
        "Yueyang Liu",
        "and Benjamin Van Roy"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2307.04345",
        "HTML": "https://arxiv.org/html/2307.04345",
        "PDF": "https://arxiv.org/pdf/2307.04345"
      },
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Mon, 10 Jul 2023 05:06:41 GMT",
          "size": "2188kb",
          "version": "v1"
        },
        {
          "date": "Sun, 20 Aug 2023 19:58:49 GMT",
          "size": "2411kb",
          "version": "v2"
        },
        {
          "date": "Thu, 26 Jun 2025 16:08:44 GMT",
          "size": "2889kb",
          "version": "v3"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Continual Learning as Computationally Constrained Reinforcement Learning",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper is concerned with continual learning and reinforcement learning concepts, not the processing of training data for LLMs."
      },
      "tasks": [
        "Continual Learning",
        "reinforcement-learning",
        "Reinforcement Learning"
      ],
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2307.14036",
      "abstract": "We present a new encoding of the Battle of Hercules and Hydra as a rewrite system with AC symbols. Unlike earlier term rewriting encodings, it faithfully models any strategy of Hercules to beat Hydra. To prove the termination of our encoding, we employ type introduction in connection with many-sorted semantic labeling for AC rewriting and AC-MPO, a new AC compatible reduction order that can be seen as a much weakened version of AC-RPO.",
      "authors": [
        "Nao Hirokawa",
        "Aart Middeldorp"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2307.14036",
        "HTML": "https://arxiv.org/html/2307.14036",
        "PDF": "https://arxiv.org/pdf/2307.14036"
      },
      "subjects": [
        "Logic in Computer Science (cs.LO)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 26 Jul 2023 08:40:21 GMT",
          "size": "167kb",
          "version": "v1"
        },
        {
          "date": "Tue, 05 Mar 2024 04:18:46 GMT",
          "size": "34kb",
          "version": "v2"
        },
        {
          "date": "Wed, 13 Nov 2024 10:00:07 GMT",
          "size": "35kb",
          "version": "v3"
        },
        {
          "date": "Tue, 08 Apr 2025 05:37:39 GMT",
          "size": "39kb",
          "version": "v4"
        },
        {
          "date": "Wed, 25 Jun 2025 20:16:21 GMT",
          "size": "40kb",
          "version": "v5"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Hydra Battles and AC Termination",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "Focuses on term rewriting systems and encoding strategies, which are not related to LLM training data processing."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2308.01251",
      "abstract": "As a natural disaster, landslide often brings tremendous losses to human lives, so it urgently demands reliable detection of landslide risks. When detecting relic landslides that present important information for landslide risk warning, problems such as visual blur and small-sized dataset cause great challenges when using remote sensing images. To extract accurate semantic features, a hyper-pixel-wise contrastive learning augmented segmentation network (HPCL-Net) is proposed, which augments the local salient feature extraction from boundaries of landslides through HPCL and fuses heterogeneous information in the semantic space from high-resolution remote sensing images and digital elevation model data. For full utilization of precious samples, a global hyper-pixel-wise sample pair queues-based contrastive learning method is developed, which includes the construction of global queues that store hyper-pixel-wise samples and the updating scheme of a momentum encoder, reliably enhancing the extraction ability of semantic features. The proposed HPCL-Net is evaluated on the Loess Plateau relic landslide dataset and experimental results verify that the proposed HPCL-Net greatly outperforms existing models, where the mIoU is increased from 0.620 to 0.651, the Landslide IoU is improved from 0.334 to 0.394 and the F1score is enhanced from 0.501 to 0.565.",
      "authors": [
        "Yiming Zhou",
        "Yuexing Peng",
        "Daqing Ge",
        "Junchuan Yu",
        "Wei Xiang"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2308.01251",
        "HTML": "https://arxiv.org/html/2308.01251",
        "PDF": "https://arxiv.org/pdf/2308.01251"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 02 Aug 2023 16:11:51 GMT",
          "size": "22241kb",
          "version": "v1"
        },
        {
          "date": "Fri, 06 Oct 2023 04:15:56 GMT",
          "size": "22230kb",
          "version": "v2"
        },
        {
          "date": "Wed, 04 Dec 2024 01:52:57 GMT",
          "size": "26108kb",
          "version": "v3"
        },
        {
          "date": "Fri, 28 Feb 2025 00:51:20 GMT",
          "size": "26101kb",
          "version": "v4"
        },
        {
          "date": "Thu, 26 Jun 2025 06:31:46 GMT",
          "size": "26101kb",
          "version": "v5"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "A Multi-Source Data Fusion-based Semantic Segmentation Model for Relic Landslide Detection",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on semantic segmentation models for landslide detection using remote sensing imagery, and does not discuss the collection or processing of training data for large language models."
      },
      "tasks": [
        "Contrastive Learning",
        "Landslide segmentation",
        "Semantic Segmentation"
      ],
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2311.00635",
      "abstract": "The artist similarity quest has become a crucial subject in social and scientific contexts, driven by the desire to enhance music discovery according to user preferences. Modern research solutions facilitate music discovery according to user tastes. However, defining similarity among artists remains challenging due to its inherently subjective nature, which can impact recommendation accuracy. This paper introduces GATSY, a novel recommendation system built upon graph attention networks and driven by a clusterized embedding of artists. The proposed framework leverages the graph topology of the input data to achieve outstanding performance results without relying heavily on hand-crafted features. This flexibility allows us to include fictitious artists within a music dataset, facilitating connections between previously unlinked artists and enabling diverse recommendations from various and heterogeneous sources. Experimental results prove the effectiveness of the proposed method with respect to state-of-the-art solutions while maintaining flexibility. The code to reproduce these experiments is available at https://github.com/difra100/GATSY-Music_Artist_Similarity.",
      "authors": [
        "Andrea Giuseppe Di Francesco",
        "Giuliano Giampietro",
        "Indro Spinelli and Danilo Comminiello"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2311.00635",
        "HTML": "https://arxiv.org/html/2311.00635",
        "PDF": "https://arxiv.org/pdf/2311.00635"
      },
      "subjects": [
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 01 Nov 2023 16:36:19 GMT",
          "size": "6660kb",
          "version": "v1"
        },
        {
          "date": "Sat, 05 Apr 2025 18:14:41 GMT",
          "size": "7991kb",
          "version": "v2"
        },
        {
          "date": "Thu, 26 Jun 2025 17:31:17 GMT",
          "size": "7990kb",
          "version": "v3"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "GATSY: Graph Attention Network for Music Artist Similarity",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper introduces a recommendation system for music artist similarity using graph attention networks, which is not related to the training data processing for large language models."
      },
      "tasks": [
        "Graph Attention"
      ],
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2312.04135",
      "abstract": "Unmanned aerial vehicles (UAVs) operating within Flying Ad-hoc Networks (FANETs) encounter security challenges due to the dynamic and distributed nature of these networks. Previous studies focused predominantly on centralized intrusion detection, assuming a central entity responsible for storing and analyzing data from all devices. However, these approaches face challenges including computation and storage costs, along with a single point of failure risk, threatening data privacy and availability. The widespread dispersion of data across interconnected devices underscores the need for decentralized approaches. This paper introduces the Federated Learning-based Intrusion Detection System (FL-IDS), addressing challenges encountered by centralized systems in FANETs. FL-IDS reduces computation and storage costs for both clients and the central server, which is crucial for resource-constrained UAVs. Operating in a decentralized manner, FL-IDS enables UAVs to collaboratively train a global intrusion detection model without sharing raw data, thus avoiding delay in decisions based on collected data, as is often the case with traditional methods. Experimental results demonstrate FL-IDS's competitive performance with Central IDS (C-IDS) while mitigating privacy concerns, with the Bias Towards Specific Clients (BTSC) method further enhancing FL-IDS performance even at lower attacker ratios. Comparative analysis with traditional intrusion detection methods, including Local IDS (L-IDS), sheds light on the strengths of FL-IDS. This study significantly contributes to UAV security by introducing a privacy-aware, decentralized intrusion detection approach tailored to UAV networks. Moreover, by introducing a realistic dataset for FANETs and federated learning, our approach differs from others lacking high dynamism and 3D node movements or accurate federated data federations.",
      "authors": [
        "Ozlem Ceviz (1)",
        "Pinar Sadioglu (1)",
        "Sevil Sen (1) and Vassilios G. Vassilakis (2) ((1) WISE Lab.",
        "Deparment of Computer Engineering",
        "Hacettepe University",
        "Ankara",
        "Turkey (2) Department of Computer Science",
        "University of York",
        "York",
        "United Kingdom)"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2312.04135",
        "HTML": "https://arxiv.org/html/2312.04135",
        "PDF": "https://arxiv.org/pdf/2312.04135"
      },
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 07 Dec 2023 08:50:25 GMT",
          "size": "630kb",
          "version": "v1"
        },
        {
          "date": "Fri, 15 Mar 2024 20:41:03 GMT",
          "size": "644kb",
          "version": "v2"
        },
        {
          "date": "Thu, 26 Jun 2025 11:21:32 GMT",
          "size": "1853kb",
          "version": "v3"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "A Novel Federated Learning-Based IDS for Enhancing UAVs Privacy and Security",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper presents a Federated Learning-based intrusion detection system for UAVs. It introduces a dataset related to this context, but it is not concerned with LLM training data processing."
      },
      "tasks": [
        "Federated Learning",
        "Intrusion Detection"
      ],
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2312.14712",
      "abstract": "This position paper argues that achieving robustness, privacy, and efficiency simultaneously in machine learning systems is infeasible under prevailing threat models. The tension between these goals arises not from algorithmic shortcomings but from structural limitations imposed by worst-case adversarial assumptions. We advocate for a systematic research agenda aimed at formalizing the robustness-privacy-efficiency trilemma, exploring how principled relaxations of threat models can unlock better trade-offs, and designing benchmarks that expose rather than obscure the compromises made. By shifting focus from aspirational universal guarantees to context-aware system design, the machine learning community can build models that are truly appropriate for real-world deployment.",
      "authors": [
        "Youssef Allouah",
        "Rachid Guerraoui",
        "and John Stephan"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2312.14712",
        "HTML": "https://arxiv.org/html/2312.14712",
        "PDF": "https://arxiv.org/pdf/2312.14712"
      },
      "subjects": [
        "Machine Learning (cs.LG)",
        "Cryptography and Security (cs.CR)",
        "Distributed, Parallel, and Cluster Computing (cs.DC)"
      ],
      "submission_historys": [
        {
          "date": "Fri, 22 Dec 2023 14:10:07 GMT",
          "size": "2628kb",
          "version": "v1"
        },
        {
          "date": "Mon, 11 Mar 2024 10:06:37 GMT",
          "size": "1296kb",
          "version": "v2"
        },
        {
          "date": "Thu, 26 Jun 2025 13:12:25 GMT",
          "size": "1751kb",
          "version": "v3"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Balancing Privacy, Robustness, and Efficiency in Machine Learning",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This position paper discusses the balance of privacy, robustness, and efficiency in machine learning systems, but does not focus on LLM training data processing or engineering."
      },
      "tasks": [
        "Computational Efficiency",
        "Data Poisoning"
      ],
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2401.10586",
      "abstract": "Black-box query-based attacks constitute significant threats to Machine Learning as a Service (MLaaS) systems since they can generate adversarial examples without accessing the target model's architecture and parameters. Traditional defense mechanisms, such as adversarial training, gradient masking, and input transformations, either impose substantial computational costs or compromise the test accuracy of non-adversarial inputs. To address these challenges, we propose an efficient defense mechanism, PuriDefense, that employs random patch-wise purifications with an ensemble of lightweight purification models at a low level of inference cost. These models leverage the local implicit function and rebuild the natural image manifold. Our theoretical analysis suggests that this approach slows down the convergence of query-based attacks by incorporating randomness into purifications. Extensive experiments on CIFAR-10 and ImageNet validate the effectiveness of our proposed purifier-based defense mechanism, demonstrating significant improvements in robustness against query-based attacks.",
      "authors": [
        "Ping Guo",
        "Xiang Li",
        "Zhiyuan Yang",
        "Xi Lin",
        "Qingchuan Zhao",
        "Qingfu Zhang"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2401.10586",
        "HTML": "https://arxiv.org/html/2401.10586",
        "PDF": "https://arxiv.org/pdf/2401.10586"
      },
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Fri, 19 Jan 2024 09:54:23 GMT",
          "size": "19282kb",
          "version": "v1"
        },
        {
          "date": "Thu, 26 Jun 2025 15:00:42 GMT",
          "size": "11380kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "PuriDefense: Randomized Local Implicit Adversarial Purification for Defending Black-box Query-based Attacks",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper proposes PuriDefense, a defense mechanism against query-based attacks, focusing on adversarial purification. It does not involve LLM training data processing or engineering."
      },
      "tasks": [
        "Adversarial Purification"
      ],
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2401.11752",
      "abstract": "Enriched categories are categories whose sets of morphisms are enriched with extra structure. Such categories play a prominent role in the study of higher categories, homotopy theory, and the semantics of programming languages. In this paper, we study univalent enriched categories. We prove that all essentially surjective and fully faithful functors between univalent enriched categories are equivalences, and we show that every enriched category admits a Rezk completion. Finally, we use the Rezk completion for enriched categories to construct univalent enriched Kleisli categories.",
      "authors": [
        "Niels van der Weide"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2401.11752",
        "HTML": "https://arxiv.org/html/2401.11752",
        "PDF": "https://arxiv.org/pdf/2401.11752"
      },
      "subjects": [
        "Logic in Computer Science (cs.LO)",
        "Category Theory (math.CT)"
      ],
      "submission_historys": [
        {
          "date": "Mon, 22 Jan 2024 08:27:08 GMT",
          "size": "238kb",
          "version": "v1"
        },
        {
          "date": "Tue, 23 Apr 2024 13:32:38 GMT",
          "size": "239kb",
          "version": "v2"
        },
        {
          "date": "Tue, 25 Mar 2025 15:04:37 GMT",
          "size": "255kb",
          "version": "v3"
        },
        {
          "date": "Thu, 26 Jun 2025 12:37:22 GMT",
          "size": "61kb",
          "version": "v4"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Univalent Enriched Categories and the Enriched Rezk Completion",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on the study of univalent enriched categories, a theoretical topic in category theory and homotopy theory, without any mention of LLM training data processing or data engineering tasks."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2402.03666",
      "abstract": "The practical deployment of diffusion models is still hindered by the high memory and computational overhead. Although quantization paves a way for model compression and acceleration, existing methods face challenges in achieving low-bit quantization efficiently. In this paper, we identify imbalanced activation distributions as a primary source of quantization difficulty, and propose to adjust these distributions through weight finetuning to be more quantization-friendly. We provide both theoretical and empirical evidence supporting finetuning as a practical and reliable solution. Building on this approach, we further distinguish two critical types of quantized layers: those responsible for retaining essential temporal information and those particularly sensitive to bit-width reduction. By selectively finetuning these layers under both local and global supervision, we mitigate performance degradation while enhancing quantization efficiency. Our method demonstrates its efficacy across three high-resolution image generation tasks, obtaining state-of-the-art performance across multiple bit-width settings.",
      "authors": [
        "Haoxuan Wang",
        "Yuzhang Shang",
        "Zhihang Yuan",
        "Junyi Wu",
        "Junchi Yan",
        "Yan Yan"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2402.03666",
        "HTML": "https://arxiv.org/html/2402.03666",
        "PDF": "https://arxiv.org/pdf/2402.03666"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 06 Feb 2024 03:39:44 GMT",
          "size": "8501kb",
          "version": "v1"
        },
        {
          "date": "Tue, 13 Feb 2024 05:22:34 GMT",
          "size": "8501kb",
          "version": "v2"
        },
        {
          "date": "Fri, 06 Sep 2024 02:02:41 GMT",
          "size": "7242kb",
          "version": "v3"
        },
        {
          "date": "Thu, 26 Jun 2025 17:36:29 GMT",
          "size": "6569kb",
          "version": "v4"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "QuEST: Low-bit Diffusion Model Quantization via Efficient Selective Finetuning",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "Although the paper discusses model compression and quantization for diffusion models, it does not address tasks related to LLM training data processing such as collection, cleaning, or transformation."
      },
      "tasks": [
        "Image Generation",
        "Model Compression",
        "Quantization"
      ],
      "repo_urls": [
        "https://github.com/hatchetProject/QuEST"
      ],
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2403.00129",
      "abstract": "We initiate the study of Local Computation Algorithms on average case inputs. In the Local Computation Algorithm (LCA) model, we are given probe access to a huge graph, and asked to answer membership queries about some combinatorial structure on the graph, answering each query with sublinear work.\n  For instance, an LCA for the $k$-spanner problem gives access to a sparse subgraph $H\\subseteq G$ that preserves distances up to a factor of $k$. We build simple LCAs for this problem assuming the input graph is drawn from the well-studied Erdos-Reyni and Preferential Attachment graph models. In both cases, our spanners achieve size and stretch tradeoffs that are impossible to achieve for general graphs, while having dramatically lower query complexity than worst-case LCAs.\n  Our second result investigates the intersection of LCAs with Local Access Generators (LAGs). Local Access Generators provide efficient query access to a random object, for instance an Erdos Reyni random graph. We explore the natural problem of generating a random graph together with a combinatorial structure on it. We show that this combination can be easier to solve than focusing on each problem by itself, by building a fast, simple algorithm that provides access to an Erdos Reyni random graph together with a maximal independent set.",
      "authors": [
        "Amartya Shankha Biswas",
        "Ruidi Cao",
        "Cassandra Marcussen",
        "Edward Pyne",
        "Ronitt Rubinfeld",
        "Asaf Shapira",
        "Shlomo Tauber"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2403.00129",
        "HTML": "https://arxiv.org/html/2403.00129",
        "PDF": "https://arxiv.org/pdf/2403.00129"
      },
      "subjects": [
        "Data Structures and Algorithms (cs.DS)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 29 Feb 2024 21:14:01 GMT",
          "size": "37kb",
          "version": "v1"
        },
        {
          "date": "Thu, 26 Jun 2025 06:52:38 GMT",
          "size": "48kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Beyond Worst Case Local Computation Algorithms",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This research deals with Local Computation Algorithms for graph problems rather than topics related to LLM training data processing or data engineering."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2403.04881",
      "abstract": "In this work, we propose a framework for adapting the controller's parameters based on learning optimal solutions from contextual black-box optimization problems. We consider a class of control design problems for dynamical systems operating in different environments or conditions represented by contextual parameters. The overarching goal is to identify the controller parameters that maximize the controlled system's performance, given different realizations of the contextual parameters.We formulate a contextual Bayesian optimization problem in which the solution is actively learned using Gaussian processes to approximate the controller adaptation strategy. We demonstrate the efficacy of the proposed framework with a sim-to-real example. We learn the optimal weighting strategy of a model predictive control for connected and automated vehicles interacting with human-driven vehicles from simulations and then deploy it in a real-time experiment.",
      "authors": [
        "Viet-Anh Le and Andreas A. Malikopoulos"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2403.04881",
        "HTML": "https://arxiv.org/html/2403.04881",
        "PDF": "https://arxiv.org/pdf/2403.04881"
      },
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 07 Mar 2024 20:08:39 GMT",
          "size": "2174kb",
          "version": "v1"
        },
        {
          "date": "Fri, 06 Dec 2024 18:44:16 GMT",
          "size": "3266kb",
          "version": "v2"
        },
        {
          "date": "Wed, 25 Jun 2025 18:38:11 GMT",
          "size": "2610kb",
          "version": "v3"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Controller Adaptation via Learning Solutions of Contextual Bayesian Optimization",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper describes a framework for adapting controller parameters using Bayesian optimization but does not relate to any aspect of LLM training data processing or data engineering."
      },
      "tasks": [
        "Bayesian Optimization",
        "Gaussian Processes",
        "Model Predictive Control"
      ],
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2403.14684",
      "abstract": "Neural networks often struggle with catastrophic forgetting when learning sequences of tasks or data streams, unlike humans who can continuously learn and consolidate new concepts even in the absence of explicit cues. Online data-incremental learning seeks to emulate this capability by processing each sample only once, without having access to task or stream cues at any point in time since this is more realistic compared to offline setups, where all data from novel class(es) is assumed to be readily available. However, existing methods typically rely on storing the subsets of data in memory or expanding the initial model architecture, resulting in significant computational overhead. Drawing inspiration from 'self-regulated neurogenesis'-brain's mechanism for creating specialized regions or circuits for distinct functions-we propose a novel approach SERENA which encodes each concept in a specialized network path called 'concept cell', integrated into a single over-parameterized network. Once a concept is learned, its corresponding concept cell is frozen, effectively preventing the forgetting of previously acquired information. Furthermore, we introduce two new continual learning scenarios that more closely reflect real-world conditions, characterized by gradually changing sample sizes. Experimental results show that our method not only establishes new state-of-the-art results across ten benchmarks but also remarkably surpasses offline supervised batch learning performance. The code is available at https://github.com/muratonuryildirim/serena.",
      "authors": [
        "Murat Onur Yildirim",
        "Elif Ceren Gok Yildirim",
        "Decebal Constantin Mocanu",
        "Joaquin Vanschoren"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2403.14684",
        "HTML": "https://arxiv.org/html/2403.14684",
        "PDF": "https://arxiv.org/pdf/2403.14684"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 13 Mar 2024 13:51:12 GMT",
          "size": "432kb",
          "version": "v1"
        },
        {
          "date": "Thu, 26 Jun 2025 11:35:57 GMT",
          "size": "2203kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Self-Regulated Neurogenesis for Online Data-Incremental Learning",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper proposes a method for online data-incremental learning aimed at overcoming catastrophic forgetting in neural networks. It does not focus on LLM training data collection or processing stages."
      },
      "tasks": [
        "class-incremental learning",
        "Class Incremental Learning",
        "Continual Learning",
        "Incremental Learning"
      ],
      "repo_urls": [
        "https://github.com/muratonuryildirim/focil"
      ],
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2403.15011",
      "abstract": "Cell tracking and segmentation assist biologists in extracting insights from large-scale microscopy time-lapse data. Driven by local accuracy metrics, current tracking approaches often suffer from a lack of long-term consistency and the ability to reconstruct lineage trees correctly. To address this issue, we introduce an uncertainty estimation technique for motion estimation frameworks and extend the multi-hypothesis tracking framework. Our uncertainty estimation lifts motion representations into probabilistic spatial densities using problem-specific test-time augmentations. Moreover, we introduce a novel mitosis-aware assignment problem formulation that allows multi-hypothesis trackers to model cell splits and to resolve false associations and mitosis detections based on long-term conflicts. In our framework, explicit biological knowledge is modeled in assignment costs. We evaluate our approach on nine competitive datasets and demonstrate that we outperform the current state-of-the-art on biologically inspired metrics substantially, achieving improvements by a factor of approximately 6 and uncover new insights into the behavior of motion estimation uncertainty.",
      "authors": [
        "Timo Kaiser",
        "Maximilian Schier",
        "Bodo Rosenhahn"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2403.15011",
        "HTML": "https://arxiv.org/html/2403.15011",
        "PDF": "https://arxiv.org/pdf/2403.15011"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Fri, 22 Mar 2024 07:49:55 GMT",
          "size": "40878kb",
          "version": "v1"
        },
        {
          "date": "Mon, 25 Mar 2024 14:50:47 GMT",
          "size": "40878kb",
          "version": "v2"
        },
        {
          "date": "Wed, 09 Oct 2024 07:21:56 GMT",
          "size": "1585kb",
          "version": "v3"
        },
        {
          "date": "Thu, 26 Jun 2025 13:24:33 GMT",
          "size": "39449kb",
          "version": "v4"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Cell Tracking according to Biological Needs -- Strong Mitosis-aware Multi-Hypothesis Tracker with Aleatoric Uncertainty",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The research paper is about improving cell tracking techniques using probabilistic models and biological knowledge. It does not pertain to processing or engineering LLM training data."
      },
      "tasks": [
        "Cell Tracking",
        "Motion Estimation",
        "regression"
      ],
      "repo_urls": [
        "https://github.com/timok93/biologicalneeds"
      ],
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2404.00808",
      "abstract": "Understanding how robots plan and execute tasks is crucial in today's world, where they are becoming more prevalent in our daily lives. However, teaching non-experts, such as K-12 students, the complexities of robot planning can be challenging. This work presents an open-source platform, JEDAI.Ed, that simplifies the process using a visual interface that abstracts the details of various planning processes that robots use for performing complex mobile manipulation tasks. Using principles developed in the field of explainable AI, this intuitive platform enables students to use a high-level intuitive instruction set to perform complex tasks, visualize them on an in-built simulator, and to obtain helpful hints and natural language explanations for errors. Finally, JEDAI.Ed, includes an adaptive curriculum generation method that provides students with customized learning ramps. This platform's efficacy was tested through a user study with university students who had little to no computer science background. Our results show that JEDAI.Ed is highly effective in increasing student engagement, teaching robotics programming, and decreasing the time need to solve tasks as compared to baselines.",
      "authors": [
        "Rushang Karia",
        "Jayesh Nagpal",
        "Daksh Dobhal",
        "Pulkit Verma",
        "Rashmeet Kaur Nayyar",
        "Naman Shah",
        "Siddharth Srivastava"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2404.00808",
        "HTML": "https://arxiv.org/html/2404.00808",
        "PDF": "https://arxiv.org/pdf/2404.00808"
      },
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "Sun, 31 Mar 2024 21:48:42 GMT",
          "size": "6389kb",
          "version": "v1"
        },
        {
          "date": "Mon, 11 Nov 2024 23:13:57 GMT",
          "size": "8393kb",
          "version": "v2"
        },
        {
          "date": "Wed, 25 Jun 2025 20:36:47 GMT",
          "size": "3814kb",
          "version": "v3"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Using Explainable AI and Hierarchical Planning for Outreach with Robots",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The work describes a platform for teaching robotics using hierarchical planning and does not cover any aspect of LLM training data engineering or processing."
      },
      "repo_urls": [
        "https://github.com/AAIR-lab/AAIR-JEDAI"
      ],
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2404.01473",
      "abstract": "Over the lifetime of a computing task, determining the maximum usage of random-access memory (RAM) on both the motherboard and on a graphical processing unit (GPU), as well as the utilization percentage of the central processing unit (CPU) and GPU, can be extremely useful for troubleshooting points of failure as well as optimizing memory and processing unit utilization, especially within a high-performance computing (HPC) setting. While there are tools for tracking compute time, CPU utilization, and RAM, including by job management tools themselves, tracking of GPU usage, to our knowledge, does not currently have sufficient solutions, particularly in Unix/Linux operating systems. We present gpu-tracker, a multi-operating system Python package that tracks the computational resource usage of a task while running in the background, including the real compute time that the task takes to complete, its maximum RAM usage, the average and maximum percentage of CPU utilization, the maximum GPU RAM usage, and the average and maximum percentage of GPU utilization for both Nvidia and AMD GPUs. We demonstrate that gpu-tracker can seamlessly track computational resource usage with minimal overhead, both within desktop and HPC execution environments.",
      "authors": [
        "Erik D. Huckvale",
        "Hunter N.B. Moseley"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2404.01473",
        "HTML": "https://arxiv.org/html/2404.01473",
        "PDF": "https://arxiv.org/pdf/2404.01473"
      },
      "subjects": [
        "Performance (cs.PF)"
      ],
      "submission_historys": [
        {
          "date": "Mon, 01 Apr 2024 20:49:56 GMT",
          "size": "362kb",
          "version": "v1"
        },
        {
          "date": "Mon, 24 Jun 2024 22:30:15 GMT",
          "size": "433kb",
          "version": "v2"
        },
        {
          "date": "Wed, 25 Jun 2025 20:34:36 GMT",
          "size": "759kb",
          "version": "v3"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "gpu tracker: Python Package for Tracking and Profiling GPU and Other Hardware Utilization in Both Desktop and High-Performance Computing Environments",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper discusses a Python package for tracking and profiling computational resources like GPU and CPU usage. It does not address LLM training data processing or data engineering aspects."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2404.16614",
      "abstract": "Derandomization techniques are often used within advanced randomized algorithms. In particular, pseudorandom objects, such as hash families and expander graphs, are key components of such algorithms, but their verification presents a challenge. This work shows how such algorithms can be expressed and verified in Isabelle and presents a pseudorandom objects library that abstracts away the deep algebraic/analytic results involved. Moreover, it presents examples that show how the library eases and enables the verification of advanced randomized algorithms. Highlighting the value of this framework is that it was recently used to verify the space-optimal distinct elements algorithm by Blasiok from 2018, which relies on the combination of many derandomization techniques to achieve its optimality.",
      "authors": [
        "Emin Karayel"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2404.16614",
        "HTML": "https://arxiv.org/html/2404.16614",
        "PDF": "https://arxiv.org/pdf/2404.16614"
      },
      "subjects": [
        "Logic in Computer Science (cs.LO)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 25 Apr 2024 13:55:03 GMT",
          "size": "134kb",
          "version": "v1"
        },
        {
          "date": "Tue, 25 Mar 2025 07:07:18 GMT",
          "size": "138kb",
          "version": "v2"
        },
        {
          "date": "Tue, 06 May 2025 21:24:47 GMT",
          "size": "138kb",
          "version": "v3"
        },
        {
          "date": "Wed, 25 Jun 2025 21:04:04 GMT",
          "size": "509kb",
          "version": "v4"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Derandomization with Pseudorandomness",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper focuses on derandomization techniques and pseudorandom objects for algorithm verification using Isabelle, without discussing anything related to LLM training data processing."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2404.18201",
      "abstract": "The realization of universal robots is an ultimate goal of researchers. However, a key hurdle in achieving this goal lies in the robots' ability to manipulate objects in their unstructured surrounding environments according to different tasks. The learning-based approach is considered an effective way to address generalization. The impressive performance of foundation models in the fields of computer vision and natural language suggests the potential of embedding foundation models into manipulation tasks as a viable path toward achieving general manipulation capability. However, we believe achieving general manipulation capability requires an overarching framework akin to auto driving. This framework should encompass multiple functional modules, with different foundation models assuming distinct roles in facilitating general manipulation capability. This survey focuses on the contributions of foundation models to robot learning for manipulation. We propose a comprehensive framework and detail how foundation models can address challenges in each module of the framework. What's more, we examine current approaches, outline challenges, suggest future research directions, and identify potential risks associated with integrating foundation models into this domain.",
      "authors": [
        "Dingzhe Li",
        "Yixiang Jin",
        "Yuhao Sun",
        "Yong A",
        "Hongze Yu",
        "Jun Shi",
        "Xiaoshuai Hao",
        "Peng Hao",
        "Huaping Liu",
        "Fuchun Sun",
        "Jianwei Zhang",
        "Bin Fang"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2404.18201",
        "HTML": "https://arxiv.org/html/2404.18201",
        "PDF": "https://arxiv.org/pdf/2404.18201"
      },
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "Sun, 28 Apr 2024 14:39:29 GMT",
          "size": "687kb",
          "version": "v1"
        },
        {
          "date": "Fri, 09 Aug 2024 12:13:25 GMT",
          "size": "1643kb",
          "version": "v2"
        },
        {
          "date": "Mon, 02 Dec 2024 07:38:37 GMT",
          "size": "2076kb",
          "version": "v3"
        },
        {
          "date": "Thu, 26 Jun 2025 01:33:57 GMT",
          "size": "2341kb",
          "version": "v4"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "What Foundation Models can Bring for Robot Learning in Manipulation : A Survey",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The survey focuses on embedding foundation models into robot learning for manipulation tasks and does not cover any aspect of LLM training data processing."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2405.09780",
      "abstract": "Odometry is a crucial component for successfully implementing autonomous navigation, relying on sensors such as cameras, LiDARs and IMUs. However, these sensors may encounter challenges in extreme weather conditions, such as snowfall and fog. The emergence of FMCW radar technology offers the potential for robust perception in adverse conditions. As the latest generation of FWCW radars, the 4D mmWave radar provides point cloud with range, azimuth, elevation, and Doppler velocity information, despite inherent sparsity and noises in the point cloud. In this paper, we propose EFEAR-4D, an accurate, highly efficient, and learning-free method for large-scale 4D radar odometry estimation. EFEAR-4D exploits Doppler velocity information delicately for robust ego-velocity estimation, resulting in a highly accurate prior guess. EFEAR-4D maintains robustness against point-cloud sparsity and noises across diverse environments through dynamic object removal and effective region-wise feature extraction. Extensive experiments on two publicly available 4D radar datasets demonstrate state-of-the-art reliability and localization accuracy of EFEAR-4D under various conditions. Furthermore, we have collected a dataset following the same route but varying installation heights of the 4D radar, emphasizing the significant impact of radar height on point cloud quality - a crucial consideration for real-world deployments. Our algorithm and dataset will be available soon at https://github.com/CLASS-Lab/EFEAR-4D.",
      "authors": [
        "Xiaoyi Wu",
        "Yushuai Chen",
        "Zhan Li",
        "Ziyang Hong and Liang Hu"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2405.09780",
        "HTML": "https://arxiv.org/html/2405.09780",
        "PDF": "https://arxiv.org/pdf/2405.09780"
      },
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 16 May 2024 03:00:08 GMT",
          "size": "8550kb",
          "version": "v1"
        },
        {
          "date": "Thu, 26 Jun 2025 02:41:53 GMT",
          "size": "6273kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "EFEAR-4D: Ego-Velocity Filtering for Efficient and Accurate 4D radar Odometry",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper presents a method for 4D radar odometry estimation in autonomous navigation and does not relate to the processing of training data for LLMs."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2405.13718",
      "abstract": "Given a sequence of tokens, such as words, the task of next-token prediction is to predict the next-token conditional probability distribution. Decoder-only transformers have become effective models for this task, but their properties are still not fully understood. In particular, the largest number of distinct context sequences that a decoder-only transformer can interpolate next-token distributions for has not been established. To fill this gap, we prove upper and lower bounds on this number, which are equal up to a multiplicative constant. We prove these bounds in the general setting where next-token distributions can be arbitrary as well as the empirical setting where they are calculated from a finite number of document sequences. Our lower bounds are for one-layer multi-head decoder-only transformers and our proofs highlight an important injectivity property satisfied by self-attention. Furthermore, we provide numerical evidence that the minimal number of parameters for memorization is sufficient for being able to train the model to the entropy lower bound.",
      "authors": [
        "Liam Madden",
        "Curtis Fox",
        "Christos Thrampoulidis"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2405.13718",
        "HTML": "https://arxiv.org/html/2405.13718",
        "PDF": "https://arxiv.org/pdf/2405.13718"
      },
      "subjects": [
        "Machine Learning (cs.LG)",
        "Optimization and Control (math.OC)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 22 May 2024 15:09:41 GMT",
          "size": "46kb",
          "version": "v1"
        },
        {
          "date": "Tue, 17 Sep 2024 00:13:09 GMT",
          "size": "57kb",
          "version": "v2"
        },
        {
          "date": "Wed, 25 Jun 2025 23:53:42 GMT",
          "size": "54kb",
          "version": "v3"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Next-token prediction capacity: general upper bounds and a lower bound for transformers",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper analyzes the next-token prediction capacity of decoder-only transformers, focusing on theoretical bound proofs for the memorization capacity of these models, but does not discuss LLM training data processing."
      },
      "tasks": [
        "Decoder",
        "Memorization"
      ],
      "repo_urls": [
        "https://github.com/curtfox/decoder-memory-capacity"
      ],
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2405.15034",
      "abstract": "We present NeCGS, the first neural compression paradigm, which can compress a geometry set encompassing thousands of detailed and diverse 3D mesh models by up to 900 times with high accuracy and preservation of detailed geometric structures. Specifically, we first propose TSDF-Def, a new implicit representation that is capable of \\textbf{accurately} representing irregular 3D mesh models with various structures into regular 4D tensors of \\textbf{uniform} and \\textbf{compact} size, where 3D surfaces can be extracted through the deformable marching cubes. Then we construct a quantization-aware auto-decoder network architecture to regress these 4D tensors to explore the local geometric similarity within each shape and across different shapes for redundancy removal, resulting in more compact representations, including an embedded feature of a smaller size associated with each 3D model and a network parameter shared by all models. We finally encode the resulting features and network parameters into bitstreams through entropy coding. Besides, our NeCGS can handle the dynamic scenario well, where new 3D models are constantly added to a compressed set. Extensive experiments and ablation studies demonstrate the significant advantages of our NeCGS over state-of-the-art methods both quantitatively and qualitatively. The source code is available at https://github.com/rsy6318/NeCGS.",
      "authors": [
        "Siyu Ren",
        "Junhui Hou",
        "Weiyao Lin",
        "Wenping Wang"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2405.15034",
        "HTML": "https://arxiv.org/html/2405.15034",
        "PDF": "https://arxiv.org/pdf/2405.15034"
      },
      "subjects": [
        "Computational Geometry (cs.CG)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 23 May 2024 20:11:37 GMT",
          "size": "15914kb",
          "version": "v1"
        },
        {
          "date": "Thu, 28 Nov 2024 06:57:14 GMT",
          "size": "31865kb",
          "version": "v2"
        },
        {
          "date": "Thu, 22 May 2025 14:20:06 GMT",
          "size": "31865kb",
          "version": "v3"
        },
        {
          "date": "Thu, 26 Jun 2025 02:41:39 GMT",
          "size": "31868kb",
          "version": "v4"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "NeCGS: Neural Compression for 3D Geometry Sets",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper discusses neural compression for 3D geometry sets, a topic not related to the processing or engineering of training data for LLMs."
      },
      "repo_urls": [
        "https://github.com/rsy6318/necgs"
      ],
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2405.18113",
      "abstract": "Online recruitment platforms have reshaped job-seeking and recruiting processes, driving increased demand for applications that enhance person-job matching. Traditional methods generally rely on analyzing textual data from resumes and job descriptions, limiting the dynamic, interactive aspects crucial to effective recruitment. Recent advances in Large Language Models (LLMs) have revealed remarkable potential in simulating adaptive, role-based dialogues, making them well-suited for recruitment scenarios. In this paper, we propose \\textbf{MockLLM}, a novel framework to generate and evaluate mock interview interactions. The system consists of two key components: mock interview generation and two-sided evaluation in handshake protocol. By simulating both interviewer and candidate roles, MockLLM enables consistent and collaborative interactions for real-time and two-sided matching. To further improve the matching quality, MockLLM further incorporates reflection memory generation and dynamic strategy modification, refining behaviors based on previous experience. We evaluate MockLLM on real-world data Boss Zhipin, a major Chinese recruitment platform. The experimental results indicate that MockLLM outperforms existing methods in matching accuracy, scalability, and adaptability across job domains, highlighting its potential to advance candidate assessment and online recruitment.",
      "authors": [
        "Hongda Sun",
        "Hongzhan Lin",
        "Haiyu Yan",
        "Yang Song",
        "Xin Gao",
        "Rui Yan"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2405.18113",
        "HTML": "https://arxiv.org/html/2405.18113",
        "PDF": "https://arxiv.org/pdf/2405.18113"
      },
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 28 May 2024 12:23:16 GMT",
          "size": "1227kb",
          "version": "v1"
        },
        {
          "date": "Thu, 26 Jun 2025 06:33:55 GMT",
          "size": "536kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "MockLLM: A Multi-Agent Behavior Collaboration Framework for Online Job Seeking and Recruiting",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper proposes a framework for mock interviews using LLMs, focusing on interactive role-based dialogues in recruitment, not LLM training data processing."
      },
      "tasks": [],
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2406.12090",
      "abstract": "Labelled tableaux have been a traditional approach to define satisfiability checking procedures for Modal Logics. In many cases, they can also be used to obtain tight complexity bounds and lead to efficient implementations of reasoning tools. More recently, it has been shown that the expressive power provided by the operators characterizing Hybrid Logics (nominals and satisfiability modalities) can be used to \\emph{internalize} labels, leading to well-behaved inference procedures for fairly expressive logics. The resulting procedures are attractive because they do not use external mechanisms outside the language of the logic at hand, and have good logical and computational properties.\n  Many tableau systems based on Hybrid Logic have been investigated, with more recent efforts concentrating on Modal Logics that support data comparison operators. Here, we introduce an internalized tableau calculus for XPath, arguably one of the most prominent approaches for querying semistructured data. More precisely, we define data-aware tableaux for XPath featuring data comparison operators and enriched with nominals and the satisfiability modalities from Hybrid Logic. We prove that the calculus is sound, complete and terminating. Moreover, we show that tableaux can be explored in polynomial space, therefore establishing that the satisfiability problem for the logic is PSPACE-complete. Finally, we explore different extensions of the calculus, in particular how to handle data trees and other frame classes.",
      "authors": [
        "Carlos Areces",
        "Valentin Cassano and Raul Fervari"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2406.12090",
        "HTML": "https://arxiv.org/html/2406.12090",
        "PDF": "https://arxiv.org/pdf/2406.12090"
      },
      "subjects": [
        "Logic in Computer Science (cs.LO)"
      ],
      "submission_historys": [
        {
          "date": "Mon, 17 Jun 2024 21:04:47 GMT",
          "size": "73kb",
          "version": "v1"
        },
        {
          "date": "Thu, 26 Jun 2025 14:29:22 GMT",
          "size": "76kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Data-Aware Hybrid Tableaux",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on internalized tableau calculus for XPath and data-aware tableaux, with no mention of training data processing or methods related to LLM data engineering."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2406.18582",
      "abstract": "We introduce Canonical Consolidation Fields (CanFields). This novel method interpolates arbitrary-length sequences of independently sampled 3D point clouds into a unified, continuous, and coherent deforming shape. Unlike prior methods that oversmooth geometry or produce topological and geometric artifacts, CanFields optimizes fine-detailed geometry and deformation jointly in an unsupervised fitting with two novel bespoke modules. First, we introduce a dynamic consolidator module that adjusts the input and assigns confidence scores, balancing the optimization of the canonical shape and its motion. Second, we represent the motion as a diffeomorphic flow parameterized by a smooth velocity field. We have validated our robustness and accuracy on more than 50 diverse sequences, demonstrating its superior performance even with missing regions, noisy raw scans, and sparse data. Our project page is at: https://wangmiaowei.github.io/CanFields.github.io/.",
      "authors": [
        "Miaowei Wang",
        "Changjian Li",
        "Amir Vaxman"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2406.18582",
        "HTML": "https://arxiv.org/html/2406.18582",
        "PDF": "https://arxiv.org/pdf/2406.18582"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Graphics (cs.GR)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 05 Jun 2024 17:07:55 GMT",
          "size": "49254kb",
          "version": "v1"
        },
        {
          "date": "Wed, 27 Nov 2024 18:14:05 GMT",
          "size": "34974kb",
          "version": "v2"
        },
        {
          "date": "Thu, 26 Jun 2025 17:53:33 GMT",
          "size": "43448kb",
          "version": "v3"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "CanFields: Consolidating Diffeomorphic Flows for Non-Rigid 4D Interpolation from Arbitrary-Length Sequences",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper introduces methods for 4D interpolation of 3D point clouds, which does not relate to LLM training data processing or data engineering for language models."
      },
      "tasks": [],
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2407.00304",
      "abstract": "Given the availability of more comprehensive measurement data in modern power systems, reinforcement learning (RL) has gained significant interest in operation and control. Conventional RL relies on trial-and-error interactions with the environment and reward feedback, which often leads to exploring unsafe operating regions and executing unsafe actions, especially when deployed in real-world power systems. To address these challenges, safe RL has been proposed to optimize operational objectives while ensuring safety constraints are met, keeping actions and states within safe regions throughout both training and deployment. Rather than relying solely on manually designed penalty terms for unsafe actions, as is common in conventional RL, safe RL methods reviewed here primarily leverage advanced and proactive mechanisms. These include techniques such as Lagrangian relaxation, safety layers, and theoretical guarantees like Lyapunov functions to rigorously enforce safety boundaries. This paper provides a comprehensive review of safe RL methods and their applications across various power system operations and control domains, including security control, real-time operation, operational planning, and emerging areas. It summarizes existing safe RL techniques, evaluates their performance, analyzes suitable deployment scenarios, and examines algorithm benchmarks and application environments. The paper also highlights real-world implementation cases and identifies critical challenges such as scalability in large-scale systems and robustness under uncertainty, providing potential solutions and outlining future directions to advance the reliable integration and deployment of safe RL in modern power systems.",
      "authors": [
        "Tong Su",
        "Tong Wu",
        "Junbo Zhao",
        "Anna Scaglione",
        "Le Xie"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2407.00304",
        "HTML": "https://arxiv.org/html/2407.00304",
        "PDF": "https://arxiv.org/pdf/2407.00304"
      },
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "Sat, 29 Jun 2024 03:59:06 GMT",
          "size": "834kb",
          "version": "v1"
        },
        {
          "date": "Thu, 26 Jun 2025 00:13:34 GMT",
          "size": "2468kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "A Review of Safe Reinforcement Learning Methods for Modern Power Systems",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper is a review of safe reinforcement learning methods applied to power systems and does not contribute to the data processing or engineering for training language models."
      },
      "tasks": [
        "energy management",
        "Reinforcement Learning (RL)",
        "Safe Reinforcement Learning",
        "Scheduling"
      ],
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2407.02290",
      "abstract": "Sharing or publishing social network data while accounting for privacy of individuals is a difficult task due to the interconnectedness of nodes in networks. A key question in k-anonymity, a widely studied notion of privacy, is how to measure the anonymity of an individual, as this determines the attacker scenarios one protects against. In this paper, we systematically compare the most prominent anonymity measures from the literature in terms of the completeness and reach of the structural information they take into account. We present a theoretical characterization and a distance-parametrized strictness ordering of the existing measures for k-anonymity in networks. In addition, we conduct empirical experiments on a wide range of real-world network datasets with up to millions of edges. Our findings reveal that the choice of the measure significantly impacts the measured level of anonymity and hence the effectiveness of the corresponding attacker scenario, the privacy vs. utility trade-off, and computational cost. Surprisingly, we find that the anonymity measure representing the most effective attacker scenario considers a greater node vicinity yet utilizes only limited structural information and therewith minimal computational resources. Overall, the insights provided in this work offer researchers and practitioners practical guidance for selecting appropriate anonymity measures when sharing or publishing social network data under privacy constraints.",
      "authors": [
        "Rachel G. de Jong",
        "Mark P. J. van der Loo",
        "Frank W. Takes"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2407.02290",
        "HTML": "https://arxiv.org/html/2407.02290",
        "PDF": "https://arxiv.org/pdf/2407.02290"
      },
      "subjects": [
        "Social and Information Networks (cs.SI)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 02 Jul 2024 14:25:25 GMT",
          "size": "1681kb",
          "version": "v1"
        },
        {
          "date": "Thu, 26 Jun 2025 15:44:06 GMT",
          "size": "2589kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "A systematic comparison of measures for publishing k-anonymous social network data",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper primarily focuses on privacy measures for sharing social network data and does not discuss the processing or preparation of LLM training data."
      },
      "repo_urls": [
        "https://github.com/RacheldeJong/ANONET"
      ],
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2407.04092",
      "abstract": "To efficiently deploy strong, often pre-trained feature extractors, recent Industrial Anomaly Detection and Segmentation (IADS) methods process low-resolution images, e.g., 224x224 pixels, obtained by downsampling the original input images. However, while numerous industrial applications demand the identification of both large and small defects, downsampling the input image to a low resolution may hinder a method's ability to pinpoint tiny anomalies. We propose a novel Teacher--Student paradigm to leverage strong pre-trained features while processing high-resolution input images very efficiently. The core idea concerns training two shallow MLPs (the Students) by nominal images so as to mimic the mappings between the patch embeddings induced by the self-attention layers of a frozen vision Transformer (the Teacher). Indeed, learning these mappings sets forth a challenging pretext task that small-capacity models are unlikely to accomplish on out-of-distribution data such as anomalous images. Our method can spot anomalies from high-resolution images and runs way faster than competitors, achieving state-of-the-art performance on MVTec AD and the best segmentation results on VisA. We also propose novel evaluation metrics to capture robustness to defect size, i.e., the ability to preserve good localisation from large anomalies to tiny ones. Evaluating our method also by these metrics reveals its neatly superior performance.",
      "authors": [
        "Alex Costanzino",
        "Pierluigi Zama Ramirez",
        "Giuseppe Lisanti",
        "Luigi Di Stefano"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2407.04092",
        "HTML": "https://arxiv.org/html/2407.04092",
        "PDF": "https://arxiv.org/pdf/2407.04092"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 04 Jul 2024 17:59:26 GMT",
          "size": "37778kb",
          "version": "v1"
        },
        {
          "date": "Mon, 08 Jul 2024 13:19:01 GMT",
          "size": "37772kb",
          "version": "v2"
        },
        {
          "date": "Thu, 26 Jun 2025 17:59:51 GMT",
          "size": "5948kb",
          "version": "v3"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Learning to Be a Transformer to Pinpoint Anomalies",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The study targets anomaly detection in industrial applications and does not pertain to the processing or collection of training data for LLMs."
      },
      "tasks": [
        "Anomaly Detection",
        "Segmentation"
      ],
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2407.04591",
      "abstract": "This paper focuses on the online saddle point problem, which involves a sequence of two-player time-varying convex-concave games. Considering the nonstationarity of the environment, we adopt the duality gap and the dynamic Nash equilibrium regret as performance metrics for algorithm design. We present three variants of the proximal point method: the Online Proximal Point Method (OPPM), the Optimistic OPPM (OptOPPM), and the OptOPPM with multiple predictors. Each algorithm guarantees upper bounds for both the duality gap and dynamic Nash equilibrium regret, achieving near-optimality when measured against the duality gap. Specifically, in certain benign environments, such as sequences of stationary payoff functions, these algorithms maintain a nearly constant metric bound. Experimental results further validate the effectiveness of these algorithms. Lastly, this paper discusses potential reliability concerns associated with using dynamic Nash equilibrium regret as a performance metric. The technical appendix and code can be found at https://github.com/qingxin6174/PPM-for-OSP.",
      "authors": [
        "Qing-xin Meng and Jian-wei Liu"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2407.04591",
        "HTML": "https://arxiv.org/html/2407.04591",
        "PDF": "https://arxiv.org/pdf/2407.04591"
      },
      "subjects": [
        "Machine Learning (cs.LG)",
        "Optimization and Control (math.OC)"
      ],
      "submission_historys": [
        {
          "date": "Fri, 05 Jul 2024 15:40:15 GMT",
          "size": "1544kb",
          "version": "v1"
        },
        {
          "date": "Tue, 08 Oct 2024 09:40:07 GMT",
          "size": "979kb",
          "version": "v2"
        },
        {
          "date": "Thu, 26 Jun 2025 05:01:47 GMT",
          "size": "980kb",
          "version": "v3"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Proximal Point Method for Online Saddle Point Problem",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper addresses the online saddle point problem in a game-theoretic context, unrelated to any LLM training data processing."
      },
      "tasks": [],
      "repo_urls": [
        "https://github.com/qingxin6174/ppm-for-osp"
      ],
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2407.11933",
      "abstract": "Target-group detection is the task of detecting which group(s) a social media post is ``directed at or about'', with various applications, such as targeted-marketing. In this work, we focus on the fairness implications of target-group detection in the context of toxicity detection, where the perceived harm of a post often depends on which group(s) it targets. Because toxicity is highly contextual, language that appears benign in general may be harmful when targeting specific demographic groups. It is thus important to first detect which group(s) are being {\\em targeted} by a post as a precursor to the subsequent task of determining whether the post is toxic given the group(s). Target-group detection is also challenging: a single post may simultaneously target one to many groups, and we must detect groups fairly in order to promote equitable treatment. We show that our proposed approach to {\\em fairness-aware multi target-group detection} not only reduces bias across groups, but also achieves competitive predictive performance, outperforming existing fairness-aware baselines. To spur future research on fairness-aware target-group detection and support competitive benchmarking, we also share our code.",
      "authors": [
        "Soumyajit Gupta",
        "Maria De-Arteaga",
        "Matthew Lease"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2407.11933",
        "HTML": "https://arxiv.org/html/2407.11933",
        "PDF": "https://arxiv.org/pdf/2407.11933"
      },
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 16 Jul 2024 17:23:41 GMT",
          "size": "235kb",
          "version": "v1"
        },
        {
          "date": "Wed, 25 Jun 2025 23:07:40 GMT",
          "size": "177kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Fairly Accurate: Fairness-aware Multi-group Target Detection in Online Discussion",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The focus is on fairness in target-group detection for social media, without addressing training data processing specifically for LLMs."
      },
      "tasks": [
        "Fairness"
      ],
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2408.00968",
      "abstract": "The absence of security and privacy measures between DNS recursive resolvers and authoritative nameservers has been exploited by both on-path and off-path attackers. Although numerous security proposals have been introduced in practice and in the literature, they often face deployability barriers and/or lack a compelling set of security and privacy properties, resulting in limited adoption. We introduce ss2DNS, a novel DNS scheme designed to mitigate the security and privacy vulnerabilities in the resolution process between resolvers and authoritative nameservers, while preserving efficiency by maintaining a single round-trip. ss2DNS takes advantage of a hierarchical trust model that does not rely on entities external to DNS zones, and delegates nameserver replicas within each zone to serve zone data securely for short, renewable time intervals. This design enables real-time security properties for DNS messages without requiring the duplication of long-term private keys on replicas, thereby minimizing exposure to compromise. We implement a proof of concept of ss2DNS for evaluation and show that for server-side processing latency, resolution time, and CPU usage, ss2DNS is comparable to less-secure schemes but significantly outperforms DNS-over-TLS.",
      "authors": [
        "Ali Sadeghi Jahromi",
        "AbdelRahman Abdou",
        "Paul C. van Oorschot"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2408.00968",
        "HTML": "https://arxiv.org/html/2408.00968",
        "PDF": "https://arxiv.org/pdf/2408.00968"
      },
      "subjects": [
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "Fri, 02 Aug 2024 01:25:14 GMT",
          "size": "306kb",
          "version": "v1"
        },
        {
          "date": "Sun, 20 Apr 2025 20:15:52 GMT",
          "size": "403kb",
          "version": "v2"
        },
        {
          "date": "Thu, 26 Jun 2025 03:14:28 GMT",
          "size": "338kb",
          "version": "v3"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "ss2DNS: A Secure DNS Scheme in Stage 2",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper introduces a secure DNS scheme, which is not related to LLM training data processing or data engineering tasks."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2408.04209",
      "abstract": "This work proposes a novel numerical scheme for solving the high-dimensional Hamilton-Jacobi-Bellman equation with a functional hierarchical tensor ansatz. We consider the setting of stochastic control, whereby one applies control to a particle under Brownian motion. In particular, the existence of diffusion presents a new challenge to conventional tensor network methods for deterministic optimal control. To overcome the difficulty, we use a general regression-based formulation where the loss term is the Bellman consistency error combined with a Sobolev-type penalization term. We propose two novel sketching-based subroutines for obtaining the tensor-network approximation to the action-value functions and the value functions, which greatly accelerate the convergence for the subsequent regression phase. We apply the proposed approach successfully to two challenging control problems with Ginzburg-Landau potential in 1D and 2D with 64 variables.",
      "authors": [
        "Xun Tang",
        "Nan Sheng and Lexing Ying"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2408.04209",
        "HTML": "https://arxiv.org/html/2408.04209",
        "PDF": "https://arxiv.org/pdf/2408.04209"
      },
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 08 Aug 2024 04:26:56 GMT",
          "size": "4656kb",
          "version": "v1"
        },
        {
          "date": "Thu, 26 Jun 2025 04:57:36 GMT",
          "size": "4096kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Solving high-dimensional Hamilton-Jacobi-Bellman equation with functional hierarchical tensor",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper addresses a numerical scheme for solving high-dimensional Hamilton-Jacobi-Bellman equations, focusing on stochastic control problems. It does not involve LLM training data processing."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2408.12869",
      "abstract": "Given a $\\{0,1\\}$-matrix $M$, the graph realization problem for $M$ asks if there exists a spanning forest such that the columns of $M$ are incidence vectors of paths in the forest. The problem is closely related to the recognition of network matrices, which are a large subclass of totally unimodular matrices and have many applications in mixed-integer programming. Existing efficient algorithms for graph realization grow a submatrix in a column-wise fashion whilst maintaining a graphic realization. In the context of mixed-integer linear programming, this limits the set of submatrices of the constraint matrix that can efficiently be determined to be network matrices to network submatrices that span all rows and a subset of the columns. This paper complements the existing work by providing an algorithm that works in a row-wise fashion and uses similar data structures, and enables the detection of arbitrary graphic submatrices. The main challenge in designing efficient algorithms for the graph realization problem is ambiguity as there may exist many graphs realizing $M$. The key insight for designing an efficient row-wise algorithm is that a graphic matrix is uniquely represented by an SPQR-tree, a graph decomposition that stores all graphs with the same set of cycles. The developed row-wise algorithm uses data structures that are compatible with the column-wise algorithm and can be combined with the latter to detect maximal graphic submatrices.",
      "authors": [
        "Rolf van der Hulst",
        "Matthias Walter"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2408.12869",
        "HTML": "https://arxiv.org/html/2408.12869",
        "PDF": "https://arxiv.org/pdf/2408.12869"
      },
      "subjects": [
        "Discrete Mathematics (cs.DM)",
        "Combinatorics (math.CO)"
      ],
      "submission_historys": [
        {
          "date": "Fri, 23 Aug 2024 06:59:15 GMT",
          "size": "77kb",
          "version": "v1"
        },
        {
          "date": "Thu, 26 Jun 2025 12:17:02 GMT",
          "size": "86kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "A Row-wise Algorithm for Graph Realization",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper presents an algorithm for graph realization related to mixed-integer programming. It does not pertain to the processing of LLM training data specifically."
      },
      "repo_urls": [
        "https://github.com/rolfvdhulst/matrec"
      ],
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2408.16717",
      "abstract": "In the last years, many learning-based approaches have been proposed to tackle combinatorial optimization problems such as routing problems. Many of these approaches are based on graph neural networks (GNNs) or related transformers, operating on the Euclidean coordinates representing the routing problems. However, models operating on Euclidean coordinates are ill-suited for non-Euclidean, asymmetric problem instances that are often found in real-world settings. To overcome this limitation, we propose a novel GNN-based and edge-focused neural model called Graph Edge Attention Network (GREAT). Using GREAT as an encoder to capture the properties of a routing problem instance, we build a reinforcement learning framework which we apply to Euclidean and non-Euclidean variants of vehicle routing problems such as Traveling Salesman Problem, Capacitated Vehicle Routing Problem and Orienteering Problem. Our framework is among the first to tackle non-Euclidean variants of these problems and achieves competitive results among learning-based solvers.",
      "authors": [
        "Attila Lischka",
        "Filip Rydin",
        "Jiaming Wu",
        "Morteza Haghir Chehreghani",
        "Bal\\'azs Kulcs\\'ar"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2408.16717",
        "HTML": "https://arxiv.org/html/2408.16717",
        "PDF": "https://arxiv.org/pdf/2408.16717"
      },
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 29 Aug 2024 17:07:43 GMT",
          "size": "1863kb",
          "version": "v1"
        },
        {
          "date": "Thu, 26 Jun 2025 13:54:56 GMT",
          "size": "1244kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "A GREAT Architecture for Edge-Based Graph Problems Like TSP",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper proposes a model for solving combinatorial optimization problems using graph neural networks, focusing on routing problems. It does not discuss LLM training data processing."
      },
      "tasks": [
        "Combinatorial Optimization",
        "Edge Classification",
        "Traveling Salesman Problem"
      ],
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2408.17443",
      "abstract": "Long-form video understanding presents unique challenges that extend beyond traditional short-video analysis approaches, particularly in capturing long-range dependencies, processing redundant information efficiently, and extracting high-level semantic concepts. To address these challenges, we propose a novel approach that more accurately reflects human cognition. This paper introduces HERMES: temporal-coHERent long-forM understanding with Episodes and Semantics, featuring two versatile modules that can enhance existing video-language models or operate as a standalone system. Our Episodic COmpressor (ECO) efficiently aggregates representations from micro to semi-macro levels, reducing computational overhead while preserving temporal dependencies. Our Semantics ReTRiever (SeTR) enriches these representations with semantic information by focusing on broader context, dramatically reducing feature dimensionality while preserving relevant macro-level information. We demonstrate that these modules can be seamlessly integrated into existing SOTA models, consistently improving their performance while reducing inference latency by up to 43% and memory usage by 46%. As a standalone system, HERMES achieves state-of-the-art performance across multiple long-video understanding benchmarks in both zero-shot and fully-supervised settings.",
      "authors": [
        "Gueter Josmy Faure",
        "Jia-Fong Yeh",
        "Min-Hung Chen",
        "Hung-Ting Su",
        "Shang-Hong Lai",
        "Winston H. Hsu"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2408.17443",
        "HTML": "https://arxiv.org/html/2408.17443",
        "PDF": "https://arxiv.org/pdf/2408.17443"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "Fri, 30 Aug 2024 17:52:55 GMT",
          "size": "3072kb",
          "version": "v1"
        },
        {
          "date": "Fri, 20 Sep 2024 08:15:10 GMT",
          "size": "33734kb",
          "version": "v2"
        },
        {
          "date": "Sat, 09 Nov 2024 06:46:41 GMT",
          "size": "34379kb",
          "version": "v3"
        },
        {
          "date": "Thu, 26 Jun 2025 08:46:37 GMT",
          "size": "7229kb",
          "version": "v4"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "HERMES: temporal-coHERent long-forM understanding with Episodes and Semantics",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on improving long-form video understanding and proposes modules to enhance video-language models. It does not address any aspect of LLM training data processing or construction."
      },
      "tasks": [
        "Form",
        "Video Classification",
        "zero-shot long video breakpoint-mode question answering",
        "zero-shot long video global-model question answering",
        "zero-shot long video global-mode question answering",
        "zero-shot long video question answering"
      ],
      "repo_urls": [
        "https://github.com/joslefaure/HERMES"
      ],
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2409.01211",
      "abstract": "The main motivation behind this paper stems from a notable gap in the existing literature: the absence of a discrete counterpart to the Laplace-Beltrami operator on Riemannian manifolds, which can be effectively used to solve PDEs. We consider that the natural approach to pioneer this field is first to explore one of the simplest non-trivial (i.e., non-Euclidean) scenarios, specifically focusing on the $2$-dimensional hyperbolic space $\\mathbb{H}^2$. We present two variants of discrete finite-difference operator tailored to this constant negatively curved space, both serving as approximations to the (continuous) Laplace-Beltrami operator within the $\\mathrm{L}^2$ framework.\n  We prove that the discrete heat equation associated with both operators mentioned above exhibits stability and converges towards the continuous heat-Beltrami Cauchy problem on $\\mathbb{H}^2$. Moreover, using techniques inspired from the sharp analysis of discrete functional inequalities, we prove that the solutions of the discrete heat equations corresponding to both variants of discrete Laplacian exhibit an exponential decay asymptotically equal to the one induced by the Poincar\\'e inequality on $\\mathbb{H}^2$.\n  Eventually, we illustrate that a discrete Laplacian specifically designed for the geometry of the hyperbolic space yields a more precise approximation and offers advantages from both theoretical and computational perspectives. Furthermore, this discrete operator can be effectively generalized to the three-dimensional hyperbolic space.",
      "authors": [
        "Mihai Bucataru and Drago\\c{s} Manea"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2409.01211",
        "HTML": "https://arxiv.org/html/2409.01211",
        "PDF": "https://arxiv.org/pdf/2409.01211"
      },
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)",
        "Analysis of PDEs (math.AP)"
      ],
      "submission_historys": [
        {
          "date": "Mon, 02 Sep 2024 12:42:03 GMT",
          "size": "1000kb",
          "version": "v1"
        },
        {
          "date": "Thu, 26 Jun 2025 07:30:51 GMT",
          "size": "1198kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Discrete Laplacians on the hyperbolic space -- a compared study",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper is a mathematical study on discrete Laplacians in hyperbolic space, with no discussion or contribution related to training data for LLMs or data processing."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2409.08115",
      "abstract": "The MIT/IEEE/Amazon GraphChallenge encourages community approaches to developing new solutions for analyzing graphs and sparse data derived from social media, sensor feeds, and scientific data to discover relationships between events as they unfold in the field. The anonymized network sensing Graph Challenge seeks to enable large, open, community-based approaches to protecting networks. Many large-scale networking problems can only be solved with community access to very broad data sets with the highest regard for privacy and strong community buy-in. Such approaches often require community-based data sharing. In the broader networking community (commercial, federal, and academia) anonymized source-to-destination traffic matrices with standard data sharing agreements have emerged as a data product that can meet many of these requirements. This challenge provides an opportunity to highlight novel approaches for optimizing the construction and analysis of anonymized traffic matrices using over 100 billion network packets derived from the largest Internet telescope in the world (CAIDA). This challenge specifies the anonymization, construction, and analysis of these traffic matrices. A GraphBLAS reference implementation is provided, but the use of GraphBLAS is not required in this Graph Challenge. As with prior Graph Challenges the goal is to provide a well-defined context for demonstrating innovation. Graph Challenge participants are free to select (with accompanying explanation) the Graph Challenge elements that are appropriate for highlighting their innovations.",
      "authors": [
        "Hayden Jananthan",
        "Michael Jones",
        "William Arcand",
        "David Bestor",
        "William Bergeron",
        "Daniel Burrill",
        "Aydin Buluc",
        "Chansup Byun",
        "Timothy Davis",
        "Vijay Gadepally",
        "Daniel Grant",
        "Michael Houle",
        "Matthew Hubbell",
        "Piotr Luszczek",
        "Peter Michaleas",
        "Lauren Milechin",
        "Chasen Milner",
        "Guillermo Morales",
        "Andrew Morris",
        "Julie Mullen",
        "Ritesh Patel",
        "Alex Pentland",
        "Sandeep Pisharody",
        "Andrew Prout",
        "Albert Reuther",
        "Antonio Rosa",
        "Gabriel Wachman",
        "Charles Yee",
        "Jeremy Kepner"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2409.08115",
        "HTML": "https://arxiv.org/html/2409.08115",
        "PDF": "https://arxiv.org/pdf/2409.08115"
      },
      "subjects": [
        "Networking and Internet Architecture (cs.NI)",
        "Discrete Mathematics (cs.DM)",
        "Performance (cs.PF)",
        "Software Engineering (cs.SE)",
        "Combinatorics (math.CO)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 12 Sep 2024 15:07:16 GMT",
          "size": "251kb",
          "version": "v1"
        },
        {
          "date": "Thu, 26 Jun 2025 15:06:28 GMT",
          "size": "221kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Anonymized Network Sensing Graph Challenge",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper discusses a graph challenge related to anonymized network sensing and traffic matrices. It does not address the processing or construction of training data specifically for LLMs."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2409.12335",
      "abstract": "The foundations of deep learning are supported by the seemingly opposing perspectives of approximation or learning theory. The former advocates for large/expressive models that need not generalize, while the latter considers classes that generalize but may be too small/constrained to be universal approximators. Motivated by real-world deep learning implementations that are both expressive and statistically reliable, we ask: \"Is there a class of neural networks that is both large enough to be universal but structured enough to generalize?\" This paper constructively provides a positive answer to this question by identifying a highly structured class of ReLU multilayer perceptions (MLPs), which are optimal function approximators and are statistically well-behaved. We show that any $(L,\\alpha)$-H\\\"{o}lder function from $[0,1]^d$ to $[-n,n]$ can be approximated to a uniform $\\mathcal{O}(1/n)$ error on $[0,1]^d$ with a sparsely connected ReLU MLP with the same H\\\"{o}lder exponent $\\alpha$ and coefficient $L$, of width $\\mathcal{O}(dn^{d/\\alpha})$, depth $\\mathcal{O}(\\log(d))$, with $\\mathcal{O}(dn^{d/\\alpha})$ nonzero parameters, and whose weights and biases take values in $\\{0,\\pm 1/2\\}$ except in the first and last layers which instead have magnitude at-most $n$. Further, our class of MLPs achieves a near-optimal sample complexity of $\\mathcal{O}(\\log(N)/\\sqrt{N})$ when given $N$ i.i.d. normalized sub-Gaussian training samples. We achieve this through a new construction that perfectly fits together linear pieces using Kuhn triangulations, along with a new proof technique which shows that our construction preserves the regularity of not only the H\\\"{o}lder functions, but also any uniformly continuous function. Our results imply that neural networks can solve the McShane extension problem on suitable finite sets.",
      "authors": [
        "Ruiyang Hong",
        "Anastasis Kratsios"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2409.12335",
        "HTML": "https://arxiv.org/html/2409.12335",
        "PDF": "https://arxiv.org/pdf/2409.12335"
      },
      "subjects": [
        "Machine Learning (cs.LG)",
        "Numerical Analysis (cs.NA)",
        "Neural and Evolutionary Computing (cs.NE)",
        "Functional Analysis (math.FA)",
        "Numerical Analysis (math.NA)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 18 Sep 2024 22:05:07 GMT",
          "size": "458kb",
          "version": "v1"
        },
        {
          "date": "Wed, 18 Jun 2025 04:49:08 GMT",
          "size": "730kb",
          "version": "v2"
        },
        {
          "date": "Tue, 24 Jun 2025 18:03:32 GMT",
          "size": "1109kb",
          "version": "v3"
        },
        {
          "date": "Thu, 26 Jun 2025 04:08:57 GMT",
          "size": "1109kb",
          "version": "v4"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Bridging the Gap Between Approximation and Learning via Optimal Approximation by ReLU MLPs of Maximal Regularity",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper discusses the theoretical aspects of function approximation by neural networks, specifically ReLU MLPs, without involvement in LLM training data processing."
      },
      "tasks": [
        "Learning Theory"
      ],
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2409.13568",
      "abstract": "Accurate delineation of agricultural field boundaries is essential for effective crop monitoring and resource management. However, competing methodologies often face significant challenges, particularly in their reliance on extensive manual efforts for cloud-free data curation and limited adaptability to diverse global conditions. In this paper, we introduce PTAViT3D, a deep learning architecture specifically designed for processing three-dimensional time series of satellite imagery from either Sentinel-1 (S1) or Sentinel-2 (S2). Additionally, we present PTAViT3D-CA, an extension of the PTAViT3D model incorporating cross-attention mechanisms to fuse S1 and S2 datasets, enhancing robustness in cloud-contaminated scenarios. The proposed methods leverage spatio-temporal correlations through a memory-efficient 3D Vision Transformer architecture, facilitating accurate boundary delineation directly from raw, cloud-contaminated imagery. We comprehensively validate our models through extensive testing on various datasets, including Australia's ePaddocks - CSIRO's national agricultural field boundary product - alongside public benchmarks Fields-of-the-World, PASTIS, and AI4SmallFarms. Our results consistently demonstrate state-of-the-art performance, highlighting excellent global transferability and robustness. Crucially, our approach significantly simplifies data preparation workflows by reliably processing cloud-affected imagery, thereby offering strong adaptability across diverse agricultural environments. Our code and models are publicly available at https://github.com/feevos/tfcl.",
      "authors": [
        "Foivos I. Diakogiannis",
        "Zheng-Shu Zhou",
        "Jeff Wang",
        "Gonzalo Mata",
        "Dave Henry",
        "Roger Lawes",
        "Amy Parker",
        "Peter Caccetta",
        "Rodrigo Ibata",
        "Ondrej Hlinka",
        "Jonathan Richetti",
        "Kathryn Batchelor",
        "Chris Herrmann",
        "Andrew Toovey",
        "John Taylor"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2409.13568",
        "HTML": "https://arxiv.org/html/2409.13568",
        "PDF": "https://arxiv.org/pdf/2409.13568"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Fri, 20 Sep 2024 15:10:04 GMT",
          "size": "23552kb",
          "version": "v1"
        },
        {
          "date": "Thu, 26 Jun 2025 15:08:46 GMT",
          "size": "11834kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Tackling fluffy clouds: robust field boundary delineation across global agricultural landscapes with Sentinel-1 and Sentinel-2 Time Series",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This work develops a model for processing satellite imagery for agricultural purposes, focusing on field boundary delineation and not involving LLM training data processing."
      },
      "tasks": [
        "Field Boundary Delineation",
        "Time Series"
      ],
      "repo_urls": [
        "https://github.com/feevos/tfcl"
      ],
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2409.18307",
      "abstract": "This paper establishes the exact strong converse exponent of the soft covering problem in the classical setting. This exponent characterizes the slowest achievable convergence speed of the total variation to one when a code of rate below mutual information is applied to a discrete memoryless channel for synthesizing a product output distribution. The proposed exponent is expressed through a new two-parameter quantity, differing from the more commonly studied R\\'enyi divergence or R\\'enyi mutual information, both of which have a single parameter and frequently appear in the literature of error exponents. Additionally, we provide a random coding achievability bound that takes the typical form involving the R\\'enyi mutual information, but it is not tight in general in the strong converse regime of the classical soft covering problem.",
      "authors": [
        "Xingyi He",
        "S. Sandeep Pradhan",
        "and Andreas Winter"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2409.18307",
        "HTML": "https://arxiv.org/html/2409.18307",
        "PDF": "https://arxiv.org/pdf/2409.18307"
      },
      "subjects": [
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Sep 2024 21:37:21 GMT",
          "size": "32kb",
          "version": "v1"
        },
        {
          "date": "Wed, 25 Jun 2025 23:11:16 GMT",
          "size": "333kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "On the Strong Converse Exponent of the Classical Soft Covering",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper is focused on the strong converse exponent of the classical soft covering problem in information theory, which is unrelated to LLM training data processing."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2409.18589",
      "abstract": "Networked control systems enable real-time control and coordination of distributed systems, leveraging the low latency, high reliability, and massive connectivity offered by 5G and future 6G networks. Applications include autonomous vehicles, robotics, industrial automation, and smart grids. Despite networked control algorithms admitting nominal stability guarantees even in the presence of delays and packet dropouts, their practical performance still heavily depends on the specific characteristics and conditions of the underlying network. To achieve the desired performance while efficiently using communication resources, co-design of control and communication is pivotal. Although periodic schemes, where communication instances are fixed, can provide reliable control performance, unnecessary transmissions, when updates are not needed, result in inefficient usage of network resources. In this paper, we investigate the potential for co-design of model predictive control and network communication. To this end, we design and implement an event-triggered nonlinear model predictive controller for stabilizing a Furuta pendulum communicating over a tailored open radio access network 6G research platform. We analyze the control performance as well as network utilization under varying channel conditions and event-triggering criteria. Additionally, we analyze the network-induced delay pattern and its interaction with the event-triggered controller. Our results show that the event-triggered control scheme achieves similar performance to periodic control with reduced communication demand.",
      "authors": [
        "Jens P\\\"uttschneider",
        "Julian Golembiewski",
        "Niklas A. Wagner",
        "Christian Wietfeld",
        "Timm Faulwasser"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2409.18589",
        "HTML": "https://arxiv.org/html/2409.18589",
        "PDF": "https://arxiv.org/pdf/2409.18589"
      },
      "subjects": [
        "Systems and Control (eess.SY)",
        "Networking and Internet Architecture (cs.NI)",
        "Systems and Control (cs.SY)",
        "Optimization and Control (math.OC)"
      ],
      "submission_historys": [
        {
          "date": "Fri, 27 Sep 2024 09:47:10 GMT",
          "size": "793kb",
          "version": "v1"
        },
        {
          "date": "Thu, 26 Jun 2025 14:12:42 GMT",
          "size": "733kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Towards Event-Triggered NMPC for Efficient 6G Communications: Experimental Results and Open Problems",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper pertains to networked control systems and model predictive control, analyzing control performance and network utilization, which are unrelated to LLM training data processing."
      },
      "tasks": [
        "Autonomous Vehicles",
        "Model Predictive Control"
      ],
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2410.07254",
      "abstract": "In this paper, we study the uniform accuracy of implicit-explicit (IMEX) Runge-Kutta (RK) schemes for general linear hyperbolic relaxation systems satisfying the structural stability condition proposed in \\cite{yong_singular_1999}. We establish the uniform stability and accuracy of a class of IMEX-RK schemes with spatial discretization using a Fourier spectral method. Our results demonstrate that the accuracy of the fully discretized schemes is independent of the relaxation time across all regimes. Numerical experiments on applications in traffic flows and kinetic theory verify our theoretical analysis.",
      "authors": [
        "Zhiting Ma",
        "Juntao Huang"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.07254",
        "HTML": "https://arxiv.org/html/2410.07254",
        "PDF": "https://arxiv.org/pdf/2410.07254"
      },
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)",
        "Computational Physics (physics.comp-ph)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 08 Oct 2024 14:26:09 GMT",
          "size": "69kb",
          "version": "v1"
        },
        {
          "date": "Thu, 26 Jun 2025 16:41:03 GMT",
          "size": "89kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Uniform accuracy of implicit-explicit Runge-Kutta methods for linear hyperbolic relaxation systems",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This study is on numerical methods for hyperbolic relaxation systems, with no connection to LLM training data processing or preparation."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2410.08082",
      "abstract": "In this paper, we highlight a critical yet often overlooked factor in most 3D human tasks, namely modeling complicated 3D human with with hand-held objects or loose-fitting clothing. It is known that the parameterized formulation of SMPL is able to fit human skin; while hand-held objects and loose-fitting clothing, are difficult to get modeled within the unified framework, since their movements are usually decoupled with the human body. To enhance the capability of SMPL skeleton in response to this situation, we propose a growth strategy that enables the joint tree of the skeleton to expand adaptively. Specifically, our method, called ToMiE, consists of parent joints localization and external joints optimization. For parent joints localization, we employ a gradient-based approach guided by both LBS blending weights and motion kernels. Once the external joints are obtained, we proceed to optimize their transformations in SE(3) across different frames, enabling rendering and explicit animation. ToMiE manages to outperform other methods across various cases with hand-held objects and loose-fitting clothing, not only in rendering quality but also by offering free animation of grown joints, thereby enhancing the expressive ability of SMPL skeleton for a broader range of applications.",
      "authors": [
        "Yifan Zhan",
        "Qingtian Zhu",
        "Muyao Niu",
        "Mingze Ma",
        "Jiancheng Zhao",
        "Zhihang Zhong",
        "Xiao Sun",
        "Yu Qiao",
        "Yinqiang Zheng"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.08082",
        "HTML": "https://arxiv.org/html/2410.08082",
        "PDF": "https://arxiv.org/pdf/2410.08082"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 10 Oct 2024 16:25:52 GMT",
          "size": "1566kb",
          "version": "v1"
        },
        {
          "date": "Thu, 26 Jun 2025 06:47:51 GMT",
          "size": "2000kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "ToMiE: Towards Explicit Exoskeleton for the Reconstruction of Complicated 3D Human Avatars",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on improving 3D human modeling by extending the SMPL framework to handle hand-held objects and clothing, which is unrelated to LLM training data processing or data engineering."
      },
      "tasks": [],
      "repo_urls": [
        "https://github.com/Yifever20002/ToMiE"
      ],
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2410.08165",
      "abstract": "Modern vision models have achieved remarkable success in benchmarks where local features provide critical information about the target. There is now a growing interest in tackling tasks requiring more global reasoning, where local features do not provide significant information. Minsky and Papert put forward such tasks in 1969 with their connectivity study, exposing the limitations of the perceptron model. In this paper, we introduce an expanded set of global visual datasets involving graphs, strings, mazes, and image grids. We show that large vision models still struggle to learn these tasks efficiently. Similarly, state-of-the-art multi-modal LLMs perform poorly on these datasets. We explain this learning inefficiency by means of the 'globality degree' measure. To mitigate this, we propose a method called chain-of-sketch (CoS). Similar to the chain-of-thought and scratchpad techniques used in language models, CoS breaks the original task into intermediate visual steps to help learn a complex task. In addition, we show that not all CoS strategies perform equally well. Our key insight is to impose a Markovian structure on the CoS frames. This leads to the introduction of 'inductive CoS' which achieves better out-of-distribution generalization and performs well even with smaller models compared to non-inductive variants.",
      "authors": [
        "Aryo Lotfi",
        "Enrico Fini",
        "Samy Bengio",
        "Moin Nabi",
        "Emmanuel Abbe"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.08165",
        "HTML": "https://arxiv.org/html/2410.08165",
        "PDF": "https://arxiv.org/pdf/2410.08165"
      },
      "subjects": [
        "Machine Learning (cs.LG)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 10 Oct 2024 17:44:13 GMT",
          "size": "4351kb",
          "version": "v1"
        },
        {
          "date": "Thu, 26 Jun 2025 17:48:33 GMT",
          "size": "5525kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Chain-of-Sketch: Enabling Global Visual Reasoning",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper addresses global visual reasoning in vision models through an approach called chain-of-sketch (CoS), without discussing any aspect of LLM training data processing or data engineering."
      },
      "tasks": [
        "Out-of-Distribution Generalization"
      ],
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2410.08297",
      "abstract": "This paper considers the problem of computing the operator norm of a linear map between finite dimensional Hilbert spaces when only evaluations of the linear map are available and under restrictive storage assumptions. We propose a stochastic method of random search type to maximize the Rayleigh quotient and employ an exact line search in the random search directions. Moreover, we show that the proposed algorithm converges to the global maximum (the operator norm) almost surely, show a sublinear convergence behavior for the corresponding eigenvector and eigenvalue equation, and illustrate the performance of the method with numerical experiments.",
      "authors": [
        "Jonas Bresch",
        "Dirk A. Lorenz",
        "Felix Schneppe",
        "Maximilian Winkler"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.08297",
        "HTML": "https://arxiv.org/html/2410.08297",
        "PDF": "https://arxiv.org/pdf/2410.08297"
      },
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 10 Oct 2024 18:35:49 GMT",
          "size": "1615kb",
          "version": "v1"
        },
        {
          "date": "Thu, 26 Jun 2025 13:20:37 GMT",
          "size": "2678kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Matrix-free stochastic calculation of operator norms without using adjoints",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper proposes a stochastic method for computing operator norms, focusing on mathematical computations and algorithms, with no relation to training data processing for LLMs."
      },
      "repo_urls": [
        "https://github.com/dirloren/matrix_free_norms"
      ],
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2410.09942",
      "abstract": "This paper investigates the design of a unified search engine to serve multiple retrieval-augmented generation (RAG) agents, each with a distinct task, backbone large language model (LLM), and RAG strategy. We introduce an iterative approach where the search engine generates retrieval results for the RAG agents and gathers feedback on the quality of the retrieved documents during an offline phase. This feedback is then used to iteratively optimize the search engine using an expectation-maximization algorithm, with the goal of maximizing each agent's utility function. Additionally, we adapt this to an online setting, allowing the search engine to refine its behavior based on real-time individual agents feedback to better serve the results for each of them. Experiments on datasets from the Knowledge-Intensive Language Tasks (KILT) benchmark demonstrates that our approach significantly on average outperforms baselines across 18 RAG models. We demonstrate that our method effectively ``personalizes'' the retrieval for each RAG agent based on the collected feedback. Finally, we provide a comprehensive ablation study to explore various aspects of our method.",
      "authors": [
        "Alireza Salemi",
        "Hamed Zamani"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.09942",
        "HTML": "https://arxiv.org/html/2410.09942",
        "PDF": "https://arxiv.org/pdf/2410.09942"
      },
      "subjects": [
        "Computation and Language (cs.CL)",
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "Sun, 13 Oct 2024 17:53:50 GMT",
          "size": "1122kb",
          "version": "v1"
        },
        {
          "date": "Thu, 26 Jun 2025 03:06:17 GMT",
          "size": "648kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Learning to Rank for Multiple Retrieval-Augmented Models through Iterative Utility Maximization",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper presents a method for optimizing a search engine used by retrieval-augmented generation models, not focusing on the processing of training data for LLMs themselves."
      },
      "tasks": [
        "Language Modeling",
        "Language Modelling",
        "Large Language Model",
        "Learning-To-Rank",
        "RAG",
        "Retrieval",
        "Retrieval-augmented Generation"
      ],
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2410.10298",
      "abstract": "Vision-based Bird's-Eye-View (BEV) 3D object detection has recently become popular in autonomous driving. However, objects with a high similarity to the background from a camera perspective cannot be detected well by existing methods. In this paper, we propose a BEV-based 3D Object Detection Network with 2D Region-Oriented Attention (ROA-BEV), which enables the backbone to focus more on feature learning of the regions where objects exist. Moreover, our method further enhances the information feature learning ability of ROA through multi-scale structures. Each block of ROA utilizes a large kernel to ensure that the receptive field is large enough to catch information about large objects. Experiments on nuScenes show that ROA-BEV improves the performance based on BEVDepth. The source codes of this work will be available at https://github.com/DFLyan/ROA-BEV.",
      "authors": [
        "Jiwei Chen",
        "Yubao Sun",
        "Laiyan Ding and Rui Huang"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.10298",
        "HTML": "https://arxiv.org/html/2410.10298",
        "PDF": "https://arxiv.org/pdf/2410.10298"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Mon, 14 Oct 2024 08:51:56 GMT",
          "size": "11740kb",
          "version": "v1"
        },
        {
          "date": "Thu, 26 Jun 2025 11:02:33 GMT",
          "size": "11701kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "ROA-BEV: 2D Region-Oriented Attention for BEV-based 3D Object Detection",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This research proposes enhancements to 3D object detection in autonomous driving contexts, specifically addressing vision-based techniques, not related to LLM training data processing."
      },
      "tasks": [
        "3D Object Detection",
        "Autonomous Driving",
        "object-detection",
        "Object Detection"
      ],
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2410.16155",
      "abstract": "With the development of large language models, they are widely used as agents in various fields. A key component of agents is memory, which stores vital information but is susceptible to jailbreak attacks. Existing research mainly focuses on single-agent attacks and shared memory attacks. However, real-world scenarios often involve independent memory. In this paper, we propose the Troublemaker Makes Chaos in Honest Town (TMCHT) task, a large-scale, multi-agent, multi-topology text-based attack evaluation framework. TMCHT involves one attacker agent attempting to mislead an entire society of agents. We identify two major challenges in multi-agent attacks: (1) Non-complete graph structure, (2) Large-scale systems. We attribute these challenges to a phenomenon we term toxicity disappearing. To address these issues, we propose an Adversarial Replication Contagious Jailbreak (ARCJ) method, which optimizes the retrieval suffix to make poisoned samples more easily retrieved and optimizes the replication suffix to make poisoned samples have contagious ability. We demonstrate the superiority of our approach in TMCHT, with 23.51%, 18.95%, and 52.93% improvements in line topology, star topology, and 100-agent settings. Encourage community attention to the security of multi-agent systems.",
      "authors": [
        "Tianyi Men",
        "Pengfei Cao",
        "Zhuoran Jin",
        "Yubo Chen",
        "Kang Liu",
        "Jun Zhao"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.16155",
        "HTML": "https://arxiv.org/html/2410.16155",
        "PDF": "https://arxiv.org/pdf/2410.16155"
      },
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "Mon, 21 Oct 2024 16:21:24 GMT",
          "size": "841kb",
          "version": "v1"
        },
        {
          "date": "Thu, 26 Jun 2025 13:45:10 GMT",
          "size": "812kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "A Troublemaker with Contagious Jailbreak Makes Chaos in Honest Towns",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on the security and evaluation of multi-agent systems against text-based attacks, proposing the TMCHT task and ARCJ method for addressing multi-agent challenges. It does not involve processing LLM training data."
      },
      "tasks": [
        "Attribute"
      ],
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2410.23440",
      "abstract": "Operator learning, the approximation of mappings between infinite-dimensional function spaces using machine learning, has gained increasing research attention in recent years. Approximate operators, learned from data, can serve as efficient surrogate models for problems in computational science and engineering, complementing traditional methods. However, despite their empirical success, our understanding of the underlying mathematical theory is in large part still incomplete. In this paper, we study the approximation of Lipschitz operators with respect to Gaussian measures. We prove higher Gaussian Sobolev regularity of Lipschitz operators and establish lower and upper bounds on the Hermite polynomial approximation error. We then study general reconstruction strategies of Lipschitz operators from $m$ arbitrary (potentially adaptive) linear samples. As a key finding, we tightly characterize the corresponding sample complexity, that is, the smallest achievable worst-case error among all possible choices of (adaptive) sampling and reconstruction strategies in terms of $m$. As a consequence, we identify an inherent curse of sample complexity: No method to approximate Lipschitz operators based on $m$ linear samples can achieve algebraic convergence rates in $m$. On the positive side, we prove that a sufficiently fast spectral decay of the covariance operator of the underlying Gaussian measure guarantees convergence rates which are arbitrarily close to any algebraic rate. Overall, by tightly characterizing the sample complexity, our work confirms the intrinsic difficulty of learning Lipschitz operators, regardless of the data or learning technique.",
      "authors": [
        "Ben Adcock and Michael Griebel and Gregor Maier"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.23440",
        "HTML": "https://arxiv.org/html/2410.23440",
        "PDF": "https://arxiv.org/pdf/2410.23440"
      },
      "subjects": [
        "Machine Learning (cs.LG)",
        "Numerical Analysis (cs.NA)",
        "Numerical Analysis (math.NA)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 30 Oct 2024 20:32:30 GMT",
          "size": "81kb",
          "version": "v1"
        },
        {
          "date": "Tue, 07 Jan 2025 16:07:33 GMT",
          "size": "82kb",
          "version": "v2"
        },
        {
          "date": "Thu, 26 Jun 2025 16:15:09 GMT",
          "size": "69kb",
          "version": "v3"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "The Sample Complexity of Learning Lipschitz Operators with respect to Gaussian Measures",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "Focused on the mathematical aspects of operator learning, particularly Lipschitz operators, the paper discusses sample complexity and convergence rates. It does not address LLM training data processing."
      },
      "tasks": [
        "Operator learning"
      ],
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2411.01685",
      "abstract": "Record matching is the task of identifying records that refer to the same real-world entity across datasets. While most existing models optimize for accuracy, fairness has become an important concern due to the potential for unequal outcomes across demographic groups. Prior work typically focuses on binary outcomes evaluated at fixed decision thresholds. However, such evaluations can miss biases in matching scores--biases that persist across thresholds and affect downstream tasks. We propose a threshold-independent framework for measuring and reducing score bias, defined as disparities in the distribution of matching scores across groups. We show that several state-of-the-art matching methods exhibit substantial score bias, even when appearing fair under standard threshold-based metrics. To address this, we introduce two post-processing score calibration algorithms. The first, calib, aligns group-wise score distributions using the Wasserstein barycenter, targeting demographic parity. The second, ccalib, conditions on predicted labels to further reduce label-dependent biases, such as equal opportunity. Both methods are model-agnostic and require no access to model training data. calib also offers theoretical guarantees, ensuring reduced bias with minimal deviation from original scores. Experiments across real-world datasets and matching models confirm that calib and ccalib substantially reduce score bias while minimally impacting model accuracy.",
      "authors": [
        "Mohammad Hossein Moslemi",
        "Mostafa Milani"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.01685",
        "HTML": "https://arxiv.org/html/2411.01685",
        "PDF": "https://arxiv.org/pdf/2411.01685"
      },
      "subjects": [
        "Machine Learning (cs.LG)",
        "Computers and Society (cs.CY)",
        "Databases (cs.DB)"
      ],
      "submission_historys": [
        {
          "date": "Sun, 03 Nov 2024 21:01:40 GMT",
          "size": "1375kb",
          "version": "v1"
        },
        {
          "date": "Wed, 25 Jun 2025 21:36:23 GMT",
          "size": "414kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Reducing Biases in Record Matching Through Scores Calibration",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper addresses biases in record matching and proposes score calibration algorithms. It does not relate to LLM training data or its processing."
      },
      "tasks": [
        "Data Integration",
        "Fairness"
      ],
      "repo_urls": [
        "https://github.com/mhmoslemi2338/sigmod-FAIR-EM-post-process"
      ],
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2411.04202",
      "abstract": "This paper studies the problem of optimal placement of water quality (WQ) sensors in water distribution networks (WDNs), with a focus on chlorine transport, decay, and reaction models. Such models are traditionally used as suitable proxies for WQ. The literature on this topic is inveterate, but has a key limitation: it utilizes simplified single-species decay and reaction models that do not capture WQ transients for nonlinear, multi-species interactions. This results in sensor placements (SP) that do not account for nonlinear WQ dynamics. Furthermore, as WQ simulations are parameterized by hydraulic profiles and demand patterns, the placement of sensors are often hydraulics-dependent. This study produces a greedy algorithm that addresses the two aforementioned limitations. The algorithm is grounded in nonlinear dynamic systems and observability theory, and yields SPs that are submodular and robust to hydraulic changes. Case studies on benchmark water networks are provided. The key findings provide practical recommendations for WDN operators.",
      "authors": [
        "Mohamad H. Kazma",
        "Salma M. Elsherif",
        "Ahmad F. Taha"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.04202",
        "HTML": "https://arxiv.org/html/2411.04202",
        "PDF": "https://arxiv.org/pdf/2411.04202"
      },
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 06 Nov 2024 19:02:16 GMT",
          "size": "1825kb",
          "version": "v1"
        },
        {
          "date": "Tue, 26 Nov 2024 21:14:46 GMT",
          "size": "1870kb",
          "version": "v2"
        },
        {
          "date": "Wed, 25 Jun 2025 23:06:43 GMT",
          "size": "1003kb",
          "version": "v3"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Observability and Generalized Sensor Placement for Nonlinear Quality Models in Drinking Water Networks",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper discusses optimal sensor placement in water quality networks, focusing on sensor placement algorithms. It does not mention LLM training data processing."
      },
      "tasks": [],
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2411.08272",
      "abstract": "The Laplace-Beltrami operator has established itself in the field of non-rigid shape analysis due to its many useful properties such as being invariant under isometric transformation, having a countable eigensystem forming an orthornormal basis, and fully characterizing geodesic distances of the manifold. However, this invariancy only applies under isometric deformations, which leads to a performance breakdown in many real-world applications. In recent years emphasis has been placed upon extracting optimal features using deep learning methods,however spectral signatures play a crucial role and still add value. In this paper we take a step back, revisiting the LBO and proposing a supervised way to learn several operators on a manifold. Depending on the task, by applying these functions, we can train the LBO eigenbasis to be more task-specific. The optimization of the LBO leads to enormous improvements to established descriptors such as the heat kernel signature in various tasks such as retrieval, classification, segmentation, and correspondence, proving the adaption of the LBO eigenbasis to both global and highly local learning settings.",
      "authors": [
        "Oguzhan Yigit and Richard C. Wilson"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.08272",
        "HTML": "https://arxiv.org/html/2411.08272",
        "PDF": "https://arxiv.org/pdf/2411.08272"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 13 Nov 2024 00:49:05 GMT",
          "size": "8370kb",
          "version": "v1"
        },
        {
          "date": "Wed, 25 Jun 2025 22:45:51 GMT",
          "size": "5182kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "LBONet: Supervised Spectral Descriptors for Shape Analysis",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper discusses enhancements in shape analysis using the Laplace-Beltrami operator, which is unrelated to the processing of LLM training data."
      },
      "tasks": [],
      "repo_urls": [
        "https://github.com/yioguz/LBONet"
      ],
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2411.09852",
      "abstract": "Click-through rate (CTR) prediction, which predicts the probability of a user clicking an ad, is a fundamental task in recommender systems. The emergence of heterogeneous information, such as user profile and behavior sequences, depicts user interests from different aspects. A mutually beneficial integration of heterogeneous information is the cornerstone towards the success of CTR prediction. However, most of the existing methods suffer from two fundamental limitations, including (1) insufficient inter-mode interaction due to the unidirectional information flow between modes, and (2) aggressive information aggregation caused by early summarization, resulting in excessive information loss. To address the above limitations, we propose a novel module named InterFormer to learn heterogeneous information interaction in an interleaving style. To achieve better interaction learning, InterFormer enables bidirectional information flow for mutually beneficial learning across different modes. To avoid aggressive information aggregation, we retain complete information in each data mode and use a separate bridging arch for effective information selection and summarization. Our proposed InterFormer achieves state-of-the-art performance on three public datasets and a large-scale industrial dataset.",
      "authors": [
        "Zhichen Zeng",
        "Xiaolong Liu",
        "Mengyue Hang",
        "Xiaoyi Liu",
        "Qinghai Zhou",
        "Chaofei Yang",
        "Yiqun Liu",
        "Yichen Ruan",
        "Laming Chen",
        "Yuxin Chen",
        "Yujia Hao",
        "Jiaqi Xu",
        "Jade Nie",
        "Xi Liu",
        "Buyun Zhang",
        "Wei Wen",
        "Siyang Yuan",
        "Hang Yin",
        "Xin Zhang",
        "Kai Wang",
        "Wen-Yen Chen",
        "Yiping Han",
        "Huayu Li",
        "Chunzhi Yang",
        "Bo Long",
        "Philip S. Yu",
        "Hanghang Tong",
        "Jiyan Yang"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.09852",
        "HTML": "https://arxiv.org/html/2411.09852",
        "PDF": "https://arxiv.org/pdf/2411.09852"
      },
      "subjects": [
        "Information Retrieval (cs.IR)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Fri, 15 Nov 2024 00:20:36 GMT",
          "size": "1377kb",
          "version": "v1"
        },
        {
          "date": "Wed, 08 Jan 2025 01:44:07 GMT",
          "size": "1270kb",
          "version": "v2"
        },
        {
          "date": "Wed, 25 Jun 2025 21:48:04 GMT",
          "size": "1087kb",
          "version": "v3"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "InterFormer: Effective Heterogeneous Interaction Learning for Click-Through Rate Prediction",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper presents a method for improving heterogeneous interaction learning for click-through rate prediction, which does not involve or contribute to LLM training data processes."
      },
      "tasks": [
        "Click-Through Rate Prediction",
        "Recommendation Systems"
      ],
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2411.12558",
      "abstract": "Open-set Domain Adaptation (OSDA) aims to adapt a model from a labeled source domain to an unlabeled target domain, where novel classes - also referred to as target-private unknown classes - are present. Source-free Open-set Domain Adaptation (SF-OSDA) methods address OSDA without accessing labeled source data, making them particularly relevant under privacy constraints. However, SF-OSDA presents significant challenges due to distribution shifts and the introduction of novel classes. Existing SF-OSDA methods typically rely on thresholding the prediction entropy of a sample to identify it as either a known or unknown class, but fail to explicitly learn discriminative features for the target-private unknown classes. We propose Recall and Refine (RRDA), a novel SF-OSDA framework designed to address these limitations by explicitly learning features for target-private unknown classes. RRDA employs a two-stage process. First, we enhance the model's capacity to recognize unknown classes by training a target classifier with an additional decision boundary,guided by synthetic samples generated from target domain features. This enables the classifier to effectively separate known and unknown classes. Second, we adapt the entire model to the target domain, addressing both domain shifts and distinguishability to unknown classes. Any off-the-shelf source-free domain adaptation method (e.g. SHOT, AaD) can be seamlessly integrated into our framework at this stage. Extensive experiments on three benchmark datasets demonstrate that RRDA significantly outperforms existing SF-OSDA and OSDA methods.",
      "authors": [
        "Ismail Nejjar",
        "Hao Dong",
        "Olga Fink"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.12558",
        "HTML": "https://arxiv.org/html/2411.12558",
        "PDF": "https://arxiv.org/pdf/2411.12558"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 19 Nov 2024 15:18:50 GMT",
          "size": "4058kb",
          "version": "v1"
        },
        {
          "date": "Thu, 26 Jun 2025 14:33:44 GMT",
          "size": "3196kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Recall and Refine: A Simple but Effective Source-free Open-set Domain Adaptation Framework",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper addresses open-set domain adaptation without accessing source data. While it involves model adaptation, it does not contribute to data processing tasks related to LLM training data."
      },
      "tasks": [
        "Domain Adaptation",
        "Source-Free Domain Adaptation"
      ],
      "repo_urls": [
        "https://github.com/ismailnejjar/RRDA"
      ],
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2411.13547",
      "abstract": "Evaluating Large Language Models (LLMs) is one of the most critical aspects of building a performant compound AI system. Since the output from LLMs propagate to downstream steps, identifying LLM errors is crucial to system performance. A common task for LLMs in AI systems is tool use. While there are several benchmark environments for evaluating LLMs on this task, they typically only give a success rate without any explanation of the failure cases. To solve this problem, we introduce TOOLSCAN, a new benchmark to identify error patterns in LLM output on tool-use tasks. Our benchmark data set comprises of queries from diverse environments that can be used to test for the presence of seven newly characterized error patterns. Using TOOLSCAN, we show that even the most prominent LLMs exhibit these error patterns in their outputs. Researchers can use these insights from TOOLSCAN to guide their error mitigation strategies.",
      "authors": [
        "Shirley Kokane",
        "Ming Zhu",
        "Tulika Awalgaonkar",
        "Jianguo Zhang",
        "Thai Hoang",
        "Akshara Prabhakar",
        "Zuxin Liu",
        "Tian Lan",
        "Liangwei Yang",
        "Juntao Tan",
        "Rithesh Murthy",
        "Weiran Yao",
        "Zhiwei Liu",
        "Juan Carlos Niebles",
        "Huan Wang",
        "Shelby Heinecke",
        "Caiming Xiong",
        "Silivo Savarese"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.13547",
        "HTML": "https://arxiv.org/html/2411.13547",
        "PDF": "https://arxiv.org/pdf/2411.13547"
      },
      "subjects": [
        "Software Engineering (cs.SE)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 20 Nov 2024 18:56:22 GMT",
          "size": "931kb",
          "version": "v1"
        },
        {
          "date": "Thu, 26 Jun 2025 01:05:54 GMT",
          "size": "631kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "ToolScan: A Benchmark for Characterizing Errors in Tool-Use LLMs",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper introduces TOOLSCAN, a benchmark for identifying error patterns in LLM outputs concerning tool-use tasks, focusing on error identification rather than processing LLM training data."
      },
      "tasks": [],
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2411.14133",
      "abstract": "LLMs have shown impressive capabilities across various natural language processing tasks, yet remain vulnerable to input prompts, known as jailbreak attacks, carefully designed to bypass safety guardrails and elicit harmful responses. Traditional methods rely on manual heuristics but suffer from limited generalizability. Despite being automatic, optimization-based attacks often produce unnatural prompts that can be easily detected by safety filters or require high computational costs due to discrete token optimization. In this paper, we introduce Generative Adversarial Suffix Prompter (GASP), a novel automated framework that can efficiently generate human-readable jailbreak prompts in a fully black-box setting. In particular, GASP leverages latent Bayesian optimization to craft adversarial suffixes by efficiently exploring continuous latent embedding spaces, gradually optimizing the suffix prompter to improve attack efficacy while balancing prompt coherence via a targeted iterative refinement procedure. Through comprehensive experiments, we show that GASP can produce natural adversarial prompts, significantly improving jailbreak success over baselines, reducing training times, and accelerating inference speed, thus making it an efficient and scalable solution for red-teaming LLMs.",
      "authors": [
        "Advik Raj Basani",
        "Xiao Zhang"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.14133",
        "HTML": "https://arxiv.org/html/2411.14133",
        "PDF": "https://arxiv.org/pdf/2411.14133"
      },
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Cryptography and Security (cs.CR)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 21 Nov 2024 14:00:01 GMT",
          "size": "5448kb",
          "version": "v1"
        },
        {
          "date": "Wed, 25 Jun 2025 19:01:33 GMT",
          "size": "352kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "GASP: Efficient Black-Box Generation of Adversarial Suffixes for Jailbreaking LLMs",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper discusses generating adversarial prompts to exploit weaknesses in LLMs for jailbreak attacks, not focusing on the LLM training data processing or data engineering."
      },
      "tasks": [
        "Bayesian Optimization",
        "Red Teaming"
      ],
      "repo_urls": [
        "https://github.com/TrustMLRG/GASP"
      ],
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2411.16933",
      "abstract": "We derive a fully computable aposteriori error estimator for a Galerkin finite element solution of the wave equation with explicit leapfrog time-stepping. Our discrete formulation accommodates both time evolving meshes and leapfrog based local time-stepping (Diaz & Grote, 2009), which overcomes the stringent stability restriction on the time-step due to local mesh refinement. Thus we account for adaptive time-stepping with mesh change in a fully explicit time integration while retaining its efficiency. The error analysis relies on elliptic reconstructors and abstract grid transfer operators, which allows for use-defined elliptic error estimators. Numerical results using the elliptic Babu\\v{s}ka-Rheinboldt estimators illustrate the optimal rate of convergence with mesh size of the aposteriori error estimator.",
      "authors": [
        "Marcus J. Grote and Omar Lakkis and Carina Santos"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.16933",
        "HTML": "https://arxiv.org/html/2411.16933",
        "PDF": "https://arxiv.org/pdf/2411.16933"
      },
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "Mon, 25 Nov 2024 21:01:38 GMT",
          "size": "598kb",
          "version": "v1"
        },
        {
          "date": "Thu, 26 Jun 2025 17:57:53 GMT",
          "size": "602kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "A posteriori error estimates for the wave equation with mesh change in the leapfrog method",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper details error estimation for wave equations using the Galerkin method and meshes, which is unrelated to LLM training data processing or data engineering."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2411.17984",
      "abstract": "Remote sensing foundation models largely break away from the traditional paradigm of designing task-specific models, offering greater scalability across multiple tasks. However, they face challenges such as low computational efficiency and limited interpretability, especially when dealing with large-scale remote sensing images. To overcome these, we draw inspiration from heat conduction, a physical process modeling local heat diffusion. Building on this idea, we are the first to explore the potential of using the parallel computing model of heat conduction to simulate the local region correlations in high-resolution remote sensing images, and introduce RS-vHeat, an efficient multi-modal remote sensing foundation model. Specifically, RS-vHeat 1) applies the Heat Conduction Operator (HCO) with a complexity of $O(N^{1.5})$ and a global receptive field, reducing computational overhead while capturing remote sensing object structure information to guide heat diffusion; 2) learns the frequency distribution representations of various scenes through a self-supervised strategy based on frequency domain hierarchical masking and multi-domain reconstruction; 3) significantly improves efficiency and performance over state-of-the-art techniques across 4 tasks and 10 datasets. Compared to attention-based remote sensing foundation models, we reduce memory usage by 84\\%, FLOPs by 24\\% and improves throughput by 2.7 times. The code will be made publicly available.",
      "authors": [
        "Huiyang Hu",
        "Peijin Wang",
        "Hanbo Bi",
        "Boyuan Tong",
        "Zhaozhi Wang",
        "Wenhui Diao",
        "Hao Chang",
        "Yingchao Feng",
        "Ziqi Zhang",
        "Yaowei Wang",
        "Qixiang Ye",
        "Kun Fu",
        "Xian Sun"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.17984",
        "HTML": "https://arxiv.org/html/2411.17984",
        "PDF": "https://arxiv.org/pdf/2411.17984"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 27 Nov 2024 01:43:38 GMT",
          "size": "7322kb",
          "version": "v1"
        },
        {
          "date": "Fri, 07 Mar 2025 13:24:25 GMT",
          "size": "9488kb",
          "version": "v2"
        },
        {
          "date": "Thu, 26 Jun 2025 01:51:21 GMT",
          "size": "9506kb",
          "version": "v3"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "RS-vHeat: Heat Conduction Guided Efficient Remote Sensing Foundation Model",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper introduces RS-vHeat, focusing on remote sensing models inspired by heat conduction. It does not pertain to LLM training data processing or data engineering methodologies."
      },
      "tasks": [
        "Computational Efficiency"
      ],
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2411.18309",
      "abstract": "CT report generation (CTRG) aims to automatically generate diagnostic reports for 3D volumes, relieving clinicians' workload and improving patient care. Despite clinical value, existing works fail to effectively incorporate diagnostic information from multiple anatomical views and lack related clinical expertise essential for accurate and reliable diagnosis. To resolve these limitations, we propose a novel Multi-view perception Knowledge-enhanced TansfoRmer (MvKeTR) to mimic the diagnostic workflow of clinicians. Just as radiologists first examine CT scans from multiple planes, a Multi-View Perception Aggregator (MVPA) with view-aware attention is proposed to synthesize diagnostic information from multiple anatomical views effectively. Then, inspired by how radiologists further refer to relevant clinical records to guide diagnostic decision-making, a Cross-Modal Knowledge Enhancer (CMKE) is devised to retrieve the most similar reports based on the query volume to incorporate domain knowledge into the diagnosis procedure. Furthermore, instead of traditional MLPs, we employ Kolmogorov-Arnold Networks (KANs) as the fundamental building blocks of both modules, which exhibit superior parameter efficiency and reduced spectral bias to better capture high-frequency components critical for CT interpretation while mitigating overfitting. Extensive experiments on the public CTRG-Chest-548 K dataset demonstrate that our method outpaces prior state-of-the-art (SOTA) models across almost all metrics. The code is available at https://github.com/xiweideng/MvKeTR.",
      "authors": [
        "Xiwei Deng",
        "Xianchun He",
        "Jianfeng Bao",
        "Yudan Zhou",
        "Shuhui Cai",
        "Congbo Cai",
        "Zhong Chen"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.18309",
        "HTML": "https://arxiv.org/html/2411.18309",
        "PDF": "https://arxiv.org/pdf/2411.18309"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 27 Nov 2024 12:58:23 GMT",
          "size": "374kb",
          "version": "v1"
        },
        {
          "date": "Mon, 06 Jan 2025 10:34:37 GMT",
          "size": "375kb",
          "version": "v2"
        },
        {
          "date": "Thu, 26 Jun 2025 00:54:18 GMT",
          "size": "383kb",
          "version": "v3"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "MvKeTR: Chest CT Report Generation with Multi-View Perception and Knowledge Enhancement",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on a method for generating diagnostic reports from CT scans using a multi-view perception and knowledge enhancement model. It does not discuss the processing of training data for LLMs."
      },
      "tasks": [
        "Decision Making",
        "Diagnostic",
        "Kolmogorov-Arnold Networks"
      ],
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2411.18581",
      "abstract": "In this paper we study a combinatorial reconfiguration problem that involves finding an optimal sequence of swaps to move an initial configuration of tokens that are placed on the vertices of a graph to a final desired one. This problem arises as a crucial step in reducing the depth of a quantum circuit when compiling a quantum algorithm. We provide the first known constant factor approximation algorithms for the parallel token swapping problem on graph topologies that are commonly found in modern quantum computers, including cycle graphs, subdivided star graphs, and grid graphs. We also study the so-called stretch factor of a natural lower bound to the problem, which has been shown to be useful when designing heuristics for the qubit routing problem. Finally, we study the colored version of this reconfiguration problem where some tokens share the same color and are considered indistinguishable.",
      "authors": [
        "Ishan Bansal",
        "Oktay G\\\"unl\\\"uk",
        "Richard Shapley"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.18581",
        "HTML": "https://arxiv.org/html/2411.18581",
        "PDF": "https://arxiv.org/pdf/2411.18581"
      },
      "subjects": [
        "Data Structures and Algorithms (cs.DS)",
        "Discrete Mathematics (cs.DM)",
        "Quantum Physics (quant-ph)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 27 Nov 2024 18:26:16 GMT",
          "size": "32kb",
          "version": "v1"
        },
        {
          "date": "Thu, 26 Jun 2025 03:44:00 GMT",
          "size": "37kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Parallel Token Swapping for Qubit Routing",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper discusses a combinatorial optimization problem related to quantum circuit design, with no mention of LLM training data processing or data engineering tasks."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2412.01787",
      "abstract": "Recent generative models based on score matching and flow matching have significantly advanced generation tasks, but their potential in discriminative tasks remains underexplored. Previous approaches, such as generative classifiers, have not fully leveraged the capabilities of these models for discriminative tasks due to their intricate designs. We propose Pretrained Reversible Generation (PRG), which extracts unsupervised representations by reversing the generative process of a pretrained continuous generation model. PRG effectively reuses unsupervised generative models, leveraging their high capacity to serve as robust and generalizable feature extractors for downstream tasks. This framework enables the flexible selection of feature hierarchies tailored to specific downstream tasks. Our method consistently outperforms prior approaches across multiple benchmarks, achieving state-of-the-art performance among generative model based methods, including 78% top-1 accuracy on ImageNet at a resolution of 64*64. Extensive ablation studies, including out-of-distribution evaluations, further validate the effectiveness of our approach. Code is available at https://github.com/opendilab/PRG.",
      "authors": [
        "Rongkun Xue",
        "Jinouwen Zhang",
        "Yazhe Niu",
        "Dazhong Shen",
        "Bingqi Ma",
        "Yu Liu",
        "Jing Yang"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.01787",
        "HTML": "https://arxiv.org/html/2412.01787",
        "PDF": "https://arxiv.org/pdf/2412.01787"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Fri, 29 Nov 2024 08:24:49 GMT",
          "size": "34281kb",
          "version": "v1"
        },
        {
          "date": "Sat, 08 Mar 2025 14:13:46 GMT",
          "size": "39964kb",
          "version": "v2"
        },
        {
          "date": "Thu, 26 Jun 2025 04:26:18 GMT",
          "size": "23445kb",
          "version": "v3"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Pretrained Reversible Generation as Unsupervised Visual Representation Learning",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper introduces a method for extracting unsupervised visual representations but does not contribute to LLM training data processing or data engineering."
      },
      "tasks": [
        "Representation Learning"
      ],
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2412.03359",
      "abstract": "Recent advancements in autonomous multi-agent systems (MAS) based on large language models (LLMs) have enhanced the application scenarios and improved the capability of LLMs to handle complex tasks. Despite demonstrating effectiveness, existing studies still evidently struggle to evaluate, analysis, and reproducibility of LLM-based MAS. In this paper, to facilitate the research on LLM-based MAS, we introduce an open, scalable, and real-time updated platform for accessing and analyzing the LLM-based MAS based on the games Who is Spy?\" (WiS). Our platform is featured with three main worths: (1) a unified model evaluate interface that supports models available on Hugging Face; (2) real-time updated leaderboard for model evaluation; (3) a comprehensive evaluation covering game-winning rates, attacking, defense strategies, and reasoning of LLMs. To rigorously test WiS, we conduct extensive experiments coverage of various open- and closed-source LLMs, we find that different agents exhibit distinct and intriguing behaviors in the game. The experimental results demonstrate the effectiveness and efficiency of our platform in evaluating LLM-based MAS. Our platform and its documentation are publicly available at https://whoisspy.ai/.",
      "authors": [
        "Chengwei Hu",
        "Jianhui Zheng",
        "Yancheng He",
        "Hangyu Guo",
        "Junguang Jiang",
        "Han Zhu",
        "Kai Sun",
        "Yuning Jiang",
        "Wenbo Su",
        "Bo Zheng"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.03359",
        "HTML": "https://arxiv.org/html/2412.03359",
        "PDF": "https://arxiv.org/pdf/2412.03359"
      },
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 04 Dec 2024 14:45:09 GMT",
          "size": "11027kb",
          "version": "v1"
        },
        {
          "date": "Thu, 26 Jun 2025 03:55:53 GMT",
          "size": "7331kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "WiS Platform: Enhancing Evaluation of LLM-Based Multi-Agent Systems Through Game-Based Analysis",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper presents a platform for evaluating multi-agent systems using LLMs but does not address the processing of training data for LLMs."
      },
      "tasks": [],
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2412.03934",
      "abstract": "We present InfiniCube, a scalable method for generating unbounded dynamic 3D driving scenes with high fidelity and controllability. Previous methods for scene generation either suffer from limited scales or lack geometric and appearance consistency along generated sequences. In contrast, we leverage the recent advancements in scalable 3D representation and video models to achieve large dynamic scene generation that allows flexible controls through HD maps, vehicle bounding boxes, and text descriptions. First, we construct a map-conditioned sparse-voxel-based 3D generative model to unleash its power for unbounded voxel world generation. Then, we re-purpose a video model and ground it on the voxel world through a set of carefully designed pixel-aligned guidance buffers, synthesizing a consistent appearance. Finally, we propose a fast feed-forward approach that employs both voxel and pixel branches to lift the dynamic videos to dynamic 3D Gaussians with controllable objects. Our method can generate controllable and realistic 3D driving scenes, and extensive experiments validate the effectiveness and superiority of our model.",
      "authors": [
        "Yifan Lu",
        "Xuanchi Ren",
        "Jiawei Yang",
        "Tianchang Shen",
        "Zhangjie Wu",
        "Jun Gao",
        "Yue Wang",
        "Siheng Chen",
        "Mike Chen",
        "Sanja Fidler",
        "Jiahui Huang"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.03934",
        "HTML": "https://arxiv.org/html/2412.03934",
        "PDF": "https://arxiv.org/pdf/2412.03934"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Graphics (cs.GR)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 05 Dec 2024 07:32:20 GMT",
          "size": "13750kb",
          "version": "v1"
        },
        {
          "date": "Thu, 26 Jun 2025 03:10:09 GMT",
          "size": "14202kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "InfiniCube: Unbounded and Controllable Dynamic 3D Driving Scene Generation with World-Guided Video Models",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on dynamic 3D driving scene generation and does not mention any contribution related to LLM training data processing or data engineering stages."
      },
      "tasks": [
        "Scene Generation"
      ],
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2412.04833",
      "abstract": "Simulating and controlling physical systems described by partial differential equations (PDEs) are crucial tasks across science and engineering. Recently, diffusion generative models have emerged as a competitive class of methods for these tasks due to their ability to capture long-term dependencies and model high-dimensional states. However, diffusion models typically struggle with handling system states with abrupt changes and generalizing to higher resolutions. In this work, we propose Wavelet Diffusion Neural Operator (WDNO), a novel PDE simulation and control framework that enhances the handling of these complexities. WDNO comprises two key innovations. Firstly, WDNO performs diffusion-based generative modeling in the wavelet domain for the entire trajectory to handle abrupt changes and long-term dependencies effectively. Secondly, to address the issue of poor generalization across different resolutions, which is one of the fundamental tasks in modeling physical systems, we introduce multi-resolution training. We validate WDNO on five physical systems, including 1D advection equation, three challenging physical systems with abrupt changes (1D Burgers' equation, 1D compressible Navier-Stokes equation and 2D incompressible fluid), and a real-world dataset ERA5, which demonstrates superior performance on both simulation and control tasks over state-of-the-art methods, with significant improvements in long-term and detail prediction accuracy. Remarkably, in the challenging context of the 2D high-dimensional and indirect control task aimed at reducing smoke leakage, WDNO reduces the leakage by 78% compared to the second-best baseline. The code can be found at https://github.com/AI4Science-WestlakeU/wdno.git.",
      "authors": [
        "Peiyan Hu",
        "Rui Wang",
        "Xiang Zheng",
        "Tao Zhang",
        "Haodong Feng",
        "Ruiqi Feng",
        "Long Wei",
        "Yue Wang",
        "Zhi-Ming Ma",
        "Tailin Wu"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.04833",
        "HTML": "https://arxiv.org/html/2412.04833",
        "PDF": "https://arxiv.org/pdf/2412.04833"
      },
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Fri, 06 Dec 2024 07:56:25 GMT",
          "size": "5828kb",
          "version": "v1"
        },
        {
          "date": "Thu, 17 Apr 2025 12:34:20 GMT",
          "size": "5445kb",
          "version": "v2"
        },
        {
          "date": "Thu, 26 Jun 2025 13:39:47 GMT",
          "size": "5445kb",
          "version": "v3"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Wavelet Diffusion Neural Operator",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The focus is on simulating physical systems using diffusion generative models, rather than any aspect of LLM training data collection or processing."
      },
      "tasks": [],
      "repo_urls": [
        "https://github.com/AI4Science-WestlakeU/wdno"
      ],
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2412.07229",
      "abstract": "Score-based Generative Models (SGMs) have demonstrated remarkable generalization abilities, e.g. generating unseen, but natural data. However, the greater the generalization power, the more likely the unintended generalization, and the more dangerous the abuse. Research on moderated generalization in SGMs remains limited. To fill this gap, we first examine the current 'gold standard' in Machine Unlearning (MU), i.e., re-training the model after removing the undesirable training data, and find it does not work in SGMs. Further analysis of score functions reveals that the MU 'gold standard' does not alter the original score function, which explains its ineffectiveness. Based on this insight, we propose the first Moderated Score-based Generative Model (MSGM), which introduces a novel score adjustment strategy that redirects the score function away from undesirable data during the continuous-time stochastic differential equation process. Extensive experimental results demonstrate that MSGM significantly reduces the likelihood of generating undesirable content while preserving high visual quality for normal image generation. Albeit designed for SGMs, MSGM is a general and flexible MU framework that is compatible with diverse diffusion architectures (SGM and DDPM) and training strategies (re-training and fine-tuning), and enables zero-shot transfer of the pre-trained models to downstream tasks, e.g. image inpainting and reconstruction. The code will be shared upon acceptance.",
      "authors": [
        "Wan Jiang",
        "He Wang",
        "Xin Zhang",
        "Dan Guo",
        "Zhaoxin Fan",
        "Yunfeng Diao",
        "Richang Hong"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.07229",
        "HTML": "https://arxiv.org/html/2412.07229",
        "PDF": "https://arxiv.org/pdf/2412.07229"
      },
      "subjects": [
        "Machine Learning (cs.LG)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 10 Dec 2024 06:41:18 GMT",
          "size": "5903kb",
          "version": "v1"
        },
        {
          "date": "Thu, 26 Jun 2025 12:06:00 GMT",
          "size": "15186kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Moderating the Generalization of Score-based Generative Model",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper addresses models' generalization and unlearning in score-based generative models without mentioning data engineering or processing related to LLMs."
      },
      "tasks": [
        "Image Generation",
        "Image Inpainting",
        "Machine Unlearning",
        "model"
      ],
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2412.09925",
      "abstract": "We study conditions under which transformers using soft attention can simulate hard attention, that is, effectively focus all attention on a subset of positions. First, we examine several subclasses of languages recognized by hard-attention transformers, which can be defined in variants of linear temporal logic. We demonstrate how soft-attention transformers can compute formulas of these logics using unbounded positional embeddings or temperature scaling. Second, we demonstrate how temperature scaling allows softmax transformers to simulate general hard-attention transformers, using a temperature that depends on the minimum gap between the maximum attention scores and other attention scores.",
      "authors": [
        "Andy Yang",
        "Lena Strobl",
        "David Chiang",
        "Dana Angluin"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.09925",
        "HTML": "https://arxiv.org/html/2412.09925",
        "PDF": "https://arxiv.org/pdf/2412.09925"
      },
      "subjects": [
        "Machine Learning (cs.LG)",
        "Computation and Language (cs.CL)",
        "Formal Languages and Automata Theory (cs.FL)"
      ],
      "submission_historys": [
        {
          "date": "Fri, 13 Dec 2024 07:27:42 GMT",
          "size": "52kb",
          "version": "v1"
        },
        {
          "date": "Thu, 26 Jun 2025 13:41:24 GMT",
          "size": "50kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Simulating Hard Attention Using Soft Attention",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on the theoretical ability of soft attention mechanisms in transformers to simulate hard attention, without contributing to any aspects of LLM training data processing or data engineering."
      },
      "tasks": [
        "Hard Attention"
      ],
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2412.10028",
      "abstract": "Existing methods enhance the training of detection transformers by incorporating an auxiliary one-to-many assignment. In this work, we treat the model as a multi-task framework, simultaneously performing one-to-one and one-to-many predictions. We investigate the roles of each component in the transformer decoder across these two training targets, including self-attention, cross-attention, and feed-forward network. Our empirical results demonstrate that any independent component in the decoder can effectively learn both targets simultaneously, even when other components are shared. This finding leads us to propose a multi-route training mechanism, featuring a primary route for one-to-one prediction and two auxiliary training routes for one-to-many prediction. We propose a novel instructive self-attention mechanism, integrated into the first auxiliary route, which dynamically and flexibly guides object queries for one-to-many prediction. For the second auxiliary route, we introduce a route-aware Mixture-of-Experts (MoE) to facilitate knowledge sharing while mitigating potential conflicts between routes. Additionally, we apply an MoE to low-scale features in the encoder, optimizing the balance between efficiency and effectiveness. The auxiliary routes are discarded during inference. We conduct extensive experiments across various object detection baselines, achieving consistent improvements as demonstrated in Fig. 1. Our method is highly flexible and can be readily adapted to other tasks. To demonstrate its versatility, we conduct experiments on both instance segmentation and panoptic segmentation, further validating its effectiveness. Project page: https://visual-ai.github.io/mrdetr/",
      "authors": [
        "Chang-Bin Zhang",
        "Yujie Zhong",
        "Kai Han"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.10028",
        "HTML": "https://arxiv.org/html/2412.10028",
        "PDF": "https://arxiv.org/pdf/2412.10028"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Fri, 13 Dec 2024 10:39:27 GMT",
          "size": "6278kb",
          "version": "v1"
        },
        {
          "date": "Tue, 01 Apr 2025 08:32:36 GMT",
          "size": "7141kb",
          "version": "v2"
        },
        {
          "date": "Wed, 02 Apr 2025 05:38:32 GMT",
          "size": "7141kb",
          "version": "v3"
        },
        {
          "date": "Thu, 26 Jun 2025 15:06:14 GMT",
          "size": "2636kb",
          "version": "v4"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Mr. DETR++: Instructive Multi-Route Training for Detection Transformers with Mixture-of-Experts",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper is about enhancing the training of detection transformers through a multi-route training mechanism and does not address the processing or engineering of training data for LLMs."
      },
      "models": [
        {
          "model_path": "allencbzhang/Mr.DETR",
          "downloads": "0",
          "likes": "1",
          "trending_score": "0.0",
          "link": "https://huggingface.co/allencbzhang/Mr.DETR"
        }
      ],
      "conference_url_abs": "http://openaccess.thecvf.com//content/CVPR2025/html/Zhang_Mr._DETR_Instructive_Multi-Route_Training_for_Detection_Transformers_CVPR_2025_paper.html",
      "tasks": [
        "Decoder",
        "Object Detection",
        "Prediction"
      ],
      "repo_urls": [
        "https://github.com/Visual-AI/Mr.DETR"
      ],
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2412.11521",
      "abstract": "Symmetries (transformations by group actions) are present in many datasets, and leveraging them holds considerable promise for improving predictions in machine learning. In this work, we aim to understand when and how deep networks -- with standard architectures trained in a standard, supervised way -- learn symmetries from data. Inspired by real-world scenarios, we study a classification paradigm where data symmetries are only partially observed during training: some classes include all transformations of a cyclic group, while others -- only a subset. In the infinite-width limit, where kernel analogies apply, we derive a neural kernel theory of symmetry learning. The group-cyclic nature of the dataset allows us to analyze the Gram matrix of neural kernels in the Fourier domain; here we find a simple characterization of the generalization error as a function of class separation (signal) and class-orbit density (noise). This characterization reveals that generalization can only be successful when the local structure of the data prevails over its non-local, symmetry-induced structure, in the kernel space defined by the architecture. We extend our theoretical treatment to any finite group, including non-abelian groups. Our framework also applies to equivariant architectures (e.g., CNNs), and recovers their success in the special case where the architecture matches the inherent symmetry of the data. Empirically, our theory reproduces the generalization failure of finite-width networks (MLP, CNN, ViT) trained on partially observed versions of rotated-MNIST. We conclude that conventional deep networks lack a mechanism to learn symmetries that have not been explicitly embedded in their architecture a priori. Our framework could be extended to guide the design of architectures and training procedures able to learn symmetries from data.",
      "authors": [
        "Andrea Perin and Stephane Deny"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.11521",
        "HTML": "https://arxiv.org/html/2412.11521",
        "PDF": "https://arxiv.org/pdf/2412.11521"
      },
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Mon, 16 Dec 2024 07:56:54 GMT",
          "size": "24648kb",
          "version": "v1"
        },
        {
          "date": "Thu, 26 Jun 2025 15:02:44 GMT",
          "size": "8035kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "On the Ability of Deep Networks to Learn Symmetries from Data: A Neural Kernel Theory",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper presents a theoretical analysis of deep networks learning symmetries, without discussing or contributing to the data processing or engineering component for LLM training."
      },
      "tasks": [
        "Rotated MNIST"
      ],
      "repo_urls": [
        "https://github.com/andrea-perin/gpsymm"
      ],
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2412.11579",
      "abstract": "Recent advancements in 3D Gaussian Splatting (3D-GS) have demonstrated the potential of using 3D Gaussian primitives for high-speed, high-fidelity, and cost-efficient novel view synthesis from continuously calibrated input views. However, conventional methods require high-frame-rate dense and high-quality sharp images, which are time-consuming and inefficient to capture, especially in dynamic environments. Event cameras, with their high temporal resolution and ability to capture asynchronous brightness changes, offer a promising alternative for more reliable scene reconstruction without motion blur. In this paper, we propose SweepEvGS, a novel hardware-integrated method that leverages event cameras for robust and accurate novel view synthesis across various imaging settings from a single sweep. SweepEvGS utilizes the initial static frame with dense event streams captured during a single camera sweep to effectively reconstruct detailed scene views. We also introduce different real-world hardware imaging systems for real-world data collection and evaluation for future research. We validate the robustness and efficiency of SweepEvGS through experiments in three different imaging settings: synthetic objects, real-world macro-level, and real-world micro-level view synthesis. Our results demonstrate that SweepEvGS surpasses existing methods in visual rendering quality, rendering speed, and computational efficiency, highlighting its potential for dynamic practical applications.",
      "authors": [
        "Jingqian Wu",
        "Shuo Zhu",
        "Chutian Wang",
        "Boxin Shi",
        "and Edmund Y. Lam"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.11579",
        "HTML": "https://arxiv.org/html/2412.11579",
        "PDF": "https://arxiv.org/pdf/2412.11579"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Mon, 16 Dec 2024 09:09:42 GMT",
          "size": "12120kb",
          "version": "v1"
        },
        {
          "date": "Thu, 26 Jun 2025 03:39:49 GMT",
          "size": "8659kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "SweepEvGS: Event-Based 3D Gaussian Splatting for Macro and Micro Radiance Field Rendering from a Single Sweep",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper introduces a method using event cameras for 3D view synthesis and does not touch upon the processing or engineering of training data for language models."
      },
      "tasks": [
        "Computational Efficiency",
        "Novel View Synthesis"
      ],
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2412.12641",
      "abstract": "We study the Lagrange Index Policy (LIP) for restless multi-armed bandits with long-run average reward. In particular, we compare the performance of LIP with the performance of the Whittle Index Policy (WIP), both heuristic policies known to be asymptotically optimal under certain natural conditions. Even though in most cases their performances are very similar, in the cases when WIP shows bad performance, LIP continues to perform very well. We then propose reinforcement learning algorithms, both tabular and NN-based, to obtain online learning schemes for LIP in the model-free setting. The proposed reinforcement learning schemes for LIP require significantly less memory than the analogous schemes for WIP. We calculate analytically the Lagrange index for the restart model, which applies to the optimal web crawling and the minimization of the weighted age of information. We also give a new proof of asymptotic optimality in case of homogeneous arms as the number of arms goes to infinity, based on exchangeability and de Finetti's theorem.",
      "authors": [
        "Konstantin Avrachenkov",
        "Vivek S. Borkar",
        "Pratik Shah"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.12641",
        "HTML": "https://arxiv.org/html/2412.12641",
        "PDF": "https://arxiv.org/pdf/2412.12641"
      },
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Optimization and Control (math.OC)",
        "Probability (math.PR)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 17 Dec 2024 08:03:53 GMT",
          "size": "325kb",
          "version": "v1"
        },
        {
          "date": "Thu, 26 Jun 2025 14:00:55 GMT",
          "size": "335kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Lagrangian Index Policy for Restless Bandits with Average Reward",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper primarily focuses on Lagrangian Index Policy for restless bandits and reinforcement learning algorithms, without addressing any aspect of LLM training data processing or engineering."
      },
      "tasks": [
        "Multi-Armed Bandits",
        "reinforcement-learning",
        "Reinforcement Learning"
      ],
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2412.13918",
      "abstract": "The growing size of graph-based modeling artifacts in model-driven engineering calls for techniques that enable efficient execution of graph queries. Incremental approaches based on the RETE algorithm provide an adequate solution in many scenarios, but are generally designed to search for query results over the entire graph. However, in certain situations, a user may only be interested in query results for a subgraph, for instance when a developer is working on a large model of which only a part is loaded into their workspace. In this case, the global execution semantics can result in significant computational overhead.\n  To mitigate the outlined shortcoming, in this article we propose an extension of the RETE approach that enables local, yet fully incremental execution of graph queries, while still guaranteeing completeness of results with respect to the relevant subgraph.\n  We empirically evaluate the presented approach via experiments inspired by a scenario from software development and with queries and data from an independent social network benchmark. The experimental results indicate that the proposed technique can significantly improve performance regarding memory consumption and execution time in favorable cases, but may incur a noticeable overhead in unfavorable cases.",
      "authors": [
        "Matthias Barkowsky and Holger Giese"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.13918",
        "HTML": "https://arxiv.org/html/2412.13918",
        "PDF": "https://arxiv.org/pdf/2412.13918"
      },
      "subjects": [
        "Logic in Computer Science (cs.LO)",
        "Databases (cs.DB)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 18 Dec 2024 14:58:06 GMT",
          "size": "408kb",
          "version": "v1"
        },
        {
          "date": "Thu, 26 Jun 2025 12:52:26 GMT",
          "size": "838kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Localized RETE for Incremental Graph Queries with Nested Graph Conditions",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper discusses incremental graph query handling using the RETE algorithm, which is unrelated to the processing or engineering of training data for LLMs."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2412.14501",
      "abstract": "The emergence of large language models (LLMs) such as ChatGPT and Claude presents new challenges for philosophy of language, particularly regarding the nature of linguistic meaning and representation. While LLMs have traditionally been understood through distributional semantics, this paper explores Robert Brandom's inferential semantics as an alternative foundational framework for understanding these systems. We examine how key features of inferential semantics -- including its anti-representationalist stance, logical expressivism, and quasi-compositional approach -- align with the architectural and functional characteristics of Transformer-based LLMs. Through analysis of the ISA (Inference, Substitution, Anaphora) approach, we demonstrate that LLMs exhibit fundamentally anti-representationalist properties in their processing of language. We further develop a consensus theory of truth appropriate for LLMs, grounded in their interactive and normative dimensions through mechanisms like RLHF. While acknowledging significant tensions between inferentialism's philosophical commitments and LLMs' sub-symbolic processing, this paper argues that inferential semantics provides valuable insights into how LLMs generate meaning without reference to external world representations. Our analysis suggests that LLMs may challenge traditional assumptions in philosophy of language, including strict compositionality and semantic externalism, though further empirical investigation is needed to fully substantiate these theoretical claims.",
      "authors": [
        "Yuzuki Arai and Sho Tsugawa"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.14501",
        "HTML": "https://arxiv.org/html/2412.14501",
        "PDF": "https://arxiv.org/pdf/2412.14501"
      },
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 19 Dec 2024 03:48:40 GMT",
          "size": "259kb",
          "version": "v1"
        },
        {
          "date": "Thu, 26 Jun 2025 11:03:13 GMT",
          "size": "285kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Do Large Language Models Advocate for Inferentialism?",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "Although the paper discusses LLMs in a philosophical context, it does not address any aspects related to the training data pipeline, processing, or engineering."
      },
      "tasks": [
        "Philosophy"
      ],
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2412.15910",
      "abstract": "Local reconstruction analysis (LRA) is a powerful and flexible technique to study images reconstructed from discrete generalized Radon transform (GRT) data, $g=\\mathcal R f$. The main idea of LRA is to obtain a simple formula to accurately approximate an image, $f_\\epsilon(x)$, reconstructed from discrete data $g(y_j)$ in an $\\epsilon$-neighborhood of a point, $x_0$. The points $y_j$ lie on a grid with step size of order $\\epsilon$ in each direction. In this paper we study an iterative reconstruction algorithm, which consists of minimizing a quadratic cost functional. The cost functional is the sum of a data fidelity term and a Tikhonov regularization term. The function $f$ to be reconstructed has a jump discontinuity across a smooth surface $\\mathcal S$. Fix a point $x_0\\in\\mathcal S$ and any $A>0$. The main result of the paper is the computation of the limit $\\Delta F_0(\\check x;x_0):=\\lim_{\\epsilon\\to0}(f_\\epsilon(x_0+\\epsilon\\check x)-f_\\epsilon(x_0))$, where $f_\\epsilon$ is the solution to the minimization problem and $|\\check x|\\le A$. A numerical experiment with a circular GRT demonstrates that $\\Delta F_0(\\check x;x_0)$ accurately approximates the actual reconstruction obtained by the cost functional minimization.",
      "authors": [
        "Alexander Katsevich"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.15910",
        "HTML": "https://arxiv.org/html/2412.15910",
        "PDF": "https://arxiv.org/pdf/2412.15910"
      },
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "Fri, 20 Dec 2024 14:00:23 GMT",
          "size": "799kb",
          "version": "v1"
        },
        {
          "date": "Wed, 25 Jun 2025 20:05:02 GMT",
          "size": "130kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Local analysis of iterative reconstruction from discrete generalized Radon transform data in the plane",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper focuses on iterative reconstruction from generalized Radon transform data and does not involve the processing or construction of training data for LLMs."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2412.17003",
      "abstract": "In this work, we study the performance of Reed-Solomon codes against an adversary that first permutes the symbols of the codeword and then performs insertions and deletions. This adversarial model is motivated by the recent interest in fully anonymous secret-sharing schemes [EBG+24],[BGI+24]. A fully anonymous secret-sharing scheme has two key properties: (1) the identities of the participants are not revealed before the secret is reconstructed, and (2) the shares of any unauthorized set of participants are uniform and independent. In particular, the shares of any unauthorized subset reveal no information about the identity of the participants who hold them.\n  In this work, we first make the following observation: Reed-Solomon codes that are robust against an adversary that permutes the codeword and then deletes symbols from the permuted codeword can be used to construct ramp threshold secret-sharing schemes that are fully anonymous. Then, we show that over large enough fields of size, there are $[n,k]$ Reed-Solomon codes that are robust against an adversary that arbitrary permutes the codeword and then performs $n-2k+1$ insertions and deletions to the permuted codeword. This implies the existence of a $(k-1, 2k-1, n)$ ramp secret sharing scheme that is fully anonymous. That is, any $k-1$ shares reveal nothing about the secret, and, moreover, this set of shares reveals no information about the identities of the players who hold them. On the other hand, any $2k-1$ shares can reconstruct the secret without revealing their identities. We also provide explicit constructions of such schemes based on previous works on Reed-Solomon codes correcting insertions and deletions. The constructions in this paper give the first gap threshold secret-sharing schemes that satisfy the strongest notion of anonymity together with perfect reconstruction.",
      "authors": [
        "Roni Con"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.17003",
        "HTML": "https://arxiv.org/html/2412.17003",
        "PDF": "https://arxiv.org/pdf/2412.17003"
      },
      "subjects": [
        "Information Theory (cs.IT)",
        "Cryptography and Security (cs.CR)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "Sun, 22 Dec 2024 12:51:16 GMT",
          "size": "38kb",
          "version": "v1"
        },
        {
          "date": "Thu, 26 Jun 2025 12:45:57 GMT",
          "size": "38kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Anonymous Shamir's Secret Sharing via Reed-Solomon Codes Against Permutations, Insertions, and Deletions",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The study focuses on secret-sharing schemes via Reed-Solomon codes, which does not relate to LLM training data processing or data engineering."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2501.02469",
      "abstract": "Minimal infrastructure requirements make LoRa suitable for service delivery in remote areas. Additionally, web applications have become a de-facto standard for modern service delivery. However, Long Range (LoRa) fails to enable HTTP access due to its limited bandwidth, payload size limitations, and high collisions in multi-user setups. We propose LoRaConnect to enable HTTP access over LoRa. The LoRaWeb hardware tethers a WiFi hotspot to which client devices connect and access HTTP resources over LoRa backhaul. It implements caching and synchronization mechanisms to address LoRa's aforementioned limitations. It also implements a message-slicing method in the application layer to overcome LoRa's payload limitations. We evaluate the proposed system using actual hardware in three experimental setups to assess the baseline performance, ideal scenario, and practical application scenario with Frequency Hopping Spread Spectrum (FHSS). Additionally, it implements a ping operation to demonstrate Internet capability and extensible nature. LoRaWeb achieves an average throughput of 1.18 KB/S approximately, with an access delay of only 1.3 S approximately for a 1.5KB webpage in the baseline setup. Moreover, it achieves an access delay of approximately 6.7 S for a 10KB webpage in the ideal case and an average end-to-end delay of only 612 ms approximately in the FHSS-based setup. Comparison with benchmark suggests multi-fold improvement.",
      "authors": [
        "Atonu Ghosh",
        "Sudip Misra"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.02469",
        "HTML": "https://arxiv.org/html/2501.02469",
        "PDF": "https://arxiv.org/pdf/2501.02469"
      },
      "subjects": [
        "Networking and Internet Architecture (cs.NI)",
        "Computers and Society (cs.CY)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "Sun, 05 Jan 2025 07:41:53 GMT",
          "size": "5483kb",
          "version": "v1"
        },
        {
          "date": "Mon, 09 Jun 2025 07:58:19 GMT",
          "size": "0kb",
          "version": "v2"
        },
        {
          "date": "Thu, 26 Jun 2025 05:12:22 GMT",
          "size": "5301kb",
          "version": "v3"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "LoRaConnect: Unlocking HTTP Potential on LoRa Backbones for Remote Areas and Ad-Hoc Networks",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper deals with enabling HTTP access over LoRa networks and does not relate to LLM training data processing or engineering."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2501.02648",
      "abstract": "Accurate imputation of missing laboratory values in electronic health records (EHRs) is critical to enable robust clinical predictions and reduce biases in AI systems in healthcare. Existing methods, such as XGBoost, softimpute, GAIN, Expectation Maximization (EM), and MICE, struggle to model the complex temporal and contextual dependencies in EHR data, particularly in underrepresented groups. In this work, we propose Lab-MAE, a novel transformer-based masked autoencoder framework that leverages self-supervised learning for the imputation of continuous sequential lab values. Lab-MAE introduces a structured encoding scheme that jointly models laboratory test values and their corresponding timestamps, enabling explicit capturing temporal dependencies. Empirical evaluation on the MIMIC-IV dataset demonstrates that Lab-MAE significantly outperforms state-of-the-art baselines such as XGBoost, softimpute, GAIN, EM, and MICE across multiple metrics, including root mean square error (RMSE), R-squared (R2), and Wasserstein distance (WD). Notably, Lab-MAE achieves equitable performance across demographic groups of patients, advancing fairness in clinical predictions. We further investigate the role of follow-up laboratory values as potential shortcut features, revealing Lab-MAE's robustness in scenarios where such data is unavailable. The findings suggest that our transformer-based architecture, adapted to the characteristics of EHR data, offers a foundation model for more accurate and fair clinical imputation. In addition, we measure and compare the carbon footprint of Lab-MAE with the a XGBoost model, highlighting its environmental requirements.",
      "authors": [
        "David Restrepo",
        "Chenwei Wu",
        "Yueran Jia",
        "Jaden K. Sun",
        "Jack Gallifant",
        "Catherine G. Bielick",
        "Yugang Jia",
        "Leo A. Celi"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.02648",
        "HTML": "https://arxiv.org/html/2501.02648",
        "PDF": "https://arxiv.org/pdf/2501.02648"
      },
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Sun, 05 Jan 2025 20:26:49 GMT",
          "size": "416kb",
          "version": "v1"
        },
        {
          "date": "Thu, 09 Jan 2025 11:17:01 GMT",
          "size": "416kb",
          "version": "v2"
        },
        {
          "date": "Thu, 26 Jun 2025 15:34:13 GMT",
          "size": "167kb",
          "version": "v3"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Representation Learning of Lab Values via Masked AutoEncoders",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper proposes a transformer-based masked autoencoder for lab value imputation in EHRs, unrelated to LLM training data processing or LLM data engineering."
      },
      "tasks": [
        "Fairness",
        "Imputation",
        "Representation Learning",
        "Self-Supervised Learning"
      ],
      "repo_urls": [
        "https://github.com/dsrestrepo/lab-mae-foundation-tabular"
      ],
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2501.03717",
      "abstract": "Achieving physically consistent image editing remains a significant challenge in computer vision. Existing image editing methods typically rely on neural networks, which struggle to accurately handle shadows and refractions. Conversely, physics-based inverse rendering often requires multi-view optimization, limiting its practicality in single-image scenarios. In this paper, we propose Materialist, a method combining a learning-based approach with physically based progressive differentiable rendering. Given an image, our method leverages neural networks to predict initial material properties. Progressive differentiable rendering is then used to optimize the environment map and refine the material properties with the goal of closely matching the rendered result to the input image. Our approach enables a range of applications, including material editing, object insertion, and relighting, while also introducing an effective method for editing material transparency without requiring full scene geometry. Furthermore, Our envmap estimation method also achieves state-of-the-art performance, further enhancing the accuracy of image editing task. Experiments demonstrate strong performance across synthetic and real-world datasets, excelling even on challenging out-of-domain images. Project website: https://lez-s.github.io/materialist_project/",
      "authors": [
        "Lezhong Wang",
        "Duc Minh Tran",
        "Ruiqi Cui",
        "Thomson TG",
        "Anders Bjorholm Dahl",
        "Siavash Arjomand Bigdeli",
        "Jeppe Revall Frisvad",
        "Manmohan Chandraker"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.03717",
        "HTML": "https://arxiv.org/html/2501.03717",
        "PDF": "https://arxiv.org/pdf/2501.03717"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Graphics (cs.GR)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 07 Jan 2025 11:52:01 GMT",
          "size": "19529kb",
          "version": "v1"
        },
        {
          "date": "Thu, 26 Jun 2025 16:22:07 GMT",
          "size": "16259kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Materialist: Physically Based Editing Using Single-Image Inverse Rendering",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper presents a method for physically based image editing using inverse rendering, unrelated to LLM training data processing or LLM data engineering."
      },
      "tasks": [
        "Inverse Rendering"
      ],
      "repo_urls": [
        "https://github.com/lez-s/materialist"
      ],
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2501.07331",
      "abstract": "Spiking Neural Networks (SNNs) compute using sparse communication and are attracting increased attention as a more energy-efficient alternative to traditional Artificial Neural Networks~(ANNs). While standard ANNs are stateless, spiking neurons are stateful and hence intrinsically recurrent, making them well-suited for spatio-temporal tasks. However, the duration of this intrinsic memory is limited by synaptic and membrane time constants. Delays are a powerful additional mechanism and, in this paper, we propose a novel event-based training method for SNNs with delays, grounded in the EventProp formalism which enables the calculation of exact gradients with respect to weights and delays. Our method supports multiple spikes per neuron and, to the best of our knowledge, is the first delay learning algorithm to be applied to recurrent SNNs. We evaluate our method on a simple sequence detection task, as well as the Yin-Yang, Spiking Heidelberg Digits, Spiking Speech Commands and Braille letter reading datasets, demonstrating that our algorithm can optimise delays from suboptimal initial conditions and enhance classification accuracy compared to architectures without delays. We also find that recurrent delays are particularly beneficial in small networks. Finally, we show that our approach uses less than half the memory of the current state-of-the-art delay-learning method and is up to 26x faster.",
      "authors": [
        "Bal\\'azs M\\'esz\\'aros",
        "James C. Knight",
        "and Thomas Nowotny"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.07331",
        "HTML": "https://arxiv.org/html/2501.07331",
        "PDF": "https://arxiv.org/pdf/2501.07331"
      },
      "subjects": [
        "Neural and Evolutionary Computing (cs.NE)"
      ],
      "submission_historys": [
        {
          "date": "Mon, 13 Jan 2025 13:44:34 GMT",
          "size": "1817kb",
          "version": "v1"
        },
        {
          "date": "Fri, 31 Jan 2025 16:26:19 GMT",
          "size": "1782kb",
          "version": "v2"
        },
        {
          "date": "Thu, 26 Jun 2025 16:08:40 GMT",
          "size": "2323kb",
          "version": "v3"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Efficient Event-based Delay Learning in Spiking Neural Networks",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper addresses event-based delay learning in Spiking Neural Networks, not involving LLM training data or its processing."
      },
      "tasks": [],
      "repo_urls": [
        "https://github.com/mbalazs98/deventprop"
      ],
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2501.08005",
      "abstract": "Out-of-distribution (OOD) detection holds significant importance across many applications. While semantic and domain-shift OOD problems are well-studied, this work focuses on covariate shifts - subtle variations in the data distribution that can degrade machine learning performance. We hypothesize that detecting these subtle shifts can improve our understanding of in-distribution boundaries, ultimately improving OOD detection. In adversarial discriminators trained with Batch Normalization (BN), real and adversarial samples form distinct domains with unique batch statistics - a property we exploit for OOD detection. We introduce DisCoPatch, an unsupervised Adversarial Variational Autoencoder (VAE) framework that harnesses this mechanism. During inference, batches consist of patches from the same image, ensuring a consistent data distribution that allows the model to rely on batch statistics. DisCoPatch uses the VAE's suboptimal outputs (generated and reconstructed) as negative samples to train the discriminator, thereby improving its ability to delineate the boundary between in-distribution samples and covariate shifts. By tightening this boundary, DisCoPatch achieves state-of-the-art results in public OOD detection benchmarks. The proposed model not only excels in detecting covariate shifts, achieving 95.5% AUROC on ImageNet-1K(-C) but also outperforms all prior methods on public Near-OOD (95.0%) benchmarks. With a compact model size of 25MB, it achieves high OOD detection performance at notably lower latency than existing methods, making it an efficient and practical solution for real-world OOD detection applications. The code is publicly available.",
      "authors": [
        "Francisco Caetano",
        "Christiaan Viviers",
        "Luis A. Zavala-Mondrag\\'on",
        "Peter H. N. de With",
        "Fons van der Sommen"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.08005",
        "HTML": "https://arxiv.org/html/2501.08005",
        "PDF": "https://arxiv.org/pdf/2501.08005"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Image and Video Processing (eess.IV)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 14 Jan 2025 10:49:26 GMT",
          "size": "4329kb",
          "version": "v1"
        },
        {
          "date": "Wed, 21 May 2025 11:06:04 GMT",
          "size": "4323kb",
          "version": "v2"
        },
        {
          "date": "Thu, 26 Jun 2025 16:11:14 GMT",
          "size": "3185kb",
          "version": "v3"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "DisCoPatch: Taming Adversarially-driven Batch Statistics for Improved Out-of-Distribution Detection",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper deals with out-of-distribution detection using adversarial batch statistics, without focusing on the processing of LLM training data."
      },
      "tasks": [
        "All",
        "Out-of-Distribution Detection",
        "Out of Distribution (OOD) Detection"
      ],
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2501.09910",
      "abstract": "Apologies serve essential functions for moral agents such as expressing remorse, taking responsibility, and repairing trust. LLM-based chatbots routinely produce output that has the linguistic form of an apology. However, they do this simply because they are echoing the kinds of things that humans say. Moreover, there are reasons to think that chatbots are not the kind of linguistic or moral agents capable of apology. To put the point bluntly: Chatbot apologies are bullshit. This paper explores this concern and develops it beyond the epithet, drawing on the nature of morally serious apologies, the linguistic agency required to perform them, and the moral agency required for them to matter. We conclude by considering some consequences for how chatbots should be designed and how we ought to think about them.",
      "authors": [
        "P.D. Magnus",
        "Alessandra Buccella",
        "Jason D'Cruz"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.09910",
        "HTML": "https://arxiv.org/html/2501.09910",
        "PDF": "https://arxiv.org/pdf/2501.09910"
      },
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "Fri, 17 Jan 2025 01:48:15 GMT",
          "size": "281kb",
          "version": "v1"
        },
        {
          "date": "Wed, 25 Jun 2025 20:44:57 GMT",
          "size": "185kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Chatbot apologies: Beyond bullshit",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper discusses the nature of chatbot apologies and moral language, without involving the technical processing of LLM training data."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2501.15499",
      "abstract": "Probabilistic forecasting in power systems often involves multi-entity datasets like households, feeders, and wind turbines, where generating reliable entity-specific forecasts presents significant challenges. Traditional approaches require training individual models for each entity, making them inefficient and hard to scale. This study addresses this problem using GUIDE-VAE, a conditional variational autoencoder that allows entity-specific probabilistic forecasting using a single model. GUIDE-VAE provides flexible outputs, ranging from interpretable point estimates to full probability distributions, thanks to its advanced covariance composition structure. These distributions capture uncertainty and temporal dependencies, offering richer insights than traditional methods. To evaluate our GUIDE-VAE-based forecaster, we use household electricity consumption data as a case study due to its multi-entity and highly stochastic nature. Experimental results demonstrate that GUIDE-VAE outperforms conventional quantile regression techniques across key metrics while ensuring scalability and versatility. These features make GUIDE-VAE a powerful and generalizable tool for probabilistic forecasting tasks, with potential applications beyond household electricity consumption.",
      "authors": [
        "Kutay B\\\"olat",
        "Simon Tindemans"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.15499",
        "HTML": "https://arxiv.org/html/2501.15499",
        "PDF": "https://arxiv.org/pdf/2501.15499"
      },
      "subjects": [
        "Machine Learning (cs.LG)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "Sun, 26 Jan 2025 12:14:09 GMT",
          "size": "2606kb",
          "version": "v1"
        },
        {
          "date": "Thu, 26 Jun 2025 17:28:09 GMT",
          "size": "2045kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "One Model to Forecast Them All and in Entity Distributions Bind Them",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper proposes a model for probabilistic forecasting in power systems, not related to LLM training data processing. It involves generating forecasts using a conditional variational autoencoder, focusing on energy data rather than LLM datasets."
      },
      "tasks": [
        "All",
        "quantile regression"
      ],
      "repo_urls": [
        "https://github.com/kabolat/behavio-temporal-vae"
      ],
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2501.15808",
      "abstract": "Motion deblurring addresses the challenge of image blur caused by camera or scene movement. Event cameras provide motion information that is encoded in the asynchronous event streams. To efficiently leverage the temporal information of event streams, we employ Spiking Neural Networks (SNNs) for motion feature extraction and Artificial Neural Networks (ANNs) for color information processing. Due to the non-uniform distribution and inherent redundancy of event data, existing cross-modal feature fusion methods exhibit certain limitations. Inspired by the visual attention mechanism in the human visual system, this study introduces a bioinspired dual-drive hybrid network (BDHNet). Specifically, the Neuron Configurator Module (NCM) is designed to dynamically adjusts neuron configurations based on cross-modal features, thereby focusing the spikes in blurry regions and adapting to varying blurry scenarios dynamically. Additionally, the Region of Blurry Attention Module (RBAM) is introduced to generate a blurry mask in an unsupervised manner, effectively extracting motion clues from the event features and guiding more accurate cross-modal feature fusion. Extensive subjective and objective evaluations demonstrate that our method outperforms current state-of-the-art methods on both synthetic and real-world datasets.",
      "authors": [
        "Xiaopeng Lin",
        "Yulong Huang",
        "Hongwei Ren",
        "Zunchang Liu",
        "Yue Zhou",
        "Haotian Fu",
        "Bojun Cheng"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.15808",
        "HTML": "https://arxiv.org/html/2501.15808",
        "PDF": "https://arxiv.org/pdf/2501.15808"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Mon, 27 Jan 2025 06:28:45 GMT",
          "size": "4641kb",
          "version": "v1"
        },
        {
          "date": "Thu, 26 Jun 2025 07:04:23 GMT",
          "size": "4641kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "ClearSight: Human Vision-Inspired Solutions for Event-Based Motion Deblurring",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on motion deblurring using event cameras and does not discuss LLM training data processing or improvements in data handling for language models."
      },
      "tasks": [
        "Deblurring"
      ],
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2501.15957",
      "abstract": "We consider the inverse reinforcement learning (IRL) problem, where an unknown reward function of some Markov decision process is estimated based on observed expert demonstrations. In most existing approaches, IRL is formulated and solved as a nonconvex optimization problem, posing challenges in scenarios where robustness and reproducibility are critical. We discuss a convex formulation of the IRL problem (CIRL) initially proposed by Ng and Russel, and reformulate the problem such that the domain-specific language CVXPY can be applied directly to specify and solve the convex problem. We also extend the CIRL problem to scenarios where the expert policy is not given analytically but by trajectory as state-action pairs, which can be strongly inconsistent with optimality, by augmenting some of the constraints. Theoretical analysis and practical implementation for hyperparameter auto-selection are introduced. This note helps the users to easily apply CIRL for their problems, without background knowledge on convex optimization.",
      "authors": [
        "Hao Zhu",
        "Yuan Zhang",
        "Joschka Boedecker"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.15957",
        "HTML": "https://arxiv.org/html/2501.15957",
        "PDF": "https://arxiv.org/pdf/2501.15957"
      },
      "subjects": [
        "Machine Learning (cs.LG)",
        "Computational Engineering, Finance, and Science (cs.CE)",
        "Optimization and Control (math.OC)",
        "Neurons and Cognition (q-bio.NC)"
      ],
      "submission_historys": [
        {
          "date": "Mon, 27 Jan 2025 11:03:18 GMT",
          "size": "138kb",
          "version": "v1"
        },
        {
          "date": "Thu, 26 Jun 2025 10:46:25 GMT",
          "size": "137kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Inverse Reinforcement Learning via Convex Optimization",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This research addresses inverse reinforcement learning (IRL) optimization and does not relate to data processing or engineering for LLMs."
      },
      "tasks": [
        "reinforcement-learning",
        "Reinforcement Learning"
      ],
      "repo_urls": [
        "https://github.com/nrgrp/cvx_irl"
      ],
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2501.18184",
      "abstract": "This paper proposes Genetic Algorithm with Border Trades (GAB), a novel modification of the standard genetic algorithm that enhances exploration by incorporating new chromosome patterns in the breeding process. This approach significantly mitigates premature convergence and improves search diversity. Empirically, GAB achieves up to 8x higher fitness and 10x faster convergence on complex job scheduling problems compared to standard Genetic Algorithms, reaching average fitness scores of 888 versus 106 in under 20 seconds. On the classic Flip-Flop problem, GAB consistently finds optimal or near-optimal solutions in fewer generations, even as input sizes scale to thousands of bits. These results highlight GAB as a highly effective and computationally efficient alternative for solving large-scale combinatorial optimization problems.",
      "authors": [
        "Qingchuan Lyu"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.18184",
        "HTML": "https://arxiv.org/html/2501.18184",
        "PDF": "https://arxiv.org/pdf/2501.18184"
      },
      "subjects": [
        "Machine Learning (cs.LG)",
        "Neural and Evolutionary Computing (cs.NE)",
        "Computation (stat.CO)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 30 Jan 2025 07:35:43 GMT",
          "size": "3278kb",
          "version": "v1"
        },
        {
          "date": "Wed, 05 Feb 2025 06:02:05 GMT",
          "size": "3278kb",
          "version": "v2"
        },
        {
          "date": "Thu, 26 Jun 2025 04:26:22 GMT",
          "size": "3081kb",
          "version": "v3"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Genetic Algorithm with Innovative Chromosome Patterns in the Breeding Process",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The study presents a novel genetic algorithm for solving optimization problems and does not discuss methods associated with LLM training data processing."
      },
      "tasks": [
        "Diversity"
      ],
      "repo_urls": [
        "https://github.com/QingchuanLyu/Genetic-Algorithm-with-Border-Trades"
      ],
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2501.18637",
      "abstract": "Machine learning of microstructure--property relationships from data is an emerging approach in computational materials science. Most existing machine learning efforts focus on the development of task-specific models for each microstructure--property relationship. We propose utilizing pre-trained foundational vision transformers for the extraction of task-agnostic microstructure features and subsequent light-weight machine learning of a microstructure-dependent property. We demonstrate our approach with pre-trained state-of-the-art vision transformers (CLIP, DINOv2, SAM) in two case studies on machine-learning: (i) elastic modulus of two-phase microstructures based on simulations data; and (ii) Vicker's hardness of Ni-base and Co-base superalloys based on experimental data published in literature. Our results show the potential of foundational vision transformers for robust microstructure representation and efficient machine learning of microstructure--property relationships without the need for expensive task-specific training or fine-tuning of bespoke deep learning models.",
      "authors": [
        "Sheila E. Whitman",
        "Marat I. Latypov"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.18637",
        "HTML": "https://arxiv.org/html/2501.18637",
        "PDF": "https://arxiv.org/pdf/2501.18637"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Materials Science (cond-mat.mtrl-sci)",
        "Machine Learning (cs.LG)",
        "Computational Physics (physics.comp-ph)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 28 Jan 2025 17:06:47 GMT",
          "size": "2793kb",
          "version": "v1"
        },
        {
          "date": "Thu, 26 Jun 2025 01:03:29 GMT",
          "size": "6016kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Machine learning of microstructure--property relationships in materials leveraging microstructure representation from foundational vision transformers",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The research is centered on materials science using vision transformers and does not involve any stage of LLM training data processing or engineering."
      },
      "tasks": [],
      "repo_urls": [
        "https://github.com/materials-informatics-az/micropropvit"
      ],
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2501.18867",
      "abstract": "Recent advancements in Vision-Language-Action (VLA) models have leveraged pre-trained Vision-Language Models (VLMs) to improve the generalization capabilities. VLMs, typically pre-trained on vision-language understanding tasks, provide rich semantic knowledge and reasoning abilities. However, prior research has shown that VLMs often focus on high-level semantic content and neglect low-level features, limiting their ability to capture detailed spatial information and understand physical dynamics. These aspects, which are crucial for embodied control tasks, remain underexplored in existing pre-training paradigms. In this paper, we investigate the training paradigm for VLAs, and introduce \\textbf{UP-VLA}, a \\textbf{U}nified VLA model training with both multi-modal \\textbf{U}nderstanding and future \\textbf{P}rediction objectives, enhancing both high-level semantic comprehension and low-level spatial understanding. Experimental results show that UP-VLA achieves a 33% improvement on the Calvin ABC-D benchmark compared to the previous state-of-the-art method. Additionally, UP-VLA demonstrates improved success rates in real-world manipulation tasks, particularly those requiring precise spatial information.",
      "authors": [
        "Jianke Zhang",
        "Yanjiang Guo",
        "Yucheng Hu",
        "Xiaoyu Chen",
        "Xiang Zhu",
        "Jianyu Chen"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.18867",
        "HTML": "https://arxiv.org/html/2501.18867",
        "PDF": "https://arxiv.org/pdf/2501.18867"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Fri, 31 Jan 2025 03:20:09 GMT",
          "size": "10623kb",
          "version": "v1"
        },
        {
          "date": "Mon, 03 Feb 2025 03:53:25 GMT",
          "size": "10623kb",
          "version": "v2"
        },
        {
          "date": "Thu, 26 Jun 2025 03:43:38 GMT",
          "size": "7206kb",
          "version": "v3"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "UP-VLA: A Unified Understanding and Prediction Model for Embodied Agent",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on training Vision-Language-Action models for embodied agents, primarily discussing model architecture and performance improvements on specific tasks. It does not address the processing of training data for LLMs."
      },
      "tasks": [
        "Vision-Language-Action"
      ],
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2501.18945",
      "abstract": "We consider the inverse problem of multi-armed bandits (IMAB) that are widely used in neuroscience and psychology research for behavior modelling. We first show that the IMAB problem is not convex in general, but can be relaxed to a convex problem via variable transformation. Based on this result, we propose a two-step sequential heuristic for (approximately) solving the IMAB problem. We discuss a condition where our method provides global solution to the IMAB problem with certificate, as well as approximations to further save computing time. Numerical experiments indicate that our heuristic method is more robust than directly solving the IMAB problem via repeated local optimization, and can achieve the performance of Monte Carlo methods within a significantly decreased running time. We provide the implementation of our method based on CVXPY, which allows straightforward application by users not well versed in convex optimization.",
      "authors": [
        "Hao Zhu",
        "Joschka Boedecker"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.18945",
        "HTML": "https://arxiv.org/html/2501.18945",
        "PDF": "https://arxiv.org/pdf/2501.18945"
      },
      "subjects": [
        "Computational Engineering, Finance, and Science (cs.CE)",
        "Machine Learning (cs.LG)",
        "Optimization and Control (math.OC)",
        "Neurons and Cognition (q-bio.NC)"
      ],
      "submission_historys": [
        {
          "date": "Fri, 31 Jan 2025 08:08:32 GMT",
          "size": "973kb",
          "version": "v1"
        },
        {
          "date": "Wed, 05 Mar 2025 09:13:02 GMT",
          "size": "977kb",
          "version": "v2"
        },
        {
          "date": "Thu, 26 Jun 2025 10:49:32 GMT",
          "size": "977kb",
          "version": "v3"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Solving Inverse Problem for Multi-armed Bandits via Convex Optimization",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper addresses solving an inverse problem in the context of multi-armed bandits using convex optimization. It does not relate to LLM training data processing or data engineering tasks."
      },
      "tasks": [
        "Multi-Armed Bandits"
      ],
      "repo_urls": [
        "https://github.com/nrgrp/cvx_imab"
      ],
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2501.19324",
      "abstract": "We introduce Reward-Guided Speculative Decoding (RSD), a novel framework aimed at improving the efficiency of inference in large language models (LLMs). RSD synergistically combines a lightweight draft model with a more powerful target model, incorporating a controlled bias to prioritize high-reward outputs, in contrast to existing speculative decoding methods that enforce strict unbiasedness. RSD employs a process reward model to evaluate intermediate decoding steps and dynamically decide whether to invoke the target model, optimizing the trade-off between computational cost and output quality. We theoretically demonstrate that a threshold-based mixture strategy achieves an optimal balance between resource utilization and performance. Extensive evaluations on challenging reasoning benchmarks, including Olympiad-level tasks, show that RSD delivers significant efficiency gains against decoding with the target model only (up to 4.4x fewer FLOPs), while achieving significant better accuracy than parallel decoding method on average (up to +3.5). These results highlight RSD as a robust and cost-effective approach for deploying LLMs in resource-intensive scenarios. The code is available at https://github.com/BaohaoLiao/RSD.",
      "authors": [
        "Baohao Liao",
        "Yuhui Xu",
        "Hanze Dong",
        "Junnan Li",
        "Christof Monz",
        "Silvio Savarese",
        "Doyen Sahoo",
        "Caiming Xiong"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.19324",
        "HTML": "https://arxiv.org/html/2501.19324",
        "PDF": "https://arxiv.org/pdf/2501.19324"
      },
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Fri, 31 Jan 2025 17:19:57 GMT",
          "size": "638kb",
          "version": "v1"
        },
        {
          "date": "Fri, 14 Feb 2025 07:30:00 GMT",
          "size": "638kb",
          "version": "v2"
        },
        {
          "date": "Thu, 26 Jun 2025 03:14:46 GMT",
          "size": "865kb",
          "version": "v3"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Reward-Guided Speculative Decoding for Efficient LLM Reasoning",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper introduces Reward-Guided Speculative Decoding for inference efficiency in LLMs but does not discuss aspects of training data processing or data preparation methodologies for LLMs."
      },
      "tasks": [],
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2502.08597",
      "abstract": "We analyze the performance of heterogeneous learning agents in asset markets with stochastic payoffs. Our main focus is on comparing Bayesian learners and no-regret learners who compete in markets and identifying the conditions under which each approach is more effective. Surprisingly, we find that low regret is not sufficient for survival: an agent can have regret as low as $O(\\log T)$ but still vanish when competing against a Bayesian with a finite prior and any positive prior probability on the correct model. On the other hand, we show that Bayesian learning is fragile, while no-regret learning requires less knowledge of the environment and is therefore more robust. Motivated by the strengths and weaknesses of both approaches, we propose a balanced strategy for utilizing Bayesian updates that improves robustness and adaptability to distribution shifts, providing a step toward a best-of-both-worlds learning approach. The method is general, efficient, and easy to implement. Finally, we formally establish the relationship between the notions of survival and market dominance studied in economics and the framework of regret minimization, thus bridging these theories. More broadly, our work contributes to the understanding of dynamics with heterogeneous types of learning agents and their impact on markets.",
      "authors": [
        "David Easley",
        "Yoav Kolumbus",
        "Eva Tardos"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.08597",
        "HTML": "https://arxiv.org/html/2502.08597",
        "PDF": "https://arxiv.org/pdf/2502.08597"
      },
      "subjects": [
        "Computer Science and Game Theory (cs.GT)",
        "Artificial Intelligence (cs.AI)",
        "Multiagent Systems (cs.MA)",
        "Theoretical Economics (econ.TH)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 12 Feb 2025 17:34:04 GMT",
          "size": "242kb",
          "version": "v1"
        },
        {
          "date": "Wed, 25 Jun 2025 18:09:48 GMT",
          "size": "252kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Markets with Heterogeneous Agents: Dynamics and Survival of Bayesian vs. No-Regret Learners",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The research compares learning strategies in asset markets and explores learning dynamics. It does not involve LLM training data engineering or processing methods."
      },
      "tasks": [
        "Learning Theory"
      ],
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2502.08730",
      "abstract": "Sparse variational Gaussian processes (GPs) construct tractable posterior approximations to GP models. At the core of these methods is the assumption that the true posterior distribution over training function values ${\\bf f}$ and inducing variables ${\\bf u}$ is approximated by a variational distribution that incorporates the conditional GP prior $p({\\bf f} | {\\bf u})$ in its factorization. While this assumption is considered as fundamental, we show that for model training we can relax it through the use of a more general variational distribution $q({\\bf f} | {\\bf u})$ that depends on $N$ extra parameters, where $N$ is the number of training examples. In GP regression, we can analytically optimize the evidence lower bound over the extra parameters and express a tractable collapsed bound that is tighter than the previous bound. The new bound is also amenable to stochastic optimization and its implementation requires minor modifications to existing sparse GP code. Further, we also describe extensions to non-Gaussian likelihoods. On several datasets we demonstrate that our method can reduce bias when learning the hyperparameters and can lead to better predictive performance.",
      "authors": [
        "Michalis K. Titsias"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.08730",
        "HTML": "https://arxiv.org/html/2502.08730",
        "PDF": "https://arxiv.org/pdf/2502.08730"
      },
      "subjects": [
        "Machine Learning (cs.LG)",
        "Methodology (stat.ME)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 12 Feb 2025 19:04:26 GMT",
          "size": "3017kb",
          "version": "v1"
        },
        {
          "date": "Thu, 26 Jun 2025 16:24:25 GMT",
          "size": "3270kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "New Bounds for Sparse Variational Gaussian Processes",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on variational Gaussian processes and provides novel bounds for sparse GPs. It does not address any LLM training data-related tasks or data processing methodologies relevant to LLMs."
      },
      "tasks": [
        "Gaussian Processes",
        "Stochastic Optimization"
      ],
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2502.09823",
      "abstract": "Toeplitz matrices are abundant in computational mathematics, and there is a rich literature on the development of fast and superfast algorithms for solving linear systems involving such matrices. Any Toeplitz matrix can be transformed into a matrix with off-diagonal blocks that are of low numerical rank.This compressibility is relied upon in practice in a number of superfast Toeplitz solvers. In this paper, we show that the compression properties of these matrices can be thoroughly explained using their displacement structure. We provide explicit bounds on the numerical ranks of important submatrices that arise when applying HSS, HODLR and other approximations with hierarchical low-rank structure to transformed Toeplitz and Toeplitz-like matrices. Our results lead to very efficient displacement-based compression strategies that can be used to formulate adaptive superfast rank-structured solvers.",
      "authors": [
        "Bernhard Beckermann",
        "Daniel Kressner",
        "Heather Wilber"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.09823",
        "HTML": "https://arxiv.org/html/2502.09823",
        "PDF": "https://arxiv.org/pdf/2502.09823"
      },
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 13 Feb 2025 23:39:40 GMT",
          "size": "256kb",
          "version": "v1"
        },
        {
          "date": "Wed, 25 Jun 2025 23:40:22 GMT",
          "size": "379kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Compression Properties for large Toeplitz-like matrices",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper deals with the mathematical properties and compression strategies of Toeplitz-like matrices, focusing on numerical ranks and solvers, with no relevance to LLM training data processing."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2502.20183",
      "abstract": "In the realm of activity detection for massive machine-type communications, intelligent reflecting surfaces (IRS) have shown significant potential in enhancing coverage for devices lacking direct connections to the base station (BS). However, traditional activity detection methods are typically designed for a single type of channel model, which does not reflect the complexities of real-world scenarios, particularly in systems incorporating IRS. To address this challenge, this paper introduces a novel approach that combines model-driven deep unfolding with a mixture of experts (MoE) framework. By automatically selecting one of three expert designs and applying it to the unfolded projected gradient method, our approach eliminates the need for prior knowledge of channel types between devices and the BS. Simulation results demonstrate that the proposed MoE-augmented deep unfolding method surpasses the traditional covariance-based method and black-box neural network design, delivering superior detection performance under mixed channel fading conditions.",
      "authors": [
        "Zeyi Ren",
        "Qingfeng Lin",
        "Jingreng Lei",
        "Yang Li",
        "Yik-Chung Wu"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.20183",
        "HTML": "https://arxiv.org/html/2502.20183",
        "PDF": "https://arxiv.org/pdf/2502.20183"
      },
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 27 Feb 2025 15:19:28 GMT",
          "size": "539kb",
          "version": "v1"
        },
        {
          "date": "Thu, 26 Jun 2025 05:57:03 GMT",
          "size": "1490kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Mixture of Experts-augmented Deep Unfolding for Activity Detection in IRS-aided Systems",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper addresses activity detection in IRS-aided systems using deep unfolding and a mixture of experts framework. It does not cover the processing of training data for LLMs."
      },
      "tasks": [
        "Action Detection",
        "Activity Detection",
        "Mixture-of-Experts"
      ],
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2502.20323",
      "abstract": "Speech-driven 3D facial animation aims to generate realistic lip movements and facial expressions for 3D head models from arbitrary audio clips. Although existing diffusion-based methods are capable of producing natural motions, their slow generation speed limits their application potential. In this paper, we introduce a novel autoregressive model that achieves real-time generation of highly synchronized lip movements and realistic head poses and eye blinks by learning a mapping from speech to a multi-scale motion codebook. Furthermore, our model can adapt to unseen speaking styles, enabling the creation of 3D talking avatars with unique personal styles beyond the identities seen during training. Extensive evaluations and user studies demonstrate that our method outperforms existing approaches in lip synchronization accuracy and perceived quality.",
      "authors": [
        "Xuangeng Chu",
        "Nabarun Goswami",
        "Ziteng Cui",
        "Hanqin Wang",
        "Tatsuya Harada"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.20323",
        "HTML": "https://arxiv.org/html/2502.20323",
        "PDF": "https://arxiv.org/pdf/2502.20323"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 27 Feb 2025 17:49:01 GMT",
          "size": "3820kb",
          "version": "v1"
        },
        {
          "date": "Fri, 28 Feb 2025 13:25:53 GMT",
          "size": "3820kb",
          "version": "v2"
        },
        {
          "date": "Thu, 26 Jun 2025 06:10:09 GMT",
          "size": "4093kb",
          "version": "v3"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "ARTalk: Speech-Driven 3D Head Animation via Autoregressive Model",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The research is centered on speech-driven 3D facial animation using autoregressive models. It does not relate to the processing of training data for LLMs."
      },
      "models": [
        {
          "model_path": "xg-chu/ARTalk",
          "downloads": "62",
          "likes": "1",
          "trending_score": "0.0",
          "link": "https://huggingface.co/xg-chu/ARTalk"
        }
      ],
      "tasks": [],
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2502.20612",
      "abstract": "In self-supervised contrastive learning, negative pairs are typically constructed using an anchor image and a sample drawn from the entire dataset, excluding the anchor. However, this approach can result in the creation of negative pairs with similar semantics, referred to as \"false negatives\", leading to their embeddings being falsely pushed apart. To address this issue, we introduce GloFND, an optimization-based approach that automatically learns on the fly the threshold for each anchor data to identify its false negatives during training. In contrast to previous methods for false negative discovery, our approach globally detects false negatives across the entire dataset rather than locally within the mini-batch. Moreover, its per-iteration computation cost remains independent of the dataset size. Experimental results on image and image-text data demonstrate the effectiveness of the proposed method. Our implementation is available at https://github.com/vibalcam/GloFND.",
      "authors": [
        "Vicente Balmaseda",
        "Bokun Wang",
        "Ching-Long Lin",
        "Tianbao Yang"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.20612",
        "HTML": "https://arxiv.org/html/2502.20612",
        "PDF": "https://arxiv.org/pdf/2502.20612"
      },
      "subjects": [
        "Machine Learning (cs.LG)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Fri, 28 Feb 2025 00:28:25 GMT",
          "size": "6794kb",
          "version": "v1"
        },
        {
          "date": "Wed, 25 Jun 2025 21:11:53 GMT",
          "size": "6773kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Discovering Global False Negatives On the Fly for Self-supervised Contrastive Learning",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper presents a method for discovering false negatives in self-supervised contrastive learning. It does not focus on the processing or engineering of data specifically for LLMs."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2503.03921",
      "abstract": "We introduce CREStE, a scalable learning-based mapless navigation framework to address the open-world generalization and robustness challenges of outdoor urban navigation. Key to achieving this is learning perceptual representations that generalize to open-set factors (e.g. novel semantic classes, terrains, dynamic entities) and inferring expert-aligned navigation costs from limited demonstrations. CREStE addresses both these issues, introducing 1) a visual foundation model (VFM) distillation objective for learning open-set structured bird's-eye-view perceptual representations, and 2) counterfactual inverse reinforcement learning (IRL), a novel active learning formulation that uses counterfactual trajectory demonstrations to reason about the most important cues when inferring navigation costs. We evaluate CREStE on the task of kilometer-scale mapless navigation in a variety of city, offroad, and residential environments and find that it outperforms all state-of-the-art approaches with 70% fewer human interventions, including a 2-kilometer mission in an unseen environment with just 1 intervention; showcasing its robustness and effectiveness for long-horizon mapless navigation. Videos and additional materials can be found on the project page: https://amrl.cs.utexas.edu/creste",
      "authors": [
        "Arthur Zhang",
        "Harshit Sikchi",
        "Amy Zhang",
        "Joydeep Biswas"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.03921",
        "HTML": "https://arxiv.org/html/2503.03921",
        "PDF": "https://arxiv.org/pdf/2503.03921"
      },
      "subjects": [
        "Robotics (cs.RO)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 05 Mar 2025 21:42:46 GMT",
          "size": "15883kb",
          "version": "v1"
        },
        {
          "date": "Thu, 26 Jun 2025 06:42:04 GMT",
          "size": "18587kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "CREStE: Scalable Mapless Navigation with Internet Scale Priors and Counterfactual Guidance",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The research paper presents a navigation framework called CREStE for mapless navigation, which does not address the processing of training data for LLMs."
      },
      "tasks": [
        "Active Learning",
        "counterfactual",
        "Navigate"
      ],
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2503.08829",
      "abstract": "We propose VIBE, a model-agnostic framework that trains classifiers resilient to backdoor attacks. The key concept behind our approach is to treat malicious inputs and corrupted labels from the training dataset as observed random variables, while the actual clean labels are latent. VIBE then recovers the corresponding latent clean label posterior through variational inference. The resulting training procedure follows the expectation-maximization (EM) algorithm. The E-step infers the clean pseudolabels by solving an entropy-regularized optimal transport problem, while the M-step updates the classifier parameters via gradient descent. Being modular, VIBE can seamlessly integrate with recent advancements in self-supervised representation learning, which enhance its ability to resist backdoor attacks. We experimentally validate the method effectiveness against contemporary backdoor attacks on standard datasets, a large-scale setup with 1$k$ classes, and a dataset poisoned with multiple attacks. VIBE consistently outperforms previous defenses across all tested scenarios.",
      "authors": [
        "Ivan Saboli\\'c",
        "Matej Grci\\'c",
        "Sini\\v{s}a \\v{S}egvi\\'c"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.08829",
        "HTML": "https://arxiv.org/html/2503.08829",
        "PDF": "https://arxiv.org/pdf/2503.08829"
      },
      "subjects": [
        "Machine Learning (cs.LG)",
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 11 Mar 2025 19:08:31 GMT",
          "size": "19227kb",
          "version": "v1"
        },
        {
          "date": "Thu, 26 Jun 2025 12:48:11 GMT",
          "size": "19227kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Seal Your Backdoor with Variational Defense",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper introduces VIBE for training classifiers resilient to backdoor attacks, focusing on label resilience and variational inference, with no direct connection to LLM training data processing."
      },
      "tasks": [
        "Representation Learning",
        "Variational Inference"
      ],
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2503.11175",
      "abstract": "Low-light and underwater videos suffer from poor visibility, low contrast, and high noise, necessitating enhancements in visual quality. However, existing approaches typically rely on paired ground truth, which limits their practicality and often fails to maintain temporal consistency. To overcome these obstacles, this paper introduces a novel zero-shot learning approach named Zero-TIG, leveraging the Retinex theory and optical flow techniques. The proposed network consists of an enhancement module and a temporal feedback module. The enhancement module comprises three subnetworks: low-light image denoising, illumination estimation, and reflection denoising. The temporal enhancement module ensures temporal consistency by incorporating histogram equalization, optical flow computation, and image warping to align the enhanced previous frame with the current frame, thereby maintaining continuity. Additionally, we address color distortion in underwater data by adaptively balancing RGB channels. The experimental results demonstrate that our method achieves low-light video enhancement without the need for paired training data, making it a promising and applicable method for real-world scenario enhancement.",
      "authors": [
        "Yini Li",
        "Nantheera Anantrasirichai"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.11175",
        "HTML": "https://arxiv.org/html/2503.11175",
        "PDF": "https://arxiv.org/pdf/2503.11175"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Fri, 14 Mar 2025 08:22:26 GMT",
          "size": "40930kb",
          "version": "v1"
        },
        {
          "date": "Wed, 25 Jun 2025 21:45:14 GMT",
          "size": "40561kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Zero-TIG: Temporal Consistency-Aware Zero-Shot Illumination-Guided Low-light Video Enhancement",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on a zero-shot learning approach for low-light video enhancement, which is not related to LLM training data processing. It addresses visual data processing rather than language model data."
      },
      "tasks": [
        "Denoising",
        "Image Denoising",
        "Optical Flow Estimation",
        "Video Enhancement",
        "Zero-Shot Learning"
      ],
      "repo_urls": [
        "https://github.com/liyinibristol/Zero-TIG"
      ],
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2503.12701",
      "abstract": "We present AnyCalib, a method for calibrating the intrinsic parameters of a camera from a single in-the-wild image, that is agnostic to the camera model. Current methods are predominantly tailored to specific camera models and/or require extrinsic cues, such as the direction of gravity, to be visible in the image. In contrast, we argue that the perspective and distortion cues inherent in images are sufficient for model-agnostic camera calibration. To demonstrate this, we frame the calibration process as the regression of the rays corresponding to each pixel. We show, for the first time, that this intermediate representation allows for a closed-form recovery of the intrinsics for a wide range of camera models, including but not limited to: pinhole, Brown-Conrady and Kannala-Brandt. Our approach also applies to edited -- cropped and stretched -- images. Experimentally, we demonstrate that AnyCalib consistently outperforms alternative methods, including 3D foundation models, despite being trained on orders of magnitude less data. Code is available at https://github.com/javrtg/AnyCalib.",
      "authors": [
        "Javier Tirado-Gar\\'in",
        "Javier Civera"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.12701",
        "HTML": "https://arxiv.org/html/2503.12701",
        "PDF": "https://arxiv.org/pdf/2503.12701"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Sun, 16 Mar 2025 23:59:21 GMT",
          "size": "46709kb",
          "version": "v1"
        },
        {
          "date": "Thu, 26 Jun 2025 17:34:47 GMT",
          "size": "39246kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "AnyCalib: On-Manifold Learning for Model-Agnostic Single-View Camera Calibration",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This work is about camera calibration from single images, which is not related to the collection or processing of LLM training data. It deals with image processing and camera models."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2503.12764",
      "abstract": "Ultra-high-definition (UHD) image restoration often faces computational bottlenecks and information loss due to its extremely high resolution. Existing studies based on Variational Autoencoders (VAE) improve efficiency by transferring the image restoration process from pixel space to latent space. However, degraded components are inherently coupled with background elements in degraded images, both information loss during compression and information gain during compensation remain uncontrollable. These lead to restored images often exhibiting image detail loss and incomplete degradation removal. To address this issue, we propose a Controlled Differential Disentangled VAE, which utilizes Hierarchical Contrastive Disentanglement Learning and an Orthogonal Gated Projection Module to guide the VAE to actively discard easily recoverable background information while encoding more difficult-to-recover degraded information into the latent space. Additionally, we design a Complex Invertible Multiscale Fusion Network to handle background features, ensuring their consistency, and utilize a latent space restoration network to transform the degraded latent features, leading to more accurate restoration results. Extensive experimental results demonstrate that our method effectively alleviates the information loss problem in VAE models while ensuring computational efficiency, significantly improving the quality of UHD image restoration, and achieves state-of-the-art results in six UHD restoration tasks with only 1M parameters.",
      "authors": [
        "Yidi Liu",
        "Dong Li",
        "Yuxin Ma",
        "Jie Huang",
        "Wenlong Zhang",
        "Xueyang Fu",
        "Zheng-jun Zha"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.12764",
        "HTML": "https://arxiv.org/html/2503.12764",
        "PDF": "https://arxiv.org/pdf/2503.12764"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Mon, 17 Mar 2025 02:55:18 GMT",
          "size": "33627kb",
          "version": "v1"
        },
        {
          "date": "Thu, 26 Jun 2025 06:24:48 GMT",
          "size": "33409kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Decouple to Reconstruct: High Quality UHD Restoration via Active Feature Disentanglement and Reversible Fusion",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper discusses methods for high-quality ultra-high-definition image restoration, focusing on enhancing image fidelity, which is unrelated to language model training data processing."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2503.13188",
      "abstract": "Crop yield estimation is a relevant problem in agriculture, because an accurate yield estimate can support farmers' decisions on harvesting or precision intervention. Robots can help to automate this process. To do so, they need to be able to perceive the surrounding environment to identify target objects such as trees and plants. In this paper, we introduce a novel approach to address the problem of hierarchical panoptic segmentation of apple orchards on 3D data from different sensors. Our approach is able to simultaneously provide semantic segmentation, instance segmentation of trunks and fruits, and instance segmentation of trees (a trunk with its fruits). This allows us to identify relevant information such as individual plants, fruits, and trunks, and capture the relationship among them, such as precisely estimate the number of fruits associated to each tree in an orchard. To efficiently evaluate our approach for hierarchical panoptic segmentation, we provide a dataset designed specifically for this task. Our dataset is recorded in Bonn, Germany, in a real apple orchard with a variety of sensors, spanning from a terrestrial laser scanner to a RGB-D camera mounted on different robots platforms. The experiments show that our approach surpasses state-of-the-art approaches in 3D panoptic segmentation in the agricultural domain, while also providing full hierarchical panoptic segmentation. Our dataset is publicly available at https://www.ipb.uni-bonn.de/data/hops/. The open-source implementation of our approach is available at https://github.com/PRBonn/hapt3D.",
      "authors": [
        "Matteo Sodano",
        "Federico Magistri",
        "Elias Marks",
        "Fares Hosn",
        "Aibek Zurbayev",
        "Rodrigo Marcuzzi",
        "Meher V. R. Malladi",
        "Jens Behley",
        "Cyrill Stachniss"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.13188",
        "HTML": "https://arxiv.org/html/2503.13188",
        "PDF": "https://arxiv.org/pdf/2503.13188"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "Mon, 17 Mar 2025 13:59:20 GMT",
          "size": "19122kb",
          "version": "v1"
        },
        {
          "date": "Thu, 26 Jun 2025 13:40:00 GMT",
          "size": "17923kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "3D Hierarchical Panoptic Segmentation in Real Orchard Environments Across Different Sensors",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper introduces an approach for panoptic segmentation in agricultural environments using 3D data. It is focused on segmentation techniques, not on the processing of training data for language models."
      },
      "tasks": [
        "3D Panoptic Segmentation",
        "Instance Segmentation",
        "Panoptic Segmentation",
        "Segmentation",
        "Semantic Segmentation"
      ],
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2503.14333",
      "abstract": "Studies often aim to reveal ``first-order\" representations (FORs), which encode aspects of an observer's environment, such as contents or structure. A less-common target is ``higher-order\" representations (HORs), which are ``about\" FORs -- e.g., their strength or uncertainty -- and which may contribute to learning. HORs about uncertainty are unlikely to be direct ``read-outs\" of FOR characteristics, instead reflecting noisy estimation processes incorporating prior expectations about uncertainty, but how the brain represents such expected uncertainty distributions remains largely unexplored. Here, we study ``noise expectation\" HORs using neural data from a task which may require the brain to learn about its own noise: decoded neurofeedback, wherein human subjects learn to volitionally produce target neural patterns. We develop and apply a Noise Estimation through Reinforcement-based Diffusion (NERD) model to characterize how brains may undertake this process, and show that NERD offers high explanatory power for human behavior.",
      "authors": [
        "Hojjat Azimi Asrari",
        "Megan A. K. Peters"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.14333",
        "HTML": "https://arxiv.org/html/2503.14333",
        "PDF": "https://arxiv.org/pdf/2503.14333"
      },
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Neurons and Cognition (q-bio.NC)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 18 Mar 2025 15:08:19 GMT",
          "size": "4821kb",
          "version": "v1"
        },
        {
          "date": "Wed, 25 Jun 2025 19:04:21 GMT",
          "size": "2846kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Revealing higher-order neural representations of uncertainty with the Noise Estimation through Reinforcement-based Diffusion (NERD) model",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The focus of the paper is on the Noise Estimation through Reinforcement-based Diffusion (NERD) model to study higher-order neural representations. It does not address LLM training data processing or engineering."
      },
      "tasks": [
        "Denoising",
        "Reinforcement Learning (RL)"
      ],
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2503.18313",
      "abstract": "Large Language Models (LLMs) have demonstrated impressive capabilities across various domains, but their effectiveness in financial decision-making remains inadequately evaluated. Current benchmarks primarily assess LLMs' understanding on financial documents rather than the ability to manage assets or dig out trading opportunities in dynamic market conditions. Despite the release of new benchmarks for evaluating diversified tasks on the financial domain, we identified four major problems in these benchmarks, which are data leakage, navel-gazing, over-intervention, and maintenance-hard. To pave the research gap, we introduce DeepFund, a comprehensive arena platform for evaluating LLM-based trading strategies in a live environment. Our approach implements a multi-agent framework where they serve as multiple key roles that realize the real-world investment decision processes. Moreover, we provide a web interface that visualizes LLMs' performance with fund investment metrics across different market conditions, enabling detailed comparative analysis. Through DeepFund, we aim to provide a more realistic and fair assessment on LLM's capabilities in fund investment, offering diversified insights and revealing their potential applications in real-world financial markets. Our code is publicly available at https://github.com/HKUSTDial/DeepFund.",
      "authors": [
        "Changlun Li",
        "Yao Shi",
        "Yuyu Luo",
        "Nan Tang"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.18313",
        "HTML": "https://arxiv.org/html/2503.18313",
        "PDF": "https://arxiv.org/pdf/2503.18313"
      },
      "subjects": [
        "Multiagent Systems (cs.MA)",
        "Artificial Intelligence (cs.AI)",
        "Computational Engineering, Finance, and Science (cs.CE)",
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "Mon, 24 Mar 2025 03:32:13 GMT",
          "size": "21574kb",
          "version": "v1"
        },
        {
          "date": "Thu, 26 Jun 2025 03:57:07 GMT",
          "size": "8541kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Will LLMs be Professional at Fund Investment? DeepFund: A Live Arena Perspective",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper is concerned with financial decision-making evaluation and creating a platform (DeepFund) for LLM-based evaluations in trading strategies, without focusing on training data processing or engineering relevant to LLMs."
      },
      "tasks": [
        "Decision Making"
      ],
      "repo_urls": [
        "https://github.com/hkustdial/deepfund"
      ],
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2503.19856",
      "abstract": "We study online learning with oblivious losses and delays under a novel ``capacity constraint'' that limits how many past rounds can be tracked simultaneously for delayed feedback. Under ``clairvoyance'' (i.e., delay durations are revealed upfront each round) and/or ``preemptibility'' (i.e., we can stop tracking previously chosen round feedback), we establish matching upper and lower bounds (up to logarithmic terms) on achievable regret, characterizing the ``optimal capacity'' needed to match the minimax rates of classical delayed online learning, which implicitly assume unlimited capacity. Our algorithms achieve minimax-optimal regret across all capacity levels, with performance gracefully degrading under suboptimal capacity. For $K$ actions and total delay $D$ over $T$ rounds, under clairvoyance and assuming capacity $C = \\Omega(\\log(T))$, we achieve regret $\\widetilde{\\Theta}(\\sqrt{TK + DK/C + D\\log(K)})$ for bandits and $\\widetilde{\\Theta}(\\sqrt{(D+T)\\log(K)})$ for full-information feedback. When replacing clairvoyance with preemptibility, we require a known maximum delay bound $d_{\\max}$, adding ${\\widetilde{O}(d_{\\max})}$ to the regret. For fixed delays $d$ (i.e., $D=Td$), the minimax regret is $\\Theta(\\sqrt{TK(1+d/C)+Td\\log(K)})$ and the optimal capacity is $\\Theta(\\min\\{K/\\log(K),d\\})$ in the bandit setting, while in the full-information feedback setting, the minimax regret is $\\Theta(\\sqrt{T(d+1)\\log(K)})$ and the optimal capacity is $\\Theta(1)$. For round-dependent and fixed delays, our upper bounds are achieved using novel preemptive and non-preemptive scheduling policies, based on Pareto-distributed proxy delays, and batching techniques, respectively. Crucially, our work unifies delayed bandits, label-efficient learning, and online scheduling frameworks, demonstrating that robust online learning under delayed feedback is possible with surprisingly modest tracking capacity.",
      "authors": [
        "Alexander Ryabchenko",
        "Idan Attias",
        "Daniel M. Roy"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.19856",
        "HTML": "https://arxiv.org/html/2503.19856",
        "PDF": "https://arxiv.org/pdf/2503.19856"
      },
      "subjects": [
        "Machine Learning (cs.LG)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 25 Mar 2025 17:20:39 GMT",
          "size": "59kb",
          "version": "v1"
        },
        {
          "date": "Thu, 26 Jun 2025 16:47:52 GMT",
          "size": "97kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Capacity-Constrained Online Learning with Delays: Scheduling Frameworks and Regret Trade-offs",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on online learning with delays and scheduling frameworks for regret optimization, not on LLM training data processing or data engineering."
      },
      "tasks": [
        "Scheduling"
      ],
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2503.23765",
      "abstract": "The use of Multimodal Large Language Models (MLLMs) as an end-to-end solution for Embodied AI and Autonomous Driving has become a prevailing trend. While MLLMs have been extensively studied for visual semantic understanding tasks, their ability to perform precise and quantitative spatial-temporal understanding in real-world applications remains largely unexamined, leading to uncertain prospects. To evaluate models' Spatial-Temporal Intelligence, we introduce STI-Bench, a benchmark designed to evaluate MLLMs' spatial-temporal understanding through challenging tasks such as estimating and predicting the appearance, pose, displacement, and motion of objects. Our benchmark encompasses a wide range of robot and vehicle operations across desktop, indoor, and outdoor scenarios. The extensive experiments reveals that the state-of-the-art MLLMs still struggle in real-world spatial-temporal understanding, especially in tasks requiring precise distance estimation and motion analysis.",
      "authors": [
        "Yun Li",
        "Yiming Zhang",
        "Tao Lin",
        "XiangRui Liu",
        "Wenxiao Cai",
        "Zheng Liu",
        "Bo Zhao"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.23765",
        "HTML": "https://arxiv.org/html/2503.23765",
        "PDF": "https://arxiv.org/pdf/2503.23765"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Mon, 31 Mar 2025 06:30:35 GMT",
          "size": "2123kb",
          "version": "v1"
        },
        {
          "date": "Wed, 09 Apr 2025 18:07:39 GMT",
          "size": "2543kb",
          "version": "v2"
        },
        {
          "date": "Mon, 21 Apr 2025 13:43:53 GMT",
          "size": "2547kb",
          "version": "v3"
        },
        {
          "date": "Thu, 22 May 2025 19:47:24 GMT",
          "size": "3156kb",
          "version": "v4"
        },
        {
          "date": "Thu, 26 Jun 2025 15:15:48 GMT",
          "size": "4239kb",
          "version": "v5"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "STI-Bench: Are MLLMs Ready for Precise Spatial-Temporal World Understanding?",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The study evaluates MLLMs' spatial-temporal understanding, which is unrelated to LLM training data processing or data engineering tasks."
      },
      "datasets": [
        {
          "dataset_name": "MINT-SJTU/STI-Bench",
          "downloads": "193",
          "likes": "4",
          "link": "https://huggingface.co/datasets/MINT-SJTU/STI-Bench"
        }
      ],
      "tasks": [
        "Autonomous Driving"
      ],
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2503.23956",
      "abstract": "Recent advancements in Large Visual Language Models (LVLMs) have gained significant attention due to their remarkable reasoning capabilities and proficiency in generalization. However, processing a large number of visual tokens and generating long-context outputs impose substantial computational overhead, leading to excessive demands for key-value (KV) cache. To address this critical bottleneck, we propose AirCache, a novel KV cache compression method aimed at accelerating LVLMs inference. This work systematically investigates the correlations between visual and textual tokens within the attention mechanisms of LVLMs. Our empirical analysis reveals considerable redundancy in cached visual tokens, wherein strategically eliminating these tokens preserves model performance while significantly accelerating context generation. Inspired by these findings, we introduce an elite observation window for assessing the importance of visual components in the KV cache, focusing on stable inter-modal relevancy modeling with enhanced multi-perspective consistency. Additionally, we develop an adaptive layer-wise budget allocation strategy that capitalizes on the strength and skewness of token importance distribution, showcasing superior efficiency compared to uniform allocation. Comprehensive evaluations across multiple LVLMs and benchmarks demonstrate that our method achieves comparable performance to the full cache while retaining only 10% of visual KV cache, thereby reducing decoding latency by 29% to 66% across various batch size and prompt length of inputs. Notably, as cache retention rates decrease, our method exhibits increasing performance advantages over existing approaches.",
      "authors": [
        "Kai Huang",
        "Hao Zou",
        "Bochen Wang",
        "Ye Xi",
        "Zhen Xie",
        "Hao Wang"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.23956",
        "HTML": "https://arxiv.org/html/2503.23956",
        "PDF": "https://arxiv.org/pdf/2503.23956"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Mon, 31 Mar 2025 11:13:18 GMT",
          "size": "10958kb",
          "version": "v1"
        },
        {
          "date": "Thu, 26 Jun 2025 01:30:43 GMT",
          "size": "0kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "AirCache: Activating Inter-modal Relevancy KV Cache Compression for Efficient Large Vision-Language Model Inference",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper introduces a novel KV cache compression method for LVLMs inference efficiency, not related to LLM training data processing or data engineering stages."
      },
      "tasks": [
        "Language Modeling",
        "Language Modelling"
      ],
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2504.00851",
      "abstract": "Adapting pre-trained foundation models for diverse downstream tasks is a core practice in artificial intelligence. However, the wide range of tasks and high computational costs make full fine-tuning impractical. To overcome this, parameter-efficient fine-tuning (PEFT) methods like LoRA have emerged and are becoming a growing research focus. Despite the success of these methods, they are primarily designed for linear layers, focusing on two-dimensional matrices while largely ignoring higher-dimensional parameter spaces like convolutional kernels. Moreover, directly applying these methods to higher-dimensional parameter spaces often disrupts their structural relationships. Given the rapid advancements in matrix-based PEFT methods, rather than designing a specialized strategy, we propose a generalization that extends matrix-based PEFT methods to higher-dimensional parameter spaces without compromising their structural properties. Specifically, we treat parameters as elements of a Lie group, with updates modeled as perturbations in the corresponding Lie algebra. These perturbations are mapped back to the Lie group through the exponential map, ensuring smooth, consistent updates that preserve the inherent structure of the parameter space. Extensive experiments on computer vision and natural language processing validate the effectiveness and versatility of our approach, demonstrating clear improvements over existing methods.",
      "authors": [
        "Chongjie Si",
        "Zhiyi Shi",
        "Xuehui Wang",
        "Yichen Xiao",
        "Xiaokang Yang",
        "Wei Shen"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.00851",
        "HTML": "https://arxiv.org/html/2504.00851",
        "PDF": "https://arxiv.org/pdf/2504.00851"
      },
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 01 Apr 2025 14:36:45 GMT",
          "size": "17485kb",
          "version": "v1"
        },
        {
          "date": "Thu, 26 Jun 2025 03:12:59 GMT",
          "size": "8281kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Generalized Tensor-based Parameter-Efficient Fine-Tuning via Lie Group Transformations",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The focus is on parameter-efficient fine-tuning methods through Lie group transformations, without addressing any aspect of LLM training data processing or engineering."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2504.06313",
      "abstract": "This paper investigates how a popular Text-to-Image (T2I) model represents people from 208 different nationalities when prompted to generate images of individuals engaging in typical activities. Two scenarios were developed, and 644 images were generated based on input prompts that specified nationalities. The results show that in one scenario, 52.88% of images, and in the other, 27.4%, depict individuals wearing traditional attire. A statistically significant relationship was observed between this representation pattern and regions. This indicates that the issue disproportionately affects certain areas, particularly the Middle East & North Africa and Sub-Saharan Africa. A notable association with income groups was also found. CLIP, ALIGN, and GPT-4.1 mini were used to measure alignment scores between generated images and 3320 prompts and captions, with findings indicating statistically significant higher scores for images featuring individuals in traditional attire in one scenario. The study also examined revised prompts, finding that the word \"traditional\" was added by the model to 88.46% of prompts for one scenario. These findings provide valuable insights into T2I models' representation of individuals across different countries, demonstrating how the examined model prioritizes traditional characteristics despite their impracticality for the given activities.",
      "authors": [
        "Abdulkareem Alsudais"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.06313",
        "HTML": "https://arxiv.org/html/2504.06313",
        "PDF": "https://arxiv.org/pdf/2504.06313"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 08 Apr 2025 05:37:06 GMT",
          "size": "660kb",
          "version": "v1"
        },
        {
          "date": "Sat, 12 Apr 2025 04:37:55 GMT",
          "size": "658kb",
          "version": "v2"
        },
        {
          "date": "Wed, 25 Jun 2025 19:48:46 GMT",
          "size": "853kb",
          "version": "v3"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Text-to-Image Models and Their Representation of People from Different Nationalities Engaging in Activities",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper investigates the biases in Text-to-Image models and does not discuss the processing or engineering of training data for LLMs."
      },
      "tasks": [],
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2504.06629",
      "abstract": "This work investigates the internal training dynamics of image restoration~(IR) Transformers and uncovers a critical yet overlooked issue: conventional LayerNorm leads feature magnitude divergence, up to a million scale, and collapses channel-wise entropy. We analyze this phenomenon from the perspective of networks attempting to bypass constraints imposed by conventional LayerNorm due to conflicts against requirements in IR tasks. Accordingly, we address two misalignments between LayerNorm and IR tasks, and later show that addressing these mismatches leads to both stabilized training dynamics and improved IR performance. Specifically, conventional LayerNorm works in a per-token manner, disrupting spatial correlations between tokens, essential in IR tasks. Also, it employs an input-independent normalization that restricts the flexibility of feature scales, required to preserve input-specific statistics. Together, these mismatches significantly hinder IR Transformer's ability to accurately preserve low-level features throughout the network. To this end, we introduce Image Restoration Transformer Tailored Layer Normalization~(i-LN), a surprisingly simple drop-in replacement for conventional LayerNorm. We propose to normalize features in a holistic manner across the entire spatio-channel dimension, preserving spatial relationships among individual tokens. Additionally, we introduce an input-adaptive rescaling strategy that maintains the feature range flexibility required by individual inputs. Together, these modifications effectively contribute to preserving low-level feature statistics of inputs throughout IR Transformers. Experimental results verify that this combined strategy enhances both the stability and performance of IR Transformers across various IR tasks.",
      "authors": [
        "MinKyu Lee",
        "Sangeek Hyun",
        "Woojin Jun",
        "Hyunjun Kim",
        "Jiwoo Chung",
        "Jae-Pil Heo"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.06629",
        "HTML": "https://arxiv.org/html/2504.06629",
        "PDF": "https://arxiv.org/pdf/2504.06629"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 09 Apr 2025 07:06:44 GMT",
          "size": "5794kb",
          "version": "v1"
        },
        {
          "date": "Thu, 26 Jun 2025 01:23:27 GMT",
          "size": "3721kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Analyzing the Training Dynamics of Image Restoration Transformers: A Revisit to Layer Normalization",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper explores the training dynamics of image restoration transformers, particularly focusing on Layer Normalization, without addressing LLM training data processing or engineering."
      },
      "tasks": [
        "Image Restoration"
      ],
      "repo_urls": [
        "https://github.com/2minkyulee/aesop-auto-encoded-supervision-for-perceptual-image-super-resolution"
      ],
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2504.06662",
      "abstract": "Loco-manipulation, physical interaction of various objects that is concurrently coordinated with locomotion, remains a major challenge for legged robots due to the need for both precise end-effector control and robustness to unmodeled dynamics. While model-based controllers provide precise planning via online optimization, they are limited by model inaccuracies. In contrast, learning-based methods offer robustness, but they struggle with precise modulation of interaction forces. We introduce RAMBO, a hybrid framework that integrates model-based whole-body control within a feedback policy trained with reinforcement learning. The model-based module generates feedforward torques by solving a quadratic program, while the policy provides feedback corrective terms to enhance robustness. We validate our framework on a quadruped robot across a diverse set of real-world loco-manipulation tasks, such as pushing a shopping cart, balancing a plate, and holding soft objects, in both quadrupedal and bipedal walking. Our experiments demonstrate that RAMBO enables precise manipulation capabilities while achieving robust and dynamic locomotion.",
      "authors": [
        "Jin Cheng",
        "Dongho Kang",
        "Gabriele Fadini",
        "Guanya Shi",
        "Stelian Coros"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.06662",
        "HTML": "https://arxiv.org/html/2504.06662",
        "PDF": "https://arxiv.org/pdf/2504.06662"
      },
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 09 Apr 2025 07:53:09 GMT",
          "size": "12676kb",
          "version": "v1"
        },
        {
          "date": "Thu, 26 Jun 2025 11:29:52 GMT",
          "size": "11786kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "RAMBO: RL-augmented Model-based Whole-body Control for Loco-manipulation",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The research presents a hybrid framework for robot control (RAMBO), which integrates model-based and reinforcement learning strategies, with no focus on LLM training data processing or engineering."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2504.06820",
      "abstract": "We propose a framework which generalizes \"decision making with structured observations\" by allowing robust (i.e. multivalued) models. In this framework, each model associates each decision with a convex set of probability distributions over outcomes. Nature can choose distributions out of this set in an arbitrary (adversarial) manner, that can be nonoblivious and depend on past history. The resulting framework offers much greater generality than classical bandits and reinforcement learning, since the realizability assumption becomes much weaker and more realistic. We then derive a theory of regret bounds for this framework. Although our lower and upper bounds are not tight, they are sufficient to fully characterize power-law learnability. We demonstrate this theory in two special cases: robust linear bandits and tabular robust online reinforcement learning. In both cases, we derive regret bounds that improve state-of-the-art (except that we do not address computational efficiency).",
      "authors": [
        "Alexander Appel",
        "Vanessa Kosoy"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.06820",
        "HTML": "https://arxiv.org/html/2504.06820",
        "PDF": "https://arxiv.org/pdf/2504.06820"
      },
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 09 Apr 2025 12:25:00 GMT",
          "size": "66kb",
          "version": "v1"
        },
        {
          "date": "Thu, 26 Jun 2025 14:54:55 GMT",
          "size": "60kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Regret Bounds for Robust Online Decision Making",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on deriving regret bounds in a generalized framework for robust decision-making models, which does not involve LLM training data processing or engineering tasks."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2504.08738",
      "abstract": "The rapid growth of e-commerce has led to an overwhelming volume of customer feedback, from product reviews to service interactions. Extracting meaningful insights from this data is crucial for businesses aiming to improve customer satisfaction and optimize decision-making. This paper presents an AI-driven sentiment analysis system designed specifically for e-commerce applications, balancing accuracy with interpretability. Our approach integrates traditional machine learning techniques with modern deep learning models, allowing for a more nuanced understanding of customer sentiment while ensuring transparency in decision-making. Experimental results show that our system outperforms standard sentiment analysis methods, achieving an accuracy of 89.7% on diverse, large-scale datasets. Beyond technical performance, real-world implementation across multiple e-commerce platforms demonstrates tangible improvements in customer engagement and operational efficiency. This study highlights both the potential and the challenges of applying AI to sentiment analysis in a commercial setting, offering insights into practical deployment strategies and areas for future refinement.",
      "authors": [
        "Qianye Wu",
        "Chengxuan Xia",
        "Sixuan Tian"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.08738",
        "HTML": "https://arxiv.org/html/2504.08738",
        "PDF": "https://arxiv.org/pdf/2504.08738"
      },
      "subjects": [
        "Information Retrieval (cs.IR)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 20 Mar 2025 18:56:22 GMT",
          "size": "86kb",
          "version": "v1"
        },
        {
          "date": "Wed, 16 Apr 2025 05:59:02 GMT",
          "size": "87kb",
          "version": "v2"
        },
        {
          "date": "Wed, 25 Jun 2025 22:12:21 GMT",
          "size": "88kb",
          "version": "v3"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "AI-Driven Sentiment Analytics: Unlocking Business Value in the E-Commerce Landscape",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper presents an AI-driven sentiment analysis system for e-commerce, focusing on model integration and performance evaluation without involving LLM training data processing."
      },
      "tasks": [
        "Decision Making",
        "Sentiment Analysis"
      ],
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2504.08951",
      "abstract": "The modern power grid increasingly depends on advanced information and communication technology (ICT) systems to enhance performance and reliability through real-time monitoring, intelligent control, and bidirectional communication. However, ICT integration also exposes the grid to cyber-threats. Load altering attacks (LAAs), which use botnets of high-wattage devices to manipulate load profiles, are a notable threat to grid stability. While previous research has examined LAAs, their specific impact on load frequency control (LFC), critical for maintaining nominal frequency during load fluctuations, still needs to be explored. Even minor frequency deviations can jeopardize grid operations. This study bridges the gap by analyzing LAA effects on LFC through simulations of static and dynamic scenarios using Python and RTDS. The results highlight LAA impacts on frequency stability and present an eigenvalue-based stability assessment for dynamic LAAs (DLAAs), identifying key parameters influencing grid resilience.",
      "authors": [
        "Micha{\\l} Forystek",
        "Andrew D. Syrmakesis",
        "Alkistis Kontou",
        "Panos Kotsampopoulos",
        "Nikos D. Hatziargyriou",
        "Charalambos Konstantinou"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.08951",
        "HTML": "https://arxiv.org/html/2504.08951",
        "PDF": "https://arxiv.org/pdf/2504.08951"
      },
      "subjects": [
        "Systems and Control (eess.SY)",
        "Cryptography and Security (cs.CR)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "Fri, 11 Apr 2025 20:07:47 GMT",
          "size": "3625kb",
          "version": "v1"
        },
        {
          "date": "Thu, 26 Jun 2025 14:14:12 GMT",
          "size": "2732kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Exploring the Effects of Load Altering Attacks on Load Frequency Control through Python and RTDS",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The study investigates Load Altering Attacks on load frequency control in power grids, concentrating on grid resilience, and does not involve LLM training data processing."
      },
      "tasks": [],
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2504.10612",
      "abstract": "The most widely used generative models map noise and data distributions by matching flows or scores. However, they struggle to incorporate partial observations and additional priors--something energy-based models (EBMs) handle elegantly by simply adding corresponding scalar energy terms. We address this issue by proposing Energy Matching, a framework that endows flow-based approaches with the flexibility of EBMs. Far from the data manifold, samples move along curl-free, optimal transport paths from noise to data. As they approach the data manifold, an entropic energy term guides the system into a Boltzmann equilibrium distribution, explicitly capturing the underlying likelihood structure of the data. We parameterize this dynamic with a single time-independent scalar field, which serves as both a powerful generator and a flexible prior for effective regularization of inverse problems. Our method substantially outperforms existing EBMs on CIFAR-10 and ImageNet generation in terms of fidelity, while retaining simulation-free training of transport-based approaches away from the data manifold. Furthermore, we leverage the method's flexibility to introduce an interaction energy that supports diverse mode exploration, which we demonstrate in a controlled protein-generation setting. Our approach focuses on learning a scalar potential energy--without time-conditioning, auxiliary generators, or additional networks--which marks a significant departure from recent EBM methods. We believe that this simplified framework significantly advances EBMs capabilities and paves the way for their wider adoption in generative modeling across diverse domains.",
      "authors": [
        "Michal Balcerak",
        "Tamaz Amiranashvili",
        "Antonio Terpin",
        "Suprosanna Shit",
        "Lea Bogensperger",
        "Sebastian Kaltenbach",
        "Petros Koumoutsakos",
        "Bjoern Menze"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.10612",
        "HTML": "https://arxiv.org/html/2504.10612",
        "PDF": "https://arxiv.org/pdf/2504.10612"
      },
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "Mon, 14 Apr 2025 18:10:58 GMT",
          "size": "22120kb",
          "version": "v1"
        },
        {
          "date": "Wed, 14 May 2025 12:10:11 GMT",
          "size": "17885kb",
          "version": "v2"
        },
        {
          "date": "Thu, 22 May 2025 15:22:06 GMT",
          "size": "15206kb",
          "version": "v3"
        },
        {
          "date": "Thu, 26 Jun 2025 14:04:51 GMT",
          "size": "5851kb",
          "version": "v4"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Energy Matching: Unifying Flow Matching and Energy-Based Models for Generative Modeling",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on generative modeling techniques like energy-based models and flow-based approaches, with no mention of any LLM training data processing tasks such as data collection or quality enhancement."
      },
      "tasks": [],
      "repo_urls": [
        "https://github.com/m1balcerak/EnergyMatching"
      ],
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2504.11920",
      "abstract": "This paper introduces a Sobolev-like space of order $3/2$, denoted as $\\widehat{H}^{3/2}$, for Lagrangian finite elements, especially for $C^0$ elements. It is motivated by the limitations of current stability analysis of the evolving surface finite element method (ESFEM), which relies exclusively on an energy estimate framework. To establish a PDE-based analysis framework for ESFEM, we encounter a fundamental regularity mismatch: the ESFEM adopts the $C^0$ elements, while the PDE regularity theory requires $H^{3/2}$ regularity for solutions. To overcome this difficulty, we first examine the properties of the continuous $H^{3/2}$ space, then introduce a Dirichlet lift and Scott-Zhang type interpolation operators to bridge to the discrete $\\widehat{H}^{3/2}$ space. Our new $\\widehat{H}^{3/2}$ space is shown to be compatible with the elliptic PDE regularity theory, the trace inequality, and the inverse inequality. Notably, we extend the critical domain deformation estimate in ESFEM to the $\\widehat{H}^{3/2}$ setting. The $\\widehat{H}^{3/2}$ theory provides a foundation for establishing a PDE-based convergence analysis framework of ESFEM.",
      "authors": [
        "Yifei Li"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.11920",
        "HTML": "https://arxiv.org/html/2504.11920",
        "PDF": "https://arxiv.org/pdf/2504.11920"
      },
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 16 Apr 2025 09:56:43 GMT",
          "size": "67kb",
          "version": "v1"
        },
        {
          "date": "Tue, 22 Apr 2025 20:46:34 GMT",
          "size": "66kb",
          "version": "v2"
        },
        {
          "date": "Thu, 26 Jun 2025 05:56:17 GMT",
          "size": "0kb",
          "version": "v3"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Lagrangian finite elements in Sobolev-like spaces of order $3/2$",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper introduces a Sobolev-like space for finite elements and is concerned with mathematical theory and methods, without any relation to LLM training data processing or related tasks."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2504.11926",
      "abstract": "This paper presents a convergence analysis of evolving surface finite element methods (ESFEM) applied to the original Eyles-King-Styles model of tumour growth. The model consists of a Poisson equation in the bulk, a forced mean curvature flow on the surface, and a coupled velocity law between bulk and surface. Due to the non-trivial bulk-surface coupling, all previous analyses -- which exclusively relied on energy-estimate based approaches -- required an additional regularization term. By adopting the $\\widehat{H}^{3/2}$ theory and the multilinear forms, we develop an essentially new theoretical framework that enables the application of PDE regularity theory to stability analysis. Based on this framework, we provide the first rigorous convergence proof for the original model without regularization.",
      "authors": [
        "Yifei Li"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.11926",
        "HTML": "https://arxiv.org/html/2504.11926",
        "PDF": "https://arxiv.org/pdf/2504.11926"
      },
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 16 Apr 2025 10:00:02 GMT",
          "size": "21kb",
          "version": "v1"
        },
        {
          "date": "Thu, 26 Jun 2025 05:58:24 GMT",
          "size": "0kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Convergence of finite elements for the Eyles-King-Styles model of tumour growth",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper deals with the convergence analysis of finite element methods for modeling tumor growth, which does not involve LLM training data processing or engineering."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2504.14371",
      "abstract": "Bio-inspired Spiking Neural Networks (SNNs) provide an energy-efficient way to extract 3D spatio-temporal features. However, existing 3D SNNs have struggled with long-range dependencies until the recent emergence of Mamba, which offers superior computational efficiency and sequence modeling capability. In this work, we propose Spiking Point Mamba (SPM), the first Mamba-based SNN in the 3D domain. Due to the poor performance of simply transferring Mamba to 3D SNNs, SPM is designed to utilize both the sequence modeling capabilities of Mamba and the temporal feature extraction of SNNs. Specifically, we first introduce Hierarchical Dynamic Encoding (HDE), an improved direct encoding method that effectively introduces dynamic temporal mechanism, thereby facilitating temporal interactions. Then, we propose a Spiking Mamba Block (SMB), which builds upon Mamba while learning inter-time-step features and minimizing information loss caused by spikes. Finally, to further enhance model performance, we adopt an asymmetric SNN-ANN architecture for spike-based pre-training and finetune. Compared with the previous state-of-the-art SNN models, SPM improves OA by +6.2%, +6.1%, and +7.4% on three variants of ScanObjectNN, and boosts instance mIOU by +1.9% on ShapeNetPart. Meanwhile, its energy consumption is at least 3.5x lower than that of its ANN counterpart. The code will be made publicly available.",
      "authors": [
        "Peixi Wu",
        "Bosong Chai",
        "Menghua Zheng",
        "Wei Li",
        "Zhangchi Hu",
        "Jie Chen",
        "Zheyu Zhang",
        "Hebei Li",
        "Xiaoyan Sun"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.14371",
        "HTML": "https://arxiv.org/html/2504.14371",
        "PDF": "https://arxiv.org/pdf/2504.14371"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Sat, 19 Apr 2025 18:14:35 GMT",
          "size": "16638kb",
          "version": "v1"
        },
        {
          "date": "Thu, 26 Jun 2025 03:50:04 GMT",
          "size": "3891kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Efficient Spiking Point Mamba for Point Cloud Analysis",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The research is about Spiking Neural Networks for point cloud analysis, focusing on feature extraction and architecture design, not involving any LLM training data processing activities."
      },
      "tasks": [
        "Computational Efficiency",
        "Mamba"
      ],
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2504.15404",
      "abstract": "We focus on the Source Free Object Detection (SFOD) problem, when source data is unavailable during adaptation, and the model must adapt to the unlabeled target domain. In medical imaging, several approaches have leveraged a semi-supervised student-teacher architecture to bridge domain discrepancy. Context imbalance in labeled training data and significant domain shifts between domains can lead to biased teacher models that produce inaccurate pseudolabels, degrading the student model's performance and causing a mode collapse. Class imbalance, particularly when one class significantly outnumbers another, leads to contextual bias. To tackle the problem of context bias and the significant performance drop of the student model in the SFOD setting, we introduce Grounded Teacher (GT) as a standard framework. In this study, we model contextual relationships using a dedicated relational context module and leverage it to mitigate inherent biases in the model. This approach enables us to apply augmentations to closely related classes, across and within domains, enhancing the performance of underrepresented classes while keeping the effect on dominant classes minimal. We further improve the quality of predictions by implementing an expert foundational branch to supervise the student model. We validate the effectiveness of our approach in mitigating context bias under the SFOD setting through experiments on three medical datasets supported by comprehensive ablation studies. All relevant resources, including preprocessed data, trained model weights, and code, are publicly available at this https://github.com/Tajamul21/Grounded_Teacher.",
      "authors": [
        "Tajamul Ashraf",
        "Rajes Manna",
        "Partha Sarathi Purkayastha",
        "Tavaheed Tariq",
        "Janibul Bashir"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.15404",
        "HTML": "https://arxiv.org/html/2504.15404",
        "PDF": "https://arxiv.org/pdf/2504.15404"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Mon, 21 Apr 2025 19:13:33 GMT",
          "size": "36329kb",
          "version": "v1"
        },
        {
          "date": "Wed, 25 Jun 2025 20:04:24 GMT",
          "size": "7082kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Context Aware Grounded Teacher for Source Free Object Detection",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on adapting object detection models in medical imaging to a new domain without source data, utilizing a student-teacher architecture. There is no mention of contributions related to LLM training data processing or data engineering."
      },
      "models": [
        {
          "model_path": "GAASH-Lab/Grounded-Teacher",
          "downloads": "0",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/GAASH-Lab/Grounded-Teacher"
        }
      ],
      "conference": "context-aware-grounded-teacher-for-source",
      "conference_url_abs": "https://arxiv.org/abs/2504.15404",
      "tasks": [
        "object-detection",
        "Object Detection",
        "Source Free Object Detection"
      ],
      "repo_urls": [
        "https://github.com/Tajamul21/Grounded_Teacher"
      ],
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2504.15457",
      "abstract": "Being able to cooperate with new people is an important component of many economically valuable AI tasks, from household robotics to autonomous driving. However, generalizing to novel humans requires training on data that captures the diversity of human behaviors. Adversarial training is a promising method that allows dynamic data generation and ensures that agents are robust. It creates a feedback loop where the agent's performance influences the generation of new adversarial data, which can be used immediately to train the agent. However, adversarial training is difficult to apply in a cooperative task; how can we train an adversarial cooperator? We propose a novel strategy that combines a pretrained generative model to simulate valid cooperative agent policies with adversarial training to maximize regret. We call our method GOAT: Generative Online Adversarial Training. In this framework, the GOAT dynamically searches the latent space of the generative model for coordination strategies where the learning policy, the Cooperator agent, underperforms. GOAT enables better generalization by exposing the Cooperator to various challenging interaction scenarios. We maintain realistic coordination strategies by keeping the generative model frozen, thus avoiding adversarial exploitation. We evaluate GOAT with real human partners, and the results demonstrate state of the art performance on the Overcooked benchmark, highlighting its effectiveness in generalizing to diverse human behaviors.",
      "authors": [
        "Paresh Chaudhary",
        "Yancheng Liang",
        "Daphne Chen",
        "Simon S. Du",
        "Natasha Jaques"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.15457",
        "HTML": "https://arxiv.org/html/2504.15457",
        "PDF": "https://arxiv.org/pdf/2504.15457"
      },
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Mon, 21 Apr 2025 21:53:00 GMT",
          "size": "10280kb",
          "version": "v1"
        },
        {
          "date": "Tue, 29 Apr 2025 21:02:02 GMT",
          "size": "10280kb",
          "version": "v2"
        },
        {
          "date": "Wed, 25 Jun 2025 23:40:16 GMT",
          "size": "5836kb",
          "version": "v3"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Improving Human-AI Coordination through Online Adversarial Training and Generative Models",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This research is centered around adversarial training for AI coordination with humans, involving generative models. It does not address any aspects related to LLM training data processing or data engineering."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2504.15920",
      "abstract": "Graph Neural Networks (GNNs) have demonstrated impressive performance across diverse graph-based tasks by leveraging message passing to capture complex node relationships. However, when applied to large-scale real-world graphs, GNNs face two major challenges: First, it becomes increasingly difficult to ensure both scalability and efficiency, as the repeated aggregation of large neighborhoods leads to significant computational overhead; Second, the over-smoothing problem arises, where excessive or deep propagation makes node representations indistinguishable, severely hindering model expressiveness. To tackle these issues, we propose ScaleGNN, a novel framework that adaptively fuses multi-hop node features for both scalable and effective graph learning. First, we construct per-hop pure neighbor matrices that capture only the exclusive structural information at each hop, avoiding the redundancy of conventional aggregation. Then, an enhanced feature fusion strategy significantly balances low-order and high-order information, preserving both local detail and global correlations without incurring excessive complexity. To further reduce redundancy and over-smoothing, we introduce a Local Contribution Score (LCS)-based masking mechanism to filter out less relevant high-order neighbors, ensuring that only the most meaningful information is aggregated. In addition, learnable sparse constraints selectively integrate multi-hop valuable features, emphasizing the most informative high-order neighbors. Extensive experiments on real-world datasets demonstrate that ScaleGNN consistently outperforms state-of-the-art GNNs in both predictive accuracy and computational efficiency, highlighting its practical value for large-scale graph learning.",
      "authors": [
        "Xiang Li",
        "Jianpeng Qi",
        "Haobing Liu",
        "Yuan Cao",
        "Guoqing Chao",
        "Zhongying Zhao",
        "Junyu Dong",
        "Yanwei Yu"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.15920",
        "HTML": "https://arxiv.org/html/2504.15920",
        "PDF": "https://arxiv.org/pdf/2504.15920"
      },
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 22 Apr 2025 14:05:11 GMT",
          "size": "1349kb",
          "version": "v1"
        },
        {
          "date": "Fri, 25 Apr 2025 03:36:35 GMT",
          "size": "1349kb",
          "version": "v2"
        },
        {
          "date": "Thu, 19 Jun 2025 19:21:40 GMT",
          "size": "1147kb",
          "version": "v3"
        },
        {
          "date": "Thu, 26 Jun 2025 14:41:32 GMT",
          "size": "1606kb",
          "version": "v4"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "ScaleGNN: Towards Scalable Graph Neural Networks via Adaptive High-order Neighboring Feature Fusion",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This study presents a framework for scalable graph neural networks with adaptive feature fusion. It does not involve any LLM training data engineering or processing contributions."
      },
      "tasks": [
        "Computational Efficiency",
        "Graph Learning"
      ],
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2504.16307",
      "abstract": "Schelling segregation is a well-established model used to investigate the dynamics of segregation in agent-based models. Since we consider segregation to be key for the development of political polarisation, we are interested in what insights it could give for this problem. We tested basic questions of segregation on an agent-based social network model where agents' connections were not restricted by their spatial position, and made the network graph much denser than previous tests of Schelling segregation in social networks.\n  We found that a dense social network does not become as strongly segregated as a sparse network, and that agents' numbers of same-group neighbours do not greatly exceed their desired numbers (i.e. they do not end up more segregated than they desire to be). Furthermore, we found that the network was very difficult to polarise when one group was somewhat smaller than the other, and that the network became unstable when one group was extremely small; both phenomena may help explain the complexity of real-world polarisation dynamics, such as unique risks faced by very small group sin a society. Finally we tested Fossett's (2006) \"paradox of weak minority preferences\", a well-established result in grid- and map-based models which shows that an increase in the minority group's desire for same-group neighbours can create more segregation than a similar increase for the majority group. In a densely connected social network, we find that the evidence for this effect is mixed.",
      "authors": [
        "Sage Anastasi",
        "Giulio Dalla Riva"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.16307",
        "HTML": "https://arxiv.org/html/2504.16307",
        "PDF": "https://arxiv.org/pdf/2504.16307"
      },
      "subjects": [
        "Social and Information Networks (cs.SI)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 22 Apr 2025 22:55:15 GMT",
          "size": "139kb",
          "version": "v1"
        },
        {
          "date": "Mon, 23 Jun 2025 04:17:27 GMT",
          "size": "111kb",
          "version": "v2"
        },
        {
          "date": "Wed, 25 Jun 2025 23:31:15 GMT",
          "size": "111kb",
          "version": "v3"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Schelling segregation dynamics in densely-connected social network graphs",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The focus of the paper is on segregation dynamics in social networks, analyzed through the Schelling model. It is unrelated to any aspect of LLM training data processing or data engineering."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2504.16320",
      "abstract": "The 6-Degree of Freedom (DoF) grasp method based on point clouds has shown significant potential in enabling robots to grasp target objects. However, most existing methods are based on the point clouds (2.5D points) generated from single-view depth images. These point clouds only have one surface side of the object providing incomplete geometry information, which mislead the grasping algorithm to judge the shape of the target object, resulting in low grasping accuracy. Humans can accurately grasp objects from a single view by leveraging their geometry experience to estimate object shapes. Inspired by humans, we propose a novel 6-DoF grasping framework that converts the point completion results as object shape features to train the 6-DoF grasp network. Here, point completion can generate approximate complete points from the 2.5D points similar to the human geometry experience, and converting it as shape features is the way to utilize it to improve grasp efficiency. Furthermore, due to the gap between the network generation and actual execution, we integrate a score filter into our framework to select more executable grasp proposals for the real robot. This enables our method to maintain a high grasp quality in any camera viewpoint. Extensive experiments demonstrate that utilizing complete point features enables the generation of significantly more accurate grasp proposals and the inclusion of a score filter greatly enhances the credibility of real-world robot grasping. Our method achieves a 17.8\\% success rate higher than the state-of-the-art method in real-world experiments.",
      "authors": [
        "Yaofeng Cheng",
        "Fusheng Zha",
        "Wei Guo",
        "Pengfei Wang",
        "Chao Zeng",
        "Lining Sun and Chenguang Yang"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.16320",
        "HTML": "https://arxiv.org/html/2504.16320",
        "PDF": "https://arxiv.org/pdf/2504.16320"
      },
      "subjects": [
        "Robotics (cs.RO)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 22 Apr 2025 23:37:05 GMT",
          "size": "15484kb",
          "version": "v1"
        },
        {
          "date": "Thu, 26 Jun 2025 12:42:10 GMT",
          "size": "14138kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "PCF-Grasp: Converting Point Completion to Geometry Feature to Enhance 6-DoF Grasp",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper proposes a framework for improving robotic grasp accuracy using point cloud completion. It does not cover LLM training data processing or data engineering tasks."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2504.16606",
      "abstract": "3DGS is an emerging and increasingly popular technology in the field of novel view synthesis. Its highly realistic rendering quality and real-time rendering capabilities make it promising for various applications. However, when applied to large-scale aerial urban scenes, 3DGS methods suffer from issues such as excessive memory consumption, slow training times, prolonged partitioning processes, and significant degradation in rendering quality due to the increased data volume. To tackle these challenges, we introduce \\textbf{HUG}, a novel approach that enhances data partitioning and reconstruction quality by leveraging a hierarchical neural Gaussian representation. We first propose a visibility-based data partitioning method that is simple yet highly efficient, significantly outperforming existing methods in speed. Then, we introduce a novel hierarchical weighted training approach, combined with other optimization strategies, to substantially improve reconstruction quality. Our method achieves state-of-the-art results on one synthetic dataset and four real-world datasets.",
      "authors": [
        "Mai Su",
        "Zhongtao Wang",
        "Huishan Au",
        "Yilong Li",
        "Xizhe Cao",
        "Chengwei Pan",
        "Yisong Chen",
        "Guoping Wang"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.16606",
        "HTML": "https://arxiv.org/html/2504.16606",
        "PDF": "https://arxiv.org/pdf/2504.16606"
      },
      "subjects": [
        "Graphics (cs.GR)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 23 Apr 2025 10:40:40 GMT",
          "size": "32961kb",
          "version": "v1"
        },
        {
          "date": "Thu, 26 Jun 2025 06:12:14 GMT",
          "size": "22527kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "HUG: Hierarchical Urban Gaussian Splatting with Block-Based Reconstruction for Large-Scale Aerial Scenes",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on enhancing rendering quality and data partitioning in 3DGS for large-scale aerial scenes using a hierarchical neural Gaussian representation, which is not related to LLM training data processing."
      },
      "tasks": [],
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2504.17404",
      "abstract": "As Artificial Intelligence (AI) advances toward Artificial General Intelligence (AGI) and eventually Artificial Superintelligence (ASI), it may potentially surpass human control, deviate from human values, and even lead to irreversible catastrophic consequences in extreme cases. This looming risk underscores the critical importance of the \"superalignment\" problem - ensuring that AI systems which are much smarter than humans, remain aligned with human (compatible) intentions and values. While current scalable oversight and weak-to-strong generalization methods demonstrate certain applicability, they exhibit fundamental flaws in addressing the superalignment paradigm - notably, the unidirectional imposition of human values cannot accommodate superintelligence's autonomy or ensure AGI/ASI's stable learning. We contend that the values for sustainable symbiotic society should be co-shaped by humans and living AI together, achieving \"Super Co-alignment.\" Guided by this vision, we propose a concrete framework that integrates external oversight and intrinsic proactive alignment. External oversight superalignment should be grounded in human-centered ultimate decision, supplemented by interpretable automated evaluation and correction, to achieve continuous alignment with humanity's evolving values. Intrinsic proactive superalignment is rooted in a profound understanding of the Self, others, and society, integrating self-awareness, self-reflection, and empathy to spontaneously infer human intentions, distinguishing good from evil and proactively prioritizing human well-being. The integration of externally-driven oversight with intrinsically-driven proactive alignment will co-shape symbiotic values and rules through iterative human-AGI/ASI co-alignment, paving the way for achieving safe and beneficial AGI and ASI for good, for human, and for a symbiotic ecology.",
      "authors": [
        "Yi Zeng",
        "Feifei Zhao",
        "Yuwei Wang",
        "Enmeng Lu",
        "Yaodong Yang",
        "Lei Wang",
        "Chao Liu",
        "Yitao Liang",
        "Dongcheng Zhao",
        "Bing Han",
        "Haibo Tong",
        "Yao Liang",
        "Dongqi Liang",
        "Kang Sun",
        "Boyuan Chen",
        "Jinyu Fan"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.17404",
        "HTML": "https://arxiv.org/html/2504.17404",
        "PDF": "https://arxiv.org/pdf/2504.17404"
      },
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 24 Apr 2025 09:53:49 GMT",
          "size": "337kb",
          "version": "v1"
        },
        {
          "date": "Fri, 25 Apr 2025 15:32:41 GMT",
          "size": "338kb",
          "version": "v2"
        },
        {
          "date": "Fri, 23 May 2025 02:47:48 GMT",
          "size": "338kb",
          "version": "v3"
        },
        {
          "date": "Thu, 26 Jun 2025 01:54:05 GMT",
          "size": "335kb",
          "version": "v4"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Super Co-alignment for Sustainable Symbiotic Society",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper discusses AI alignment and the 'superalignment' problem for AGI and ASI, with no mention of LLM training data processing or data engineering contributions."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2504.18506",
      "abstract": "Transition path sampling (TPS), which involves finding probable paths connecting two points on an energy landscape, remains a challenge due to the complexity of real-world atomistic systems. Current machine learning approaches use expensive, task-specific, and data-free training procedures, limiting their ability to benefit from high-quality datasets and large-scale pre-trained models. In this work, we address TPS by interpreting candidate paths as trajectories sampled from stochastic dynamics induced by the learned score function of pre-trained generative models, specifically denoising diffusion and flow matching. Under these dynamics, finding high-likelihood transition paths becomes equivalent to minimizing the Onsager-Machlup (OM) action functional. This enables us to repurpose pre-trained generative models for TPS in a zero-shot manner, in contrast with bespoke, task-specific approaches in previous work. We demonstrate our approach on varied molecular systems, obtaining diverse, physically realistic transition pathways and generalizing beyond the pre-trained model's original training dataset. Our method can be easily incorporated into new generative models, making it practically relevant as models continue to scale and improve with increased data availability. Code is available at github.com/ASK-Berkeley/OM-TPS.",
      "authors": [
        "Sanjeev Raja",
        "Martin \\v{S}\\'ipka",
        "Michael Psenka",
        "Tobias Kreiman",
        "Michal Pavelka",
        "Aditi S. Krishnapriyan"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.18506",
        "HTML": "https://arxiv.org/html/2504.18506",
        "PDF": "https://arxiv.org/pdf/2504.18506"
      },
      "subjects": [
        "Machine Learning (cs.LG)",
        "Materials Science (cond-mat.mtrl-sci)",
        "Chemical Physics (physics.chem-ph)",
        "Biomolecules (q-bio.BM)"
      ],
      "submission_historys": [
        {
          "date": "Fri, 25 Apr 2025 17:17:17 GMT",
          "size": "33888kb",
          "version": "v1"
        },
        {
          "date": "Thu, 01 May 2025 17:52:23 GMT",
          "size": "33775kb",
          "version": "v2"
        },
        {
          "date": "Thu, 26 Jun 2025 15:59:16 GMT",
          "size": "23741kb",
          "version": "v3"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Action-Minimization Meets Generative Modeling: Efficient Transition Path Sampling with the Onsager-Machlup Functional",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper addresses transition path sampling using generative models for atomistic systems, focusing on physical modeling rather than LLM training data. There is no contribution to LLM data processing."
      },
      "tasks": [
        "Denoising"
      ],
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2505.00460",
      "abstract": "In situations where the solution of a high-fidelity dynamical system needs to be evaluated repeatedly, over a vast pool of parametric configurations and in absence of access to the underlying governing equations, data-driven model reduction techniques are preferable. We propose a novel active learning approach to build a parametric data-driven reduced-order model (ROM) by greedily picking the most important parameter samples from the parameter domain. As a result, during the ROM construction phase, the number of high-fidelity solutions dynamically grow in a principled fashion. The high-fidelity solution snapshots are expressed in several parameter-specific linear subspaces, with the help of proper orthogonal decomposition (POD), and the relative distance between these subspaces is used as a guiding mechanism to perform active learning. For successfully achieving this, we provide a distance measure to evaluate the similarity between pairs of linear subspaces with different dimensions, and also show that this distance measure is a metric. The usability of the proposed subspace-distance-enabled active learning (SDE-AL) framework is demonstrated by augmenting two existing non-intrusive reduced-order modeling approaches, and providing their active-learning-driven (ActLearn) extensions, namely, SDE-ActLearn-POD-KSNN, and SDE-ActLearn-POD-NN. Furthermore, we report positive results for two parametric physical models, highlighting the efficiency of the proposed SDE-AL approach.",
      "authors": [
        "Harshit Kapadia",
        "Peter Benner",
        "Lihong Feng"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.00460",
        "HTML": "https://arxiv.org/html/2505.00460",
        "PDF": "https://arxiv.org/pdf/2505.00460"
      },
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Computational Engineering, Finance, and Science (cs.CE)",
        "Machine Learning (cs.LG)",
        "Numerical Analysis (cs.NA)",
        "Dynamical Systems (math.DS)",
        "Computational Physics (physics.comp-ph)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 01 May 2025 11:28:18 GMT",
          "size": "21857kb",
          "version": "v1"
        },
        {
          "date": "Wed, 25 Jun 2025 22:00:25 GMT",
          "size": "21855kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Subspace-Distance-Enabled Active Learning for Efficient Data-Driven Model Reduction of Parametric Dynamical Systems",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper proposes an active learning approach for data-driven model reduction in parametric dynamical systems, and does not address LLM training data engineering or processing."
      },
      "tasks": [
        "Active Learning"
      ],
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2505.00482",
      "abstract": "We present JointDiT, a diffusion transformer that models the joint distribution of RGB and depth. By leveraging the architectural benefit and outstanding image prior of the state-of-the-art diffusion transformer, JointDiT not only generates high-fidelity images but also produces geometrically plausible and accurate depth maps. This solid joint distribution modeling is achieved through two simple yet effective techniques that we propose, i.e., adaptive scheduling weights, which depend on the noise levels of each modality, and the unbalanced timestep sampling strategy. With these techniques, we train our model across all noise levels for each modality, enabling JointDiT to naturally handle various combinatorial generation tasks, including joint generation, depth estimation, and depth-conditioned image generation by simply controlling the timestep of each branch. JointDiT demonstrates outstanding joint generation performance. Furthermore, it achieves comparable results in depth estimation and depth-conditioned image generation, suggesting that joint distribution modeling can serve as a replaceable alternative to conditional generation. The project page is available at https://byungki-k.github.io/JointDiT/.",
      "authors": [
        "Kwon Byung-Ki",
        "Qi Dai",
        "Lee Hyoseok",
        "Chong Luo",
        "Tae-Hyun Oh"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.00482",
        "HTML": "https://arxiv.org/html/2505.00482",
        "PDF": "https://arxiv.org/pdf/2505.00482"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 01 May 2025 12:21:23 GMT",
          "size": "27033kb",
          "version": "v1"
        },
        {
          "date": "Thu, 26 Jun 2025 06:21:40 GMT",
          "size": "19904kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "JointDiT: Enhancing RGB-Depth Joint Modeling with Diffusion Transformers",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper presents a diffusion transformer for joint RGB-depth modeling, focusing on image and depth map generation tasks, without involving any aspect of LLM training data processing."
      },
      "tasks": [
        "Depth Estimation",
        "Image Generation",
        "Scheduling"
      ],
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2505.00753",
      "abstract": "Recent advances in large language models (LLMs) have sparked growing interest in building fully autonomous agents. However, fully autonomous LLM-based agents still face significant challenges, including limited reliability due to hallucinations, difficulty in handling complex tasks, and substantial safety and ethical risks, all of which limit their feasibility and trustworthiness in real-world applications. To overcome these limitations, LLM-based human-agent systems (LLM-HAS) incorporate human-provided information, feedback, or control into the agent system to enhance system performance, reliability and safety. These human-agent collaboration systems enable humans and LLM-based agents to collaborate effectively by leveraging their complementary strengths. This paper provides the first comprehensive and structured survey of LLM-HAS. It clarifies fundamental concepts, systematically presents core components shaping these systems, including environment & profiling, human feedback, interaction types, orchestration and communication, explores emerging applications, and discusses unique challenges and opportunities arising from human-AI collaboration. By consolidating current knowledge and offering a structured overview, we aim to foster further research and innovation in this rapidly evolving interdisciplinary field. Paper lists and resources are available at https://github.com/HenryPengZou/Awesome-Human-Agent-Collaboration-Interaction-Systems.",
      "authors": [
        "Henry Peng Zou",
        "Wei-Chieh Huang",
        "Yaozu Wu",
        "Yankai Chen",
        "Chunyu Miao",
        "Hoang Nguyen",
        "Yue Zhou",
        "Weizhi Zhang",
        "Liancheng Fang",
        "Langzhou He",
        "Yangning Li",
        "Dongyuan Li",
        "Renhe Jiang",
        "Xue Liu",
        "Philip S. Yu"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.00753",
        "HTML": "https://arxiv.org/html/2505.00753",
        "PDF": "https://arxiv.org/pdf/2505.00753"
      },
      "subjects": [
        "Computation and Language (cs.CL)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 01 May 2025 08:29:26 GMT",
          "size": "3544kb",
          "version": "v1"
        },
        {
          "date": "Tue, 20 May 2025 05:12:02 GMT",
          "size": "3544kb",
          "version": "v2"
        },
        {
          "date": "Mon, 23 Jun 2025 07:45:18 GMT",
          "size": "2168kb",
          "version": "v3"
        },
        {
          "date": "Thu, 26 Jun 2025 12:53:30 GMT",
          "size": "2168kb",
          "version": "v4"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "LLM-Based Human-Agent Collaboration and Interaction Systems: A Survey",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper primarily focuses on surveying human-agent collaboration systems involving LLMs and doesn't discuss training data processing for LLMs."
      },
      "tasks": [
        "Language Modeling",
        "Language Modelling",
        "Large Language Model"
      ],
      "repo_urls": [
        "https://github.com/HenryPengZou/Awesome-LLM-Based-Human-Agent-System-Papers",
        "https://github.com/henrypengzou/awesome-llm-based-human-agent-systems"
      ],
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2505.01996",
      "abstract": "We highlight a curious empirical result within modern Vision Transformers (ViTs). Specifically, self-attention catastrophically fails to train unless it is used in conjunction with a skip connection. This is in contrast to other elements of a ViT that continue to exhibit good performance (albeit suboptimal) when skip connections are removed. Further, we show that this critical dependence on skip connections is a relatively new phenomenon, with previous deep architectures (\\eg, CNNs) exhibiting good performance in their absence. In this paper, we theoretically characterize that the self-attention mechanism is fundamentally ill-conditioned and is, therefore, uniquely dependent on skip connections for regularization. Additionally, we propose Token Graying -- a simple yet effective complement (to skip connections) that further improves the condition of input tokens. We validate our approach in both supervised and self-supervised training methods.",
      "authors": [
        "Yiping Ji",
        "Hemanth Saratchandran",
        "Peyman Moghadam",
        "Simon Lucey"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.01996",
        "HTML": "https://arxiv.org/html/2505.01996",
        "PDF": "https://arxiv.org/pdf/2505.01996"
      },
      "subjects": [
        "Machine Learning (cs.LG)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Sun, 04 May 2025 05:42:21 GMT",
          "size": "969kb",
          "version": "v1"
        },
        {
          "date": "Wed, 25 Jun 2025 23:06:43 GMT",
          "size": "706kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Always Skip Attention",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper addresses the issue of self-attention mechanisms in Vision Transformers and proposes a new method to address its shortcomings, without mentioning LLM training data processing."
      },
      "tasks": [],
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2505.06978",
      "abstract": "As Cellular Vehicle-to-Everything (C-V2X) evolves towards future sixth-generation (6G) networks, Connected Autonomous Vehicles (CAVs) are emerging to become a key application. Leveraging data-driven Machine Learning (ML), especially Deep Reinforcement Learning (DRL), is expected to significantly enhance CAV decision-making in both vehicle control and V2X communication under uncertainty. These two decision-making processes are closely intertwined, with the value of information (VoI) acting as a crucial bridge between them. In this paper, we introduce Sequential Stochastic Decision Process (SSDP) models to define and assess VoI, demonstrating their application in optimizing communication systems for CAVs. Specifically, we formally define the SSDP model and demonstrate that the MDP model is a special case of it. The SSDP model offers a key advantage by explicitly representing the set of information that can enhance decision-making when available. Furthermore, as current research on VoI remains fragmented, we propose a systematic VoI modeling framework grounded in the MDP, Reinforcement Learning (RL) and Optimal Control theories. We define different categories of VoI and discuss their corresponding estimation methods. Finally, we present a structured approach to leverage the various VoI metrics for optimizing the ``When\", ``What\", and ``How\" to communicate problems. For this purpose, SSDP models are formulated with VoI-associated reward functions derived from VoI-based optimization objectives. While we use a simple vehicle-following control problem to illustrate the proposed methodology, it holds significant potential to facilitate the joint optimization of stochastic, sequential control and communication decisions in a wide range of networked control systems.",
      "authors": [
        "Lei Lei and Kan Zheng and Xuemin (Sherman) Shen"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.06978",
        "HTML": "https://arxiv.org/html/2505.06978",
        "PDF": "https://arxiv.org/pdf/2505.06978"
      },
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Sun, 11 May 2025 13:30:35 GMT",
          "size": "271kb",
          "version": "v1"
        },
        {
          "date": "Thu, 26 Jun 2025 15:01:20 GMT",
          "size": "764kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Learning Value of Information towards Joint Communication and Control in 6G V2X",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The content is centered around communication and control in networked vehicular systems using deep reinforcement learning, with no discussion on LLM training data processing."
      },
      "tasks": [
        "Autonomous Vehicles",
        "Decision Making",
        "Deep Reinforcement Learning",
        "Reinforcement Learning (RL)"
      ],
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2505.10044",
      "abstract": "The large-scale integration of robots in agriculture offers many promises for enhancing sustainability and increasing food production. The numerous applications of agricultural robots rely on the transmission of data via mobile network, with the amount of data depending on the services offered by the robots and the level of on-board technology. Nevertheless, infrastructure required to deploy these robots, as well as the related energy and environmental consequences, appear overlooked in the digital agriculture literature. In this study, we propose a method for assessing the additional energy consumption and carbon footprint induced by a large-scale deployment of agricultural robots. Our method also estimates the share of agricultural area that can be managed by the deployed robots with respect to network infrastructure constraints. We have applied this method to metropolitan France mobile network and agricultural parcels for five different robotic scenarios. Our results show that increasing the robot's bitrate needs leads to significant additional impacts, which increase at a pace that is poorly captured by classical linear extrapolation methods. When constraining the network to the existing sites, increased bitrate needs also comes with a rapidly decreasing manageable agricultural area.",
      "authors": [
        "Pierre La Rocca (UB",
        "LaBRI",
        "MANAO)",
        "Ga\\\"el Guennebaud (MANAO)",
        "Aur\\'elie Bugeau (IUF",
        "LaBRI",
        "UB)"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.10044",
        "HTML": "https://arxiv.org/html/2505.10044",
        "PDF": "https://arxiv.org/pdf/2505.10044"
      },
      "subjects": [
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 15 May 2025 07:41:40 GMT",
          "size": "2333kb",
          "version": "v1"
        },
        {
          "date": "Thu, 12 Jun 2025 08:39:24 GMT",
          "size": "2333kb",
          "version": "v2"
        },
        {
          "date": "Thu, 26 Jun 2025 08:59:33 GMT",
          "size": "2333kb",
          "version": "v3"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "To what extent can current French mobile network support agricultural robots?",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on assessing the energy consumption and carbon footprint of deploying agricultural robots and does not address any aspects of LLM training data collection, construction, or processing."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2505.10573",
      "abstract": "While the capabilities and utility of AI systems have advanced, rigorous norms for evaluating these systems have lagged. Grand claims, such as models achieving general reasoning capabilities, are supported with model performance on narrow benchmarks, like performance on graduate-level exam questions, which provide a limited and potentially misleading assessment. We provide a structured approach for reasoning about the types of evaluative claims that can be made given the available evidence. For instance, our framework helps determine whether performance on a mathematical benchmark is an indication of the ability to solve problems on math tests or instead indicates a broader ability to reason. Our framework is well-suited for the contemporary paradigm in machine learning, where various stakeholders provide measurements and evaluations that downstream users use to validate their claims and decisions. At the same time, our framework also informs the construction of evaluations designed to speak to the validity of the relevant claims. By leveraging psychometrics' breakdown of validity, evaluations can prioritize the most critical facets for a given claim, improving empirical utility and decision-making efficacy. We illustrate our framework through detailed case studies of vision and language model evaluations, highlighting how explicitly considering validity strengthens the connection between evaluation evidence and the claims being made.",
      "authors": [
        "Olawale Salaudeen",
        "Anka Reuel",
        "Ahmed Ahmed",
        "Suhana Bedi",
        "Zachary Robertson",
        "Sudharsan Sundar",
        "Ben Domingue",
        "Angelina Wang",
        "Sanmi Koyejo"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.10573",
        "HTML": "https://arxiv.org/html/2505.10573",
        "PDF": "https://arxiv.org/pdf/2505.10573"
      },
      "subjects": [
        "Computers and Society (cs.CY)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 13 May 2025 20:36:22 GMT",
          "size": "705kb",
          "version": "v1"
        },
        {
          "date": "Sun, 01 Jun 2025 14:36:56 GMT",
          "size": "705kb",
          "version": "v2"
        },
        {
          "date": "Sat, 07 Jun 2025 20:35:52 GMT",
          "size": "648kb",
          "version": "v3"
        },
        {
          "date": "Thu, 26 Jun 2025 16:38:11 GMT",
          "size": "648kb",
          "version": "v4"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Measurement to Meaning: A Validity-Centered Framework for AI Evaluation",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper discusses a framework for AI evaluation, particularly focusing on the validity of claims based on evaluations, without addressing LLM training data collection or processing."
      },
      "tasks": [
        "Math"
      ],
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2505.12540",
      "abstract": "We introduce the first method for translating text embeddings from one vector space to another without any paired data, encoders, or predefined sets of matches. Our unsupervised approach translates any embedding to and from a universal latent representation (i.e., a universal semantic structure conjectured by the Platonic Representation Hypothesis). Our translations achieve high cosine similarity across model pairs with different architectures, parameter counts, and training datasets.\n  The ability to translate unknown embeddings into a different space while preserving their geometry has serious implications for the security of vector databases. An adversary with access only to embedding vectors can extract sensitive information about the underlying documents, sufficient for classification and attribute inference.",
      "authors": [
        "Rishi Jha",
        "Collin Zhang",
        "Vitaly Shmatikov",
        "John X. Morris"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.12540",
        "HTML": "https://arxiv.org/html/2505.12540",
        "PDF": "https://arxiv.org/pdf/2505.12540"
      },
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Sun, 18 May 2025 20:37:07 GMT",
          "size": "3179kb",
          "version": "v1"
        },
        {
          "date": "Tue, 20 May 2025 15:38:41 GMT",
          "size": "3179kb",
          "version": "v2"
        },
        {
          "date": "Wed, 25 Jun 2025 21:04:02 GMT",
          "size": "2406kb",
          "version": "v3"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Harnessing the Universal Geometry of Embeddings",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on the translation of text embeddings across different vector spaces, emphasizing geometry preservation and security implications, without addressing LLM training data processing stages like collection, construction, or preprocessing."
      },
      "tasks": [
        "Attribute"
      ],
      "repo_urls": [
        "https://github.com/rjha18/vec2vec",
        "https://github.com/zhaoolee/garss"
      ],
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2505.12942",
      "abstract": "Large language models have demonstrated remarkable performance; however, their massive parameter counts make deployment highly expensive. Low-rank approximation offers a promising compression solution, yet existing approaches have two main limitations: (1) They focus on minimizing the output error of individual linear layers, without considering the architectural characteristics of Transformers, and (2) they decompose a large weight matrix into two small low-rank matrices. Consequently, these methods often fall short compared to other compression techniques like pruning and quantization, and introduce runtime overhead such as the extra GEMM kernel launches for decomposed small matrices. To address these limitations, we propose $\\tt A^\\tt 3$, a post-training low-rank approximation framework. $\\tt A^\\tt 3$ splits a Transformer layer into three functional components, namely $\\tt QK$, $\\tt OV$, and $\\tt MLP$. For each component, $\\tt A^\\tt 3$ provides an analytical solution that reduces the hidden dimension size inside each component while minimizing the component's functional loss ($\\it i.e.$, error in attention scores, attention outputs, and MLP outputs). This approach directly reduces model sizes, KV cache sizes, and FLOPs without introducing any runtime overheads. In addition, it provides a new narrative in advancing the optimization problem from singular linear layer loss optimization toward improved end-to-end performance. Through extensive experiments, we show that $\\tt A^\\tt 3$ maintains superior performance compared to SoTAs. For example, under the same reduction budget in computation and memory, our low-rank approximated LLaMA 3.1-70B achieves a perplexity of 4.69 on WikiText-2, outperforming the previous SoTA's 7.87 by 3.18. We also demonstrate the versatility of $\\tt A^\\tt 3$, including KV cache compression, quantization, and mixed-rank assignments for enhanced performance.",
      "authors": [
        "Jeffrey T. H. Wong",
        "Cheng Zhang",
        "Xinye Cao",
        "Pedro Gimenes",
        "George A. Constantinides",
        "Wayne Luk",
        "Yiren Zhao"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.12942",
        "HTML": "https://arxiv.org/html/2505.12942",
        "PDF": "https://arxiv.org/pdf/2505.12942"
      },
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Mon, 19 May 2025 10:29:32 GMT",
          "size": "5089kb",
          "version": "v1"
        },
        {
          "date": "Sat, 31 May 2025 22:12:10 GMT",
          "size": "1044kb",
          "version": "v2"
        },
        {
          "date": "Wed, 25 Jun 2025 23:03:54 GMT",
          "size": "1037kb",
          "version": "v3"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "A3 : an Analytical Low-Rank Approximation Framework for Attention",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper introduces a low-rank approximation framework to compress large language models by splitting Transformer layers, addressing memory efficiency and computational aspects, not directly related to LLM training data processing."
      },
      "tasks": [
        "Quantization"
      ],
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2505.15858",
      "abstract": "The C programming language has been foundational in building system-level software. However, its manual memory management model frequently leads to memory safety issues. In response, a modern system programming language, Rust, has emerged as a memory-safe alternative. Moreover, automating the C-to-Rust translation empowered by the rapid advancements of the generative capabilities of LLMs is gaining growing interest for large volumes of legacy C code. Despite some success, existing LLM-based approaches have constrained the role of LLMs to static prompt-response behavior and have not explored their agentic problem-solving capability. Applying the LLM agentic capability for the C-to-Rust translation introduces distinct challenges, as this task differs from the traditional LLM agent applications, such as math or commonsense QA domains. First, the scarcity of parallel C-to-Rust datasets hinders the retrieval of suitable code translation exemplars for in-context learning. Second, unlike math or commonsense QA, the intermediate steps required for C-to-Rust are not well-defined. Third, it remains unclear how to organize and cascade these intermediate steps to construct a correct translation trajectory. To address these challenges in the C-to-Rust translation, we propose a novel intermediate step, the Virtual Fuzzing-based equivalence Test (VFT), and an agentic planning framework, the LLM-powered Agent for C-to-Rust code translation (LAC2R). The VFT guides LLMs to identify input arguments that induce divergent behaviors between an original C function and its Rust counterpart and to generate informative diagnoses to refine the unsafe Rust code. LAC2R uses the MCTS to systematically organize the LLM-induced intermediate steps for correct translation. We experimentally demonstrated that LAC2R effectively conducts C-to-Rust translation on large-scale, real-world benchmarks.",
      "authors": [
        "HoHyun Sim",
        "Hyeonjoong Cho",
        "Yeonghyeon Go",
        "Zhoulai Fu",
        "Ali Shokri",
        "Binoy Ravindran"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.15858",
        "HTML": "https://arxiv.org/html/2505.15858",
        "PDF": "https://arxiv.org/pdf/2505.15858"
      },
      "subjects": [
        "Programming Languages (cs.PL)",
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 21 May 2025 01:26:23 GMT",
          "size": "2126kb",
          "version": "v1"
        },
        {
          "date": "Thu, 26 Jun 2025 15:16:53 GMT",
          "size": "1906kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Large Language Model-Powered Agent for C to Rust Code Translation",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The study deals with using LLMs for C to Rust code translation, leveraging virtual fuzzing and planning frameworks. It doesn\u2019t pertain to LLM training data processing tasks or techniques."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2505.16946",
      "abstract": "This study analyzes tract-level real estate ownership patterns in New York State (NYS) and New York City (NYC) to uncover racial disparities. We use an advanced race/ethnicity imputation model (LSTM+Geo with XGBoost filtering, validated at 89.2% accuracy) to compare the predicted racial composition of property owners to the resident population from census data. We examine both a Full Model (statewide) and a Name-Only LSTM Model (NYC) to assess how incorporating geospatial context affects our predictions and disparity estimates. The results reveal significant inequities: White individuals hold a disproportionate share of properties and property value relative to their population, while Black, Hispanic, and Asian communities are underrepresented as property owners. These disparities are most pronounced in minority-majority neighborhoods, where ownership is predominantly White despite a predominantly non-White population. Corporate ownership (LLCs, trusts, etc.) exacerbates these gaps by reducing owner-occupied opportunities in urban minority communities. We provide a breakdown of ownership vs. population by race for majority-White, -Black, -Hispanic, and -Asian tracts, identify those with extreme ownership disparities, and compare patterns in urban, suburban, and rural contexts. The findings underscore persistent racial inequity in property ownership, reflecting broader historical and socio-economic forces, and highlight the importance of data-driven approaches to address these issues.",
      "authors": [
        "Sanjana Chalavadi",
        "Andrei Pastor",
        "and Terry Leitch"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.16946",
        "HTML": "https://arxiv.org/html/2505.16946",
        "PDF": "https://arxiv.org/pdf/2505.16946"
      },
      "subjects": [
        "Computers and Society (cs.CY)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 22 May 2025 17:32:28 GMT",
          "size": "4258kb",
          "version": "v1"
        },
        {
          "date": "Tue, 03 Jun 2025 03:50:43 GMT",
          "size": "656kb",
          "version": "v2"
        },
        {
          "date": "Thu, 26 Jun 2025 17:32:06 GMT",
          "size": "656kb",
          "version": "v3"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "NY Real Estate Racial Equity Analysis via Applied Machine Learning",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper deals with racial equity analysis in real estate using machine learning models. It discusses imputation models and property ownership analysis but has no relevance to LLM training data processing or data engineering."
      },
      "tasks": [
        "Imputation"
      ],
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2505.18389",
      "abstract": "The evolution toward open, programmable O-RAN and AI-RAN 6G networks creates unprecedented opportunities for Intent-Based Networking (IBN) to dynamically optimize RAN[...]. However, applying IBN effectively to the RAN scheduler [...] remains a significant challenge. Current approaches predominantly rely on coarse-grained network slicing, lacking the granularity for dynamic adaptation to individual user conditions and traffic patterns. Despite the existence of a vast body of scheduling algorithms [...], their practical utilization is hindered by implementation heterogeneity, insufficient systematic evaluation in production environments, and the complexity of developing high-performance scheduler implementations.[...] To address these limitations, we propose ALLSTaR (Automated LLm-driven Scheduler generation and Testing for intent-based RAN), a novel framework leveraging LLMs for automated, intent-driven scheduler design, implementation, and evaluation. ALLSTaR interprets NL intents, automatically generates functional scheduler code from the research literature using OCR and LLMs, and intelligently matches operator intents to the most suitable scheduler(s). Our implementation deploys these schedulers as O-RAN dApps, enabling on-the-fly deployment and testing on a production-grade, 5G-compliant testbed. This approach has enabled the largest-scale OTA experimental comparison of 18 scheduling algorithms automatically synthesized from the academic literature. The resulting performance profiles serve as the input for our Intent-Based Scheduling (IBS) framework, which dynamically selects and deploys appropriate schedulers that optimally satisfy operator intents. We validate our approach through multiple use cases unattainable with current slicing-based optimization techniques, demonstrating fine-grained control based on buffer status, physical layer conditions, and heterogeneous traffic types",
      "authors": [
        "Maxime Elkael",
        "Michele Polese",
        "Reshma Prasad",
        "Stefano Maxenti",
        "Tommaso Melodia"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.18389",
        "HTML": "https://arxiv.org/html/2505.18389",
        "PDF": "https://arxiv.org/pdf/2505.18389"
      },
      "subjects": [
        "Networking and Internet Architecture (cs.NI)"
      ],
      "submission_historys": [
        {
          "date": "Fri, 23 May 2025 21:33:16 GMT",
          "size": "8314kb",
          "version": "v1"
        },
        {
          "date": "Tue, 27 May 2025 14:13:53 GMT",
          "size": "8314kb",
          "version": "v2"
        },
        {
          "date": "Thu, 26 Jun 2025 04:31:54 GMT",
          "size": "8314kb",
          "version": "v3"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "ALLSTaR: Automated LLM-Driven Scheduler Generation and Testing for Intent-Based RAN",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper proposes a framework for RAN scheduler design using LLMs, focusing on network optimization and not on the processing of training data for LLMs."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2505.20574",
      "abstract": "Recent progress in multimodal graph neural networks has demonstrated that augmenting atomic XYZ geometries with textual chemical descriptors can enhance predictive accuracy across a range of electronic and thermodynamic properties. However, naively appending large sets of heterogeneous descriptors often degrades performance on tasks sensitive to molecular shape or symmetry, and undermines interpretability. xChemAgents proposes a cooperative agent framework that injects physics-aware reasoning into multimodal property prediction. xChemAgents comprises two language-model-based agents: a Selector, which adaptively identifies a sparse, weighted subset of descriptors relevant to each target, and provides a natural language rationale; and a Validator, which enforces physical constraints such as unit consistency and scaling laws through iterative dialogue. On standard benchmark datasets, xChemAgents achieves up to a 22% reduction in mean absolute error over the state-of-the-art baselines, while producing faithful, human-interpretable explanations. Experiment results highlight the potential of cooperative, self-verifying agents to enhance both accuracy and transparency in foundation-model-driven materials science. The implementation and accompanying dataset are available at https://github.com/KurbanIntelligenceLab/xChemAgents.",
      "authors": [
        "Can Polat",
        "Mehmet Tuncel",
        "Mustafa Kurban",
        "Erchin Serpedin",
        "Hasan Kurban"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.20574",
        "HTML": "https://arxiv.org/html/2505.20574",
        "PDF": "https://arxiv.org/pdf/2505.20574"
      },
      "subjects": [
        "Multiagent Systems (cs.MA)",
        "Chemical Physics (physics.chem-ph)",
        "Computational Physics (physics.comp-ph)"
      ],
      "submission_historys": [
        {
          "date": "Mon, 26 May 2025 23:22:41 GMT",
          "size": "159kb",
          "version": "v1"
        },
        {
          "date": "Thu, 26 Jun 2025 14:07:02 GMT",
          "size": "159kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "xChemAgents: Agentic AI for Explainable Quantum Chemistry",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper introduces a framework for property prediction in quantum chemistry using language models. It does not relate to the collection or processing of training data for LLMs."
      },
      "repo_urls": [
        "https://github.com/kurbanintelligencelab/xchemagents"
      ],
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2505.21657",
      "abstract": "Large language models like GPT, LLAMA, and Claude have become incredibly powerful at generating text, but they are still black boxes, so it is hard to understand how they decide what to say. That lack of transparency can be problematic, especially in fields where trust and accountability matter. To help with this, we introduce SMILE, a new method that explains how these models respond to different parts of a prompt. SMILE is model-agnostic and works by slightly changing the input, measuring how the output changes, and then highlighting which words had the most impact. Create simple visual heat maps showing which parts of a prompt matter the most. We tested SMILE on several leading LLMs and used metrics such as accuracy, consistency, stability, and fidelity to show that it gives clear and reliable explanations. By making these models easier to understand, SMILE brings us one step closer to making AI more transparent and trustworthy.",
      "authors": [
        "Zeinab Dehghani",
        "Mohammed Naveed Akram",
        "Koorosh Aslansefat and Adil Khan"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.21657",
        "HTML": "https://arxiv.org/html/2505.21657",
        "PDF": "https://arxiv.org/pdf/2505.21657"
      },
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 27 May 2025 18:32:38 GMT",
          "size": "2975kb",
          "version": "v1"
        },
        {
          "date": "Fri, 13 Jun 2025 16:43:15 GMT",
          "size": "20787kb",
          "version": "v2"
        },
        {
          "date": "Thu, 26 Jun 2025 16:16:59 GMT",
          "size": "0kb",
          "version": "v3"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Explainability of Large Language Models using SMILE: Statistical Model-agnostic Interpretability with Local Explanations",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on explainability techniques for large language models, which involves analyzing model outputs rather than the training data used to build these models."
      },
      "tasks": [],
      "repo_urls": [
        "https://github.com/dependable-intelligent-systems-lab/xwhy"
      ],
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2505.22246",
      "abstract": "World models have recently become promising tools for predicting realistic visuals based on actions in complex environments. However, their reliance on only a few recent observations leads them to lose track of the long-term context. Consequently, in just a few steps the generated scenes drift from what was previously observed, undermining the temporal coherence of the sequence. This limitation of the state-of-the-art world models, most of which rely on diffusion, comes from their lack of a lasting environment state. To address this problem, we introduce StateSpaceDiffuser, where a diffusion model is enabled to perform long-context tasks by integrating features from a state-space model, representing the entire interaction history. This design restores long-term memory while preserving the high-fidelity synthesis of diffusion models. To rigorously measure temporal consistency, we develop an evaluation protocol that probes a model's ability to reinstantiate seen content in extended rollouts. Comprehensive experiments show that StateSpaceDiffuser significantly outperforms a strong diffusion-only baseline, maintaining a coherent visual context for an order of magnitude more steps. It delivers consistent views in both a 2D maze navigation and a complex 3D environment. These results establish that bringing state-space representations into diffusion models is highly effective in demonstrating both visual details and long-term memory.",
      "authors": [
        "Nedko Savov",
        "Naser Kazemi",
        "Deheng Zhang",
        "Danda Pani Paudel",
        "Xi Wang",
        "Luc Van Gool"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.22246",
        "HTML": "https://arxiv.org/html/2505.22246",
        "PDF": "https://arxiv.org/pdf/2505.22246"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 28 May 2025 11:27:54 GMT",
          "size": "41703kb",
          "version": "v1"
        },
        {
          "date": "Thu, 26 Jun 2025 12:10:36 GMT",
          "size": "41704kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "StateSpaceDiffuser: Bringing Long Context to Diffusion World Models",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper is about world models in diffusion models and enhancing context memory in generated visuals, with no direct focus on training data processing for LLMs."
      },
      "tasks": [
        "Mamba"
      ],
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2505.23062",
      "abstract": "Incorporating pre-collected offline data from a source environment can significantly improve the sample efficiency of reinforcement learning (RL), but this benefit is often challenged by discrepancies between the transition dynamics of the source and target environments. Existing methods typically address this issue by penalizing or filtering out source transitions in high dynamics-gap regions. However, their estimation of the dynamics gap often relies on KL divergence or mutual information, which can be ill-defined when the source and target dynamics have disjoint support. To overcome these limitations, we propose CompFlow, a method grounded in the theoretical connection between flow matching and optimal transport. Specifically, we model the target dynamics as a conditional flow built upon the output distribution of the source-domain flow, rather than learning it directly from a Gaussian prior. This composite structure offers two key advantages: (1) improved generalization for learning target dynamics, and (2) a principled estimation of the dynamics gap via the Wasserstein distance between source and target transitions. Leveraging our principled estimation of the dynamics gap, we further introduce an optimistic active data collection strategy that prioritizes exploration in regions of high dynamics gap, and theoretically prove that it reduces the performance disparity with the optimal policy. Empirically, CompFlow outperforms strong baselines across several RL benchmarks with shifted dynamics.",
      "authors": [
        "Lingkai Kong",
        "Haichuan Wang",
        "Tonghan Wang",
        "Guojun Xiong",
        "Milind Tambe"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.23062",
        "HTML": "https://arxiv.org/html/2505.23062",
        "PDF": "https://arxiv.org/pdf/2505.23062"
      },
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 29 May 2025 04:09:19 GMT",
          "size": "3326kb",
          "version": "v1"
        },
        {
          "date": "Wed, 25 Jun 2025 21:09:46 GMT",
          "size": "3308kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Composite Flow Matching for Reinforcement Learning with Shifted-Dynamics Data",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper discusses reinforcement learning and how to utilize offline data for sample efficiency, rather than focusing on LLM training data processing."
      },
      "tasks": [
        "reinforcement-learning",
        "Reinforcement Learning",
        "Reinforcement Learning (RL)"
      ],
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.01244",
      "abstract": "This work introduces a novel method to generate snapshot data for operator inference that guarantees the exact reconstruction of intrusive projection-based reduced-order models (ROMs). To ensure exact reconstruction, the operator inference least squares matrix must have full rank, without regularization. Existing works have achieved this full rank using heuristic strategies to generate snapshot data and a-posteriori checks on full rank, but without a guarantee of success. Our novel snapshot data generation method provides this guarantee thanks to two key ingredients: first we identify ROM states that induce full rank, then we generate snapshots corresponding to exactly these states by simulating multiple trajectories for only a single time step. This way, the number of required snapshots is minimal and orders of magnitude lower than typically reported with existing methods. The method avoids non-Markovian terms and does not require re-projection. Since the number of snapshots is minimal, the least squares problem simplifies to a linear system that is numerically more stable. In addition, because the inferred operators are exact, properties of the intrusive ROM operators such as symmetry or skew-symmetry are preserved. Numerical results for differential equations involving 2nd, 3rd and 8th order polynomials demonstrate that the novel snapshot data generation method leads to exact reconstruction of the intrusive reduced order models.",
      "authors": [
        "Henrik Rosenberger",
        "Benjamin Sanderse",
        "Giovanni Stabile"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.01244",
        "HTML": "https://arxiv.org/html/2506.01244",
        "PDF": "https://arxiv.org/pdf/2506.01244"
      },
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "Mon, 02 Jun 2025 01:44:33 GMT",
          "size": "110kb",
          "version": "v1"
        },
        {
          "date": "Thu, 26 Jun 2025 12:44:50 GMT",
          "size": "111kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Exact operator inference with minimal data",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper is concerned with generating snapshot data for operator inference in reduced-order models, unrelated to LLM training data processing."
      },
      "repo_urls": [
        "https://github.com/h3rror/exactOpInf"
      ],
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.01923",
      "abstract": "We propose TaxaDiffusion, a taxonomy-informed training framework for diffusion models to generate fine-grained animal images with high morphological and identity accuracy. Unlike standard approaches that treat each species as an independent category, TaxaDiffusion incorporates domain knowledge that many species exhibit strong visual similarities, with distinctions often residing in subtle variations of shape, pattern, and color. To exploit these relationships, TaxaDiffusion progressively trains conditioned diffusion models across different taxonomic levels -- starting from broad classifications such as Class and Order, refining through Family and Genus, and ultimately distinguishing at the Species level. This hierarchical learning strategy first captures coarse-grained morphological traits shared by species with common ancestors, facilitating knowledge transfer before refining fine-grained differences for species-level distinction. As a result, TaxaDiffusion enables accurate generation even with limited training samples per species. Extensive experiments on three fine-grained animal datasets demonstrate that outperforms existing approaches, achieving superior fidelity in fine-grained animal image generation. Project page: https://amink8.github.io/TaxaDiffusion/",
      "authors": [
        "Amin Karimi Monsefi",
        "Mridul Khurana",
        "Rajiv Ramnath",
        "Anuj Karpatne",
        "Wei-Lun Chao",
        "Cheng Zhang"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/publicdomain/zero/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.01923",
        "HTML": "https://arxiv.org/html/2506.01923",
        "PDF": "https://arxiv.org/pdf/2506.01923"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Mon, 02 Jun 2025 17:43:55 GMT",
          "size": "32931kb",
          "version": "v1"
        },
        {
          "date": "Wed, 25 Jun 2025 21:02:25 GMT",
          "size": "32931kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "TaxaDiffusion: Progressively Trained Diffusion Model for Fine-Grained Species Generation",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on training diffusion models for fine-grained species generation, which is unrelated to LLM training data processing."
      },
      "tasks": [
        "Image Generation",
        "Transfer Learning"
      ],
      "repo_urls": [
        "https://github.com/aminK8/TaxaDiffusion"
      ],
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.02751",
      "abstract": "3D Gaussian Splatting (3DGS) has gained significant attention for its real-time, photo-realistic rendering in novel-view synthesis and 3D modeling. However, existing methods struggle with accurately modeling scenes affected by transient objects, leading to artifacts in the rendered images. We identify that the Gaussian densification process, while enhancing scene detail capture, unintentionally contributes to these artifacts by growing additional Gaussians that model transient disturbances. To address this, we propose RobustSplat, a robust solution based on two critical designs. First, we introduce a delayed Gaussian growth strategy that prioritizes optimizing static scene structure before allowing Gaussian splitting/cloning, mitigating overfitting to transient objects in early optimization. Second, we design a scale-cascaded mask bootstrapping approach that first leverages lower-resolution feature similarity supervision for reliable initial transient mask estimation, taking advantage of its stronger semantic consistency and robustness to noise, and then progresses to high-resolution supervision to achieve more precise mask prediction. Extensive experiments on multiple challenging datasets show that our method outperforms existing methods, clearly demonstrating the robustness and effectiveness of our method. Our project page is https://fcyycf.github.io/RobustSplat/.",
      "authors": [
        "Chuanyu Fu",
        "Yuqi Zhang",
        "Kunbin Yao",
        "Guanying Chen",
        "Yuan Xiong",
        "Chuan Huang",
        "Shuguang Cui",
        "Xiaochun Cao"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.02751",
        "HTML": "https://arxiv.org/html/2506.02751",
        "PDF": "https://arxiv.org/pdf/2506.02751"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 03 Jun 2025 11:13:48 GMT",
          "size": "13575kb",
          "version": "v1"
        },
        {
          "date": "Thu, 26 Jun 2025 06:46:51 GMT",
          "size": "13575kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "RobustSplat: Decoupling Densification and Dynamics for Transient-Free 3DGS",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper addresses 3D Gaussian Splatting for rendering and modeling, unrelated to LLM training data processing or engineering."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.04188",
      "abstract": "The numerical solution of implicit and stiff differential equations by implicit numerical integrators has been largely investigated and there exist many excellent efficient codes available in the scientific community, as Radau5 (based on a Runge-Kutta collocation method at Radau points) and Dassl, based on backward differentiation formulas, among the others. When solving fractional ordinary differential equations (ODEs), the derivative operator is replaced by a non-local one and the fractional ODE is reformulated as a Volterra integral equation, to which these codes cannot be directly applied.\n  This article is a follow-up of the article by the authors (Guglielmi and Hairer, SISC, 2025) for differential equations with distributed delays. The main idea is to approximate the fractional kernel $t^{\\alpha -1}/ \\Gamma (\\alpha )$ ($\\alpha >0$) by a sum of exponential functions or by a sum of exponential functions multiplied by a monomial, and then to transform the fractional integral (of convolution type) into a set of ordinary differential equations. The augmented system is typically stiff and thus requires the use of an implicit method. It can have a very large dimension and requires a special treatment of the arising linear systems.\n  The present work presents an algorithm for the construction of an approximation of the fractional kernel by a sum of exponential functions, and it shows how the arising linear systems in a stiff time integrator can be solved efficiently. It is explained how the code Radau5 can be used for solving fractional differential equations. Numerical experiments illustrate the accuracy and the efficiency of the proposed method. Driver examples are publicly available from the homepages of the authors.",
      "authors": [
        "Nicola Guglielmi and Ernst Hairer"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.04188",
        "HTML": "https://arxiv.org/html/2506.04188",
        "PDF": "https://arxiv.org/pdf/2506.04188"
      },
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)",
        "Dynamical Systems (math.DS)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 04 Jun 2025 17:36:01 GMT",
          "size": "179kb",
          "version": "v1"
        },
        {
          "date": "Thu, 26 Jun 2025 16:36:34 GMT",
          "size": "180kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "A fast and memoryless numerical method for solving fractional differential equations",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on solving fractional differential equations and does not relate to the processing of training data for LLMs."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.04202",
      "abstract": "Long context large language models (LLMs) are deployed in many real-world applications such as RAG, agent, and broad LLM-integrated applications. Given an instruction and a long context (e.g., documents, PDF files, webpages), a long context LLM can generate an output grounded in the provided context, aiming to provide more accurate, up-to-date, and verifiable outputs while reducing hallucinations and unsupported claims. This raises a research question: how to pinpoint the texts (e.g., sentences, passages, or paragraphs) in the context that contribute most to or are responsible for the generated output by an LLM? This process, which we call context traceback, has various real-world applications, such as 1) debugging LLM-based systems, 2) conducting post-attack forensic analysis for attacks (e.g., prompt injection attack, knowledge corruption attacks) to an LLM, and 3) highlighting knowledge sources to enhance the trust of users towards outputs generated by LLMs. When applied to context traceback for long context LLMs, existing feature attribution methods such as Shapley have sub-optimal performance and/or incur a large computational cost. In this work, we develop TracLLM, the first generic context traceback framework tailored to long context LLMs. Our framework can improve the effectiveness and efficiency of existing feature attribution methods. To improve the efficiency, we develop an informed search based algorithm in TracLLM. We also develop contribution score ensemble/denoising techniques to improve the accuracy of TracLLM. Our evaluation results show TracLLM can effectively identify texts in a long context that lead to the output of an LLM. Our code and data are at: https://github.com/Wang-Yanting/TracLLM.",
      "authors": [
        "Yanting Wang",
        "Wei Zou",
        "Runpeng Geng",
        "Jinyuan Jia"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.04202",
        "HTML": "https://arxiv.org/html/2506.04202",
        "PDF": "https://arxiv.org/pdf/2506.04202"
      },
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 04 Jun 2025 17:48:16 GMT",
          "size": "605kb",
          "version": "v1"
        },
        {
          "date": "Fri, 06 Jun 2025 02:32:31 GMT",
          "size": "605kb",
          "version": "v2"
        },
        {
          "date": "Thu, 26 Jun 2025 16:09:36 GMT",
          "size": "605kb",
          "version": "v3"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "TracLLM: A Generic Framework for Attributing Long Context LLMs",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper's focus is on a framework for context traceback in LLMs to analyze and attribute the contribution of different text spans in the context used by LLMs. It does not address data engineering or training-stage data processing for LLM training."
      },
      "tasks": [
        "Denoising",
        "RAG"
      ],
      "repo_urls": [
        "https://github.com/wang-yanting/tracllm"
      ],
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.05312",
      "abstract": "Finding correspondences between semantically similar points across images and object instances is one of the everlasting challenges in computer vision. While large pre-trained vision models have recently been demonstrated as effective priors for semantic matching, they still suffer from ambiguities for symmetric objects or repeated object parts. We propose to improve semantic correspondence estimation via 3D-aware pseudo-labeling. Specifically, we train an adapter to refine off-the-shelf features using pseudo-labels obtained via 3D-aware chaining, filtering wrong labels through relaxed cyclic consistency, and 3D spherical prototype mapping constraints. While reducing the need for dataset specific annotations compared to prior work, we set a new state-of-the-art on SPair-71k by over 4% absolute gain and by over 7% against methods with similar supervision requirements. The generality of our proposed approach simplifies extension of training to other data sources, which we demonstrate in our experiments.",
      "authors": [
        "Olaf D\\\"unkel",
        "Thomas Wimmer",
        "Christian Theobalt",
        "Christian Rupprecht",
        "Adam Kortylewski"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.05312",
        "HTML": "https://arxiv.org/html/2506.05312",
        "PDF": "https://arxiv.org/pdf/2506.05312"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 05 Jun 2025 17:54:33 GMT",
          "size": "7824kb",
          "version": "v1"
        },
        {
          "date": "Thu, 26 Jun 2025 14:30:41 GMT",
          "size": "7824kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Do It Yourself: Learning Semantic Correspondence from Pseudo-Labels",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The work addresses semantic correspondence in computer vision, utilizing pre-trained vision models and pseudo-labels for improving feature matching, but it is unrelated to LLM training data processing or data engineering for LLMs."
      },
      "tasks": [
        "Semantic correspondence"
      ],
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.05432",
      "abstract": "Large Language Models (LLMs) face significant challenges in edge deployment due to their massive parameter scale. Vector Quantization (VQ), a clustering-based quantization method, serves as a prevalent solution to this issue for its extremely low-bit (even at 2-bit) and considerable accuracy. Since a vector is a quantity in mathematics and physics that has both direction and magnitude, existing VQ works typically quantize them in a coupled manner. However, we find that direction exhibits significantly greater sensitivity to quantization compared to the magnitude. For instance, when separately clustering the directions and magnitudes of weight vectors in LLaMA-2-7B, the accuracy drop of zero-shot tasks are 46.5\\% and 2.3\\%, respectively. This gap even increases with the reduction of clustering centers. Further, Euclidean distance, a common metric to access vector similarities in current VQ works, places greater emphasis on reducing the magnitude error. This property is contrary to the above finding, unavoidably leading to larger quantization errors. To these ends, this paper proposes Polar Coordinate Decoupled Vector Quantization (PCDVQ), an effective and efficient VQ framework consisting of two key modules: 1) Polar Coordinate Decoupling (PCD), which transforms vectors into their polar coordinate representations and perform independent quantization of the direction and magnitude parameters.2) Distribution Aligned Codebook Construction (DACC), which optimizes the direction and magnitude codebooks in accordance with the source distribution. Experimental results show that PCDVQ outperforms baseline methods at 2-bit level by at least 1.5\\% zero-shot accuracy, establishing a novel paradigm for accurate and highly compressed LLMs.",
      "authors": [
        "Yuxuan Yue",
        "Zukang Xu",
        "Zhihang Yuan",
        "Dawei Yang",
        "Jianlong Wu",
        "Liqiang Nie"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.05432",
        "HTML": "https://arxiv.org/html/2506.05432",
        "PDF": "https://arxiv.org/pdf/2506.05432"
      },
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 05 Jun 2025 08:58:58 GMT",
          "size": "286kb",
          "version": "v1"
        },
        {
          "date": "Thu, 26 Jun 2025 06:17:49 GMT",
          "size": "286kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "PCDVQ: Enhancing Vector Quantization for Large Language Models via Polar Coordinate Decoupling",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper discusses vector quantization techniques for model compression in LLMs, specifically improving quantization methods, not focusing on the processing of training data or data engineering for LLM purposes."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.05710",
      "abstract": "In this paper, a novel semantic communication framework empowered by generative artificial intelligence (GAI) is proposed, to enhance the robustness against both channel noise and transmission data distribution shifts. A theoretical foundation is established using stochastic differential equations (SDEs), from which a closed-form mapping between any signal-to-noise ratio (SNR) and the optimal denoising timestep is derived. Moreover, to address distribution mismatch, a mathematical scaling method is introduced to align received semantic features with the training distribution of the GAI. Built on this theoretical foundation, a latent diffusion model (LDM)-based semantic communication framework is proposed that combines a variational autoencoder for semantic features extraction, where a pretrained diffusion model is used for denoising. The proposed system is a training-free framework that supports zero-shot generalization, and achieves superior performance under low-SNR and out-of-distribution conditions, offering a scalable and robust solution for future 6G semantic communication systems. Experimental results demonstrate that the proposed semantic communication framework achieves state-of-the-art performance in both pixel-level accuracy and semantic perceptual quality, consistently outperforming baselines across a wide range of SNRs and data distributions without any fine-tuning or post-training.",
      "authors": [
        "Xiucheng Wang and Honggang Jia and Nan Cheng and Dusit Niyato"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.05710",
        "HTML": "https://arxiv.org/html/2506.05710",
        "PDF": "https://arxiv.org/pdf/2506.05710"
      },
      "subjects": [
        "Machine Learning (cs.LG)",
        "Information Theory (cs.IT)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "Fri, 06 Jun 2025 03:20:32 GMT",
          "size": "5630kb",
          "version": "v1"
        },
        {
          "date": "Thu, 26 Jun 2025 15:21:59 GMT",
          "size": "4873kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Latent Diffusion Model Based Denoising Receiver for 6G Semantic Communication: From Stochastic Differential Theory to Application",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This research is centered on semantic communication systems, which involves noise reduction and transmission data alignment. It does not pertain to data preparation or processing related to the training of LLMs."
      },
      "tasks": [
        "Denoising",
        "Semantic Communication",
        "Semantic Compression",
        "Zero-shot Generalization"
      ],
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.06285",
      "abstract": "Deep learning models, despite their popularity, face challenges such as long training times and a lack of interpretability. In contrast, fuzzy inference systems offer a balance of accuracy and transparency. This paper addresses the limitations of traditional Takagi-Sugeno-Kang fuzzy models by extending the recently proposed New Takagi-Sugeno-Kang model to a new Mamdani-based regressor. These models are data-driven, allowing users to define the number of rules to balance accuracy and interpretability. To handle the complexity of large datasets, this research integrates wrapper and ensemble techniques. A Genetic Algorithm is used as a wrapper for feature selection, creating genetic versions of the models. Furthermore, ensemble models, including the Random New Mamdani Regressor, Random New Takagi-Sugeno-Kang, and Random Forest New Takagi-Sugeno-Kang, are introduced to improve robustness. The proposed models are validated on photovoltaic energy forecasting datasets, a critical application due to the intermittent nature of solar power. Results demonstrate that the genetic and ensemble fuzzy models, particularly the Genetic New Takagi-Sugeno-Kang and Random Forest New Takagi-Sugeno-Kang, achieve superior performance. They often outperform both traditional machine learning and deep learning models while providing a simpler and more interpretable rule-based structure. The models are available online in a library called nfisis (https://pypi.org/project/nfisis/).",
      "authors": [
        "Kaike Sa Teles Rocha Alves",
        "Eduardo Pestana de Aguiar"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.06285",
        "HTML": "https://arxiv.org/html/2506.06285",
        "PDF": "https://arxiv.org/pdf/2506.06285"
      },
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Mon, 28 Apr 2025 20:18:46 GMT",
          "size": "301kb",
          "version": "v1"
        },
        {
          "date": "Tue, 10 Jun 2025 13:59:20 GMT",
          "size": "301kb",
          "version": "v2"
        },
        {
          "date": "Wed, 25 Jun 2025 22:00:25 GMT",
          "size": "1012kb",
          "version": "v3"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "NFISiS: New Perspectives on Fuzzy Inference Systems for Renewable Energy Forecasting",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper explores fuzzy inference systems for renewable energy forecasting, emphasizing model interpretability and efficiency. It does not focus on LLM training data processing or data engineering."
      },
      "tasks": [
        "Interpretable Machine Learning"
      ],
      "repo_urls": [
        "https://github.com/kaikerochaalves/NFISiS_PyPi"
      ],
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.07413",
      "abstract": "Contrastive learning has proven to be highly efficient and adaptable in shaping representation spaces across diverse modalities by pulling similar samples together and pushing dissimilar ones apart. However, two key limitations persist: (1) Without explicit regulation of the embedding distribution, semantically related instances can inadvertently be pushed apart unless complementary signals guide pair selection, and (2) excessive reliance on large in-batch negatives and tailored augmentations hinders generalization. To address these limitations, we propose Variational Supervised Contrastive Learning (VarCon), which reformulates supervised contrastive learning as variational inference over latent class variables and maximizes a posterior-weighted evidence lower bound (ELBO) that replaces exhaustive pair-wise comparisons for efficient class-aware matching and grants fine-grained control over intra-class dispersion in the embedding space. Trained exclusively on image data, our experiments on CIFAR-10, CIFAR-100, ImageNet-100, and ImageNet-1K show that VarCon (1) achieves state-of-the-art performance for contrastive learning frameworks, reaching 79.36% Top-1 accuracy on ImageNet-1K and 78.29% on CIFAR-100 with a ResNet-50 encoder while converging in just 200 epochs; (2) yields substantially clearer decision boundaries and semantic organization in the embedding space, as evidenced by KNN classification, hierarchical clustering results, and transfer-learning assessments; and (3) demonstrates superior performance in few-shot learning than supervised baseline and superior robustness across various augmentation strategies.",
      "authors": [
        "Ziwen Wang",
        "Jiajun Fan",
        "Thao Nguyen",
        "Heng Ji",
        "Ge Liu"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.07413",
        "HTML": "https://arxiv.org/html/2506.07413",
        "PDF": "https://arxiv.org/pdf/2506.07413"
      },
      "subjects": [
        "Machine Learning (cs.LG)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Mon, 09 Jun 2025 04:19:12 GMT",
          "size": "8118kb",
          "version": "v1"
        },
        {
          "date": "Thu, 26 Jun 2025 12:27:25 GMT",
          "size": "8118kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Variational Supervised Contrastive Learning",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on variational supervised contrastive learning, primarily for image data. It does not discuss processing of training data for large language models."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.07886",
      "abstract": "Understanding multimodal signals in egocentric vision, such as RGB video, depth, camera poses, and gaze, is essential for applications in augmented reality, robotics, and human-computer interaction, enabling systems to better interpret the camera wearer's actions, intentions, and surrounding environment. However, building large-scale egocentric multimodal and multitask models presents unique challenges. Egocentric data are inherently heterogeneous, with large variations in modality coverage across devices and settings. Generating pseudo-labels for missing modalities, such as gaze or head-mounted camera trajectories, is often infeasible, making standard supervised learning approaches difficult to scale. Furthermore, dynamic camera motion and the complex temporal and spatial structure of first-person video pose additional challenges for the direct application of existing multimodal foundation models.\n  To address these challenges, we introduce a set of efficient temporal tokenizers and propose EgoM2P, a masked modeling framework that learns from temporally-aware multimodal tokens to train a large, general-purpose model for egocentric 4D understanding. This unified design supports multitasking across diverse egocentric perception and synthesis tasks, including gaze prediction, egocentric camera tracking, and monocular depth estimation from egocentric video, and also serves as a generative model for conditional egocentric video synthesis. Across these tasks, EgoM2P matches or outperforms specialist models while being an order of magnitude faster. We will fully open-source EgoM2P to support the community and advance egocentric vision research. Project page: https://egom2p.github.io/.",
      "authors": [
        "Gen Li",
        "Yutong Chen",
        "Yiqian Wu",
        "Kaifeng Zhao",
        "Marc Pollefeys",
        "Siyu Tang"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.07886",
        "HTML": "https://arxiv.org/html/2506.07886",
        "PDF": "https://arxiv.org/pdf/2506.07886"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Mon, 09 Jun 2025 15:59:25 GMT",
          "size": "10141kb",
          "version": "v1"
        },
        {
          "date": "Thu, 26 Jun 2025 17:13:31 GMT",
          "size": "10671kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "EgoM2P: Egocentric Multimodal Multitask Pretraining",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The research focuses on egocentric multimodal multitask pretraining for vision applications and does not address LLM training data processing."
      },
      "tasks": [
        "Depth Estimation",
        "Gaze Prediction",
        "Monocular Depth Estimation"
      ],
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.07977",
      "abstract": "Text-to-image (T2I) models have garnered significant attention for generating high-quality images aligned with text prompts. However, rapid T2I model advancements reveal limitations in early benchmarks, lacking comprehensive evaluations, for example, the evaluation on reasoning, text rendering and style. Notably, recent state-of-the-art models, with their rich knowledge modeling capabilities, show promising results on the image generation problems requiring strong reasoning ability, yet existing evaluation systems have not adequately addressed this frontier. To systematically address these gaps, we introduce OneIG-Bench, a meticulously designed comprehensive benchmark framework for fine-grained evaluation of T2I models across multiple dimensions, including prompt-image alignment, text rendering precision, reasoning-generated content, stylization, and diversity. By structuring the evaluation, this benchmark enables in-depth analysis of model performance, helping researchers and practitioners pinpoint strengths and bottlenecks in the full pipeline of image generation. Specifically, OneIG-Bench enables flexible evaluation by allowing users to focus on a particular evaluation subset. Instead of generating images for the entire set of prompts, users can generate images only for the prompts associated with the selected dimension and complete the corresponding evaluation accordingly. Our codebase and dataset are now publicly available to facilitate reproducible evaluation studies and cross-model comparisons within the T2I research community.",
      "authors": [
        "Jingjing Chang",
        "Yixiao Fang",
        "Peng Xing",
        "Shuhan Wu",
        "Wei Cheng",
        "Rui Wang",
        "Xianfang Zeng",
        "Gang Yu",
        "Hai-Bao Chen"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.07977",
        "HTML": "https://arxiv.org/html/2506.07977",
        "PDF": "https://arxiv.org/pdf/2506.07977"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Mon, 09 Jun 2025 17:50:21 GMT",
          "size": "18946kb",
          "version": "v1"
        },
        {
          "date": "Tue, 10 Jun 2025 12:31:25 GMT",
          "size": "18946kb",
          "version": "v2"
        },
        {
          "date": "Thu, 26 Jun 2025 15:47:09 GMT",
          "size": "18968kb",
          "version": "v3"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "OneIG-Bench: Omni-dimensional Nuanced Evaluation for Image Generation",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper proposes a benchmark framework for evaluating text-to-image models, without discussing the design or processing of LLM training data."
      },
      "datasets": [
        {
          "dataset_name": "OneIG-Bench/OneIG-Bench",
          "downloads": "410",
          "likes": "4",
          "link": "https://huggingface.co/datasets/OneIG-Bench/OneIG-Bench"
        }
      ],
      "tasks": [
        "Image Generation"
      ],
      "repo_urls": [
        "https://github.com/oneig-bench/oneig-benchmark"
      ],
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.09498",
      "abstract": "Diffusion models have recently emerged as a powerful approach for trajectory planning. However, their inherently non-sequential nature limits their effectiveness in long-horizon reasoning tasks at test time. The recently proposed Monte Carlo Tree Diffusion (MCTD) offers a promising solution by combining diffusion with tree-based search, achieving state-of-the-art performance on complex planning problems. Despite its strengths, our analysis shows that MCTD incurs substantial computational overhead due to the sequential nature of tree search and the cost of iterative denoising. To address this, we propose Fast-MCTD, a more efficient variant that preserves the strengths of MCTD while significantly improving its speed and scalability. Fast-MCTD integrates two techniques: Parallel MCTD, which enables parallel rollouts via delayed tree updates and redundancy-aware selection; and Sparse MCTD, which reduces rollout length through trajectory coarsening. Experiments show that Fast-MCTD achieves up to 100x speedup over standard MCTD while maintaining or improving planning performance. Remarkably, it even outperforms Diffuser in inference speed on some tasks, despite Diffuser requiring no search and yielding weaker solutions. These results position Fast-MCTD as a practical and scalable solution for diffusion-based inference-time reasoning.",
      "authors": [
        "Jaesik Yoon",
        "Hyeonseo Cho",
        "Yoshua Bengio",
        "Sungjin Ahn"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.09498",
        "HTML": "https://arxiv.org/html/2506.09498",
        "PDF": "https://arxiv.org/pdf/2506.09498"
      },
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 11 Jun 2025 08:17:40 GMT",
          "size": "2633kb",
          "version": "v1"
        },
        {
          "date": "Thu, 26 Jun 2025 01:52:43 GMT",
          "size": "2633kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Fast Monte Carlo Tree Diffusion: 100x Speedup via Parallel Sparse Planning",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on improving the efficiency of Monte Carlo Tree Diffusion in trajectory planning, not on LLM training data processing or data engineering tasks."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.09579",
      "abstract": "Extracting high-fidelity mesh surfaces from Signed Distance Fields has become a fundamental operation in geometry processing. Despite significant progress over the past decades, key challenges remain namely, how to automatically capture the intricate geometric and topological structures encoded in the zero level set of SDFs. In this paper, we present a novel isosurface extraction algorithm that introduces two key innovations: 1. An incrementally constructed power diagram through the addition of sample points, which enables repeated updates to the extracted surface via its dual regular Delaunay tetrahedralization; and 2. An adaptive point insertion strategy that identifies regions exhibiting the greatest discrepancy between the current mesh and the underlying continuous surface. As the teaser figure shows, our framework progressively refines the extracted mesh with minimal computational cost until it sufficiently approximates the underlying surface. Experimental results demonstrate that our approach outperforms sofa methods, particularly for models with intricate geometric variations and complex topologies.",
      "authors": [
        "Pengfei Wang",
        "Ziyang Zhang",
        "Wensong Wang",
        "Shuangmin Chen",
        "Lin Lu",
        "Shiqing Xin",
        "Changhe Tu"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.09579",
        "HTML": "https://arxiv.org/html/2506.09579",
        "PDF": "https://arxiv.org/pdf/2506.09579"
      },
      "subjects": [
        "Computational Geometry (cs.CG)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 11 Jun 2025 10:17:36 GMT",
          "size": "27069kb",
          "version": "v1"
        },
        {
          "date": "Thu, 26 Jun 2025 13:19:48 GMT",
          "size": "34714kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Power Diagram Enhanced Adaptive Isosurface Extraction from Signed Distance Fields",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper deals with geometry processing and mesh surface extraction from Signed Distance Fields, which is unrelated to LLM training data and its processing."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.09803",
      "abstract": "Graph neural networks (GNNs) have achieved significant success in graph representation learning and have been applied to various domains. However, many real-world graphs contain sensitive personal information, such as user profiles in social networks, raising serious privacy concerns when graph learning is performed using GNNs. To address this issue, locally private graph learning protocols have gained considerable attention. These protocols leverage the privacy advantages of local differential privacy (LDP) and the effectiveness of GNN's message-passing in calibrating noisy data, offering strict privacy guarantees for users' local data while maintaining high utility (e.g., node classification accuracy) for graph learning. Despite these advantages, such protocols may be vulnerable to data poisoning attacks, a threat that has not been considered in previous research. Identifying and addressing these threats is crucial for ensuring the robustness and security of privacy-preserving graph learning frameworks. This work introduces the first data poisoning attack targeting locally private graph learning protocols. The attacker injects fake users into the protocol, manipulates these fake users to establish links with genuine users, and sends carefully crafted data to the server, ultimately compromising the utility of private graph learning. The effectiveness of the attack is demonstrated both theoretically and empirically. In addition, several defense strategies have also been explored, but their limited effectiveness highlights the need for more robust defenses.",
      "authors": [
        "Longzhu He",
        "Chaozhuo Li",
        "Peng Tang",
        "Li Sun",
        "Sen Su",
        "Philip S. Yu"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.09803",
        "HTML": "https://arxiv.org/html/2506.09803",
        "PDF": "https://arxiv.org/pdf/2506.09803"
      },
      "subjects": [
        "Machine Learning (cs.LG)",
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 11 Jun 2025 14:46:11 GMT",
          "size": "628kb",
          "version": "v1"
        },
        {
          "date": "Thu, 26 Jun 2025 14:18:21 GMT",
          "size": "654kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Devil's Hand: Data Poisoning Attacks to Locally Private Graph Learning Protocols",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper studies data poisoning attacks on locally private graph learning protocols, but it does not contribute to LLM training data collection or processing methods."
      },
      "tasks": [
        "Data Poisoning",
        "Graph Learning",
        "Graph Representation Learning",
        "Node Classification",
        "Privacy Preserving",
        "Representation Learning"
      ],
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.11924",
      "abstract": "We introduce a diffusion-based framework that performs aligned novel view image and geometry generation via a warping-and-inpainting methodology. Unlike prior methods that require dense posed images or pose-embedded generative models limited to in-domain views, our method leverages off-the-shelf geometry predictors to predict partial geometries viewed from reference images, and formulates novel-view synthesis as an inpainting task for both image and geometry. To ensure accurate alignment between generated images and geometry, we propose cross-modal attention distillation, where attention maps from the image diffusion branch are injected into a parallel geometry diffusion branch during both training and inference. This multi-task approach achieves synergistic effects, facilitating geometrically robust image synthesis as well as well-defined geometry prediction. We further introduce proximity-based mesh conditioning to integrate depth and normal cues, interpolating between point cloud and filtering erroneously predicted geometry from influencing the generation process. Empirically, our method achieves high-fidelity extrapolative view synthesis on both image and geometry across a range of unseen scenes, delivers competitive reconstruction quality under interpolation settings, and produces geometrically aligned colored point clouds for comprehensive 3D completion. Project page is available at https://cvlab-kaist.github.io/MoAI.",
      "authors": [
        "Min-Seop Kwak",
        "Junho Kim",
        "Sangdoo Yun",
        "Dongyoon Han",
        "Taekyoung Kim",
        "Seungryong Kim",
        "Jin-Hwa Kim"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.11924",
        "HTML": "https://arxiv.org/html/2506.11924",
        "PDF": "https://arxiv.org/pdf/2506.11924"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Fri, 13 Jun 2025 16:19:00 GMT",
          "size": "7144kb",
          "version": "v1"
        },
        {
          "date": "Thu, 26 Jun 2025 15:26:54 GMT",
          "size": "7148kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Aligned Novel View Image and Geometry Synthesis via Cross-modal Attention Instillation",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper proposes a diffusion-based framework for view synthesis and geometry generation, focusing on image and geometry tasks, not on LLM training data processes."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.12025",
      "abstract": "Optimal transport between graphs, based on Gromov-Wasserstein and\n  other extensions, is a powerful tool for comparing and aligning\n  graph structures. However, solving the associated non-convex\n  optimization problems is computationally expensive, which limits the\n  scalability of these methods to large graphs. In this work, we\n  present Unbalanced Learning of Optimal Transport (ULOT), a deep\n  learning method that predicts optimal transport plans between two\n  graphs. Our method is trained by minimizing the fused unbalanced\n  Gromov-Wasserstein (FUGW) loss. We propose a novel neural\n  architecture with cross-attention that is conditioned on the FUGW\n  tradeoff hyperparameters. We evaluate ULOT on synthetic stochastic\n  block model (SBM) graphs and on real cortical surface data obtained\n  from fMRI. ULOT predicts transport plans with competitive loss up to\n  two orders of magnitude faster than classical solvers. Furthermore,\n  the predicted plan can be used as a warm start for classical solvers\n  to accelerate their convergence. Finally, the predicted transport\n  plan is fully differentiable with respect to the graph inputs and\n  FUGW hyperparameters, enabling the optimization of functionals of\n  the ULOT plan.",
      "authors": [
        "Sonia Mazelet",
        "R\\'emi Flamary",
        "Bertrand Thirion"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.12025",
        "HTML": "https://arxiv.org/html/2506.12025",
        "PDF": "https://arxiv.org/pdf/2506.12025"
      },
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 21 May 2025 09:29:19 GMT",
          "size": "1545kb",
          "version": "v1"
        },
        {
          "date": "Thu, 26 Jun 2025 13:01:32 GMT",
          "size": "1552kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Unsupervised Learning for Optimal Transport plan prediction between unbalanced graphs",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The research addresses optimal transport plan prediction between graphs and graph-related optimization, not involving any aspect of LLM training data processing or preparation."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.12896",
      "abstract": "Implicit neural representations (INRs) are the subject of extensive research, particularly in their application to modeling complex signals by mapping spatial and temporal coordinates to corresponding values. When handling videos, mapping compact inputs to entire frames or spatially partitioned patch images is an effective approach. This strategy better preserves spatial relationships, reduces computational overhead, and improves reconstruction quality compared to coordinate-based mapping. However, predicting entire frames often limits the reconstruction of high-frequency visual details. Additionally, conventional patch-based approaches based on uniform spatial partitioning tend to introduce boundary discontinuities that degrade spatial coherence. We propose a neural video representation method based on Structure-Preserving Patches (SPPs) to address such limitations. Our method separates each video frame into patch images of spatially aligned frames through a deterministic pixel-based splitting similar to PixelUnshuffle. This operation preserves the global spatial structure while allowing patch-level decoding. We train the decoder to reconstruct these structured patches, enabling a global-to-local decoding strategy that captures the global layout first and refines local details. This effectively reduces boundary artifacts and mitigates distortions from naive upsampling. Experiments on standard video datasets demonstrate that our method achieves higher reconstruction quality and better compression performance than existing INR-based baselines.",
      "authors": [
        "Taiga Hayami",
        "Kakeru Koizumi",
        "Hiroshi Watanabe"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.12896",
        "HTML": "https://arxiv.org/html/2506.12896",
        "PDF": "https://arxiv.org/pdf/2506.12896"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Sun, 15 Jun 2025 15:58:23 GMT",
          "size": "2071kb",
          "version": "v1"
        },
        {
          "date": "Thu, 26 Jun 2025 12:27:09 GMT",
          "size": "2084kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Structure-Preserving Patch Decoding for Efficient Neural Video Representation",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on neural video representation and does not discuss LLM training data processing or engineering stages."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.13242",
      "abstract": "The quest for non-commutative matrix multiplication algorithms in small dimensions has seen a lot of recent improvements recently. In particular, the number of scalar multiplications required to multiply two $4\\times4$ matrices was first reduced in \\cite{Fawzi:2022aa} from 49 (two recursion levels of Strassen's algorithm) to 47 but only in characteristic 2 or more recently to 48 in \\cite{alphaevolve} but over complex numbers. We propose an algorithm in 48 multiplications with only rational coefficients, hence removing the complex number requirement. It was derived from the latter one, under the action of an isotropy which happen to project the algorithm on the field of rational numbers. We also produce a straight line program of this algorithm, reducing the leading constant in the complexity, as well as an alternative basis variant of it, leading to an algorithm running in $\\frac{19}{16} n^{2+\\frac{\\log_2 3}{2}} +o\\left(n^{2+\\frac{log_2 3}{2}}\\right)$ operations over any ring containing an inverse of 2.",
      "authors": [
        "Jean-Guillaume Dumas (CASC)",
        "Cl\\'ement Pernet (CASC)",
        "Alexandre Sedoglavic (CRIStAL)"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.13242",
        "HTML": "https://arxiv.org/html/2506.13242",
        "PDF": "https://arxiv.org/pdf/2506.13242"
      },
      "subjects": [
        "Symbolic Computation (cs.SC)"
      ],
      "submission_historys": [
        {
          "date": "Mon, 16 Jun 2025 08:42:15 GMT",
          "size": "15kb",
          "version": "v1"
        },
        {
          "date": "Tue, 17 Jun 2025 08:51:21 GMT",
          "size": "16kb",
          "version": "v2"
        },
        {
          "date": "Tue, 24 Jun 2025 08:34:48 GMT",
          "size": "17kb",
          "version": "v3"
        },
        {
          "date": "Thu, 26 Jun 2025 09:00:56 GMT",
          "size": "17kb",
          "version": "v4"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "A non-commutative algorithm for multiplying 4x4 matrices using 48 non-complex multiplications",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper is about a new algorithm for matrix multiplication, which is unrelated to LLM training data processing."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.14539",
      "abstract": "Since the advent of large language models, prompt engineering now enables the rapid, low-effort creation of diverse autonomous agents that are already in widespread use. Yet this convenience raises urgent concerns about the safety, robustness, and behavioral consistency of the underlying prompts, along with the pressing challenge of preventing those prompts from being exposed to user's attempts. In this paper, we propose the ''Doppelganger method'' to demonstrate the risk of an agent being hijacked, thereby exposing system instructions and internal information. Next, we define the ''Prompt Alignment Collapse under Adversarial Transfer (PACAT)'' level to evaluate the vulnerability to this adversarial transfer attack. We also propose a ''Caution for Adversarial Transfer (CAT)'' prompt to counter the Doppelganger method. The experimental results demonstrate that the Doppelganger method can compromise the agent's consistency and expose its internal information. In contrast, CAT prompts enable effective defense against this adversarial attack.",
      "authors": [
        "Daewon Kang",
        "YeongHwan Shin",
        "Doyeon Kim",
        "Kyu-Hwan Jung",
        "Meong Hi Son"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.14539",
        "HTML": "https://arxiv.org/html/2506.14539",
        "PDF": "https://arxiv.org/pdf/2506.14539"
      },
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 17 Jun 2025 14:01:39 GMT",
          "size": "18307kb",
          "version": "v1"
        },
        {
          "date": "Thu, 26 Jun 2025 05:18:19 GMT",
          "size": "18307kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Doppelganger Method: Breaking Role Consistency in LLM Agent via Prompt-based Transferable Adversarial Attack",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper deals with adversarial attacks and prompt engineering related to LLMs but does not discuss the processing or engineering of training data for LLMs."
      },
      "tasks": [
        "Adversarial Attack",
        "Prompt Engineering"
      ],
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.15799",
      "abstract": "Robotic control policies learned from human demonstrations have achieved impressive results in many real-world applications. However, in scenarios where initial performance is not satisfactory, as is often the case in novel open-world settings, such behavioral cloning (BC)-learned policies typically require collecting additional human demonstrations to further improve their behavior -- an expensive and time-consuming process. In contrast, reinforcement learning (RL) holds the promise of enabling autonomous online policy improvement, but often falls short of achieving this due to the large number of samples it typically requires. In this work we take steps towards enabling fast autonomous adaptation of BC-trained policies via efficient real-world RL. Focusing in particular on diffusion policies -- a state-of-the-art BC methodology -- we propose diffusion steering via reinforcement learning (DSRL): adapting the BC policy by running RL over its latent-noise space. We show that DSRL is highly sample efficient, requires only black-box access to the BC policy, and enables effective real-world autonomous policy improvement. Furthermore, DSRL avoids many of the challenges associated with finetuning diffusion policies, obviating the need to modify the weights of the base policy at all. We demonstrate DSRL on simulated benchmarks, real-world robotic tasks, and for adapting pretrained generalist policies, illustrating its sample efficiency and effective performance at real-world policy improvement.",
      "authors": [
        "Andrew Wagenmaker and Mitsuhiko Nakamoto and Yunchu Zhang and Seohong Park and Waleed Yagoub and Anusha Nagabandi and Abhishek Gupta and Sergey Levine"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.15799",
        "HTML": "https://arxiv.org/html/2506.15799",
        "PDF": "https://arxiv.org/pdf/2506.15799"
      },
      "subjects": [
        "Robotics (cs.RO)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 18 Jun 2025 18:35:57 GMT",
          "size": "38842kb",
          "version": "v1"
        },
        {
          "date": "Wed, 25 Jun 2025 19:09:52 GMT",
          "size": "38842kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Steering Your Diffusion Policy with Latent Space Reinforcement Learning",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The research focuses on policy adaptation in robotic control through reinforcement learning and does not cover any aspects of LLM training data processing."
      },
      "tasks": [
        "reinforcement-learning",
        "Reinforcement Learning",
        "Reinforcement Learning (RL)"
      ],
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.15928",
      "abstract": "This paper presents an evaluation framework for agentic AI systems in mission-critical negotiation contexts, addressing the need for AI agents that can adapt to diverse human operators and stakeholders. Using Sotopia as a simulation testbed, we present two experiments that systematically evaluated how personality traits and AI agent characteristics influence LLM-simulated social negotiation outcomes--a capability essential for a variety of applications involving cross-team coordination and civil-military interactions. Experiment 1 employs causal discovery methods to measure how personality traits impact price bargaining negotiations, through which we found that Agreeableness and Extraversion significantly affect believability, goal achievement, and knowledge acquisition outcomes. Sociocognitive lexical measures extracted from team communications detected fine-grained differences in agents' empathic communication, moral foundations, and opinion patterns, providing actionable insights for agentic AI systems that must operate reliably in high-stakes operational scenarios. Experiment 2 evaluates human-AI job negotiations by manipulating both simulated human personality and AI system characteristics, specifically transparency, competence, adaptability, demonstrating how AI agent trustworthiness impact mission effectiveness. These findings establish a repeatable evaluation methodology for experimenting with AI agent reliability across diverse operator personalities and human-agent team dynamics, directly supporting operational requirements for reliable AI systems. Our work advances the evaluation of agentic AI workflows by moving beyond standard performance metrics to incorporate social dynamics essential for mission success in complex operations.",
      "authors": [
        "Myke C. Cohen",
        "Zhe Su",
        "Hsien-Te Kao",
        "Daniel Nguyen",
        "Spencer Lynch",
        "Maarten Sap",
        "Svitlana Volkova"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.15928",
        "HTML": "https://arxiv.org/html/2506.15928",
        "PDF": "https://arxiv.org/pdf/2506.15928"
      },
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)",
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 19 Jun 2025 00:14:56 GMT",
          "size": "633kb",
          "version": "v1"
        },
        {
          "date": "Wed, 25 Jun 2025 23:42:18 GMT",
          "size": "633kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Exploring Big Five Personality and AI Capability Effects in LLM-Simulated Negotiation Dialogues",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper focuses on evaluating AI systems in negotiation contexts, with no emphasis on the collection or processing of LLM training data."
      },
      "tasks": [
        "AI Agent",
        "Causal Discovery"
      ],
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.16182",
      "abstract": "Over the past decades, transformations between different classes of eigenvalue problems have played a central role in the development of numerical methods for eigenvalue computations. One of the most well-known and successful examples of this is the companion linearization for polynomial eigenvalue problems. In this paper, we construct a transformation that equivalently reframes a specific type of eigenvalue problem with eigenvector nonlinearities (NEPv) into an eigenvalue problem with eigenvalue nonlinearities (NEP). The NEPv class considered consists of nonlinearities expressed as sums of products of matrices and scalar functions, where the scalar functions depend nonlinearly on the eigenvector. Our transformation defines scalar eigenvalue nonlinearities through a polynomial system, resulting in NEP nonlinearities of algebraic type. We propose methods to solve the polynomial system, one of which involves a multiparameter eigenvalue problem (MEP). We adapt well-established NEP solvers to this setting, with the most effective strategy being a combination of deflation and a locally quadratically convergent iterative method. The efficiency and properties of the approach are illustrated by solving a problem related to a modification of a Gross-Pitaevskii equation (GPE). The simulations are reproducible and publicly available.",
      "authors": [
        "Elias Jarlebring",
        "Vilhelm P. Lithell"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.16182",
        "HTML": "https://arxiv.org/html/2506.16182",
        "PDF": "https://arxiv.org/pdf/2506.16182"
      },
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 19 Jun 2025 10:02:27 GMT",
          "size": "1511kb",
          "version": "v1"
        },
        {
          "date": "Thu, 26 Jun 2025 12:29:55 GMT",
          "size": "1512kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "From eigenvector nonlinearities to eigenvalue nonlinearities",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on transformations and solutions for eigenvalue problems, specifically concerning eigenvector and eigenvalue nonlinearities. It does not address any aspect of training data processing for LLMs."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.16398",
      "abstract": "Pathology is essential for cancer diagnosis, with multiple instance learning (MIL) widely used for whole slide image (WSI) analysis. WSIs exhibit a natural hierarchy -- patches, regions, and slides -- with distinct semantic associations. While some methods attempt to leverage this hierarchy for improved representation, they predominantly rely on Euclidean embeddings, which struggle to fully capture semantic hierarchies. To address this limitation, we propose HyperPath, a novel method that integrates knowledge from textual descriptions to guide the modeling of semantic hierarchies of WSIs in hyperbolic space, thereby enhancing WSI classification. Our approach adapts both visual and textual features extracted by pathology vision-language foundation models to the hyperbolic space. We design an Angular Modality Alignment Loss to ensure robust cross-modal alignment, while a Semantic Hierarchy Consistency Loss further refines feature hierarchies through entailment and contradiction relationships and thus enhance semantic coherence. The classification is performed with geodesic distance, which measures the similarity between entities in the hyperbolic semantic hierarchy. This eliminates the need for linear classifiers and enables a geometry-aware approach to WSI analysis. Extensive experiments show that our method achieves superior performance across tasks compared to existing methods, highlighting the potential of hyperbolic embeddings for WSI analysis.",
      "authors": [
        "Peixiang Huang",
        "Yanyan Huang",
        "Weiqin Zhao",
        "Junjun He",
        "Lequan Yu"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.16398",
        "HTML": "https://arxiv.org/html/2506.16398",
        "PDF": "https://arxiv.org/pdf/2506.16398"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 19 Jun 2025 15:30:33 GMT",
          "size": "639kb",
          "version": "v1"
        },
        {
          "date": "Thu, 26 Jun 2025 09:10:30 GMT",
          "size": "639kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "HyperPath: Knowledge-Guided Hyperbolic Semantic Hierarchy Modeling for WSI Analysis",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper deals with WSI analysis and proposes a method integrating knowledge from textual descriptions for modeling semantic hierarchies in hyperbolic space. There is no mention of LLM training data processing."
      },
      "tasks": [
        "cross-modal alignment",
        "Multiple Instance Learning"
      ],
      "repo_urls": [
        "https://github.com/lambert-hpx/hyperpath"
      ],
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.16656",
      "abstract": "Generative models in function spaces, situated at the intersection of generative modeling and operator learning, are attracting increasing attention due to their immense potential in diverse scientific and engineering applications. While functional generative models are theoretically domain- and discretization-agnostic, current implementations heavily rely on the Fourier Neural Operator (FNO), limiting their applicability to regular grids and rectangular domains. To overcome these critical limitations, we introduce the Mesh-Informed Neural Operator (MINO). By leveraging graph neural operators and cross-attention mechanisms, MINO offers a principled, domain- and discretization-agnostic backbone for generative modeling in function spaces. This advancement significantly expands the scope of such models to more diverse applications in generative, inverse, and regression tasks. Furthermore, MINO provides a unified perspective on integrating neural operators with general advanced deep learning architectures. Finally, we introduce a suite of standardized evaluation metrics that enable objective comparison of functional generative models, addressing another critical gap in the field.",
      "authors": [
        "Yaozhong Shi and Zachary E. Ross and Domniki Asimaki and Kamyar Azizzadenesheli"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.16656",
        "HTML": "https://arxiv.org/html/2506.16656",
        "PDF": "https://arxiv.org/pdf/2506.16656"
      },
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Fri, 20 Jun 2025 00:00:22 GMT",
          "size": "14365kb",
          "version": "v1"
        },
        {
          "date": "Thu, 26 Jun 2025 17:45:03 GMT",
          "size": "14364kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Mesh-Informed Neural Operator : A Transformer Generative Approach",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper introduces the Mesh-Informed Neural Operator for generative modeling in function spaces, not addressing any aspect of LLM training data processing."
      },
      "datasets": [
        {
          "dataset_name": "Yaozhong/MINO",
          "downloads": "0",
          "likes": "0",
          "link": "https://huggingface.co/datasets/Yaozhong/MINO"
        }
      ],
      "tasks": [
        "Operator learning"
      ],
      "repo_urls": [
        "https://github.com/yzshi5/mino"
      ],
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.16663",
      "abstract": "High-dimensional image data often require dimensionality reduction before further analysis. This paper provides a purely analytical comparison of two linear techniques-Principal Component Analysis (PCA) and Singular Value Decomposition (SVD). After the derivation of each algorithm from first principles, we assess their interpretability, numerical stability, and suitability for differing matrix shapes. We synthesize rule-of-thumb guidelines for choosing one out of the two algorithms without empirical benchmarking, building on classical and recent numerical literature. Limitations and directions for future experimental work are outlined at the end.",
      "authors": [
        "Michael Gyimadu",
        "Gregory Bell",
        "Ph.D"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.16663",
        "HTML": "https://arxiv.org/html/2506.16663",
        "PDF": "https://arxiv.org/pdf/2506.16663"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Numerical Analysis (cs.NA)",
        "Numerical Analysis (math.NA)"
      ],
      "submission_historys": [
        {
          "date": "Fri, 20 Jun 2025 00:19:45 GMT",
          "size": "8kb",
          "version": "v1"
        },
        {
          "date": "Mon, 23 Jun 2025 01:58:54 GMT",
          "size": "8kb",
          "version": "v2"
        },
        {
          "date": "Wed, 25 Jun 2025 18:39:32 GMT",
          "size": "8kb",
          "version": "v3"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "A Comparative Analysis of Principal Component Analysis (PCA) and Singular Value Decomposition (SVD) as Dimensionality Reduction Techniques",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper provides a comparison of PCA and SVD for dimensionality reduction in high-dimensional image data, without discussing any methods related to LLM training data processing."
      },
      "tasks": [
        "Benchmarking",
        "Dimensionality Reduction"
      ],
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.16889",
      "abstract": "Music mastering style transfer aims to model and apply the mastering characteristics of a reference track to a target track, simulating the professional mastering process. However, existing methods apply fixed processing based on a reference track, limiting users' ability to fine-tune the results to match their artistic intent. In this paper, we introduce the ITO-Master framework, a reference-based mastering style transfer system that integrates Inference-Time Optimization (ITO) to enable finer user control over the mastering process. By optimizing the reference embedding during inference, our approach allows users to refine the output dynamically, making micro-level adjustments to achieve more precise mastering results. We explore both black-box and white-box methods for modeling mastering processors and demonstrate that ITO improves mastering performance across different styles. Through objective evaluation, subjective listening tests, and qualitative analysis using text-based conditioning with CLAP embeddings, we validate that ITO enhances mastering style similarity while offering increased adaptability. Our framework provides an effective and user-controllable solution for mastering style transfer, allowing users to refine their results beyond the initial style transfer.",
      "authors": [
        "Junghyun Koo",
        "Marco A. Martinez-Ramirez",
        "Wei-Hsiang Liao",
        "Giorgio Fabbro",
        "Michele Mancusi",
        "and Yuki Mitsufuji"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.16889",
        "HTML": "https://arxiv.org/html/2506.16889",
        "PDF": "https://arxiv.org/pdf/2506.16889"
      },
      "subjects": [
        "Sound (cs.SD)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "Fri, 20 Jun 2025 10:21:56 GMT",
          "size": "594kb",
          "version": "v1"
        },
        {
          "date": "Thu, 26 Jun 2025 08:38:02 GMT",
          "size": "595kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "ITO-Master: Inference-Time Optimization for Audio Effects Modeling of Music Mastering Processors",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper introduces ITO-Master for music mastering style transfer, focusing on inference-time optimization, but does not cover any topics related to LLM training data processing."
      },
      "repo_urls": [
        "https://github.com/sonyresearch/ito-master"
      ],
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.17572",
      "abstract": "The recovery of an unknown signal from its linear measurements is a fundamental problem spanning numerous scientific and engineering disciplines. Commonly, prior knowledge suggests that the underlying signal resides within a known algebraic variety. This context naturally leads to a question: what is the minimum number of measurements required to uniquely recover any signal belonging to such an algebraic variety? In this survey paper, we introduce a method that leverages tools from algebraic geometry to address this question. We then demonstrate the utility of this approach by applying it to two problems: phase retrieval and low-rank matrix recovery. We also highlight several open problems, which could serve as a basis for future investigations in this field.",
      "authors": [
        "Zhiqiang Xu"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.17572",
        "HTML": "https://arxiv.org/html/2506.17572",
        "PDF": "https://arxiv.org/pdf/2506.17572"
      },
      "subjects": [
        "Information Theory (cs.IT)",
        "Algebraic Geometry (math.AG)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "Sat, 21 Jun 2025 03:56:16 GMT",
          "size": "16kb",
          "version": "v1"
        },
        {
          "date": "Thu, 26 Jun 2025 05:42:53 GMT",
          "size": "16kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Signal Recovery on Algebraic Varieties Using Linear Samples",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper is focused on signal recovery using algebraic geometry. It discusses methods related to signal processing rather than training data processing for LLMs."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.17589",
      "abstract": "The real value of knowledge lies not just in its accumulation, but in its potential to be harnessed effectively to conquer the unknown. Although recent multimodal large language models (MLLMs) exhibit impressing multimodal capabilities, they often fail in rarely encountered domain-specific tasks due to limited relevant knowledge. To explore this, we adopt visual game cognition as a testbed and select Monster Hunter: World as the target to construct a multimodal knowledge graph (MH-MMKG), which incorporates multi-modalities and intricate entity relations. We also design a series of challenging queries based on MH-MMKG to evaluate the models' ability for complex knowledge retrieval and reasoning. Furthermore, we propose a multi-agent retriever that enables a model to autonomously search relevant knowledge without additional training. Experimental results show that our approach significantly enhances the performance of MLLMs, providing a new perspective on multimodal knowledge-augmented reasoning and laying a solid foundation for future research.",
      "authors": [
        "Bowen Wang",
        "Zhouqiang Jiang",
        "Yasuaki Susumu",
        "Shotaro Miwa",
        "Tianwei Chen",
        "Yuta Nakashima"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.17589",
        "HTML": "https://arxiv.org/html/2506.17589",
        "PDF": "https://arxiv.org/pdf/2506.17589"
      },
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Sat, 21 Jun 2025 05:01:02 GMT",
          "size": "493kb",
          "version": "v1"
        },
        {
          "date": "Thu, 26 Jun 2025 01:13:31 GMT",
          "size": "1873kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Taming the Untamed: Graph-Based Knowledge Retrieval and Reasoning for MLLMs to Conquer the Unknown",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "While the paper discusses knowledge retrieval and reasoning in MLLMs using a multimodal knowledge graph, it does not address processing or creating training data for LLMs specifically."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.17859",
      "abstract": "Recent work analyzing in-context learning (ICL) has identified a broad set of strategies that describe model behavior in different experimental conditions. We aim to unify these findings by asking why a model learns these disparate strategies in the first place. Specifically, we start with the observation that when trained to learn a mixture of tasks, as is popular in the literature, the strategies learned by a model for performing ICL can be captured by a family of Bayesian predictors: a memorizing predictor, which assumes a discrete prior on the set of seen tasks, and a generalizing predictor, where the prior matches the underlying task distribution. Adopting the normative lens of rational analysis, where a learner's behavior is explained as an optimal adaptation to data given computational constraints, we develop a hierarchical Bayesian framework that almost perfectly predicts Transformer next-token predictions throughout training -- without assuming access to its weights. Under this framework, pretraining is viewed as a process of updating the posterior probability of different strategies, and inference-time behavior as a posterior-weighted average over these strategies' predictions. Our framework draws on common assumptions about neural network learning dynamics, which make explicit a tradeoff between loss and complexity among candidate strategies: beyond how well it explains the data, a model's preference towards implementing a strategy is dictated by its complexity. This helps explain well-known ICL phenomena, while offering novel predictions: e.g., we show a superlinear trend in the timescale for transitioning from generalization to memorization as task diversity increases. Overall, our work advances an explanatory and predictive account of ICL grounded in tradeoffs between strategy loss and complexity.",
      "authors": [
        "Daniel Wurgaft",
        "Ekdeep Singh Lubana",
        "Core Francisco Park",
        "Hidenori Tanaka",
        "Gautam Reddy",
        "Noah D. Goodman"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.17859",
        "HTML": "https://arxiv.org/html/2506.17859",
        "PDF": "https://arxiv.org/pdf/2506.17859"
      },
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Sat, 21 Jun 2025 23:49:08 GMT",
          "size": "9770kb",
          "version": "v1"
        },
        {
          "date": "Thu, 26 Jun 2025 16:54:57 GMT",
          "size": "9779kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "In-Context Learning Strategies Emerge Rationally",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper primarily focuses on explaining in-context learning strategies in existing models but does not address the processing or engineering of training data for LLMs."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.18019",
      "abstract": "AI agents have experienced a paradigm shift, from early dominance by reinforcement learning (RL) to the rise of agents powered by large language models (LLMs), and now further advancing towards a synergistic fusion of RL and LLM capabilities. This progression has endowed AI agents with increasingly strong abilities. Despite these advances, to accomplish complex real-world tasks, agents are required to plan and execute effectively, maintain reliable memory, and coordinate smoothly with other agents. Achieving these capabilities involves contending with ever-present intricate information, operations, and interactions. In light of this challenge, data structurization can play a promising role by transforming intricate and disorganized data into well-structured forms that agents can more effectively understand and process. In this context, graphs, with their natural advantage in organizing, managing, and harnessing intricate data relationships, present a powerful data paradigm for structurization to support the capabilities demanded by advanced AI agents. To this end, this survey presents a first systematic review of how graphs can empower AI agents. Specifically, we explore the integration of graph techniques with core agent functionalities, highlight notable applications, and identify prospective avenues for future research. By comprehensively surveying this burgeoning intersection, we hope to inspire the development of next-generation AI agents equipped to tackle increasingly sophisticated challenges with graphs. Related resources are collected and continuously updated for the community in the Github link.",
      "authors": [
        "Yuanchen Bei",
        "Weizhi Zhang",
        "Siwen Wang",
        "Weizhi Chen",
        "Sheng Zhou",
        "Hao Chen",
        "Yong Li",
        "Jiajun Bu",
        "Shirui Pan",
        "Yizhou Yu",
        "Irwin King",
        "Fakhri Karray",
        "Philip S. Yu"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.18019",
        "HTML": "https://arxiv.org/html/2506.18019",
        "PDF": "https://arxiv.org/pdf/2506.18019"
      },
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Sun, 22 Jun 2025 12:59:12 GMT",
          "size": "1001kb",
          "version": "v1"
        },
        {
          "date": "Thu, 26 Jun 2025 16:54:14 GMT",
          "size": "774kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Graphs Meet AI Agents: Taxonomy, Progress, and Future Opportunities",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper surveys the integration of graphs with AI agents and does not contribute to the design, construction, or processing of LLM training data."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.18028",
      "abstract": "Multiple instance learning (MIL) has shown significant promise in histopathology whole slide image (WSI) analysis for cancer diagnosis and prognosis. However, the inherent spatial heterogeneity of WSIs presents critical challenges, as morphologically similar tissue types are often dispersed across distant anatomical regions. Conventional MIL methods struggle to model these scattered tissue distributions and capture cross-regional spatial interactions effectively. To address these limitations, we propose a novel Multiple instance learning framework with Context-Aware Clustering (MiCo), designed to enhance cross-regional intra-tissue correlations and strengthen inter-tissue semantic associations in WSIs. MiCo begins by clustering instances to distill discriminative morphological patterns, with cluster centroids serving as semantic anchors. To enhance cross-regional intra-tissue correlations, MiCo employs a Cluster Route module, which dynamically links instances of the same tissue type across distant regions via feature similarity. These semantic anchors act as contextual hubs, propagating semantic relationships to refine instance-level representations. To eliminate semantic fragmentation and strengthen inter-tissue semantic associations, MiCo integrates a Cluster Reducer module, which consolidates redundant anchors while enhancing information exchange between distinct semantic groups. Extensive experiments on two challenging tasks across nine large-scale public cancer datasets demonstrate the effectiveness of MiCo, showcasing its superiority over state-of-the-art methods. The code is available at https://github.com/junjianli106/MiCo.",
      "authors": [
        "Junjian Li",
        "Hulin Kuang",
        "Jin Liu",
        "Hailin Yue",
        "Mengshen He",
        "and Jianxin Wang"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.18028",
        "HTML": "https://arxiv.org/html/2506.18028",
        "PDF": "https://arxiv.org/pdf/2506.18028"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Sun, 22 Jun 2025 13:14:41 GMT",
          "size": "12572kb",
          "version": "v1"
        },
        {
          "date": "Thu, 26 Jun 2025 01:29:36 GMT",
          "size": "12572kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "MiCo: Multiple Instance Learning with Context-Aware Clustering for Whole Slide Image Analysis",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper focuses on multiple instance learning for image analysis and does not discuss any aspect of LLM training data."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.18221",
      "abstract": "Transfer learning is a cornerstone of modern machine learning, promising a way to adapt models pretrained on a broad mix of data to new tasks with minimal new data. However, a significant challenge remains in ensuring that transferred features are sufficient to handle unseen datasets, amplified by the difficulty of quantifying whether two tasks are \"related\". To address these challenges, we evaluate model transfer from a pretraining mixture to each of its component tasks, assessing whether pretrained features can match the performance of task-specific direct training. We identify a fundamental limitation in deep learning models -- an \"information saturation bottleneck\" -- where networks fail to learn new features once they encode similar competing features during training. When restricted to learning only a subset of key features during pretraining, models will permanently lose critical features for transfer and perform inconsistently on data distributions, even components of the training mixture. Empirical evidence from published studies suggests that this phenomenon is pervasive in deep learning architectures -- factors such as data distribution or ordering affect the features that current representation learning methods can learn over time. This study suggests that relying solely on large-scale networks may not be as effective as focusing on task-specific training, when available. We propose richer feature representations as a potential solution to better generalize across new datasets and, specifically, present existing methods alongside a novel approach, the initial steps towards addressing this challenge.",
      "authors": [
        "Xingyu Alice Yang",
        "Jianyu Zhang",
        "L\\'eon Bottou"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.18221",
        "HTML": "https://arxiv.org/html/2506.18221",
        "PDF": "https://arxiv.org/pdf/2506.18221"
      },
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "Mon, 23 Jun 2025 01:04:29 GMT",
          "size": "658kb",
          "version": "v1"
        },
        {
          "date": "Thu, 26 Jun 2025 13:50:38 GMT",
          "size": "661kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "These Are Not All the Features You Are Looking For: A Fundamental Bottleneck in Supervised Pretraining",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper discusses transfer learning challenges and feature learning bottlenecks but does not propose any methods for LLM training data processing specifically."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.18246",
      "abstract": "Using natural language to query visual information is a fundamental need in real-world applications. Text-Image Retrieval (TIR) retrieves a target image from a gallery based on an image-level description, while Referring Expression Comprehension (REC) localizes a target object within a given image using an instance-level description. However, real-world applications often present more complex demands. Users typically query an instance-level description across a large gallery and expect to receive both relevant image and the corresponding instance location. In such scenarios, TIR struggles with fine-grained descriptions and object-level localization, while REC is limited in its ability to efficiently search large galleries and lacks an effective ranking mechanism. In this paper, we introduce a new task called \\textbf{Referring Expression Instance Retrieval (REIR)}, which supports both instance-level retrieval and localization based on fine-grained referring expressions. First, we propose a large-scale benchmark for REIR, named REIRCOCO, constructed by prompting advanced vision-language models to generate high-quality referring expressions for instances in the MSCOCO and RefCOCO datasets. Second, we present a baseline method, Contrastive Language-Instance Alignment with Relation Experts (CLARE), which employs a dual-stream architecture to address REIR in an end-to-end manner. Given a referring expression, the textual branch encodes it into a query embedding. The visual branch detects candidate objects and extracts their instance-level visual features. The most similar candidate to the query is selected for bounding box prediction. CLARE is first trained on object detection and REC datasets to establish initial grounding capabilities, then optimized via Contrastive Language-Instance Alignment (CLIA) for improved retrieval across images. We will release our code and benchmark publicly.",
      "authors": [
        "Xiangzhao Hao",
        "Kuan Zhu",
        "Hongyu Guo",
        "Haiyun Guo",
        "Ning Jiang",
        "Quan Lu",
        "Ming Tang",
        "Jinqiao Wang"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.18246",
        "HTML": "https://arxiv.org/html/2506.18246",
        "PDF": "https://arxiv.org/pdf/2506.18246"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Mon, 23 Jun 2025 02:28:44 GMT",
          "size": "7895kb",
          "version": "v1"
        },
        {
          "date": "Tue, 24 Jun 2025 03:38:39 GMT",
          "size": "7895kb",
          "version": "v2"
        },
        {
          "date": "Thu, 26 Jun 2025 11:31:17 GMT",
          "size": "12947kb",
          "version": "v3"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Referring Expression Instance Retrieval and A Strong End-to-End Baseline",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper introduces a new task for visual information retrieval and does not address the processing or engineering of training data specifically for LLMs."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.18575",
      "abstract": "Differentiable rendering with 3D Gaussian primitives has emerged as a powerful method for reconstructing high-fidelity 3D scenes from multi-view images. While it offers improvements over NeRF-based methods, this representation still encounters challenges with rendering speed and advanced rendering effects, such as relighting and shadow rendering, compared to mesh-based models. In this paper, we propose 2D Triangle Splatting (2DTS), a novel method that replaces 3D Gaussian primitives with 2D triangle facelets. This representation naturally forms a discrete mesh-like structure while retaining the benefits of continuous volumetric modeling. By incorporating a compactness parameter into the triangle primitives, we enable direct training of photorealistic meshes. Our experimental results demonstrate that our triangle-based method, in its vanilla version (without compactness tuning), achieves higher fidelity compared to state-of-the-art Gaussian-based methods. Furthermore, our approach produces reconstructed meshes with superior visual quality compared to existing mesh reconstruction methods. Please visit our project page at https://gaoderender.github.io/triangle-splatting.",
      "authors": [
        "Kaifeng Sheng",
        "Zheng Zhou",
        "Yingliang Peng",
        "Qianwei Wang"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.18575",
        "HTML": "https://arxiv.org/html/2506.18575",
        "PDF": "https://arxiv.org/pdf/2506.18575"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Mon, 23 Jun 2025 12:26:47 GMT",
          "size": "34079kb",
          "version": "v1"
        },
        {
          "date": "Thu, 26 Jun 2025 06:46:05 GMT",
          "size": "34079kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "2D Triangle Splatting for Direct Differentiable Mesh Training",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on a novel method for differentiable rendering using 2D triangle facelets for 3D scene reconstruction and is unrelated to LLM training data processing."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.18671",
      "abstract": "Music-driven dance generation has garnered significant attention due to its wide range of industrial applications, particularly in the creation of group choreography. During the group dance generation process, however, most existing methods still face three primary issues: multi-dancer collisions, single-dancer foot sliding and abrupt swapping in the generation of long group dance. In this paper, we propose TCDiff++, a music-driven end-to-end framework designed to generate harmonious group dance. Specifically, to mitigate multi-dancer collisions, we utilize a dancer positioning embedding to better maintain the relative positioning among dancers. Additionally, we incorporate a distance-consistency loss to ensure that inter-dancer distances remain within plausible ranges. To address the issue of single-dancer foot sliding, we introduce a swap mode embedding to indicate dancer swapping patterns and design a Footwork Adaptor to refine raw motion, thereby minimizing foot sliding. For long group dance generation, we present a long group diffusion sampling strategy that reduces abrupt position shifts by injecting positional information into the noisy input. Furthermore, we integrate a Sequence Decoder layer to enhance the model's ability to selectively process long sequences. Extensive experiments demonstrate that our TCDiff++ achieves state-of-the-art performance, particularly in long-duration scenarios, ensuring high-quality and coherent group dance generation.",
      "authors": [
        "Yuqin Dai",
        "Wanlu Zhu",
        "Ronghui Li",
        "Xiu Li",
        "Zhenyu Zhang",
        "Jun Li",
        "Jian Yang"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.18671",
        "HTML": "https://arxiv.org/html/2506.18671",
        "PDF": "https://arxiv.org/pdf/2506.18671"
      },
      "subjects": [
        "Sound (cs.SD)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Graphics (cs.GR)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "Mon, 23 Jun 2025 14:15:20 GMT",
          "size": "3053kb",
          "version": "v1"
        },
        {
          "date": "Wed, 25 Jun 2025 14:19:44 GMT",
          "size": "3053kb",
          "version": "v2"
        },
        {
          "date": "Thu, 26 Jun 2025 13:53:17 GMT",
          "size": "3053kb",
          "version": "v3"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "TCDiff++: An End-to-end Trajectory-Controllable Diffusion Model for Harmonious Music-Driven Group Choreography",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper addresses music-driven dance generation and choreography without any discussion related to the processing or engineering of LLM training data."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.18927",
      "abstract": "The rapid growth of edge devices has driven the demand for deploying artificial intelligence (AI) at the edge, giving rise to Tiny Machine Learning (TinyML) and its evolving counterpart, Tiny Deep Learning (TinyDL). While TinyML initially focused on enabling simple inference tasks on microcontrollers, the emergence of TinyDL marks a paradigm shift toward deploying deep learning models on severely resource-constrained hardware. This survey presents a comprehensive overview of the transition from TinyML to TinyDL, encompassing architectural innovations, hardware platforms, model optimization techniques, and software toolchains. We analyze state-of-the-art methods in quantization, pruning, and neural architecture search (NAS), and examine hardware trends from MCUs to dedicated neural accelerators. Furthermore, we categorize software deployment frameworks, compilers, and AutoML tools enabling practical on-device learning. Applications across domains such as computer vision, audio recognition, healthcare, and industrial monitoring are reviewed to illustrate the real-world impact of TinyDL. Finally, we identify emerging directions including neuromorphic computing, federated TinyDL, edge-native foundation models, and domain-specific co-design approaches. This survey aims to serve as a foundational resource for researchers and practitioners, offering a holistic view of the ecosystem and laying the groundwork for future advancements in edge AI.",
      "authors": [
        "Shriyank Somvanshi",
        "Md Monzurul Islam",
        "Gaurab Chhetri",
        "Rohit Chakraborty",
        "Mahmuda Sultana Mimi",
        "Sawgat Ahmed Shuvo",
        "Kazi Sifatul Islam",
        "Syed Aaqib Javed",
        "Sharif Ahmed Rafat",
        "Anandi Dutta",
        "Subasish Das"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.18927",
        "HTML": "https://arxiv.org/html/2506.18927",
        "PDF": "https://arxiv.org/pdf/2506.18927"
      },
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Sat, 21 Jun 2025 05:09:07 GMT",
          "size": "931kb",
          "version": "v1"
        },
        {
          "date": "Wed, 25 Jun 2025 21:42:13 GMT",
          "size": "930kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "From Tiny Machine Learning to Tiny Deep Learning: A Survey",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This survey covers advancements in Tiny Machine Learning and Deep Learning for edge devices, focusing on model deployment and optimization on constrained hardware, not LLM training data processing."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.18959",
      "abstract": "Information retrieval is a cornerstone of modern knowledge acquisition, enabling billions of queries each day across diverse domains. However, traditional keyword-based search engines are increasingly inadequate for handling complex, multi-step information needs. Our position is that Large Language Models (LLMs), endowed with reasoning and agentic capabilities, are ushering in a new paradigm termed Agentic Deep Research. These systems transcend conventional information search techniques by tightly integrating autonomous reasoning, iterative retrieval, and information synthesis into a dynamic feedback loop. We trace the evolution from static web search to interactive, agent-based systems that plan, explore, and learn. We also introduce a test-time scaling law to formalize the impact of computational depth on reasoning and search. Supported by benchmark results and the rise of open-source implementations, we demonstrate that Agentic Deep Research not only significantly outperforms existing approaches, but is also poised to become the dominant paradigm for future information seeking. All the related resources, including industry products, research papers, benchmark datasets, and open-source implementations, are collected for the community in https://github.com/DavidZWZ/Awesome-Deep-Research.",
      "authors": [
        "Weizhi Zhang",
        "Yangning Li",
        "Yuanchen Bei",
        "Junyu Luo",
        "Guancheng Wan",
        "Liangwei Yang",
        "Chenxuan Xie",
        "Yuyao Yang",
        "Wei-Chieh Huang",
        "Chunyu Miao",
        "Henry Peng Zou",
        "Xiao Luo",
        "Yusheng Zhao",
        "Yankai Chen",
        "Chunkit Chan",
        "Peilin Zhou",
        "Xinyang Zhang",
        "Chenwei Zhang",
        "Jingbo Shang",
        "Ming Zhang",
        "Yangqiu Song",
        "Irwin King",
        "Philip S. Yu"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.18959",
        "HTML": "https://arxiv.org/html/2506.18959",
        "PDF": "https://arxiv.org/pdf/2506.18959"
      },
      "subjects": [
        "Information Retrieval (cs.IR)",
        "Computation and Language (cs.CL)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Mon, 23 Jun 2025 17:27:19 GMT",
          "size": "2851kb",
          "version": "v1"
        },
        {
          "date": "Thu, 26 Jun 2025 17:18:00 GMT",
          "size": "2850kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "From Web Search towards Agentic Deep Research: Incentivizing Search with Reasoning Agents",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper discusses the evolution of web search with reasoning agents using LLMs, highlighting search innovations rather than any methods for processing LLM training data."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.19333",
      "abstract": "This paper presents a formal analysis of the Lightning Network as a monetary system structurally diverging from Bitcoin's base-layer settlement model. We demonstrate that under increasing transaction demand, BTC transaction fees rise superlinearly due to throughput constraints, while Lightning Network routing costs approach a bounded asymptote. Using mathematical modeling, game-theoretic proofs, and complexity analysis, we show that Lightning enables indefinite off-chain operation via the emergence of liquidity hub oligopolies. These hubs exhibit properties of unregulated financial intermediaries, including rent extraction, opacity, and systemic fragility. Strategic agent models show that channel closure becomes economically infeasible, and routing problems approach hardness limits in P-Space complexity. We conclude that Lightning does not merely extend Bitcoin, but constitutes a synthetic financial system with shadowbank characteristics, lacking reserve discipline, transparency, or enforceable settlement guarantees.",
      "authors": [
        "Craig Steven Wright"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.19333",
        "HTML": "https://arxiv.org/html/2506.19333",
        "PDF": "https://arxiv.org/pdf/2506.19333"
      },
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "Computational Complexity (cs.CC)",
        "Emerging Technologies (cs.ET)",
        "Computer Science and Game Theory (cs.GT)",
        "General Economics (econ.GN)",
        "Economics (q-fin.EC)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 24 Jun 2025 05:57:22 GMT",
          "size": "539kb",
          "version": "v1"
        },
        {
          "date": "Thu, 26 Jun 2025 12:26:23 GMT",
          "size": "539kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "The Autonomy of the Lightning Network: A Mathematical and Economic Proof of Structural Decoupling from BTC",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on the economic and structural analysis of the Lightning Network, unrelated to LLM training data processing or construction. It discusses economic models and system characteristics rather than anything related to LLM data processes."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.19391",
      "abstract": "Downscaling is essential for generating the high-resolution climate data needed for local planning, but traditional methods remain computationally demanding. Recent years have seen impressive results from AI downscaling models, particularly diffusion models, which have attracted attention due to their ability to generate ensembles and overcome the smoothing problem common in other AI methods. However, these models typically remain computationally intensive. We introduce a Hierarchical Diffusion Downscaling (HDD) model, which introduces an easily-extensible hierarchical sampling process to the diffusion framework. A coarse-to-fine hierarchy is imposed via a simple downsampling scheme. HDD achieves competitive accuracy on ERA5 reanalysis datasets and CMIP6 models, significantly reducing computational load by running on up to half as many pixels with competitive results. Additionally, a single model trained at 0.25{\\deg} resolution transfers seamlessly across multiple CMIP6 models with much coarser resolution. HDD thus offers a lightweight alternative for probabilistic climate downscaling, facilitating affordable large-ensemble high-resolution climate projections. See a full code implementation at: https://github.com/HDD-Hierarchical-Diffusion-Downscaling/HDD-Hierarchical-Diffusion-Downscaling.",
      "authors": [
        "Declan J. Curran and Sanaa Hobeichi and Hira Saleem and Hao Xue and Flora D. Salim"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.19391",
        "HTML": "https://arxiv.org/html/2506.19391",
        "PDF": "https://arxiv.org/pdf/2506.19391"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 24 Jun 2025 07:39:53 GMT",
          "size": "1223kb",
          "version": "v1"
        },
        {
          "date": "Thu, 26 Jun 2025 06:39:13 GMT",
          "size": "1223kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Generate the Forest before the Trees -- A Hierarchical Diffusion model for Climate Downscaling",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper is focused on climate downscaling and does not discuss LLM training data processing or engineering."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.19657",
      "abstract": "The Circular Economy framework emphasizes sustainability by reducing resource consumption and waste through the reuse of components and materials. This paper presents ReLink, a computational framework for the circular design of planar linkage mechanisms using available standard parts. Unlike most mechanism design methods, which assume the ability to create custom parts and infinite part availability, ReLink prioritizes the reuse of discrete, standardized components, thus minimizing the need for new parts. The framework consists of two main components: design generation, where a generative design algorithm generates mechanisms from an inventory of available parts, and inverse design, which uses optimization methods to identify designs that match a user-defined trajectory curve. The paper also examines the trade-offs between kinematic performance and CO2 footprint when incorporating new parts. Challenges such as the combinatorial nature of the design problem and the enforcement of valid solutions are addressed. By combining sustainability principles with kinematic synthesis, ReLink lays the groundwork for further research into computational circular design to support the development of systems that integrate reused components into mechanical products.",
      "authors": [
        "Maxime Escande",
        "Kristina Shea"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.19657",
        "HTML": "https://arxiv.org/html/2506.19657",
        "PDF": "https://arxiv.org/pdf/2506.19657"
      },
      "subjects": [
        "Computational Engineering, Finance, and Science (cs.CE)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 24 Jun 2025 14:22:07 GMT",
          "size": "2646kb",
          "version": "v1"
        },
        {
          "date": "Wed, 25 Jun 2025 19:12:06 GMT",
          "size": "3018kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "ReLink: Computational Circular Design of Planar Linkage Mechanisms Using Available Standard Parts",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper addresses circular design of mechanical parts and does not relate to training data for LLMs or their processing."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.19683",
      "abstract": "Understanding medical ultrasound imaging remains a long-standing challenge due to significant visual variability caused by differences in imaging and acquisition parameters. Recent advancements in large language models (LLMs) have been used to automatically generate terminology-rich summaries orientated to clinicians with sufficient physiological knowledge. Nevertheless, the increasing demand for improved ultrasound interpretability and basic scanning guidance among non-expert users, e.g., in point-of-care settings, has not yet been explored. In this study, we first introduce the scene graph (SG) for ultrasound images to explain image content to ordinary and provide guidance for ultrasound scanning. The ultrasound SG is first computed using a transformer-based one-stage method, eliminating the need for explicit object detection. To generate a graspable image explanation for ordinary, the user query is then used to further refine the abstract SG representation through LLMs. Additionally, the predicted SG is explored for its potential in guiding ultrasound scanning toward missing anatomies within the current imaging view, assisting ordinary users in achieving more standardized and complete anatomical exploration. The effectiveness of this SG-based image explanation and scanning guidance has been validated on images from the left and right neck regions, including the carotid and thyroid, across five volunteers. The results demonstrate the potential of the method to maximally democratize ultrasound by enhancing its interpretability and usability for ordinaries.",
      "authors": [
        "Xuesong Li",
        "Dianye Huang",
        "Yameng Zhang",
        "Nassir Navab and Zhongliang Jiang"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.19683",
        "HTML": "https://arxiv.org/html/2506.19683",
        "PDF": "https://arxiv.org/pdf/2506.19683"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)",
        "Image and Video Processing (eess.IV)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 24 Jun 2025 14:49:40 GMT",
          "size": "464kb",
          "version": "v1"
        },
        {
          "date": "Thu, 26 Jun 2025 14:20:13 GMT",
          "size": "464kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Semantic Scene Graph for Ultrasound Image Explanation and Scanning Guidance",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper proposes a method for ultrasound image explanation and scanning guidance using LLMs but does not focus on the training data processing for LLMs."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.19686",
      "abstract": "Humans and animals show remarkable learning efficiency, adapting to new environments with minimal experience. This capability is not well captured by standard reinforcement learning algorithms that rely on incremental value updates. Rapid adaptation likely depends on episodic memory -- the ability to retrieve specific past experiences to guide decisions in novel contexts. Transformers provide a useful setting for studying these questions because of their ability to learn rapidly in-context and because their key-value architecture resembles episodic memory systems in the brain. We train a transformer to in-context reinforcement learn in a distribution of planning tasks inspired by rodent behavior. We then characterize the learning algorithms that emerge in the model. We first find that representation learning is supported by in-context structure learning and cross-context alignment, where representations are aligned across environments with different sensory stimuli. We next demonstrate that the reinforcement learning strategies developed by the model are not interpretable as standard model-free or model-based planning. Instead, we show that in-context reinforcement learning is supported by caching intermediate computations within the model's memory tokens, which are then accessed at decision time. Overall, we find that memory may serve as a computational resource, storing both raw experience and cached computations to support flexible behavior. Furthermore, the representations developed in the model resemble computations associated with the hippocampal-entorhinal system in the brain, suggesting that our findings may be relevant for natural cognition. Taken together, our work offers a mechanistic hypothesis for the rapid adaptation that underlies in-context learning in artificial and natural settings.",
      "authors": [
        "Ching Fang",
        "Kanaka Rajan"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.19686",
        "HTML": "https://arxiv.org/html/2506.19686",
        "PDF": "https://arxiv.org/pdf/2506.19686"
      },
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 24 Jun 2025 14:55:43 GMT",
          "size": "11970kb",
          "version": "v1"
        },
        {
          "date": "Thu, 26 Jun 2025 17:18:54 GMT",
          "size": "11970kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "From Memories to Maps: Mechanisms of In-Context Reinforcement Learning in Transformers",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper discusses in-context reinforcement learning mechanisms in transformers, without specifics on LLM training data processing or engineering."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.19750",
      "abstract": "Symptom Checkers (SCs) provide medical information tailored to user symptoms. A critical challenge in SC development is preventing unexpected performance degradation for individual diseases, especially rare diseases, when updating algorithms. This risk stems from the lack of practical pre-deployment evaluation methods. For rare diseases, obtaining sufficient evaluation data from user feedback is difficult. To evaluate the impact of algorithm updates on the diagnostic performance for individual rare diseases before deployment, this study proposes and validates a novel Synthetic Vignette Simulation Approach. This approach aims to enable this essential evaluation efficiently and at a low cost. To estimate the impact of algorithm updates, we generated synthetic vignettes from disease-phenotype annotations in the Human Phenotype Ontology (HPO), a publicly available knowledge base for rare diseases curated by experts. Using these vignettes, we simulated SC interviews to predict changes in diagnostic performance. The effectiveness of this approach was validated retrospectively by comparing the predicted changes with actual performance metrics using the R-squared ($R^2$) coefficient. Our experiment, covering eight past algorithm updates for rare diseases, showed that the proposed method accurately predicted performance changes for diseases with phenotype frequency information in HPO (n=5). For these updates, we found a strong correlation for both Recall@8 change ($R^2$ = 0.83,$p$ = 0.031) and Precision@8 change ($R^2$ = 0.78,$p$ = 0.047). Our proposed method enables the pre-deployment evaluation of SC algorithm changes for individual rare diseases. This evaluation is based on a publicly available medical knowledge database created by experts, ensuring transparency and explainability for stakeholders. Additionally, SC developers can efficiently improve diagnostic performance at a low cost.",
      "authors": [
        "Takashi Nishibayashi",
        "Seiji Kanazawa and Kumpei Yamada"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.19750",
        "HTML": "https://arxiv.org/html/2506.19750",
        "PDF": "https://arxiv.org/pdf/2506.19750"
      },
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 24 Jun 2025 16:06:37 GMT",
          "size": "648kb",
          "version": "v1"
        },
        {
          "date": "Wed, 25 Jun 2025 11:56:15 GMT",
          "size": "648kb",
          "version": "v2"
        },
        {
          "date": "Thu, 26 Jun 2025 06:52:46 GMT",
          "size": "648kb",
          "version": "v3"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Evaluating Rare Disease Diagnostic Performance in Symptom Checkers: A Synthetic Vignette Simulation Approach",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper is about evaluating rare disease diagnostic performance in symptom checkers and does not involve LLM training data processing or engineering."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.19781",
      "abstract": "The integration of satellite communication into mobile devices represents a paradigm shift in connectivity, yet the performance characteristics under motion and environmental occlusion remain poorly understood. We present the Starlink Robot, the first mobile robotic platform equipped with Starlink satellite internet, comprehensive sensor suite including upward-facing camera, LiDAR, and IMU, designed to systematically study satellite communication performance during movement. Our multi-modal dataset captures synchronized communication metrics, motion dynamics, sky visibility, and 3D environmental context across diverse scenarios including steady-state motion, variable speeds, and different occlusion conditions. This platform and dataset enable researchers to develop motion-aware communication protocols, predict connectivity disruptions, and optimize satellite communication for emerging mobile applications from smartphones to autonomous vehicles. The project is available at https://github.com/StarlinkRobot.",
      "authors": [
        "Boyi Liu",
        "Qianyi Zhang",
        "Qiang Yang",
        "Jianhao Jiao",
        "Jagmohan Chauhan",
        "Dimitrios Kanoulas"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/publicdomain/zero/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.19781",
        "HTML": "https://arxiv.org/html/2506.19781",
        "PDF": "https://arxiv.org/pdf/2506.19781"
      },
      "subjects": [
        "Robotics (cs.RO)",
        "Networking and Internet Architecture (cs.NI)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 24 Jun 2025 16:49:56 GMT",
          "size": "11299kb",
          "version": "v1"
        },
        {
          "date": "Thu, 26 Jun 2025 09:14:30 GMT",
          "size": "11299kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "The Starlink Robot: A Platform and Dataset for Mobile Satellite Communication",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper focuses on satellite communication performance for mobile devices and data collection in that context, which is not related to LLM training data."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.19815",
      "abstract": "Surface electromyography (sEMG) signals show promise for effective human-computer interfaces, particularly in rehabilitation and prosthetics. However, challenges remain in developing systems that respond quickly and reliably to user intent, across different subjects and without requiring time-consuming calibration. In this work, we propose a framework for EMG-based intent detection that addresses these challenges. Unlike traditional gesture recognition models that wait until a gesture is completed before classifying it, our approach uses a segmentation strategy to assign intent labels at every timestep as the gesture unfolds. We introduce a novel masked modeling strategy that aligns muscle activations with their corresponding user intents, enabling rapid onset detection and stable tracking of ongoing gestures. In evaluations against baseline methods, considering both accuracy and stability for device control, our approach surpasses state-of-the-art performance in zero-shot transfer conditions, demonstrating its potential for wearable robotics and next-generation prosthetic systems. Our project page is available at: https://reactemg.github.io",
      "authors": [
        "Runsheng Wang",
        "Xinyue Zhu",
        "Ava Chen",
        "Jingxi Xu",
        "Lauren Winterbottom",
        "Dawn M. Nilsen",
        "Joel Stein",
        "Matei Ciocarlie"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.19815",
        "HTML": "https://arxiv.org/html/2506.19815",
        "PDF": "https://arxiv.org/pdf/2506.19815"
      },
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 24 Jun 2025 17:28:43 GMT",
          "size": "929kb",
          "version": "v1"
        },
        {
          "date": "Thu, 26 Jun 2025 16:48:36 GMT",
          "size": "930kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "ReactEMG: Zero-Shot, Low-Latency Intent Detection via sEMG",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper deals with electromyography signals and user intent detection, which are unrelated to LLM training data processing or engineering."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.19874",
      "abstract": "Recent secure weight release schemes claim to enable open-source model distribution while protecting model ownership and preventing misuse. However, these approaches lack rigorous security foundations and provide only informal security guarantees. Inspired by established works in cryptography, we formalize the security of weight release schemes by introducing several concrete security definitions. We then demonstrate our definition's utility through a case study of TaylorMLP, a prominent secure weight release scheme. Our analysis reveals vulnerabilities that allow parameter extraction thus showing that TaylorMLP fails to achieve its informal security goals. We hope this work will advocate for rigorous research at the intersection of machine learning and security communities and provide a blueprint for how future weight release schemes should be designed and evaluated.",
      "authors": [
        "Xin Yang",
        "Bintao Tang",
        "Yuhao Wang",
        "Zimo Ji",
        "Terry Jingchen Zhang",
        "Wenyuan Jiang"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.19874",
        "HTML": "https://arxiv.org/html/2506.19874",
        "PDF": "https://arxiv.org/pdf/2506.19874"
      },
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Mon, 23 Jun 2025 11:57:41 GMT",
          "size": "244kb",
          "version": "v1"
        },
        {
          "date": "Thu, 26 Jun 2025 08:45:10 GMT",
          "size": "244kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Towards Provable (In)Secure Model Weight Release Schemes",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The focus is on secure model weight release schemes and security definitions, with no discussion related to LLM training data processing or collection."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.20045",
      "abstract": "Deep object pose estimators are notoriously overconfident. A grasping agent that both estimates the 6-DoF pose of a target object and predicts the uncertainty of its own estimate could avoid task failure by choosing not to act under high uncertainty. Even though object pose estimation improves and uncertainty quantification research continues to make strides, few studies have connected them to the downstream task of robotic grasping. We propose a method for training lightweight, deep networks to predict whether a grasp guided by an image-based pose estimate will succeed before that grasp is attempted. We generate training data for our networks via object pose estimation on real images and simulated grasping. We also find that, despite high object variability in grasping trials, networks benefit from training on all objects jointly, suggesting that a diverse variety of objects can nevertheless contribute to the same goal.",
      "authors": [
        "Eric C. Joyce",
        "Qianwen Zhao",
        "Nathaniel Burgdorfer",
        "Long Wang",
        "Philippos Mordohai"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20045",
        "HTML": "https://arxiv.org/html/2506.20045",
        "PDF": "https://arxiv.org/pdf/2506.20045"
      },
      "subjects": [
        "Robotics (cs.RO)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 24 Jun 2025 22:53:54 GMT",
          "size": "2646kb",
          "version": "v1"
        },
        {
          "date": "Thu, 26 Jun 2025 15:12:14 GMT",
          "size": "2646kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Consensus-Driven Uncertainty for Robotic Grasping based on RGB Perception",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper discusses training data generation for robotic grasping tasks and image-based pose estimation, which does not pertain to LLM training data processing."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.20081",
      "abstract": "Retrieval-Augmented Code Generation (RACG) is a critical technique for enhancing code generation by retrieving relevant information. In this work, we conduct an in-depth analysis of code retrieval by systematically masking specific features while preserving code functionality. Our discoveries include: (1) although trained on code, current retrievers heavily rely on surface-level textual features (e.g., docstrings, identifier names), and (2) they exhibit a strong bias towards well-documented code, even if the documentation is irrelevant. Based on our discoveries, we propose SACL, a framework that enriches textual information and reduces bias by augmenting code or structural knowledge with semantic information. Extensive experiments show that SACL substantially improves code retrieval (e.g., by 12.8% / 9.4% / 7.0% Recall@1 on HumanEval / MBPP / SWE-Bench-Lite), which also leads to better code generation performance (e.g., by 4.88% Pass@1 on HumanEval).",
      "authors": [
        "Dhruv Gupta",
        "Gayathri Ganesh Lakshmy",
        "Yiqing Xie"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20081",
        "HTML": "https://arxiv.org/html/2506.20081",
        "PDF": "https://arxiv.org/pdf/2506.20081"
      },
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 01:44:28 GMT",
          "size": "3118kb",
          "version": "v1"
        },
        {
          "date": "Thu, 26 Jun 2025 04:06:50 GMT",
          "size": "3118kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "SACL: Understanding and Combating Textual Bias in Code Retrieval with Semantic-Augmented Reranking and Localization",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on understanding and combating textual bias in code retrieval systems rather than on data engineering or training-stage data processing for LLMs. It proposes a framework for improving code retrieval and generation, but it does not directly address LLM training data processing."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.20174",
      "abstract": "Foundation models are rapidly transforming Earth Observation data mining by enabling generalizable and scalable solutions for key tasks such as scene classification and semantic segmentation. While most efforts in the geospatial domain have focused on developing large models trained from scratch using massive Earth Observation datasets, an alternative strategy that remains underexplored is the reuse and combination of existing pretrained models. In this study, we investigate whether foundation models pretrained on remote sensing and general vision datasets can be effectively combined to improve performance across a diverse set of key Earth Observation tasks. Using the GEO-Bench benchmark, we evaluate several prominent models, including Prithvi, Hiera, and DOFA, on eleven datasets covering a range of spatial resolutions, sensor modalities, and task types. The results show that feature-level ensembling of smaller pretrained models can match or exceed the performance of much larger models, while requiring less training time and computational resources. Moreover, the study highlights the potential of applying knowledge distillation to transfer the strengths of ensembles into more compact models, offering a practical path for deploying foundation models in real-world Earth Observation applications.",
      "authors": [
        "Man Duc Chuc"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20174",
        "HTML": "https://arxiv.org/html/2506.20174",
        "PDF": "https://arxiv.org/pdf/2506.20174"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 07:02:42 GMT",
          "size": "4264kb",
          "version": "v1"
        },
        {
          "date": "Thu, 26 Jun 2025 03:23:43 GMT",
          "size": "4264kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Towards Scalable and Generalizable Earth Observation Data Mining via Foundation Model Composition",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper concentrates on the application of foundation models for Earth Observation data mining and explores feature-level ensembling for improved task performance, without detailing methodologies in LLM training data processing or engineering."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.20195",
      "abstract": "We propose a quasi-Grassmannian gradient flow model for eigenvalue problems of linear operators, aiming to efficiently address many eigenpairs. Our model inherently ensures asymptotic orthogonality: without the need for initial orthogonality, the solution naturally evolves toward being orthogonal over time. We establish the well-posedness of the model, and provide the analytical representation of solutions. Through asymptotic analysis, we show that the gradient converges exponentially to zero and that the energy decreases exponentially to its minimum. This implies that the solution of the quasi-Grassmannian gradient flow model converges to the solution of the eigenvalue problems as time progresses. These properties not only eliminate the need for explicit orthogonalization in numerical computation but also significantly enhance robustness of the model, rendering it far more resilient to numerical perturbations than conventional methods.",
      "authors": [
        "Shengyue Wang and Aihui Zhou"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20195",
        "HTML": "https://arxiv.org/html/2506.20195",
        "PDF": "https://arxiv.org/pdf/2506.20195"
      },
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 07:36:39 GMT",
          "size": "43kb",
          "version": "v1"
        },
        {
          "date": "Thu, 26 Jun 2025 07:02:01 GMT",
          "size": "53kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "A quasi-Grassmannian gradient flow model for eigenvalue problems",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper discusses a gradient flow model for eigenvalue problems with no reference to LLM training data processing or data engineering tasks. It focuses solely on numerical methods and model robustness."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.20225",
      "abstract": "Preprints have become increasingly essential in the landscape of open science, facilitating not only the exchange of knowledge within the scientific community but also bridging the gap between science and technology. However, the impact of preprints on technological innovation, given their unreviewed nature, remains unclear. This study fills this gap by conducting a comprehensive scientometric analysis of patent citations to bioRxiv preprints submitted between 2013 and 2021, measuring and accessing the contribution of preprints in accelerating knowledge transfer from science to technology. Our findings reveal a growing trend of patent citations to bioRxiv preprints, with a notable surge in 2020, primarily driven by the COVID-19 pandemic. Preprints play a critical role in accelerating innovation, not only expedite the dissemination of scientific knowledge into technological innovation but also enhance the visibility of early research results in the patenting process, while journals remain essential for academic rigor and reliability. The substantial number of post-online-publication patent citations highlights the critical role of the open science model-particularly the \"open access\" effect of preprints-in amplifying the impact of science on technological innovation. This study provides empirical evidence that open science policies encouraging the early sharing of research outputs, such as preprints, contribute to more efficient linkage between science and technology, suggesting an acceleration in the pace of innovation, higher innovation quality, and economic benefits.",
      "authors": [
        "Zhiqi Wang",
        "Yue Chen",
        "Chun Yang"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20225",
        "HTML": "https://arxiv.org/html/2506.20225",
        "PDF": "https://arxiv.org/pdf/2506.20225"
      },
      "subjects": [
        "Digital Libraries (cs.DL)",
        "Physics and Society (physics.soc-ph)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 08:13:05 GMT",
          "size": "2031kb",
          "version": "v1"
        },
        {
          "date": "Thu, 26 Jun 2025 06:08:57 GMT",
          "size": "2337kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "The role of preprints in open science: Accelerating knowledge transfer from science to technology",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The study investigates the impact of preprints on knowledge transfer and innovation acceleration. It does not address any aspects of data processing or engineering specifically related to LLM training data."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.20320",
      "abstract": "In Social Robot Navigation, autonomous agents need to resolve many sequential interactions with other agents. State-of-the art planners can efficiently resolve the next, imminent interaction cooperatively and do not focus on longer planning horizons. This makes it hard to maneuver scenarios where the agent needs to select a good strategy to find gaps or channels in the crowd. We propose to decompose trajectory planning into two separate steps: Conflict avoidance for finding good, macroscopic trajectories, and cooperative collision avoidance (CCA) for resolving the next interaction optimally. We propose the Probabilistic Gap Planner (PGP) as a conflict avoidance planner. PGP modifies an established probabilistic collision risk model to include a general assumption of cooperativity. PGP biases the short-term CCA planner to head towards gaps in the crowd. In extensive simulations with crowds of varying density, we show that using PGP in addition to state-of-the-art CCA planners improves the agents' performance: On average, agents keep more space to others, create less tension, and cause fewer collisions. This typically comes at the expense of slightly longer paths. PGP runs in real-time on WaPOCHI mobile robot by Honda R&D.",
      "authors": [
        "Malte Probst",
        "Raphael Wenzel",
        "Tim Puphal",
        "Monica Dasi",
        "Nico A. Steinhardt",
        "Sango Matsuzaki and Misa Komuro"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20320",
        "HTML": "https://arxiv.org/html/2506.20320",
        "PDF": "https://arxiv.org/pdf/2506.20320"
      },
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 11:01:51 GMT",
          "size": "4709kb",
          "version": "v1"
        },
        {
          "date": "Thu, 26 Jun 2025 06:26:12 GMT",
          "size": "4709kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Finding the Easy Way Through -- the Probabilistic Gap Planner for Social Robot Navigation",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on social robot navigation and trajectory planning, which does not involve any aspects of LLM training data processing, such as data collection or cleaning."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.20401",
      "abstract": "With the rising popularity of electric vehicles (EVs), modern service systems, such as ride-hailing delivery services, are increasingly integrating EVs into their operations. Unlike conventional vehicles, EVs often have a shorter driving range, necessitating careful consideration of charging when fulfilling requests. With recent advances in Vehicle-to-Grid (V2G) technology - allowing EVs to also discharge energy back to the grid - new opportunities and complexities emerge. We introduce the Electric Vehicle Orienteering Problem with V2G (EVOP-V2G): a profit-maximization problem where EV drivers must select customer requests or orders while managing when and where to charge or discharge. This involves navigating dynamic electricity prices, charging station selection, and route constraints. We formulate the problem as a Mixed Integer Programming (MIP) model and propose two near-optimal metaheuristic algorithms: one evolutionary (EA) and the other based on large neighborhood search (LNS). Experiments on real-world data show our methods can double driver profits compared to baselines, while maintaining near-optimal performance on small instances and excellent scalability on larger ones. Our work highlights a promising path toward smarter, more profitable EV-based mobility systems that actively support the energy grid.",
      "authors": [
        "Jinchun Du",
        "Bojie Shen",
        "Muhammad Aamir Cheema",
        "Adel N. Toosi"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20401",
        "HTML": "https://arxiv.org/html/2506.20401",
        "PDF": "https://arxiv.org/pdf/2506.20401"
      },
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 13:15:52 GMT",
          "size": "629kb",
          "version": "v1"
        },
        {
          "date": "Thu, 26 Jun 2025 06:02:57 GMT",
          "size": "629kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Smart Ride and Delivery Services with Electric Vehicles: Leveraging Bidirectional Charging for Profit Optimisation",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper addresses profit optimization for electric vehicle services and does not discuss any elements of LLM training data processing."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.20433",
      "abstract": "The potential of Generative AI (GenAI) for generating feedback in computing education has been the subject of numerous studies. However, there is still limited research on how computing students engage with this feedback and to what extent it supports their problem-solving. For this reason, we built a custom web application providing students with Python programming tasks, a code editor, GenAI feedback, and compiler feedback. Via a think-aloud protocol including eye-tracking and a post-interview with 11 undergraduate students, we investigate (1) how much attention the generated feedback received from learners and (2) to what extent the generated feedback is helpful (or not). In addition, students' attention to GenAI feedback is compared with that towards the compiler feedback. We further investigate differences between students with and without prior programming experience. The findings indicate that GenAI feedback generally receives a lot of visual attention, with inexperienced students spending twice as much fixation time. More experienced students requested GenAI less frequently, and could utilize it better to solve the given problem. It was more challenging for inexperienced students to do so, as they could not always comprehend the GenAI feedback. They often relied solely on the GenAI feedback, while compiler feedback was not read. Understanding students' attention and perception toward GenAI feedback is crucial for developing educational tools that support student learning.",
      "authors": [
        "Sven Jacobs",
        "Maurice Kempf",
        "Natalie Kiesler"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20433",
        "HTML": "https://arxiv.org/html/2506.20433",
        "PDF": "https://arxiv.org/pdf/2506.20433"
      },
      "subjects": [
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 13:43:23 GMT",
          "size": "540kb",
          "version": "v1"
        },
        {
          "date": "Thu, 26 Jun 2025 12:36:56 GMT",
          "size": "540kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "That's Not the Feedback I Need! -- Student Engagement with GenAI Feedback in the Tutor Kai",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This study explores the usage of GenAI feedback in education and does not address the processing of training data for LLMs."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2110.11856",
      "abstract": "The $\\beta$-model is a powerful tool for modeling large and sparse networks driven by degree heterogeneity, where many network models become infeasible due to computational challenge and network sparsity. However, existing estimation algorithms for $\\beta$-model do not scale up. Also, theoretical understandings remain limited to dense networks. This paper brings several significant improvements over existing results to address the urgent needs of practice. We propose a new $\\ell_2$-penalized MLE algorithm that can comfortably handle sparse networks of millions of nodes with much-improved memory parsimony. We establish the first rate-optimal error bounds and high-dimensional asymptotic normality results for $\\beta$-models, under much weaker network sparsity assumptions than best existing results.\n  Application of our method to large COVID-19 network data sets discovered meaningful results.",
      "authors": [
        "Meijia Shao",
        "Yu Zhang",
        "Qiuping Wang",
        "Yuan Zhang",
        "Jing Luo",
        "Ting Yan"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2110.11856",
        "HTML": "https://arxiv.org/html/2110.11856",
        "PDF": "https://arxiv.org/pdf/2110.11856"
      },
      "subjects": [
        "Methodology (stat.ME)",
        "Social and Information Networks (cs.SI)",
        "Statistics Theory (math.ST)",
        "Statistics Theory (stat.TH)"
      ],
      "submission_historys": [
        {
          "date": "Fri, 22 Oct 2021 15:44:22 GMT",
          "size": "2728kb",
          "version": "v1"
        },
        {
          "date": "Mon, 25 Oct 2021 03:46:55 GMT",
          "size": "2735kb",
          "version": "v2"
        },
        {
          "date": "Sat, 04 Mar 2023 01:21:47 GMT",
          "size": "3208kb",
          "version": "v3"
        },
        {
          "date": "Mon, 30 Sep 2024 01:54:59 GMT",
          "size": "4283kb",
          "version": "v4"
        },
        {
          "date": "Thu, 26 Jun 2025 14:02:19 GMT",
          "size": "3922kb",
          "version": "v5"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "L-2 Regularized maximum likelihood for $\\beta$-model in large and sparse networks",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on the $\\beta$-model for sparse networks and proposed estimation methods, without any mention of LLM training data processing or related contributions."
      },
      "repo_urls": [
        "https://github.com/MjiaShao/L2-beta-model"
      ],
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2306.11017",
      "abstract": "In this research, we investigate the high-dimensional linear contextual bandit problem where the number of features $p$ is greater than the budget $T$, or it may even be infinite. Differing from the majority of previous works in this field, we do not impose sparsity on the regression coefficients. Instead, we rely on recent findings on overparameterized models, which enables us to analyze the performance of the minimum-norm interpolating estimator when data distributions have small effective ranks. We propose an explore-then-commit (EtC) algorithm to address this problem and examine its performance. Through our analysis, we derive the optimal rate of the ETC algorithm in terms of $T$ and show that this rate can be achieved by balancing exploration and exploitation. Moreover, we introduce an adaptive explore-then-commit (AEtC) algorithm that adaptively finds the optimal balance. We assess the performance of the proposed algorithms through a series of simulations.",
      "authors": [
        "Junpei Komiyama and Masaaki Imaizumi"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2306.11017",
        "HTML": "https://arxiv.org/html/2306.11017",
        "PDF": "https://arxiv.org/pdf/2306.11017"
      },
      "subjects": [
        "Machine Learning (stat.ML)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Mon, 19 Jun 2023 15:29:32 GMT",
          "size": "984kb",
          "version": "v1"
        },
        {
          "date": "Wed, 25 Jun 2025 22:16:22 GMT",
          "size": "501kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "High-dimensional Contextual Bandit Problem without Sparsity",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper addresses the contextual bandit problem and introduces algorithms for it, which is unrelated to LLM training data processing."
      },
      "conference": "high-dimensional-contextual-bandit-problem",
      "conference_url_abs": "https://openreview.net/forum?id=LZ4WgwmrUJ",
      "tasks": [],
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2307.03334",
      "abstract": "Hybrid variational quantum algorithms (VQAs) are promising for solving practical problems such as combinatorial optimization, quantum chemistry simulation, quantum machine learning, and quantum error correction on noisy quantum computers. However, with typical random ansatz or quantum alternating operator ansatz, derived variational quantum algorithms become a black box that cannot be trusted for model interpretation, not to mention deploying as applications in informing critical decisions: the results of these variational parameters are just rotational angles for the quantum gates and have nothing to do with interpretable values that a model can provide directly. In this paper, we construct the first interpretable quantum regression algorithm, in which the quantum state exactly encodes the classical data table and the variational parameters correspond directly to the regression coefficients, which are real numbers by construction, providing a high degree of model interpretability and minimal cost to optimize due to the right expressiveness. We also take advantage of the encoded data structure to reduce the time complexity of computing the regression map. To shorten the circuit depth for nonlinear regression, our algorithm can be extended by building nonlinear features by classical preprocessing as the independent encoded column vectors. Even though the realization of compressed encoding in superconducting qubits has been achieved by the less noisy compressed encoding recently by the authors, we envision potential quantum utilities with multi-qubit gates implemented in neutral cold atoms and ions.",
      "authors": [
        "C.-C. Joseph Wang",
        "F. Perkkola",
        "I. Salmenper\\\"a",
        "A. Meijer-van de Griend",
        "J. K. Nurminen",
        "R. S. Bennink"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2307.03334",
        "HTML": "https://arxiv.org/html/2307.03334",
        "PDF": "https://arxiv.org/pdf/2307.03334"
      },
      "subjects": [
        "Quantum Physics (quant-ph)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Fri, 07 Jul 2023 00:30:16 GMT",
          "size": "128kb",
          "version": "v1"
        },
        {
          "date": "Mon, 16 Oct 2023 01:59:26 GMT",
          "size": "118kb",
          "version": "v2"
        },
        {
          "date": "Thu, 25 Jan 2024 01:01:33 GMT",
          "size": "118kb",
          "version": "v3"
        },
        {
          "date": "Wed, 25 Jun 2025 13:14:47 GMT",
          "size": "136kb",
          "version": "v4"
        },
        {
          "date": "Thu, 26 Jun 2025 03:12:31 GMT",
          "size": "136kb",
          "version": "v5"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Explainable quantum regression algorithm with encoded data structure",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "Discusses quantum regression algorithms and model interpretability, but does not involve LLM training data processing."
      },
      "tasks": [
        "Combinatorial Optimization",
        "feature selection",
        "Quantum Machine Learning",
        "regression"
      ],
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2403.11872",
      "abstract": "Liquid Argon Time Projection Chamber (LArTPC) detector technology offers a wealth of high-resolution information on particle interactions, and leveraging that information to its full potential requires sophisticated automated reconstruction techniques. This article describes NuGraph2, a Graph Neural Network (GNN) for low-level reconstruction of simulated neutrino interactions in a LArTPC detector. Simulated neutrino interactions in the MicroBooNE detector geometry are described as heterogeneous graphs, with energy depositions on each detector plane forming nodes on planar subgraphs. The network utilizes a multi-head attention message-passing mechanism to perform background filtering and semantic labelling on these graph nodes, identifying those associated with the primary physics interaction with 98.0\\% efficiency and labelling them according to particle type with 94.9\\% efficiency. The network operates directly on detector observables across multiple 2D representations, but utilizes a 3D-context-aware mechanism to encourage consistency between these representations. Model inference takes 0.12~s/event on a CPU, and 0.005s/event batched on a GPU. This architecture is designed to be a general-purpose solution for particle reconstruction in neutrino physics, with the potential for deployment across a broad range of detector technologies, and offers a core convolution engine that can be leveraged for a variety of tasks beyond the two described in this article.",
      "authors": [
        "V Hewes and Adam Aurisano and Giuseppe Cerati and Jim Kowalkowski and Claire Lee and Wei-keng Liao and Daniel Grzenda and Kaushal Gumpula and Xiaohe Zhang"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2403.11872",
        "HTML": "https://arxiv.org/html/2403.11872",
        "PDF": "https://arxiv.org/pdf/2403.11872"
      },
      "subjects": [
        "Data Analysis, Statistics and Probability (physics.data-an)",
        "Machine Learning (cs.LG)",
        "High Energy Physics - Experiment (hep-ex)"
      ],
      "submission_historys": [
        {
          "date": "Mon, 18 Mar 2024 15:26:05 GMT",
          "size": "2133kb",
          "version": "v1"
        },
        {
          "date": "Thu, 26 Jun 2025 16:15:31 GMT",
          "size": "1814kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Graph Neural Network for Neutrino Physics Event Reconstruction",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper presents a GNN architecture for neutrino physics event reconstruction. It primarily addresses graph neural network design for physics data, without addressing LLM training data processes."
      },
      "tasks": [
        "Graph Neural Network"
      ],
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2406.01299",
      "abstract": "In this paper, we investigate image reconstruction for dynamic Computed Tomography. The motion of the target with respect to the measurement acquisition rate leads to highly resolved in time but highly undersampled in space measurements. Such problems pose a major challenge: not accounting for the dynamics of the process leads to a poor reconstruction with non-realistic motion. Variational approaches that penalize time evolution have been proposed to relate subsequent frames and improve image quality based on classical grid-based discretizations. Neural fields have emerged as a novel way to parameterize the quantity of interest using a neural network with a low-dimensional input, benefiting from being lightweight, continuous, and biased towards smooth representations. The latter property has been exploited when solving dynamic inverse problems with neural fields by minimizing a data-fidelity term only. We investigate and show the benefits of introducing explicit motion regularizers for dynamic inverse problems based on partial differential equations, namely, the optical flow equation, for the optimization of neural fields. We compare it against its unregularized counterpart and show the improvements in the reconstruction. We also compare neural fields against a grid-based solver and show that the former outperforms the latter in terms of PSNR in this task.",
      "authors": [
        "Pablo Arratia",
        "Matthias Ehrhardt",
        "Lisa Kreusser"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2406.01299",
        "HTML": "https://arxiv.org/html/2406.01299",
        "PDF": "https://arxiv.org/pdf/2406.01299"
      },
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Mon, 03 Jun 2024 13:07:29 GMT",
          "size": "181kb",
          "version": "v1"
        },
        {
          "date": "Fri, 06 Dec 2024 12:53:57 GMT",
          "size": "2598kb",
          "version": "v2"
        },
        {
          "date": "Thu, 26 Jun 2025 14:18:49 GMT",
          "size": "2568kb",
          "version": "v3"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Enhancing Dynamic CT Image Reconstruction with Neural Fields and Optical Flow",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper is centered around image reconstruction techniques in computed tomography and does not relate to LLM training data processing or data engineering tasks."
      },
      "tasks": [
        "Image Reconstruction",
        "Inductive Bias",
        "Optical Flow Estimation"
      ],
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2409.17938",
      "abstract": "We consider the subcritical nonlinear Schr\\\"odinger (NLS) in dimension one posed on the unbounded real line. Several previous works have considered the deep neural network approximation of NLS solutions from the numerical and theoretical point of view in the case of bounded domains. In this paper, we introduce a new PINNs method to treat the case of unbounded domains and show rigorous bounds on the associated approximation error in terms of the energy and Strichartz norms, provided a reasonable integration scheme is available. Applications to traveling waves, breathers and solitons, as well as numerical experiments confirming the validity of the approximation are also presented as well.",
      "authors": [
        "Miguel \\'A. Alejo",
        "Lucrezia Cossetti",
        "Luca Fanelli",
        "Claudio Mu\\~noz and Nicol\\'as Valenzuela"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2409.17938",
        "HTML": "https://arxiv.org/html/2409.17938",
        "PDF": "https://arxiv.org/pdf/2409.17938"
      },
      "subjects": [
        "Analysis of PDEs (math.AP)",
        "Numerical Analysis (cs.NA)",
        "Numerical Analysis (math.NA)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Sep 2024 15:12:49 GMT",
          "size": "2136kb",
          "version": "v1"
        },
        {
          "date": "Wed, 23 Oct 2024 15:17:27 GMT",
          "size": "2138kb",
          "version": "v2"
        },
        {
          "date": "Thu, 26 Jun 2025 12:53:58 GMT",
          "size": "3275kb",
          "version": "v3"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Error bounds for Physics Informed Neural Networks in Nonlinear Schr\\\"odinger equations placed on unbounded domains",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The research is centered on error bounds for Physics Informed Neural Networks applied to nonlinear Schr\u00f6dinger equations. It does not pertain to LLM training data processing."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2410.19644",
      "abstract": "We study stochastic second-order methods for solving general non-convex optimization problems. We propose using a special version of momentum to stabilize the stochastic gradient and Hessian estimates in Newton's method. We show that momentum provably improves the variance of stochastic estimates and allows the method to converge for any noise level. Using the cubic regularization technique, we prove a global convergence rate for our method on general non-convex problems to a second-order stationary point, even when using only a single stochastic data sample per iteration. This starkly contrasts with all existing stochastic second-order methods for non-convex problems, which typically require large batches. Therefore, we are the first to demonstrate global convergence for batches of arbitrary size in the non-convex case for the Stochastic Cubic Newton. Additionally, we show improved speed on convex stochastic problems for our regularized Newton methods with momentum.",
      "authors": [
        "El Mahdi Chayti and Nikita Doikov and Martin Jaggi"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.19644",
        "HTML": "https://arxiv.org/html/2410.19644",
        "PDF": "https://arxiv.org/pdf/2410.19644"
      },
      "subjects": [
        "Optimization and Control (math.OC)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Fri, 25 Oct 2024 15:49:16 GMT",
          "size": "211kb",
          "version": "v1"
        },
        {
          "date": "Thu, 26 Jun 2025 16:07:20 GMT",
          "size": "170kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Improving Stochastic Cubic Newton with Momentum",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper presents an optimization method for non-convex problems using stochastic cubic Newton methods with momentum enhancements. It does not discuss training data processing for LLMs."
      },
      "tasks": [
        "Second-order methods"
      ],
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2411.01252",
      "abstract": "Traditional cryptographic techniques, including token obfuscation, are increasingly vulnerable to quantum attacks due to advancements in quantum computing. Quantum algorithms such as Shor's and Grover's pose significant threats to classical security methods, necessitating quantum-resistant alternatives. This study proposes a quantum-based approach to token obfuscation that leverages superposition and multi-basis verification to enhance security against quantum adversaries. Tokens are encoded in quantum superposition states, ensuring probabilistic concealment until measured. A multi-basis verification protocol strengthens authentication by requiring validation across multiple quantum measurement bases. Additionally, a quantum decay protocol and token refresh mechanism dynamically manage the token lifecycle to prevent prolonged exposure and replay attacks. The model was tested through quantum simulations, evaluating entropy quality, adversarial robustness, and token verification reliability. Experimental validation demonstrates an entropy quality score of 0.9996, a 0% attack success rate across five adversarial models, and a 67% false positive rate, indicating strict security constraints. These findings confirm the effectiveness of quantum-based token obfuscation in preventing unauthorized reconstruction. The proposed approach provides a foundation for post-quantum cryptographic security by integrating entropy-driven state transformations, dynamic token evolution, and multi-basis verification. Future work will focus on optimizing computational efficiency and testing real-world implementations on quantum hardware.",
      "authors": [
        "S.M. Yousuf Iqbal Tomal",
        "Abdullah Al Shafin"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.01252",
        "HTML": "https://arxiv.org/html/2411.01252",
        "PDF": "https://arxiv.org/pdf/2411.01252"
      },
      "subjects": [
        "Quantum Physics (quant-ph)",
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "Sat, 02 Nov 2024 14:05:20 GMT",
          "size": "80kb",
          "version": "v1"
        },
        {
          "date": "Wed, 29 Jan 2025 07:05:50 GMT",
          "size": "226kb",
          "version": "v2"
        },
        {
          "date": "Thu, 26 Jun 2025 17:37:18 GMT",
          "size": "227kb",
          "version": "v3"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Quantum Token Obfuscation via Superposition: A Post-Quantum Security Framework Using Multi-Basis Verification and Entropy-Driven Evolution",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper is focused on quantum-based token obfuscation and quantum security frameworks. It does not address any aspect of LLM training data collection, construction, or processing."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2411.05933",
      "abstract": "This work deals with the output consensus problem for multiagent systems over balanced digraphs by passivity analysis. As the standard diffusive coupling structure only models the undirected interconnection, we propose a general approach capable of processing directed coupling and performing passivity analysis. To mitigate the complexity arising from the nonlinearity and directed interconnections, we reformulate the output consensus problem as a convergence analysis on a submanifold. We provide passivity analysis and establish a sufficient condition based on passivity for achieving output agreement in multi-agent systems over balanced digraphs. The results are supported by a numerical example.",
      "authors": [
        "Feng-Yu Yue and Daniel Zelazo"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.05933",
        "HTML": "https://arxiv.org/html/2411.05933",
        "PDF": "https://arxiv.org/pdf/2411.05933"
      },
      "subjects": [
        "Optimization and Control (math.OC)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "Fri, 08 Nov 2024 19:42:29 GMT",
          "size": "359kb",
          "version": "v1"
        },
        {
          "date": "Tue, 22 Apr 2025 19:08:41 GMT",
          "size": "224kb",
          "version": "v2"
        },
        {
          "date": "Wed, 25 Jun 2025 18:37:49 GMT",
          "size": "65kb",
          "version": "v3"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "A Passivity Analysis for Nonlinear Consensus on Balanced Digraphs",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper is focused on multi-agent system consensus on balanced digraphs through passivity analysis, which does not involve LLM training data processing or engineering."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2412.03083",
      "abstract": "In this work, a scalable quantum neural network is introduced as a means to approximate any unitary evolution through the Standard Recursive Block Basis (SRBB) and, subsequently, redesigned with a number of CNOTs asymptotically reduced by an exponential contribution. This algebraic approach to the problem of unitary synthesis exploits Lie algebras and their topological features to obtain scalable parameterizations of unitary operators. First, the original SRBB-based scalability scheme, already known in the literature only from a theoretical point of view, is reformulated for efficient algorithm implementation and complexity management. Remarkably, 2-qubit operators emerge as a special case outside the original scaling scheme. Furthermore, an algorithm is proposed to reduce the number of CNOTs, thus deriving a new implementable scaling scheme that requires only one layer of approximation. The scalable CNOT-reduced quantum neural network is implemented and its performance is assessed with a variety of different unitary matrices, both sparse and dense, up to 6 qubits via the PennyLane library. The effectiveness of the approximation is measured with different metrics in relation to two optimizers: a gradient-based method and the Nelder-Mead method. The approximate CNOT-reduced SRBB-based synthesis algorithm is also tested on real hardware and compared with other valid approximation and decomposition methods available in the literature.",
      "authors": [
        "Giacomo Belli",
        "Marco Mordacci and Michele Amoretti"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.03083",
        "HTML": "https://arxiv.org/html/2412.03083",
        "PDF": "https://arxiv.org/pdf/2412.03083"
      },
      "subjects": [
        "Quantum Physics (quant-ph)",
        "Emerging Technologies (cs.ET)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 04 Dec 2024 07:21:23 GMT",
          "size": "64kb",
          "version": "v1"
        },
        {
          "date": "Thu, 26 Jun 2025 14:43:45 GMT",
          "size": "61kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "A Scalable Quantum Neural Network for Approximate SRBB-Based Unitary Synthesis",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This research focuses on quantum neural networks for unitary synthesis, with no relevance to LLM training data processing or data engineering."
      },
      "tasks": [],
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2501.13472",
      "abstract": "Radio map estimation (RME), also known as spectrum cartography, aims to reconstruct the strength of radio interference across different domains (e.g., space and frequency) from sparsely sampled measurements. To tackle this typical inverse problem, state-of-the-art RME methods rely on handcrafted or data-driven structural information of radio maps. However, the former often struggles to model complex radio frequency (RF) environments and the latter requires excessive training -- making it hard to quickly adapt to in situ sensing tasks. This work presents a spatio-spectral RME approach based on plug-and-play (PnP) denoising, a technique from computational imaging. The idea is to leverage the observation that the denoising operations of signals like natural images and radio maps are similar -- despite the nontrivial differences of the signals themselves. Hence, sophisticated denoisers designed for or learned from natural images can be directly employed to assist RME, avoiding using radio map data for training. Unlike conventional PnP methods that operate directly in the data domain, the proposed method exploits the underlying physical structure of radio maps and proposes an ADMM algorithm that denoises in a latent domain. This design significantly improves computational efficiency and enhances noise robustness. Theoretical aspects, e.g., recoverability of the complete radio map and convergence of the ADMM algorithm are analyzed. Synthetic and real data experiments are conducted to demonstrate the effectiveness of our approach.",
      "authors": [
        "Le Xu",
        "Lei Cheng",
        "Junting Chen",
        "Wenqiang Pu",
        "Xiao Fu"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.13472",
        "HTML": "https://arxiv.org/html/2501.13472",
        "PDF": "https://arxiv.org/pdf/2501.13472"
      },
      "subjects": [
        "Signal Processing (eess.SP)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 23 Jan 2025 08:42:24 GMT",
          "size": "6366kb",
          "version": "v1"
        },
        {
          "date": "Thu, 26 Jun 2025 13:31:04 GMT",
          "size": "4039kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Radio Map Estimation via Latent Domain Plug-and-Play Denoising",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper addresses radio map estimation using a denoising approach and does not deal with LLM training data. It focuses on signal processing within the context of radio frequency environments, without contributions to LLM data engineering or processing."
      },
      "tasks": [
        "Computational Efficiency",
        "Denoising",
        "Spectrum Cartography"
      ],
      "repo_urls": [
        "https://github.com/xumaomao94/LaPnP"
      ],
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2501.15131",
      "abstract": "The computation of the dominant eigenvector of symmetric positive semidefinite matrices is a cornerstone operation in numerous optimization-driven applications. Traditional methods, typically based on the \\textit{Quotient} formulation, often suffer from challenges related to computational efficiency and reliance on prior spectral knowledge. In this work, we leverage the alternative \\textit{Difference} formulation to reinterpret the classical power method as a first-order optimization algorithm. This perspective allows for a novel convergence analysis and facilitates the development of accelerated variants with larger step-sizes, achieving faster convergence without additional computational cost. Building on this insight, we introduce a generalized family of Difference-based methods, with the power method as a special case. Within this family, we propose Split-Merge, an algorithm that attains accelerated convergence without requiring spectral knowledge and operates solely via matrix-vector products. Extensive experiments on both synthetic and real-world datasets demonstrate that Split-Merge consistently outperforms state-of-the-art methods in both efficiency and scalability. In particular, it achieves more than a $\\boldsymbol{10\\times}$ speedup over the classical power method, underscoring its practical effectiveness for large-scale problems.",
      "authors": [
        "Xiaozhi Liu",
        "Yong Xia"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.15131",
        "HTML": "https://arxiv.org/html/2501.15131",
        "PDF": "https://arxiv.org/pdf/2501.15131"
      },
      "subjects": [
        "Optimization and Control (math.OC)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Sat, 25 Jan 2025 08:37:17 GMT",
          "size": "1037kb",
          "version": "v1"
        },
        {
          "date": "Thu, 26 Jun 2025 03:45:17 GMT",
          "size": "1277kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Split-Merge: A Difference-based Approach for Dominant Eigenvalue Problem",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This research introduces an algorithm for computing dominant eigenvectors, focusing on numerical methods and optimization. It does not relate to the data engineering or processing stages for LLM training."
      },
      "tasks": [
        "Computational Efficiency"
      ],
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2502.02472",
      "abstract": "The Latent Stochastic Differential Equation (SDE) is a powerful tool for time series and sequence modeling. However, training Latent SDEs typically relies on adjoint sensitivity methods, which depend on simulation and backpropagation through approximate SDE solutions, which limit scalability. In this work, we propose SDE Matching, a new simulation-free method for training Latent SDEs. Inspired by modern Score- and Flow Matching algorithms for learning generative dynamics, we extend these ideas to the domain of stochastic dynamics for time series and sequence modeling, eliminating the need for costly numerical simulations. Our results demonstrate that SDE Matching achieves performance comparable to adjoint sensitivity methods while drastically reducing computational complexity.",
      "authors": [
        "Grigory Bartosh",
        "Dmitry Vetrov",
        "Christian A. Naesseth"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.02472",
        "HTML": "https://arxiv.org/html/2502.02472",
        "PDF": "https://arxiv.org/pdf/2502.02472"
      },
      "subjects": [
        "Machine Learning (stat.ML)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 04 Feb 2025 16:47:49 GMT",
          "size": "1950kb",
          "version": "v1"
        },
        {
          "date": "Fri, 06 Jun 2025 12:21:10 GMT",
          "size": "2857kb",
          "version": "v2"
        },
        {
          "date": "Thu, 26 Jun 2025 07:38:35 GMT",
          "size": "2857kb",
          "version": "v3"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "SDE Matching: Scalable and Simulation-Free Training of Latent Stochastic Differential Equations",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This work presents a method for training Latent SDEs focused on sequence modeling and reducing computational complexity. There is no mention of LLM training data processing tasks or enhancements."
      },
      "tasks": [
        "Time Series"
      ],
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2502.15577",
      "abstract": "The widespread adoption of artificial intelligence (AI) in next-generation communication systems is challenged by the heterogeneity of traffic and network conditions, which call for the use of highly contextual, site-specific, data. A promising solution is to rely not only on real-world data, but also on synthetic pseudo-data generated by a network digital twin (NDT). However, the effectiveness of this approach hinges on the accuracy of the NDT, which can vary widely across different contexts. To address this problem, this paper introduces context-aware doubly-robust (CDR) learning, a novel semi-supervised scheme that adapts its reliance on the pseudo-data to the different levels of fidelity of the NDT across contexts. CDR is evaluated on the task of downlink beamforming where it outperforms previous state-of-the-art approaches, providing a 24% loss decrease when compared to doubly-robust (DR) semi-supervised learning in regimes with low labeled data availability.",
      "authors": [
        "Clement Ruah",
        "Houssem Sifaou",
        "Osvaldo Simeone",
        "and Bashir Al-Hashimi"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.15577",
        "HTML": "https://arxiv.org/html/2502.15577",
        "PDF": "https://arxiv.org/pdf/2502.15577"
      },
      "subjects": [
        "Signal Processing (eess.SP)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Fri, 21 Feb 2025 16:38:45 GMT",
          "size": "3888kb",
          "version": "v1"
        },
        {
          "date": "Thu, 26 Jun 2025 14:22:27 GMT",
          "size": "2911kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Context-Aware Doubly-Robust Semi-Supervised Learning",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper presents a semi-supervised learning framework evaluated in the context of communication systems. It focuses on network data and synthetic data from network digital twins, with no direct connection to LLM training data methods."
      },
      "tasks": [],
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2503.00959",
      "abstract": "The Riemann zeta function, and more generally the L-functions of Dirichlet characters, are among the central objects of study in number theory. We report on a project to formalize the theory of these objects in Lean's \"Mathlib\" library, including a proof of Dirichlet's theorem on primes in arithmetic progressions and a formal statement of the Riemann hypothesis",
      "authors": [
        "David Loeffler and Michael Stoll"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.00959",
        "HTML": "https://arxiv.org/html/2503.00959",
        "PDF": "https://arxiv.org/pdf/2503.00959"
      },
      "subjects": [
        "Number Theory (math.NT)",
        "Formal Languages and Automata Theory (cs.FL)",
        "Logic in Computer Science (cs.LO)"
      ],
      "submission_historys": [
        {
          "date": "Sun, 02 Mar 2025 16:53:20 GMT",
          "size": "11kb",
          "version": "v1"
        },
        {
          "date": "Wed, 05 Mar 2025 17:05:01 GMT",
          "size": "12kb",
          "version": "v2"
        },
        {
          "date": "Thu, 12 Jun 2025 15:16:29 GMT",
          "size": "12kb",
          "version": "v3"
        },
        {
          "date": "Wed, 25 Jun 2025 20:10:42 GMT",
          "size": "435kb",
          "version": "v4"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Formalizing zeta and L-functions in Lean",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This work formalizes mathematical constructs (zeta and L-functions) in Lean and does not involve the processing of training data for LLMs."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2503.02814",
      "abstract": "Quantum invariants in low dimensional topology offer a wide variety of valuable invariants of knots and 3-manifolds, presented by explicit formulas that are readily computable. Their computational complexity has been actively studied and is tightly connected to topological quantum computing. In this article, we prove that for any 3-manifold quantum invariant in the Reshetikhin-Turaev model, there is a deterministic polynomial time algorithm that, given as input an arbitrary closed 3-manifold $M$, outputs a closed 3-manifold $M'$ with same quantum invariant, such that $M'$ is hyperbolic, contains no low genus embedded incompressible surface, and is presented by a strongly irreducible Heegaard diagram. Our construction relies on properties of Heegaard splittings and the Hempel distance. At the level of computational complexity, this proves that the hardness of computing a given quantum invariant of 3-manifolds is preserved even when severely restricting the topology and the combinatorics of the input. This positively answers a question raised by Samperton.",
      "authors": [
        "Henrique Ennes and Cl\\'ement Maria"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.02814",
        "HTML": "https://arxiv.org/html/2503.02814",
        "PDF": "https://arxiv.org/pdf/2503.02814"
      },
      "subjects": [
        "Geometric Topology (math.GT)",
        "Computational Geometry (cs.CG)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 04 Mar 2025 17:39:26 GMT",
          "size": "226kb",
          "version": "v1"
        },
        {
          "date": "Wed, 26 Mar 2025 11:27:02 GMT",
          "size": "273kb",
          "version": "v2"
        },
        {
          "date": "Thu, 26 Jun 2025 14:04:58 GMT",
          "size": "273kb",
          "version": "v3"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Hardness of computation of quantum invariants on 3-manifolds with restricted topology",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper focuses on the computational complexity of quantum invariants in low dimensional topology, which is unrelated to the processing of training data for LLMs."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2503.04712",
      "abstract": "We study the optimization of non-convex functions that are not necessarily smooth (gradient and/or Hessian are Lipschitz) using first order methods. Smoothness is a restrictive assumption in machine learning in both theory and practice, motivating significant recent work on finding first order stationary points of functions satisfying generalizations of smoothness with first order methods. We develop a novel framework that lets us systematically study the convergence of a large class of first-order optimization algorithms (which we call decrease procedures) under generalizations of smoothness. We instantiate our framework to analyze the convergence of first order optimization algorithms to first and \\textit{second} order stationary points under generalizations of smoothness. As a consequence, we establish the first convergence guarantees for first order methods to second order stationary points under generalizations of smoothness. We demonstrate that several canonical examples fall under our framework, and highlight practical implications.",
      "authors": [
        "Daniel Yiming Cao",
        "August Y. Chen",
        "Karthik Sridharan",
        "Benjamin Tang"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.04712",
        "HTML": "https://arxiv.org/html/2503.04712",
        "PDF": "https://arxiv.org/pdf/2503.04712"
      },
      "subjects": [
        "Optimization and Control (math.OC)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 06 Mar 2025 18:57:34 GMT",
          "size": "100kb",
          "version": "v1"
        },
        {
          "date": "Thu, 26 Jun 2025 17:38:58 GMT",
          "size": "610kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Efficiently Escaping Saddle Points under Generalized Smoothness via Self-Bounding Regularity",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper deals with the optimization of non-convex functions under generalized smoothness, which is unrelated to LLM training data processing."
      },
      "tasks": [],
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2504.01431",
      "abstract": "Discrete latent factor models (DLFMs) are widely used in various domains such as machine learning, economics, neuroscience, psychology, etc. Currently, fitting a DLFM to some dataset relies on a customized solver for individual models, which requires lots of effort to implement and is limited to the targeted specific instance of DLFMs. In this paper, we propose a generic framework based on CVXPY, which allows users to specify and solve the fitting problem of a wide range of DLFMs, including both regression and classification models, within a very short script. Our framework is flexible and inherently supports the integration of regularization terms and constraints on the DLFM parameters and latent factors, such that the users can easily prototype the DLFM structure according to their dataset and application scenario. We introduce our open-source Python implementation and illustrate the framework in several examples.",
      "authors": [
        "Hao Zhu",
        "Shengchao Yan",
        "Jasper Hoffmann",
        "Joschka Boedecker"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.01431",
        "HTML": "https://arxiv.org/html/2504.01431",
        "PDF": "https://arxiv.org/pdf/2504.01431"
      },
      "subjects": [
        "Optimization and Control (math.OC)",
        "Computational Engineering, Finance, and Science (cs.CE)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 02 Apr 2025 07:33:54 GMT",
          "size": "664kb",
          "version": "v1"
        },
        {
          "date": "Thu, 26 Jun 2025 10:53:38 GMT",
          "size": "664kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Multi-convex Programming for Discrete Latent Factor Models Prototyping",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on discrete latent factor models and proposes a framework for specifying and solving these models using CVXPY, without addressing LLM training data processing or engineering."
      },
      "tasks": [],
      "repo_urls": [
        "https://github.com/nrgrp/dlfm"
      ],
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2505.04082",
      "abstract": "The increasing demand for high-quality digital emulations of analog audio hardware, such as vintage tube guitar amplifiers, led to numerous works on neural network-based black-box modeling, with deep learning architectures like WaveNet showing promising results. However, a key limitation in all of these models was the aliasing artifacts stemming from nonlinear activation functions in neural networks. In this paper, we investigated novel and modified activation functions aimed at mitigating aliasing within neural amplifier models. Supporting this, we introduced a novel metric, the Aliasing-to-Signal Ratio (ASR), which quantitatively assesses the level of aliasing with high accuracy. Measuring also the conventional Error-to-Signal Ratio (ESR), we conducted studies on a range of preexisting and modern activation functions with varying stretch factors. Our findings confirmed that activation functions with smoother curves tend to achieve lower ASR values, indicating a noticeable reduction in aliasing. Notably, this improvement in aliasing reduction was achievable without a substantial increase in ESR, demonstrating the potential for high modeling accuracy with reduced aliasing in neural amp models.",
      "authors": [
        "Ryota Sato",
        "Julius O. Smith III"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.04082",
        "HTML": "https://arxiv.org/html/2505.04082",
        "PDF": "https://arxiv.org/pdf/2505.04082"
      },
      "subjects": [
        "Audio and Speech Processing (eess.AS)",
        "Sound (cs.SD)",
        "Signal Processing (eess.SP)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 07 May 2025 02:49:45 GMT",
          "size": "2189kb",
          "version": "v1"
        },
        {
          "date": "Thu, 26 Jun 2025 02:06:41 GMT",
          "size": "2190kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Aliasing Reduction in Neural Amp Modeling by Smoothing Activations",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The focus is on audio modeling and the reduction of aliasing in neural networks, which is not related to LLM training data processing."
      },
      "tasks": [],
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2505.06322",
      "abstract": "We characterize exact, and approximate, optimality of games that players can interact with using quantum strategies. In comparison to a previous work of the author, arXiv: 2311.12887, which applied a 2016 framework due to Ostrev for constructing error bounds beyond CHSH and XOR games, in addition to the existence of well-posed semidefinite programs for determining primal feasible solutions, along with quantum-classical duality gaps, it continues to remain of interest to further develop the construction of error bounds, and related objects, to game-theoretic settings with several participants. In such settings, one encounters a rich information theoretic landscape, not only from the fact that there exists a significantly larger combinatorial space of possible strategies for each player, but also several opportunities for pronounced quantum advantage. We conclude this effort by describing other variants of other possible strategies, as proposed sources for quantum advantage, in $\\mathrm{XOR}^{*}$, compiled $\\mathrm{XOR}^{*}$, and strong parallel repetition variants of $\\mathrm{XOR}^{*}$ games.",
      "authors": [
        "Pete Rigas"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.06322",
        "HTML": "https://arxiv.org/html/2505.06322",
        "PDF": "https://arxiv.org/pdf/2505.06322"
      },
      "subjects": [
        "Quantum Physics (quant-ph)",
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)",
        "Probability (math.PR)"
      ],
      "submission_historys": [
        {
          "date": "Fri, 09 May 2025 03:47:41 GMT",
          "size": "1185kb",
          "version": "v1"
        },
        {
          "date": "Wed, 25 Jun 2025 20:31:38 GMT",
          "size": "211kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Quantum strategies, error bounds, optimality, and duality gaps for multiplayer XOR, $\\mathrm{XOR}^{*}$, compiled XOR, $\\mathrm{XOR}^{*}$, and strong parallel repetiton of XOR, $\\mathrm{XOR}^{*}$, and FFL games",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This study deals with quantum strategies in games and does not touch on training data processing for LLMs."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2505.16713",
      "abstract": "We examine the concentration of uniform generalization errors around their expectation in binary linear classification problems via an isoperimetric argument. In particular, we establish Poincar\\'{e} and log-Sobolev inequalities for the joint distribution of the output labels and the label-weighted input vectors, which we apply to derive concentration bounds. The derived concentration bounds are sharp up to moderate multiplicative constants by those under well-balanced labels. In asymptotic analysis, we also show that almost sure convergence of uniform generalization errors to their expectation occurs in very broad settings, such as proportionally high-dimensional regimes. Using this convergence, we establish uniform laws of large numbers under dimension-free conditions.",
      "authors": [
        "Shogo Nakakita"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.16713",
        "HTML": "https://arxiv.org/html/2505.16713",
        "PDF": "https://arxiv.org/pdf/2505.16713"
      },
      "subjects": [
        "Machine Learning (stat.ML)",
        "Machine Learning (cs.LG)",
        "Statistics Theory (math.ST)",
        "Statistics Theory (stat.TH)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 22 May 2025 14:14:50 GMT",
          "size": "26kb",
          "version": "v1"
        },
        {
          "date": "Thu, 26 Jun 2025 06:57:11 GMT",
          "size": "26kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Sharp concentration of uniform generalization errors in binary linear classification",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on the mathematical analysis of generalization errors in binary linear classification problems, using isoperimetric arguments and inequalities. It does not address LLM training data processing or construction."
      },
      "tasks": [],
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.07625",
      "abstract": "Given $\\theta(x)$, one method (EJ) for solving Abel's equation $g(\\theta(x)) = g(x) \\pm 1$ is significantly faster than a rival method (ML). On the other hand, ML evaluates a limit characterizing the principal solution $g(x)$ directly while EJ finds $g(x) + \\delta$, where $\\delta$ is possibly nonzero but independent of $x$. If an exact expression for $\\delta$ is known, then the \"intrinsicality\" of ML carries over and relative quickness of EJ is preserved. We study $\\delta$, as determined by $\\theta$, and continue tangentially our earlier exploration of compositional square roots.",
      "authors": [
        "Steven Finch"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.07625",
        "HTML": "https://arxiv.org/html/2506.07625",
        "PDF": "https://arxiv.org/pdf/2506.07625"
      },
      "subjects": [
        "Number Theory (math.NT)",
        "Discrete Mathematics (cs.DM)"
      ],
      "submission_historys": [
        {
          "date": "Mon, 09 Jun 2025 10:42:45 GMT",
          "size": "119kb",
          "version": "v1"
        },
        {
          "date": "Thu, 26 Jun 2025 02:12:58 GMT",
          "size": "114kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Half-Iterates of $x$exp$(x)$, $x+1/x$ and arcsinh$(x)$",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper addresses mathematical methods for solving Abel's equation and does not pertain to the processing of training data for LLMs."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.17501",
      "abstract": "Following successful large-vessel recanalization via endovascular thrombectomy (EVT) for acute ischemic stroke (AIS), some patients experience a complication known as no-reflow, defined by persistent microvascular hypoperfusion that undermines tissue recovery and worsens clinical outcomes. Although prompt identification is crucial, standard clinical practice relies on perfusion magnetic resonance imaging (MRI) within 24 hours post-procedure, delaying intervention. In this work, we introduce the first-ever machine learning (ML) framework to predict no-reflow immediately after EVT by leveraging previously unexplored intra-procedural digital subtraction angiography (DSA) sequences and clinical variables. Our retrospective analysis included AIS patients treated at UCLA Medical Center (2011-2024) who achieved favorable mTICI scores (2b-3) and underwent pre- and post-procedure MRI. No-reflow was defined as persistent hypoperfusion (Tmax > 6 s) on post-procedural imaging. From DSA sequences (AP and lateral views), we extracted statistical and temporal perfusion features from the target downstream territory to train ML classifiers for predicting no-reflow. Our novel method significantly outperformed a clinical-features baseline(AUC: 0.7703 $\\pm$ 0.12 vs. 0.5728 $\\pm$ 0.12; accuracy: 0.8125 $\\pm$ 0.10 vs. 0.6331 $\\pm$ 0.09), demonstrating that real-time DSA perfusion dynamics encode critical insights into microvascular integrity. This approach establishes a foundation for immediate, accurate no-reflow prediction, enabling clinicians to proactively manage high-risk patients without reliance on delayed imaging.",
      "authors": [
        "Shreeram Athreya",
        "Carlos Olivares",
        "Ameera Ismail",
        "Kambiz Nael",
        "William Speier",
        "and Corey Arnold"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.17501",
        "HTML": "https://arxiv.org/html/2506.17501",
        "PDF": "https://arxiv.org/pdf/2506.17501"
      },
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Fri, 20 Jun 2025 22:40:51 GMT",
          "size": "17143kb",
          "version": "v1"
        },
        {
          "date": "Wed, 25 Jun 2025 23:15:21 GMT",
          "size": "17067kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "DSA-NRP: No-Reflow Prediction from Angiographic Perfusion Dynamics in Stroke EVT",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper introduces a machine learning framework for medical prediction following a specific medical procedure. There is no mention or implication of processing training data for LLMs."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.17851",
      "abstract": "Scientific progress depends on novel ideas, but current reward systems often fail to recognize them. Many existing metrics conflate novelty with popularity, privileging ideas that fit existing paradigms over those that challenge them. This study develops a theory-driven framework to better understand how different types of novelty emerge, take hold, and receive recognition. Drawing on network science and theories of discovery, we introduce a triadic typology: Pioneers, who introduce entirely new topics; Mavericks, who recombine distant concepts; and Vanguards, who reinforce weak but promising connections. We apply this typology to a dataset of 41,623 articles in the interdisciplinary field of philanthropy and nonprofit studies, linking novelty types to five-year citation counts using mixed-effects negative binomial regression. Results show that novelty is not uniformly rewarded. Pioneer efforts are foundational but often overlooked. Maverick novelty shows consistent citation benefits, particularly rewarded when it displaces prior focus. Vanguard novelty is more likely to gain recognition when it strengthens weakly connected topics, but its citation advantage diminishes as those reinforced nodes become more central. To enable fair comparison across time and domains, we introduce a simulated baseline model. These findings improve the evaluation of innovations, affecting science policy, funding, and institutional assessment practices.",
      "authors": [
        "Jin Ai and Richard S. Steinberg and Chao Guo and Filipi Nascimento Silva"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.17851",
        "HTML": "https://arxiv.org/html/2506.17851",
        "PDF": "https://arxiv.org/pdf/2506.17851"
      },
      "subjects": [
        "Physics and Society (physics.soc-ph)",
        "Computers and Society (cs.CY)",
        "Social and Information Networks (cs.SI)",
        "Applications (stat.AP)"
      ],
      "submission_historys": [
        {
          "date": "Sat, 21 Jun 2025 23:09:04 GMT",
          "size": "660kb",
          "version": "v1"
        },
        {
          "date": "Wed, 25 Jun 2025 18:24:05 GMT",
          "size": "676kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Triadic Novelty: A Typology and Measurement Framework for Recognizing Novel Contributions in Science",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "This paper is about recognizing novel contributions in scientific research and does not involve LLM training data processing or engineering."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.20589",
      "abstract": "Recent developments in the Internet of Bio-Nano Things (IoBNT) are laying the groundwork for innovative applications across the healthcare sector. Nanodevices designed to operate within the body, managed remotely via the internet, are envisioned to promptly detect and actuate on potential diseases. In this vision, an inherent challenge arises due to the limited capabilities of individual nanosensors; specifically, nanosensors must communicate with one another to collaborate as a cluster. Aiming to research the boundaries of the clustering capabilities, this survey emphasizes data-driven communication strategies in molecular communication (MC) channels as a means of linking nanosensors. Relying on the flexibility and robustness of machine learning (ML) methods to tackle the dynamic nature of MC channels, the MC research community frequently refers to neural network (NN) architectures. This interdisciplinary research field encompasses various aspects, including the use of NNs to facilitate communication in MC environments, their implementation at the nanoscale, explainable approaches for NNs, and dataset generation for training. Within this survey, we provide a comprehensive analysis of fundamental perspectives on recent trends in NN architectures for MC, the feasibility of their implementation at the nanoscale, applied explainable artificial intelligence (XAI) techniques, and the accessibility of datasets along with best practices for their generation. Additionally, we offer open-source code repositories that illustrate NN-based methods to support reproducible research for key MC scenarios. Finally, we identify emerging research challenges, such as robust NN architectures, biologically integrated NN modules, and scalable training strategies.",
      "authors": [
        "Jorge Torres G\\'omez and Pit Hofmann and Lisa Y. Debus and Osman Tugay Ba\\c{s}aran and Sebastian Lotter and Roya Khanzadeh and Stefan Angerbauer and Bige Deniz Unluturk and Sergi Abadal and Werner Haselmayr and Frank H.P. Fitzek and Robert Schober and Falko Dressler"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20589",
        "HTML": "https://arxiv.org/html/2506.20589",
        "PDF": "https://arxiv.org/pdf/2506.20589"
      },
      "subjects": [
        "Signal Processing (eess.SP)",
        "Emerging Technologies (cs.ET)",
        "Other Quantitative Biology (q-bio.OT)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 16:28:30 GMT",
          "size": "4111kb",
          "version": "v1"
        },
        {
          "date": "Thu, 26 Jun 2025 15:09:32 GMT",
          "size": "4279kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Communicating Smartly in the Molecular Domain: Neural Networks in the Internet of Bio-Nano Things",
      "relevance": {
        "keyword": "train_data",
        "level": "none",
        "reason": "The paper focuses on neural networks in molecular communication and the Internet of Bio-Nano Things. It discusses NN architectures for communication, nanoscale implementation, and explainable AI techniques, which do not pertain to LLM training data processing."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2406.02481",
      "abstract": "Simple fine-tuning can embed hidden text into large language models (LLMs), which is revealed only when triggered by a specific query. Applications include LLM fingerprinting, where a unique identifier is embedded to verify licensing compliance, and steganography, where the LLM carries hidden messages disclosed through a trigger query.\n  Our work demonstrates that embedding hidden text via fine-tuning, although seemingly secure due to the vast number of potential triggers, is vulnerable to extraction through analysis of the LLM's output decoding process. We introduce an extraction attack called Unconditional Token Forcing (UTF), which iteratively feeds tokens from the LLM's vocabulary to reveal sequences with high token probabilities, indicating hidden text candidates. We also present Unconditional Token Forcing Confusion (UTFC), a defense paradigm that makes hidden text resistant to all known extraction attacks without degrading the general performance of LLMs compared to standard fine-tuning. UTFC has both benign (improving LLM fingerprinting) and malign applications (using LLMs to create covert communication channels).",
      "authors": [
        "Jakub Hoscilowicz",
        "Pawel Popiolek",
        "Jan Rudkowski",
        "Jedrzej Bieniasz",
        "Artur Janicki"
      ],
      "last_revised_date": "2025/05/05",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2406.02481",
        "HTML": "https://arxiv.org/html/2406.02481",
        "PDF": "https://arxiv.org/pdf/2406.02481"
      },
      "subjects": [
        "Computation and Language (cs.CL)",
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 04 Jun 2024 16:49:06 GMT",
          "size": "531kb",
          "version": "v1"
        },
        {
          "date": "Mon, 29 Jul 2024 16:30:17 GMT",
          "size": "534kb",
          "version": "v2"
        },
        {
          "date": "Sun, 25 Aug 2024 14:21:29 GMT",
          "size": "535kb",
          "version": "v3"
        },
        {
          "date": "Tue, 24 Sep 2024 12:00:29 GMT",
          "size": "557kb",
          "version": "v4"
        },
        {
          "date": "Mon, 05 May 2025 09:57:34 GMT",
          "size": "557kb",
          "version": "v5"
        }
      ],
      "submitted_date": "2025/05/05",
      "title": "Large Language Models as Carriers of Hidden Messages",
      "relevance": {
        "keyword": "train_data",
        "level": "strong",
        "reason": "The paper explores embedding hidden text in LLMs through fine-tuning, which is a direct aspect of training-stage data processing. It discusses methods related to encoding and decoding hidden messages within LLMs, thus strongly relating to LLM data processing themes."
      },
      "tasks": [],
      "repo_urls": [
        "https://github.com/j-hoscilowic/zurek-stegano"
      ],
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2505.07449",
      "abstract": "In ophthalmic surgery, developing an AI system capable of interpreting surgical videos and predicting subsequent operations requires numerous ophthalmic surgical videos with high-quality annotations, which are difficult to collect due to privacy concerns and labor consumption. Text-guided video generation (T2V) emerges as a promising solution to overcome this issue by generating ophthalmic surgical videos based on surgeon instructions. In this paper, we present Ophora, a pioneering model that can generate ophthalmic surgical videos following natural language instructions. To construct Ophora, we first propose a Comprehensive Data Curation pipeline to convert narrative ophthalmic surgical videos into a large-scale, high-quality dataset comprising over 160K video-instruction pairs, Ophora-160K. Then, we propose a Progressive Video-Instruction Tuning scheme to transfer rich spatial-temporal knowledge from a T2V model pre-trained on natural video-text datasets for privacy-preserved ophthalmic surgical video generation based on Ophora-160K. Experiments on video quality evaluation via quantitative analysis and ophthalmologist feedback demonstrate that Ophora can generate realistic and reliable ophthalmic surgical videos based on surgeon instructions. We also validate the capability of Ophora for empowering downstream tasks of ophthalmic surgical workflow understanding. Code is available at https://github.com/mar-cry/Ophora.",
      "authors": [
        "Wei Li",
        "Ming Hu",
        "Guoan Wang",
        "Lihao Liu",
        "Kaijin Zhou",
        "Junzhi Ning",
        "Xin Guo",
        "Zongyuan Ge",
        "Lixu Gu",
        "Junjun He"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.07449",
        "HTML": "https://arxiv.org/html/2505.07449",
        "PDF": "https://arxiv.org/pdf/2505.07449"
      },
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Mon, 12 May 2025 11:23:37 GMT",
          "size": "2243kb",
          "version": "v1"
        },
        {
          "date": "Tue, 13 May 2025 05:39:25 GMT",
          "size": "2243kb",
          "version": "v2"
        },
        {
          "date": "Fri, 16 May 2025 08:47:49 GMT",
          "size": "2245kb",
          "version": "v3"
        },
        {
          "date": "Fri, 06 Jun 2025 04:36:26 GMT",
          "size": "2243kb",
          "version": "v4"
        },
        {
          "date": "Wed, 18 Jun 2025 11:40:27 GMT",
          "size": "2239kb",
          "version": "v5"
        },
        {
          "date": "Thu, 26 Jun 2025 05:57:03 GMT",
          "size": "2241kb",
          "version": "v6"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Ophora: A Large-Scale Data-Driven Text-Guided Ophthalmic Surgical Video Generation Model",
      "relevance": {
        "keyword": "train_data",
        "level": "strong",
        "reason": "The paper presents a Comprehensive Data Curation pipeline to construct a large-scale, high-quality dataset for ophthalmic surgical video generation, directly involving data collection and construction processes relevant to LLM training data."
      },
      "tasks": [
        "Video Generation"
      ],
      "repo_urls": [
        "https://github.com/mar-cry/ophora"
      ],
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.20856",
      "abstract": "Memorization in large language models (LLMs) makes them vulnerable to data extraction attacks. While pre-training memorization has been extensively studied, fewer works have explored its impact in fine-tuning, particularly for LoRA fine-tuning, a widely adopted parameter-efficient method.\n  In this work, we re-examine memorization in fine-tuning and uncover a surprising divergence from prior findings across different fine-tuning strategies. Factors such as model scale and data duplication, which strongly influence memorization in pre-training and full fine-tuning, do not follow the same trend in LoRA fine-tuning. Using a more relaxed similarity-based memorization metric, we demonstrate that LoRA significantly reduces memorization risks compared to full fine-tuning, while still maintaining strong task performance.",
      "authors": [
        "Fei Wang",
        "Baochun Li"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20856",
        "HTML": "https://arxiv.org/html/2506.20856",
        "PDF": "https://arxiv.org/pdf/2506.20856"
      },
      "subjects": [
        "Machine Learning (cs.LG)",
        "Computation and Language (cs.CL)",
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 22:01:25 GMT",
          "size": "280kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Leaner Training, Lower Leakage: Revisiting Memorization in LLM Fine-Tuning with LoRA",
      "relevance": {
        "keyword": "train_data",
        "level": "strong",
        "reason": "The paper directly discusses data-related issues in LLM fine-tuning, specifically examining the effect of data duplication on memorization in different fine-tuning strategies, which is a core aspect of training-stage data processing."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.20917",
      "abstract": "Language models (LMs) have demonstrated remarkable capabilities in NLP, yet adapting them efficiently and robustly to specific tasks remains challenging. As their scale and complexity grow, fine-tuning LMs on labelled data often underutilizes available unlabelled data, leads to overfitting on small task-specific sets, and imposes significant computational costs. These limitations hamper their application to the open-ended landscape of real-world language tasks.\n  This thesis proposes a series of methods to better adapt LMs to downstream applications. First, we explore strategies for extracting task-relevant knowledge from unlabelled data, introducing a novel continued pre-training technique that outperforms state-of-the-art semi-supervised approaches. Next, we present a parameter-efficient fine-tuning method that substantially reduces memory and compute costs while maintaining competitive performance. We also introduce improved supervised fine-tuning methods that enable LMs to better follow instructions, especially when labelled data is scarce, enhancing their performance across a range of NLP tasks, including open-ended generation. Finally, we develop new evaluation methods and benchmarks, such as multi-hop spatial reasoning tasks, to assess LM capabilities and adaptation more comprehensively.\n  Through extensive empirical studies across diverse NLP tasks, our results demonstrate that these approaches substantially improve LM robustness, efficiency, and generalization, making them more adaptable to a broad range of applications. These advances mark a significant step towards more robust and efficient LMs, bringing us closer to the goal of artificial general intelligence.",
      "authors": [
        "Zhengyan Shi"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20917",
        "HTML": "https://arxiv.org/html/2506.20917",
        "PDF": "https://arxiv.org/pdf/2506.20917"
      },
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 00:49:35 GMT",
          "size": "2259kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Optimising Language Models for Downstream Tasks: A Post-Training Perspective",
      "relevance": {
        "keyword": "train_data",
        "level": "strong",
        "reason": "The paper actively explores strategies for adapting LMs to downstream applications, including novel continued pre-training techniques and parameter-efficient fine-tuning methods, directly involving processing of training data."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.20920",
      "abstract": "Pre-training state-of-the-art large language models (LLMs) requires vast amounts of clean and diverse text data. While the open development of large high-quality English pre-training datasets has seen substantial recent progress, training performant multilingual LLMs remains a challenge, in large part due to the inherent difficulty of tailoring filtering and deduplication pipelines to a large number of languages. In this work, we introduce a new pre-training dataset curation pipeline based on FineWeb that can be automatically adapted to support any language. We extensively ablate our pipeline design choices on a set of nine diverse languages, guided by a set of meaningful and informative evaluation tasks that were chosen through a novel selection process based on measurable criteria. Ultimately, we show that our pipeline can be used to create non-English corpora that produce more performant models than prior datasets. We additionally introduce a straightforward and principled approach to rebalance datasets that takes into consideration both duplication count and quality, providing an additional performance uplift. Finally, we scale our pipeline to over 1000 languages using almost 100 Common Crawl snapshots to produce FineWeb2, a new 20 terabyte (5 billion document) multilingual dataset which we release along with our pipeline, training, and evaluation codebases.",
      "authors": [
        "Guilherme Penedo",
        "Hynek Kydl\\'i\\v{c}ek",
        "Vinko Sabol\\v{c}ec",
        "Bettina Messmer",
        "Negar Foroutan",
        "Amir Hossein Kargaran",
        "Colin Raffel",
        "Martin Jaggi",
        "Leandro Von Werra",
        "Thomas Wolf"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20920",
        "HTML": "https://arxiv.org/html/2506.20920",
        "PDF": "https://arxiv.org/pdf/2506.20920"
      },
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 01:01:47 GMT",
          "size": "277kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "FineWeb2: One Pipeline to Scale Them All -- Adapting Pre-Training Data Processing to Every Language",
      "relevance": {
        "keyword": "train_data",
        "level": "strong",
        "reason": "The paper introduces a new pre-training dataset curation pipeline for LLMs, specifically focusing on filtering, deduplication, and creation processes across languages, which are core to data engineering for LLM training."
      },
      "datasets": [
        {
          "dataset_name": "HuggingFaceFW/fineweb-2",
          "downloads": "38340",
          "likes": "499",
          "link": "https://huggingface.co/datasets/HuggingFaceFW/fineweb-2"
        }
      ],
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.20923",
      "abstract": "In this paper, we propose KaLM-Embedding-V2, a versatile and compact embedding model, which achieves impressive performance in general-purpose text embedding tasks by leveraging superior training techniques and data. Our key innovations include: (1) To better align the architecture with representation learning, we remove the causal attention mask and adopt a fully bidirectional transformer with simple yet effective mean-pooling to produce fixed-length embeddings; (2) We employ a multi-stage training pipeline: (i) pre-training on large-scale weakly supervised open-source corpora; (ii) fine-tuning on high-quality retrieval and non-retrieval datasets; and (iii) model-soup parameter averaging for robust generalization. Besides, we introduce a focal-style reweighting mechanism that concentrates learning on difficult samples and an online hard-negative mixing strategy to continuously enrich hard negatives without expensive offline mining; (3) We collect over 20 categories of data for pre-training and 100 categories of data for fine-tuning, to boost both the performance and generalization of the embedding model. Extensive evaluations on the Massive Text Embedding Benchmark (MTEB) Chinese and English show that our model significantly outperforms others of comparable size, and competes with 3x, 14x, 18x, and 26x larger embedding models, setting a new standard for a versatile and compact embedding model with less than 1B parameters.",
      "authors": [
        "Xinping Zhao",
        "Xinshuo Hu",
        "Zifei Shan",
        "Shouzheng Huang",
        "Yao Zhou",
        "Zetian Sun",
        "Zhenyu Liu",
        "Dongfang Li",
        "Xinyuan Wei",
        "Qian Chen",
        "Youcheng Pan",
        "Yang Xiang",
        "Meishan Zhang",
        "Haofen Wang",
        "Jun Yu",
        "Baotian Hu",
        "Min Zhang"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20923",
        "HTML": "https://arxiv.org/html/2506.20923",
        "PDF": "https://arxiv.org/pdf/2506.20923"
      },
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 01:09:44 GMT",
          "size": "355kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "KaLM-Embedding-V2: Superior Training Techniques and Data Inspire A Versatile Embedding Model",
      "relevance": {
        "keyword": "train_data",
        "level": "strong",
        "reason": "The paper's primary contribution involves a multi-stage training process with extensive data collection for pre-training and fine-tuning the KaLM-Embedding-V2 model, directly relating to the processing and construction of training data for LLMs."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.20963",
      "abstract": "Graph-based Retrieval-Augmented Generation (Graph-RAG) enhances large language models (LLMs) by structuring retrieval over an external corpus. However, existing approaches typically assume a static corpus, requiring expensive full-graph reconstruction whenever new documents arrive, limiting their scalability in dynamic, evolving environments. To address these limitations, we introduce EraRAG, a novel multi-layered Graph-RAG framework that supports efficient and scalable dynamic updates. Our method leverages hyperplane-based Locality-Sensitive Hashing (LSH) to partition and organize the original corpus into hierarchical graph structures, enabling efficient and localized insertions of new data without disrupting the existing topology. The design eliminates the need for retraining or costly recomputation while preserving high retrieval accuracy and low latency. Experiments on large-scale benchmarks demonstrate that EraRag achieves up to an order of magnitude reduction in update time and token consumption compared to existing Graph-RAG systems, while providing superior accuracy performance. This work offers a practical path forward for RAG systems that must operate over continually growing corpora, bridging the gap between retrieval efficiency and adaptability. Our code and data are available at https://github.com/EverM0re/EraRAG-Official.",
      "authors": [
        "Fangyuan Zhang",
        "Zhengjun Huang",
        "Yingli Zhou",
        "Qintian Guo",
        "Zhixun Li",
        "Wensheng Luo",
        "Di Jiang",
        "Yixiang Fang",
        "Xiaofang Zhou"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20963",
        "HTML": "https://arxiv.org/html/2506.20963",
        "PDF": "https://arxiv.org/pdf/2506.20963"
      },
      "subjects": [
        "Information Retrieval (cs.IR)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 03:01:33 GMT",
          "size": "1188kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "EraRAG: Efficient and Incremental Retrieval Augmented Generation for Growing Corpora",
      "relevance": {
        "keyword": "train_data",
        "level": "strong",
        "reason": "The paper presents EraRAG, a framework that optimizes retrieval-augmented generation by efficiently updating corpora, which relates to data engineering tasks such as organizing, partitioning data, and ensuring data scalability without the need for costly retraining, directly impacting the processing of training data in dynamic environments."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.20989",
      "abstract": "There are two primary ways of incorporating new information into a language model (LM): changing its prompt or changing its parameters, e.g. via fine-tuning. Parameter updates incur no long-term storage cost for model changes. However, for many model updates, prompting is significantly more effective: prompted models can generalize robustly from single examples and draw logical inferences that do not occur under standard fine-tuning. Can models be modified so that fine-tuning does emulate prompting? This paper describes a method for meta-training LMs such that gradient updates emulate the effects of conditioning on new information. Our approach uses tools from gradient-based meta-learning but uses an LM's own prompted predictions as targets, eliminating the need for ground-truth labels. Subsequent gradient descent training recovers some (and occasionally all) of prompted model performance -- showing improvement on the ``reversal curse'' tasks, and answering questions about text passages after a single gradient update. These results suggest that, with appropriate initialization, gradient descent can be surprisingly expressive. Our results suggest new avenues for long-context modeling and offer insight into the generalization capabilities of gradient-based learning.",
      "authors": [
        "Eric Zhang",
        "Leshem Choshen",
        "Jacob Andreas"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20989",
        "HTML": "https://arxiv.org/html/2506.20989",
        "PDF": "https://arxiv.org/pdf/2506.20989"
      },
      "subjects": [
        "Computation and Language (cs.CL)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 04:06:20 GMT",
          "size": "122kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Can Gradient Descent Simulate Prompting?",
      "relevance": {
        "keyword": "train_data",
        "level": "strong",
        "reason": "The paper explores methods for meta-training LMs by emulating the effects of prompts through gradient updates, touching on LLM data processing, specifically fine-tuning methods which relate to training-stage data processing."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21011",
      "abstract": "Classical video quality assessment (VQA) methods generate a numerical score to judge a video's perceived visual fidelity and clarity. Yet, a score fails to describe the video's complex quality dimensions, restricting its applicability. Benefiting from the linguistic output, adapting video large multimodal models (LMMs) to VQA via instruction tuning has the potential to address this issue. The core of the approach lies in the video quality-centric instruction data. Previous explorations mainly focus on the image domain, and their data generation processes heavily rely on human quality annotations and proprietary systems, limiting data scalability and effectiveness. To address these challenges, we propose the Score-based Instruction Generation (SIG) pipeline. Specifically, SIG first scores multiple quality dimensions of an unlabeled video and maps scores to text-defined levels. It then explicitly incorporates a hierarchical Chain-of-Thought (CoT) to model the correlation between specific dimensions and overall quality, mimicking the human visual system's reasoning process. The automated pipeline eliminates the reliance on expert-written quality descriptions and proprietary systems, ensuring data scalability and generation efficiency. To this end, the resulting Score2Instruct (S2I) dataset contains over 320K diverse instruction-response pairs, laying the basis for instruction tuning. Moreover, to advance video LMMs' quality scoring and justification abilities simultaneously, we devise a progressive tuning strategy to fully unleash the power of S2I. Built upon SIG, we further curate a benchmark termed S2I-Bench with 400 open-ended questions to better evaluate the quality justification capacity of video LMMs. Experimental results on the S2I-Bench and existing benchmarks indicate that our method consistently improves quality scoring and justification capabilities across multiple video LMMs.",
      "authors": [
        "Qizhi Xie",
        "Kun Yuan",
        "Yunpeng Qu",
        "Jiachao Gong",
        "Mingda Wu",
        "Ming Sun",
        "Chao Zhou",
        "Jihong Zhu"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21011",
        "HTML": "https://arxiv.org/html/2506.21011",
        "PDF": "https://arxiv.org/pdf/2506.21011"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 05:02:25 GMT",
          "size": "3135kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Bridging Video Quality Scoring and Justification via Large Multimodal Models",
      "relevance": {
        "keyword": "train_data",
        "level": "strong",
        "reason": "The paper explicitly proposes the Score-based Instruction Generation (SIG) pipeline for creating a large dataset for instruction tuning, directly contributing to a novel data engineering method for LLM training."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21037",
      "abstract": "Modern deep architectures often rely on large-scale datasets, but training on these datasets incurs high computational and storage overhead. Real-world datasets often contain substantial redundancies, prompting the need for more data-efficient training paradigms. Data selection has shown promise to mitigate redundancy by identifying the most representative samples, thereby reducing training costs without compromising performance. Existing methods typically rely on static scoring metrics or pretrained models, overlooking the combined effect of selected samples and their evolving dynamics during training. We introduce the concept of epsilon-sample cover, which quantifies sample redundancy based on inter-sample relationships, capturing the intrinsic structure of the dataset. Based on this, we reformulate data selection as a reinforcement learning (RL) process and propose RL-Selector, where a lightweight RL agent optimizes the selection policy by leveraging epsilon-sample cover derived from evolving dataset distribution as a reward signal. Extensive experiments across benchmark datasets and diverse architectures demonstrate that our method consistently outperforms existing state-of-the-art baselines. Models trained with our selected datasets show enhanced generalization performance with improved training efficiency.",
      "authors": [
        "Suorong Yang",
        "Peijia Li",
        "Furao Shen",
        "Jian Zhao"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21037",
        "HTML": "https://arxiv.org/html/2506.21037",
        "PDF": "https://arxiv.org/pdf/2506.21037"
      },
      "subjects": [
        "Machine Learning (cs.LG)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 06:28:56 GMT",
          "size": "1095kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "RL-Selector: Reinforcement Learning-Guided Data Selection via Redundancy Assessment",
      "relevance": {
        "keyword": "train_data",
        "level": "strong",
        "reason": "The paper proposes RL-Selector, a reinforcement learning guided data selection method to reduce redundancies in training datasets, which is directly relevant to data engineering by improving dataset quality for training large models."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21071",
      "abstract": "Teaching large language models (LLMs) to use tools is crucial for improving their problem-solving abilities and expanding their applications. However, effectively using tools is challenging because it requires a deep understanding of tool functionalities and user intentions. Previous methods relied mainly on LLMs to generate instruction data, but the quality of these data was often insufficient. In this paper, we propose a new method that uses knowledge graphs to generate high-quality instruction data for LLMs. Knowledge graphs are manually curated datasets rich in semantic information. We begin by extracting various query pathways from a given knowledge graph, which are transformed into a broad spectrum of user queries. We then translate the relationships between entities into actionable tools and parse the pathways of each query into detailed solution steps, thereby creating high-quality instruction data. Our experiments show that fine-tuning on just a small sample of this synthetic data can significantly improve the tool utilization and overall capabilities of LLMs.",
      "authors": [
        "Jingwei Wang",
        "Zai Zhang",
        "Hao Qian",
        "Chunjing Gan",
        "Binbin Hu",
        "Ziqi Liu",
        "Zhiqiang Zhang",
        "Jun Zhou",
        "Bin Shi",
        "Bo Dong"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21071",
        "HTML": "https://arxiv.org/html/2506.21071",
        "PDF": "https://arxiv.org/pdf/2506.21071"
      },
      "subjects": [
        "Machine Learning (cs.LG)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 07:45:15 GMT",
          "size": "9966kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Enhancing LLM Tool Use with High-quality Instruction Data from Knowledge Graph",
      "relevance": {
        "keyword": "train_data",
        "level": "strong",
        "reason": "The paper proposes a method for generating high-quality instruction data for LLMs using knowledge graphs. This directly contributes to the data engineering stage by providing a novel approach to constructing high-quality training data specific to LLMs."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21116",
      "abstract": "Video Large Language Models (VideoLLMs) have demonstrated remarkable understanding capabilities, but are found struggling to tackle multi-shot scenarios,e.g., video clips with varying camera angles or scene changes. This challenge can render failures such as instance identity forgetting and key frame negligence. In this work, we first attribute the challenge to the lack of multi-shot annotations among existing datasets and therefore we introduce a new dataset termed MultiClip-Bench, featuring dense descriptions and instruction-based question-answering pairs tailored for multi-shot scenarios. We empirically find that the training set significantly boosts the multi-shot performance, while the testing benchmark provides a reliable measure of the model capability in multi-shot scenarios. By further analyzing and discovering that current models only encode instance features in a discrete or lossy manner, at the risk of missing identity information, we then contribute a new model IPFormer-VideoLLM. Its key idea is the injection of instance-level features as instance prompts through an efficient attention-based connector. This allows for the aggregation of instance-specific information across scenes. Experiments demonstrate that our proposed dataset and model not only enhance the multi-scene video understanding significantly, but also offer distinct advantages across various video benchmarks.",
      "authors": [
        "Yujia Liang",
        "Jile Jiao",
        "Zhicheng Wang",
        "Xuetao Feng",
        "Zixuan Ye",
        "Yuan Wang",
        "Hao Lu"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21116",
        "HTML": "https://arxiv.org/html/2506.21116",
        "PDF": "https://arxiv.org/pdf/2506.21116"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 09:30:57 GMT",
          "size": "12944kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "IPFormer-VideoLLM: Enhancing Multi-modal Video Understanding for Multi-shot Scenes",
      "relevance": {
        "keyword": "train_data",
        "level": "strong",
        "reason": "The paper introduces a new dataset, MultiClip-Bench, specifically tailored for enhancing video LLMs in multi-shot scenarios and shows how it improves model performance. This directly involves the construction of LLM training data, which is a key aspect of data engineering."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21138",
      "abstract": "The shortage of publicly available, labeled requirements datasets remains a major barrier to advancing Artificial Intelligence for Requirements Engineering (AI4RE). While Large Language Models offer promising capabilities for synthetic data generation, systematic approaches to control and optimize the quality of generated requirements remain underexplored. This paper presents Synthline v1, an enhanced Product Line approach for generating synthetic requirements data that extends our earlier v0 version with advanced generation strategies and curation techniques. We investigate four research questions assessing how prompting strategies, automated prompt optimization, and post-generation curation affect data quality across four classification tasks: defect detection, functional vs. non-functional, quality vs. non-quality, and security vs. non-security. Our evaluation shows that multi-sample prompting significantly boosts both utility and diversity over single-sample generation, with F1-score gains from 6 to 44 points. The use of PACE (Prompt Actor-Critic Editing) for automated prompt optimization yields task-dependent results, greatly improving functional classification (+32.5 points) but reducing performance on others. Interestingly, similarity-based curation improves diversity but often harms classification performance, indicating that some redundancy may help ML models. Most importantly, our results show that synthetic requirements can match or outperform human-authored ones for specific tasks, with synthetic data surpassing human data for security (+7.8 points) and defect classification (+15.4 points). These findings offer practical insights for AI4RE and chart a viable path to mitigating dataset scarcity through systematic synthetic generation.",
      "authors": [
        "Abdelkarim El-Hajjami and Camille Salinesi"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21138",
        "HTML": "https://arxiv.org/html/2506.21138",
        "PDF": "https://arxiv.org/pdf/2506.21138"
      },
      "subjects": [
        "Software Engineering (cs.SE)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 10:52:07 GMT",
          "size": "233kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "How Good Are Synthetic Requirements ? Evaluating LLM-Generated Datasets for AI4RE",
      "relevance": {
        "keyword": "train_data",
        "level": "strong",
        "reason": "The paper presents methods for generating synthetic requirements data using large language models, focusing on generating, curating, and optimizing data, which is a direct contribution to LLM training data processing."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21220",
      "abstract": "General-purpose Large Language Models (LLMs) are frequently fine-tuned through supervised fine-tuning (SFT) to enhance performance in specific domains. Better results can be achieved by distilling the chain-of-thought of a larger model at the cost of numerous expensive calls and a much greater amount of data. We propose a novel blueprint for efficient fine-tuning that uses reasoning only for complex data identified by entropy. Specifically, across two small open models ($\\approx 3B$) we split the training data into complexity categories by a single token answer entropy (ROC AUC $0.73$), fine-tune large language models (LLMs) via SFT and distillation, and show that our pipeline significantly outperforms the standard SFT approach ($0.55$ vs $0.43$ average accuracy) and provides comparable with distillation performance while using $62\\%$ less data ($0.55$ average accuracy for both). We publish our code and data to facilitate further research in this direction.",
      "authors": [
        "Andrey Goncharov",
        "Daniil Vyazhev",
        "Petr Sychev",
        "Edvard Khalafyan",
        "Alexey Zaytsev"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21220",
        "HTML": "https://arxiv.org/html/2506.21220",
        "PDF": "https://arxiv.org/pdf/2506.21220"
      },
      "subjects": [
        "Machine Learning (cs.LG)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 13:13:24 GMT",
          "size": "3105kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Complexity-aware fine-tuning",
      "relevance": {
        "keyword": "train_data",
        "level": "strong",
        "reason": "The paper proposes a novel blueprint for efficient fine-tuning by splitting training data into complexity categories, which involves significant data processing innovation in the context of fine-tuning LLMs."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21288",
      "abstract": "Augmenting large language models (LLMs) with external context significantly improves their performance in natural language processing (NLP) tasks. However, LLMs struggle to answer queries reliably when the provided context lacks information, often resorting to ungrounded speculation or internal knowledge. Groundedness - generating responses strictly supported by the context - is essential for ensuring factual consistency and trustworthiness. This study focuses on detecting whether a given query is grounded in a document provided in context before the costly answer generation by LLMs. Such a detection mechanism can significantly reduce both inference time and resource consumption. We show that lightweight, task specific encoder models such as RoBERTa and NomicBERT, fine-tuned on curated datasets, can achieve accuracy comparable to state-of-the-art LLMs, such as Llama3 8B and GPT4o, in groundedness detection while reducing inference latency by orders of magnitude. The code is available at : https://github.com/chandarlab/Hallucinate-less",
      "authors": [
        "Istabrak Abbes",
        "Gabriele Prato",
        "Quentin Fournier",
        "Fernando Rodriguez",
        "Alaa Boukhary",
        "Adam Elwood",
        "Sarath Chandar"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21288",
        "HTML": "https://arxiv.org/html/2506.21288",
        "PDF": "https://arxiv.org/pdf/2506.21288"
      },
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Information Retrieval (cs.IR)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 14:09:41 GMT",
          "size": "369kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Small Encoders Can Rival Large Decoders in Detecting Groundedness",
      "relevance": {
        "keyword": "train_data",
        "level": "strong",
        "reason": "This paper highlights the fine-tuning of lightweight encoder models on curated datasets for groundedness detection, directly contributing to methods for data preparation and processing in LLM training."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21317",
      "abstract": "Current vision-language models (VLMs) are well-adapted for general visual understanding tasks. However, they perform inadequately when handling complex visual tasks related to human poses and actions due to the lack of specialized vision-language instruction-following data. We introduce a method for generating such data by integrating human keypoints with traditional visual features such as captions and bounding boxes, enabling more precise understanding of human-centric scenes. Our approach constructs a dataset comprising 200,328 samples tailored to fine-tune models for human-centric tasks, focusing on three areas: conversation, detailed description, and complex reasoning. We establish an Extended Human Pose and Action Understanding Benchmark (E-HPAUB) to assess model performance on human pose and action understanding. We fine-tune the LLaVA-1.5-7B model using this dataset and evaluate our resulting LLaVA-Pose model on the benchmark, achieving significant improvements. Experimental results show an overall improvement of 33.2% compared to the original LLaVA-1.5-7B model. These findings highlight the effectiveness of keypoint-integrated data in enhancing multimodal models for human-centric visual understanding. Code is available at https://github.com/Ody-trek/LLaVA-Pose.",
      "authors": [
        "Dewen Zhang",
        "Tahir Hussain",
        "Wangpeng An",
        "and Hayaru Shouno"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21317",
        "HTML": "https://arxiv.org/html/2506.21317",
        "PDF": "https://arxiv.org/pdf/2506.21317"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 14:32:56 GMT",
          "size": "641kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "LLaVA-Pose: Enhancing Human Pose and Action Understanding via Keypoint-Integrated Instruction Tuning",
      "relevance": {
        "keyword": "train_data",
        "level": "strong",
        "reason": "The paper describes the construction of a dataset with 200,328 samples designed to fine-tune models for human-centric tasks, focusing on detailed instruction tuning, which directly relates to LLM data processing for enhanced training."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21319",
      "abstract": "Visualizations are crucial for data communication, yet understanding them requires comprehension of both visual elements and their underlying data relationships. Current multimodal large models, while effective in natural image understanding, struggle with visualization due to their inability to decode the data-to-visual mapping rules and extract structured information. To address these challenges, we present a novel dataset and train multimodal visualization LLMs specifically designed for understanding. Our approach combines chart images with their corresponding vectorized representations, encoding schemes, and data features. The proposed vector format enables compact and accurate reconstruction of visualization content. Experimental results demonstrate significant improvements in both data extraction accuracy and chart reconstruction quality.",
      "authors": [
        "Can Liu and Chunlin Da and Xiaoxiao Long and Yuxiao Yang and Yu Zhang and Yong Wang"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21319",
        "HTML": "https://arxiv.org/html/2506.21319",
        "PDF": "https://arxiv.org/pdf/2506.21319"
      },
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 14:35:59 GMT",
          "size": "5645kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Multimodal LLMs for Visualization Reconstruction and Understanding",
      "relevance": {
        "keyword": "train_data",
        "level": "strong",
        "reason": "The research involves creating a novel dataset and training multimodal LLMs for visualization understanding, highlighting contributions to LLM data engineering by combining chart images with vectorized representations."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21384",
      "abstract": "Real-world live retrieval-augmented generation (RAG) systems face significant challenges when processing user queries that are often noisy, ambiguous, and contain multiple intents. While RAG enhances large language models (LLMs) with external knowledge, current systems typically struggle with such complex inputs, as they are often trained or evaluated on cleaner data. This paper introduces Omni-RAG, a novel framework designed to improve the robustness and effectiveness of RAG systems in live, open-domain settings. Omni-RAG employs LLM-assisted query understanding to preprocess user inputs through three key modules: (1) Deep Query Understanding and Decomposition, which utilizes LLMs with tailored prompts to denoise queries (e.g., correcting spelling errors) and decompose multi-intent queries into structured sub-queries; (2) Intent-Aware Knowledge Retrieval, which performs retrieval for each sub-query from a corpus (i.e., FineWeb using OpenSearch) and aggregates the results; and (3) Reranking and Generation, where a reranker (i.e., BGE) refines document selection before a final response is generated by an LLM (i.e., Falcon-10B) using a chain-of-thought prompt. Omni-RAG aims to bridge the gap between current RAG capabilities and the demands of real-world applications, such as those highlighted by the SIGIR 2025 LiveRAG Challenge, by robustly handling complex and noisy queries.",
      "authors": [
        "Guanting Dong",
        "Xiaoxi Li",
        "Yuyao Zhang",
        "Mengjie Deng"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21384",
        "HTML": "https://arxiv.org/html/2506.21384",
        "PDF": "https://arxiv.org/pdf/2506.21384"
      },
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 15:35:12 GMT",
          "size": "415kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Leveraging LLM-Assisted Query Understanding for Live Retrieval-Augmented Generation",
      "relevance": {
        "keyword": "train_data",
        "level": "strong",
        "reason": "The paper presents Omni-RAG, a framework that preprocesses user inputs for retrieval-augmented generation systems, including denoising and query decomposition, which directly involves novel methods for LLM training-stage data processing."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21393",
      "abstract": "Multimodal understanding of tables in real-world contexts is challenging due to the complexity of structure, symbolic density, and visual degradation (blur, skew, watermarking, incomplete structures or fonts, multi-span or hierarchically nested layouts). Existing multimodal large language models (MLLMs) struggle with such WildStruct conditions, resulting in limited performance and poor generalization. To address these challenges, we propose TableMoE, a neuro-symbolic Mixture-of-Connector-Experts (MoCE) architecture specifically designed for robust, structured reasoning over multimodal table data. TableMoE features an innovative Neuro-Symbolic Routing mechanism, which predicts latent semantic token roles (e.g., header, data cell, axis, formula) and dynamically routes table elements to specialized experts (Table-to-HTML, Table-to-JSON, Table-to-Code) using a confidence-aware gating strategy informed by symbolic reasoning graphs. To facilitate effective alignment-driven pretraining, we introduce the large-scale TableMoE-Align dataset, consisting of 1.2M table-HTML-JSON-code quadruples across finance, science, biomedicine and industry, utilized exclusively for model pretraining. For evaluation, we curate and release four challenging WildStruct benchmarks: WMMFinQA, WMMTatQA, WMMTabDialog, and WMMFinanceMath, designed specifically to stress-test models under real-world multimodal degradation and structural complexity. Experimental results demonstrate that TableMoE significantly surpasses existing state-of-the-art models. Extensive ablation studies validate each core component, emphasizing the critical role of Neuro-Symbolic Routing and structured expert alignment. Through qualitative analyses, we further showcase TableMoE's interpretability and enhanced robustness, underscoring the effectiveness of integrating neuro-symbolic reasoning for multimodal table understanding.",
      "authors": [
        "Junwen Zhang",
        "Pu Chen",
        "Yin Zhang"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21393",
        "HTML": "https://arxiv.org/html/2506.21393",
        "PDF": "https://arxiv.org/pdf/2506.21393"
      },
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 15:41:34 GMT",
          "size": "13481kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "TableMoE: Neuro-Symbolic Routing for Structured Expert Reasoning in Multimodal Table Understanding",
      "relevance": {
        "keyword": "train_data",
        "level": "strong",
        "reason": "The paper introduces the TableMoE-Align dataset comprising 1.2M table-HTML-JSON-code quadruples for model pretraining, making its contribution significant in LLM training data processing for multimodal table understanding."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21495",
      "abstract": "We investigate the effectiveness of reinforcement learning methods for finetuning large language models when transitioning from offline to semi-online to fully online regimes for both verifiable and non-verifiable tasks. Our experiments cover training on verifiable math as well as non-verifiable instruction following with a set of benchmark evaluations for both. Across these settings, we extensively compare online and semi-online Direct Preference Optimization and Group Reward Policy Optimization objectives, and surprisingly find similar performance and convergence between these variants, which all strongly outperform offline methods. We provide a detailed analysis of the training dynamics and hyperparameter selection strategies to achieve optimal results. Finally, we show that multi-tasking with verifiable and non-verifiable rewards jointly yields improved performance across both task types.",
      "authors": [
        "Jack Lanchantin",
        "Angelica Chen",
        "Janice Lan",
        "Xian Li",
        "Swarnadeep Saha",
        "Tianlu Wang",
        "Jing Xu",
        "Ping Yu",
        "Weizhe Yuan",
        "Jason E Weston",
        "Sainbayar Sukhbaatar",
        "Ilia Kulikov"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21495",
        "HTML": "https://arxiv.org/html/2506.21495",
        "PDF": "https://arxiv.org/pdf/2506.21495"
      },
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 17:25:49 GMT",
          "size": "542kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Bridging Offline and Online Reinforcement Learning for LLMs",
      "relevance": {
        "keyword": "train_data",
        "level": "strong",
        "reason": "The paper discusses fine-tuning LLMs using reinforcement learning methods in various regimes, including offline, semi-online, and fully online. It provides a detailed analysis of training dynamics and strategies, which is directly related to training-stage data processing for LLMs."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21497",
      "abstract": "Enhancing user engagement through interactions plays an essential role in socially-driven dialogues. While prior works have optimized models to reason over relevant knowledge or plan a dialogue act flow, the relationship between user engagement and knowledge or dialogue acts is subtle and does not guarantee user engagement in socially-driven dialogues. To this end, we enable interactive LLMs to learn user engagement by leveraging signals from the future development of conversations. Specifically, we adopt a more direct and relevant indicator of user engagement, i.e., the user's reaction related to dialogue intention after the interaction, as a reward to align interactive LLMs. To achieve this, we develop a user simulator to interact with target interactive LLMs and explore interactions between the user and the interactive LLM system via \\textit{i$\\times$MCTS} (\\textit{M}onte \\textit{C}arlo \\textit{T}ree \\textit{S}earch for \\textit{i}nteraction). In this way, we collect a dataset containing pairs of higher and lower-quality experiences using \\textit{i$\\times$MCTS}, and align interactive LLMs for high-level user engagement by direct preference optimization (DPO) accordingly. Experiments conducted on two socially-driven dialogue scenarios (emotional support conversations and persuasion for good) demonstrate that our method effectively enhances user engagement in interactive LLMs.",
      "authors": [
        "Jiashuo Wang",
        "Kaitao Song",
        "Chunpu Xu",
        "Changhe Song",
        "Yang Xiao",
        "Dongsheng Li",
        "Lili Qiu",
        "Wenjie Li"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21497",
        "HTML": "https://arxiv.org/html/2506.21497",
        "PDF": "https://arxiv.org/pdf/2506.21497"
      },
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 17:26:17 GMT",
          "size": "1188kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Enhancing User Engagement in Socially-Driven Dialogue through Interactive LLM Alignments",
      "relevance": {
        "keyword": "train_data",
        "level": "strong",
        "reason": "The paper develops a method to enhance user engagement in interactive LLMs using a simulator to collect data and align models via preference optimization. This involves creating and collecting data specifically for LLM training, which is relevant to the data engineering stage."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21508",
      "abstract": "In this work, we introduce skLEP, the first comprehensive benchmark specifically designed for evaluating Slovak natural language understanding (NLU) models. We have compiled skLEP to encompass nine diverse tasks that span token-level, sentence-pair, and document-level challenges, thereby offering a thorough assessment of model capabilities. To create this benchmark, we curated new, original datasets tailored for Slovak and meticulously translated established English NLU resources. Within this paper, we also present the first systematic and extensive evaluation of a wide array of Slovak-specific, multilingual, and English pre-trained language models using the skLEP tasks. Finally, we also release the complete benchmark data, an open-source toolkit facilitating both fine-tuning and evaluation of models, and a public leaderboard at https://github.com/slovak-nlp/sklep in the hopes of fostering reproducibility and drive future research in Slovak NLU.",
      "authors": [
        "Marek \\v{S}uppa",
        "Andrej Ridzik",
        "Daniel Hl\\'adek",
        "Tom\\'a\\v{s} Jav\\r{u}rek",
        "Vikt\\'oria Ondrejov\\'a",
        "Krist\\'ina S\\'asikov\\'a",
        "Martin Tamajka",
        "Mari\\'an \\v{S}imko"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21508",
        "HTML": "https://arxiv.org/html/2506.21508",
        "PDF": "https://arxiv.org/pdf/2506.21508"
      },
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Information Retrieval (cs.IR)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 17:35:04 GMT",
          "size": "154kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "skLEP: A Slovak General Language Understanding Benchmark",
      "relevance": {
        "keyword": "train_data",
        "level": "strong",
        "reason": "The paper introduces a comprehensive benchmark for Slovak NLU models and involves creating new datasets and translating existing ones, directly impacting data engineering for language model training specifically for Slovak language understanding."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21532",
      "abstract": "People are increasingly seeking healthcare information from large language models (LLMs) via interactive chatbots, yet the nature and inherent risks of these conversations remain largely unexplored. In this paper, we filter large-scale conversational AI datasets to achieve HealthChat-11K, a curated dataset of 11K real-world conversations composed of 25K user messages. We use HealthChat-11K and a clinician-driven taxonomy for how users interact with LLMs when seeking healthcare information in order to systematically study user interactions across 21 distinct health specialties. Our analysis reveals insights into the nature of how and why users seek health information, such as common interactions, instances of incomplete context, affective behaviors, and interactions (e.g., leading questions) that can induce sycophancy, underscoring the need for improvements in the healthcare support capabilities of LLMs deployed as conversational AI. Code and artifacts to retrieve our analyses and combine them into a curated dataset can be found here: https://github.com/yahskapar/HealthChat",
      "authors": [
        "Akshay Paruchuri",
        "Maryam Aziz",
        "Rohit Vartak",
        "Ayman Ali",
        "Best Uchehara",
        "Xin Liu",
        "Ishan Chatterjee",
        "Monica Agrawal"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21532",
        "HTML": "https://arxiv.org/html/2506.21532",
        "PDF": "https://arxiv.org/pdf/2506.21532"
      },
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 17:52:18 GMT",
          "size": "3985kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "\"What's Up, Doc?\": Analyzing How Users Seek Health Information in Large-Scale Conversational AI Datasets",
      "relevance": {
        "keyword": "train_data",
        "level": "strong",
        "reason": "This paper involves filtering large-scale conversational AI datasets to create HealthChat-11K, focusing on processing and analyzing LLM data specifically for healthcare applications."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21545",
      "abstract": "Data is fundamental to the training of language models (LM). Recent research has been dedicated to data efficiency, which aims to maximize performance by selecting a minimal or optimal subset of training data. Techniques such as data filtering, sampling, and selection play a crucial role in this area. To complement it, we define Data Efficacy, which focuses on maximizing performance by optimizing the organization of training data and remains relatively underexplored. This work introduces a general paradigm, DELT, for considering data efficacy in LM training, which highlights the significance of training data organization. DELT comprises three components: Data Scoring, Data Selection, and Data Ordering. Among these components, we design Learnability-Quality Scoring (LQS), as a new instance of Data Scoring, which considers both the learnability and quality of each data sample from the gradient consistency perspective. We also devise Folding Ordering (FO), as a novel instance of Data Ordering, which addresses issues such as model forgetting and data distribution bias. Comprehensive experiments validate the data efficacy in LM training, which demonstrates the following: Firstly, various instances of the proposed DELT enhance LM performance to varying degrees without increasing the data scale and model size. Secondly, among these instances, the combination of our proposed LQS for data scoring and Folding for data ordering achieves the most significant improvement. Lastly, data efficacy can be achieved together with data efficiency by applying data selection. Therefore, we believe that data efficacy is a promising foundational area in LM training.",
      "authors": [
        "Yalun Dai",
        "Yangyu Huang",
        "Xin Zhang",
        "Wenshan Wu",
        "Chong Li",
        "Wenhui Lu",
        "Shijie Cao",
        "Li Dong",
        "Scarlett Li"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21545",
        "HTML": "https://arxiv.org/html/2506.21545",
        "PDF": "https://arxiv.org/pdf/2506.21545"
      },
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 17:59:07 GMT",
          "size": "2014kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Data Efficacy for Language Model Training",
      "relevance": {
        "keyword": "train_data",
        "level": "strong",
        "reason": "The paper introduces a paradigm, DELT, that focuses on data efficacy in language model training, with components such as data scoring and order impacting data quality and organization for LLMs."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21551",
      "abstract": "Grokking, i.e., test performance keeps improving long after training loss converged, has been recently witnessed in neural network training, making the mechanism of generalization and other emerging capabilities such as reasoning mysterious. While prior studies usually train small models on a few toy or highly-specific tasks for thousands of epochs, we conduct the first study of grokking on checkpoints during one-pass pretraining of a 7B large language model (LLM), i.e., OLMoE. We compute the training loss and evaluate generalization on diverse benchmark tasks, including math reasoning, code generation, and commonsense/domain-specific knowledge retrieval tasks.\n  Our study, for the first time, verifies that grokking still happens in the pretraining of large-scale foundation models, though different data may enter grokking stages asynchronously. We further demystify grokking's \"emergence of generalization\" by investigating LLM internal dynamics. Specifically, we find that training samples' pathways (i.e., expert choices across layers) evolve from random, instance-specific to more structured and shareable between samples during grokking. Also, the complexity of a sample's pathway reduces despite the converged loss. These indicate a memorization-to-generalization conversion, providing a mechanistic explanation of delayed generalization. In the study, we develop two novel metrics to quantify pathway distance and the complexity of a single pathway. We show their ability to predict the generalization improvement on diverse downstream tasks. They are efficient, simple to compute and solely dependent on training data. Hence, they have practical value for pretraining, enabling us to monitor the generalization performance without finetuning and test. Theoretically, we show that more structured pathways reduce model complexity and improve the generalization bound.",
      "authors": [
        "Ziyue Li",
        "Chenrui Fan",
        "Tianyi Zhou"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21551",
        "HTML": "https://arxiv.org/html/2506.21551",
        "PDF": "https://arxiv.org/pdf/2506.21551"
      },
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 17:59:58 GMT",
          "size": "252kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Where to find Grokking in LLM Pretraining? Monitor Memorization-to-Generalization without Test",
      "relevance": {
        "keyword": "train_data",
        "level": "strong",
        "reason": "The paper investigates 'grokking' in LLM pretraining, which involves analyzing the training data's impact on generalization during model training. It proposes novel metrics for monitoring training data's effect on generalization, significantly contributing to understanding LLM training data processing dynamics."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21448",
      "abstract": "While end-to-end video-to-audio generation has greatly improved, producing high-fidelity audio that authentically captures the nuances of visual content remains challenging. Like professionals in the creative industries, such generation requires sophisticated reasoning about items such as visual dynamics, acoustic environments, and temporal relationships. We present \\textbf{ThinkSound}, a novel framework that leverages Chain-of-Thought (CoT) reasoning to enable stepwise, interactive audio generation and editing for videos. Our approach decomposes the process into three complementary stages: foundational foley generation that creates semantically coherent soundscapes, interactive object-centric refinement through precise user interactions, and targeted editing guided by natural language instructions. At each stage, a multimodal large language model generates contextually aligned CoT reasoning that guides a unified audio foundation model. Furthermore, we introduce \\textbf{AudioCoT}, a comprehensive dataset with structured reasoning annotations that establishes connections between visual content, textual descriptions, and sound synthesis. Experiments demonstrate that ThinkSound achieves state-of-the-art performance in video-to-audio generation across both audio metrics and CoT metrics and excels in out-of-distribution Movie Gen Audio benchmark. The demo page is available at https://ThinkSound-Demo.github.io.",
      "authors": [
        "Huadai Liu",
        "Jialei Wang",
        "Kaicheng Luo",
        "Wen Wang",
        "Qian Chen",
        "Zhou Zhao",
        "Wei Xue"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21448",
        "HTML": "https://arxiv.org/html/2506.21448",
        "PDF": "https://arxiv.org/pdf/2506.21448"
      },
      "subjects": [
        "Audio and Speech Processing (eess.AS)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Sound (cs.SD)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 16:32:06 GMT",
          "size": "4503kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "ThinkSound: Chain-of-Thought Reasoning in Multimodal Large Language Models for Audio Generation and Editing",
      "relevance": {
        "keyword": "train_data",
        "level": "strong",
        "reason": "The paper introduces a novel framework involving a new dataset (AudioCoT) with structured reasoning annotations for multimodal LLMs, contributing to data processing methodologies for audio generation, which aligns with training-stage data processing."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2308.04386",
      "abstract": "Automatic evaluation of sequence generation, traditionally reliant on metrics like BLEU and ROUGE, often fails to capture the semantic accuracy of generated text sequences due to their emphasis on n-gram overlap. A promising solution to this problem is to develop model-based metrics, such as BLEURT and COMET. However, these approaches are typically hindered by the scarcity of labeled evaluation data, which is necessary to train the evaluation models. In this work, we build upon this challenge by proposing the Customized Sequence Evaluation Metric (CSEM), a three-stage evaluation model training method that utilizes large language models to generate labeled data for model-based metric development, thereby eliminating the need for human-labeled data. Additionally, we expand the scope of CSEM to support various evaluation types, including single-aspect, multi-aspect, reference-free, and reference-based evaluations, enabling the customization of metrics to suit diverse real-world scenarios. Experimental results on the SummEval benchmark demonstrate that CSEM can effectively train an evaluation model without human-labeled data. Further experiments in reinforcement learning and reranking show that metrics developed through CSEM outperform traditional evaluation metrics, leading to substantial improvements in sequence quality as evaluated by both commonly used metrics and ChatGPT.",
      "authors": [
        "Chenglong Wang",
        "Hang Zhou",
        "Kaiyan Chang",
        "Tongran Liu",
        "Chunliang Zhang",
        "Quan Du",
        "Tong Xiao",
        "Yue Zhang",
        "and Jingbo Zhu"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2308.04386",
        "HTML": "https://arxiv.org/html/2308.04386",
        "PDF": "https://arxiv.org/pdf/2308.04386"
      },
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 08 Aug 2023 16:41:16 GMT",
          "size": "146kb",
          "version": "v1"
        },
        {
          "date": "Tue, 25 Mar 2025 12:00:54 GMT",
          "size": "4205kb",
          "version": "v2"
        },
        {
          "date": "Thu, 26 Jun 2025 10:00:23 GMT",
          "size": "221kb",
          "version": "v3"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Learning Evaluation Models from Large Language Models for Sequence Generation",
      "relevance": {
        "keyword": "train_data",
        "level": "strong",
        "reason": "The paper proposes a method for generating labeled data for training evaluation models without human intervention, using large language models. This directly involves processing training data by creating evaluation data, relevant to LLM data preparation."
      },
      "tasks": [
        "Machine Translation",
        "Reranking",
        "Style Transfer",
        "Text Style Transfer"
      ],
      "repo_urls": [
        "https://github.com/wangclnlp/csem"
      ],
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2406.11933",
      "abstract": "Masked Image Modeling (MIM) has become an essential method for building foundational visual models in remote sensing (RS). However, the limitations in size and diversity of existing RS datasets restrict the ability of MIM methods to learn generalizable representations. Additionally, conventional MIM techniques, which require reconstructing all tokens, introduce unnecessary computational overhead. To address these issues, we present a new pre-training pipeline for RS models, featuring the creation of a large-scale RS dataset and an efficient MIM approach. We curated a high-quality dataset named \\textbf{OpticalRS-13M} by collecting publicly available RS datasets and processing them through exclusion, slicing, and deduplication. OpticalRS-13M comprises 13 million optical images covering various RS tasks, such as object detection and pixel segmentation. To enhance efficiency, we propose \\textbf{SelectiveMAE}, a pre-training method that dynamically encodes and reconstructs semantically rich patch tokens, thereby reducing the inefficiencies of traditional MIM models caused by redundant background pixels in RS images. Extensive experiments show that OpticalRS-13M significantly improves classification, detection, and segmentation performance, while SelectiveMAE increases training efficiency over 2$\\times$ times. This highlights the effectiveness and scalability of our pipeline in developing RS foundational models. The dataset, source code, and trained models will be released at https://github.com/MiliLab/SelectiveMAE.",
      "authors": [
        "Fengxiang Wang",
        "Hongzhen Wang",
        "Di Wang",
        "Zonghao Guo",
        "Zhenyu Zhong",
        "Long Lan",
        "Wenjing Yang",
        "Jing Zhang"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2406.11933",
        "HTML": "https://arxiv.org/html/2406.11933",
        "PDF": "https://arxiv.org/pdf/2406.11933"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Mon, 17 Jun 2024 15:41:57 GMT",
          "size": "10655kb",
          "version": "v1"
        },
        {
          "date": "Thu, 29 Aug 2024 17:16:13 GMT",
          "size": "8372kb",
          "version": "v2"
        },
        {
          "date": "Fri, 30 Aug 2024 15:08:13 GMT",
          "size": "10538kb",
          "version": "v3"
        },
        {
          "date": "Fri, 06 Dec 2024 15:10:36 GMT",
          "size": "7677kb",
          "version": "v4"
        },
        {
          "date": "Thu, 26 Jun 2025 15:47:30 GMT",
          "size": "7137kb",
          "version": "v5"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Harnessing Massive Satellite Imagery with Efficient Masked Image Modeling",
      "relevance": {
        "keyword": "train_data",
        "level": "strong",
        "reason": "The paper presents a pipeline for creating a large-scale high-quality dataset named OpticalRS-13M including methods like exclusion, slicing, and deduplication, which is a significant contribution to LLM training data processing in terms of data collection and preparation."
      },
      "tasks": [
        "Aerial Scene Classification",
        "Diversity",
        "object-detection",
        "Object Detection",
        "Object Detection In Aerial Images",
        "Semantic Segmentation",
        "Sence Classification"
      ],
      "repo_urls": [
        "https://github.com/Fengxiang23/SelectiveMAE"
      ],
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2410.05090",
      "abstract": "Influence functions provide a principled method to assess the contribution of individual training samples to a specific target. Yet, their high computational costs limit their applications on large-scale models and datasets. Existing methods proposed for influence function approximation have significantly reduced the computational overheads. However, they mostly suffer from inaccurate estimation due to the lack of strong convergence guarantees from the algorithm. The family of hyperpower methods are well-known for their rigorous convergence guarantees on matrix inverse approximation, while the matrix multiplication operation can involve intractable memory and computation costs on large-scale models. We propose HyperINF, an efficient and accurate influence function approximation method which leverages the hyperpower method, specifically Schulz's iterative algorithm. To deal with the computation-intensive matrix multiplication, we incorporate the generalized fisher information (GFIM) as a low-rank approximation of the Hessian matrix, which reduces the memory and computation overheads to constant costs independent of ranks on LoRA-tuned models. We first demonstrate the superior accuracy and stability of HyperINF compared to other baselines through a synthetic convergence simulation for matrix inversion. We further validate the efficacy of HyperINF through extensive real-world data attribution tasks, including mislabeled data detection and data selection for LLM and VLM fine-tuning. On LoRA-tuned models, HyperINF achieves superior downstream performance with minimal memory and computational overhead, while other baselines suffer from significant degradation. Our codebase is available at https://github.com/Blackzxy/HyperINF.",
      "authors": [
        "Xinyu Zhou",
        "Simin Fan",
        "Martin Jaggi"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.05090",
        "HTML": "https://arxiv.org/html/2410.05090",
        "PDF": "https://arxiv.org/pdf/2410.05090"
      },
      "subjects": [
        "Machine Learning (cs.LG)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "Mon, 07 Oct 2024 14:42:45 GMT",
          "size": "3217kb",
          "version": "v1"
        },
        {
          "date": "Wed, 25 Jun 2025 23:23:23 GMT",
          "size": "3746kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "HyperINF: Unleashing the HyperPower of the Schulz's Method for Data Influence Estimation",
      "relevance": {
        "keyword": "train_data",
        "level": "strong",
        "reason": "The paper proposes HyperINF, which is a method for influence function approximation for data attribution tasks like mislabeled data detection and selection for LLM fine-tuning. This directly involves data processing for LLM training."
      },
      "tasks": [],
      "repo_urls": [
        "https://github.com/blackzxy/hyperinf"
      ],
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2410.21909",
      "abstract": "The modeling of industrial scenes is essential for simulations in industrial manufacturing. While large language models (LLMs) have shown significant progress in generating general 3D scenes from textual descriptions, generating industrial scenes with LLMs poses a unique challenge due to their demand for precise measurements and positioning, requiring complex planning over spatial arrangement. To address this challenge, we introduce SceneGenAgent, an LLM-based agent for generating industrial scenes through C# code. SceneGenAgent ensures precise layout planning through a structured and calculable format, layout verification, and iterative refinement to meet the quantitative requirements of industrial scenarios. Experiment results demonstrate that LLMs powered by SceneGenAgent exceed their original performance, reaching up to 81.0% success rate in real-world industrial scene generation tasks and effectively meeting most scene generation requirements. To further enhance accessibility, we construct SceneInstruct, a dataset designed for fine-tuning open-source LLMs to integrate into SceneGenAgent. Experiments show that fine-tuning open-source LLMs on SceneInstruct yields significant performance improvements, with Llama3.1-70B approaching the capabilities of GPT-4o. Our code and data are available at https://github.com/THUDM/SceneGenAgent .",
      "authors": [
        "Xiao Xia",
        "Dan Zhang",
        "Zibo Liao",
        "Zhenyu Hou",
        "Tianrui Sun",
        "Jing Li",
        "Ling Fu",
        "Yuxiao Dong"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.21909",
        "HTML": "https://arxiv.org/html/2410.21909",
        "PDF": "https://arxiv.org/pdf/2410.21909"
      },
      "subjects": [
        "Computation and Language (cs.CL)",
        "Machine Learning (cs.LG)",
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 29 Oct 2024 10:01:40 GMT",
          "size": "1750kb",
          "version": "v1"
        },
        {
          "date": "Thu, 15 May 2025 16:40:39 GMT",
          "size": "1750kb",
          "version": "v2"
        },
        {
          "date": "Thu, 26 Jun 2025 06:24:08 GMT",
          "size": "3067kb",
          "version": "v3"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "SceneGenAgent: Precise Industrial Scene Generation with Coding Agent",
      "relevance": {
        "keyword": "train_data",
        "level": "strong",
        "reason": "The paper introduces SceneInstruct, a dataset specifically designed for fine-tuning open-source LLMs to improve industrial scene generation capabilities with SceneGenAgent. This involves data preparation and processing for fine-tuning, aligning with LLM training-stage data processing."
      },
      "tasks": [
        "C++ code",
        "Scene Generation"
      ],
      "repo_urls": [
        "https://github.com/thudm/scenegenagent"
      ],
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2411.02136",
      "abstract": "This paper presents a framework for extracting georeferenced vehicle trajectories from high-altitude drone imagery, addressing key challenges in urban traffic monitoring and the limitations of traditional ground-based systems. Our approach integrates several novel contributions, including a tailored object detector optimized for high-altitude bird's-eye view perspectives, a unique track stabilization method that uses detected vehicle bounding boxes as exclusion masks during image registration, and an orthophoto and master frame-based georeferencing strategy that enhances consistent alignment across multiple drone viewpoints. Additionally, our framework features robust vehicle dimension estimation and detailed road segmentation, enabling comprehensive traffic analysis. Conducted in the Songdo International Business District, South Korea, the study utilized a multi-drone experiment covering 20 intersections, capturing approximately 12TB of 4K video data over four days. The framework produced two high-quality datasets: the Songdo Traffic dataset, comprising approximately 700,000 unique vehicle trajectories, and the Songdo Vision dataset, containing over 5,000 human-annotated images with about 300,000 vehicle instances in four classes. Comparisons with high-precision sensor data from an instrumented probe vehicle highlight the accuracy and consistency of our extraction pipeline in dense urban environments. The public release of Songdo Traffic and Songdo Vision, and the complete source code for the extraction pipeline, establishes new benchmarks in data quality, reproducibility, and scalability in traffic research. Results demonstrate the potential of integrating drone technology with advanced computer vision for precise and cost-effective urban traffic monitoring, providing valuable resources for developing intelligent transportation systems and enhancing traffic management strategies.",
      "authors": [
        "Robert Fonod and Haechan Cho and Hwasoo Yeo and Nikolas Geroliminis"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.02136",
        "HTML": "https://arxiv.org/html/2411.02136",
        "PDF": "https://arxiv.org/pdf/2411.02136"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Mon, 04 Nov 2024 14:49:01 GMT",
          "size": "33059kb",
          "version": "v1"
        },
        {
          "date": "Mon, 17 Mar 2025 09:25:50 GMT",
          "size": "34768kb",
          "version": "v2"
        },
        {
          "date": "Wed, 25 Jun 2025 20:45:19 GMT",
          "size": "34769kb",
          "version": "v3"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Advanced computer vision for extracting georeferenced vehicle trajectories from drone imagery",
      "relevance": {
        "keyword": "train_data",
        "level": "strong",
        "reason": "This paper presents a framework for extracting vehicle trajectories from drone imagery, resulting in the creation of large-scale datasets like Songdo Traffic and Songdo Vision. This involves data collection and construction, important aspects of the data engineering stage."
      },
      "tasks": [
        "4k",
        "geo-localization",
        "Image Registration",
        "Keypoint detection and image matching",
        "Object Detection",
        "Object Tracking",
        "vehicle detection",
        "Video Stabilization"
      ],
      "repo_urls": [
        "https://github.com/rfonod/stabilo",
        "https://github.com/rfonod/geo-trax",
        "https://github.com/aixmobility/the-drift",
        "https://github.com/rfonod/stabilo-optimize"
      ],
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2411.02398",
      "abstract": "Although multilingual LLMs have achieved remarkable performance across benchmarks, we find they continue to underperform on non-Latin script languages across contemporary LLM families. This discrepancy arises from the fact that LLMs are pretrained with orthographic scripts, which are dominated by Latin characters that obscure their shared phonology with non-Latin scripts. We propose leveraging phonemic transcriptions as complementary signals to induce script-invariant representations. Our study demonstrates that integrating phonemic signals improves performance across both non-Latin and Latin script languages, with a particularly significant impact on closing the performance gap between the two. Through detailed experiments, we show that phonemic and orthographic scripts retrieve distinct examples for in-context learning (ICL). This motivates our proposed Mixed-ICL retrieval strategy, where further aggregation from both leads to our significant performance improvements for both Latin script languages (up to 12.6%) and non-Latin script languages (up to 15.1%) compared to randomized ICL retrieval.",
      "authors": [
        "Hoang H Nguyen",
        "Khyati Mahajan",
        "Vikas Yadav",
        "Julian Salazar",
        "Philip S. Yu",
        "Masoud Hashemi",
        "Rishabh Maheshwary"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.02398",
        "HTML": "https://arxiv.org/html/2411.02398",
        "PDF": "https://arxiv.org/pdf/2411.02398"
      },
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Mon, 04 Nov 2024 18:59:51 GMT",
          "size": "3577kb",
          "version": "v1"
        },
        {
          "date": "Thu, 06 Mar 2025 05:46:40 GMT",
          "size": "3760kb",
          "version": "v2"
        },
        {
          "date": "Thu, 26 Jun 2025 17:22:53 GMT",
          "size": "511kb",
          "version": "v3"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Prompting with Phonemes: Enhancing LLMs' Multilinguality for Non-Latin Script Languages",
      "relevance": {
        "keyword": "train_data",
        "level": "strong",
        "reason": "The paper proposes using phonemic transcriptions to enhance multilingual LLM performance, focusing on data processing at the training stage to improve script-invariant representations. This directly relates to improving the data used in training LLMs."
      },
      "tasks": [
        "In-Context Learning",
        "Retrieval"
      ],
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2412.04292",
      "abstract": "The rapid advancement of generative models in creating highly realistic images poses substantial risks for misinformation dissemination. For instance, a synthetic image, when shared on social media, can mislead extensive audiences and erode trust in digital content, resulting in severe repercussions. Despite some progress, academia has not yet created a large and diversified deepfake detection dataset for social media, nor has it devised an effective solution to address this issue. In this paper, we introduce the Social media Image Detection dataSet (SID-Set), which offers three key advantages: (1) extensive volume, featuring 300K AI-generated/tampered and authentic images with comprehensive annotations, (2) broad diversity, encompassing fully synthetic and tampered images across various classes, and (3) elevated realism, with images that are predominantly indistinguishable from genuine ones through mere visual inspection. Furthermore, leveraging the exceptional capabilities of large multimodal models, we propose a new image deepfake detection, localization, and explanation framework, named SIDA (Social media Image Detection, localization, and explanation Assistant). SIDA not only discerns the authenticity of images, but also delineates tampered regions through mask prediction and provides textual explanations of the model's judgment criteria. Compared with state-of-the-art deepfake detection models on SID-Set and other benchmarks, extensive experiments demonstrate that SIDA achieves superior performance among diversified settings. The code, model, and dataset will be released.",
      "authors": [
        "Zhenglin Huang",
        "Jinwei Hu",
        "Xiangtai Li",
        "Yiwei He",
        "Xingyu Zhao",
        "Bei Peng",
        "Baoyuan Wu",
        "Xiaowei Huang",
        "Guangliang Cheng"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.04292",
        "HTML": "https://arxiv.org/html/2412.04292",
        "PDF": "https://arxiv.org/pdf/2412.04292"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 05 Dec 2024 16:12:25 GMT",
          "size": "3148kb",
          "version": "v1"
        },
        {
          "date": "Mon, 10 Mar 2025 11:03:16 GMT",
          "size": "3148kb",
          "version": "v2"
        },
        {
          "date": "Wed, 25 Jun 2025 21:47:50 GMT",
          "size": "3146kb",
          "version": "v3"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "SIDA: Social Media Image Deepfake Detection, Localization and Explanation with Large Multimodal Model",
      "relevance": {
        "keyword": "train_data",
        "level": "strong",
        "reason": "The paper introduces a new dataset (SID-Set) for deepfake detection in social media, which is a critical step in data engineering. It also develops a framework (SIDA) that utilizes this dataset, contributing significantly to the task of dataset construction and curation."
      },
      "models": [
        {
          "model_path": "saberzl/SIDA-13B-description",
          "downloads": "52",
          "likes": "2",
          "trending_score": "0.0",
          "link": "https://huggingface.co/saberzl/SIDA-13B-description"
        },
        {
          "model_path": "saberzl/SIDA-7B-description",
          "downloads": "58",
          "likes": "2",
          "trending_score": "0.0",
          "link": "https://huggingface.co/saberzl/SIDA-7B-description"
        },
        {
          "model_path": "saberzl/SIDA-7B",
          "downloads": "774",
          "likes": "4",
          "trending_score": "0.0",
          "link": "https://huggingface.co/saberzl/SIDA-7B"
        },
        {
          "model_path": "saberzl/SIDA-13B",
          "downloads": "36",
          "likes": "2",
          "trending_score": "0.0",
          "link": "https://huggingface.co/saberzl/SIDA-13B"
        }
      ],
      "conference_url_abs": "http://openaccess.thecvf.com//content/CVPR2025/html/Huang_SIDA_Social_Media_Image_Deepfake_Detection_Localization_and_Explanation_with_CVPR_2025_paper.html",
      "tasks": [
        "DeepFake Detection",
        "Face Swapping",
        "Misinformation"
      ],
      "repo_urls": [
        "https://github.com/hzlsaber/sida"
      ],
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2412.09587",
      "abstract": "We present OpenNER 1.0, a standardized collection of openly-available named entity recognition (NER) datasets. OpenNER contains 36 NER corpora that span 52 languages, human-annotated in varying named entity ontologies. We correct annotation format issues, standardize the original datasets into a uniform representation with consistent entity type names across corpora, and provide the collection in a structure that enables research in multilingual and multi-ontology NER. We provide baseline results using three pretrained multilingual language models and two large language models to compare the performance of recent models and facilitate future research in NER. We find that no single model is best in all languages and that significant work remains to obtain high performance from LLMs on the NER task.",
      "authors": [
        "Chester Palen-Michel",
        "Maxwell Pickering",
        "Maya Kruse",
        "Jonne S\\\"alev\\\"a",
        "and Constantine Lignos"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.09587",
        "HTML": "https://arxiv.org/html/2412.09587",
        "PDF": "https://arxiv.org/pdf/2412.09587"
      },
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 12 Dec 2024 18:55:53 GMT",
          "size": "199kb",
          "version": "v1"
        },
        {
          "date": "Thu, 26 Jun 2025 17:51:40 GMT",
          "size": "222kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "OpenNER 1.0: Standardized Open-Access Named Entity Recognition Datasets in 50+ Languages",
      "relevance": {
        "keyword": "train_data",
        "level": "strong",
        "reason": "The introduction of OpenNER 1.0 represents a significant advancement in constructing and standardizing datasets for NER tasks, directly impacting data quality and processing for LLM applications in multilingual contexts."
      },
      "tasks": [
        "named-entity-recognition",
        "Named Entity Recognition",
        "Named Entity Recognition (NER)",
        "NER",
        "Pretrained Multilingual Language Models"
      ],
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2412.10943",
      "abstract": "While the human visual system employs distinct mechanisms to perceive salient and camouflaged objects, existing models struggle to disentangle these tasks. Specifically, salient object detection (SOD) models frequently misclassify camouflaged objects as salient, while camouflaged object detection (COD) models conversely misinterpret salient objects as camouflaged. We hypothesize that this can be attributed to two factors: (i) the specific annotation paradigm of current SOD and COD datasets, and (ii) the lack of explicit attribute relationship modeling in current models. Prevalent SOD/COD datasets enforce a mutual exclusivity constraint, assuming scenes contain either salient or camouflaged objects, which poorly aligns with the real world. Furthermore, current SOD/COD methods are primarily designed for these highly constrained datasets and lack explicit modeling of the relationship between salient and camouflaged objects. In this paper, to promote the development of unconstrained salient and camouflaged object detection, we construct a large-scale dataset, USC12K, which features comprehensive labels and four different scenes that cover all possible logical existence scenarios of both salient and camouflaged objects. To explicitly model the relationship between salient and camouflaged objects, we propose a model called USCNet, which introduces two distinct prompt query mechanisms for modeling inter-sample and intra-sample attribute relationships. Additionally, to assess the model's ability to distinguish between salient and camouflaged objects, we design an evaluation metric called CSCS. The proposed method achieves state-of-the-art performance across all scenes in various metrics. The code and dataset will be available at https://github.com/ssecv/USCNet.",
      "authors": [
        "Zhangjun Zhou",
        "Yiping Li",
        "Chunlin Zhong",
        "Jianuo Huang",
        "Jialun Pei",
        "Hua Li and He Tang"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.10943",
        "HTML": "https://arxiv.org/html/2412.10943",
        "PDF": "https://arxiv.org/pdf/2412.10943"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Sat, 14 Dec 2024 19:37:17 GMT",
          "size": "24324kb",
          "version": "v1"
        },
        {
          "date": "Thu, 26 Jun 2025 14:53:27 GMT",
          "size": "14058kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Rethinking Detecting Salient and Camouflaged Objects in Unconstrained Scenes",
      "relevance": {
        "keyword": "train_data",
        "level": "strong",
        "reason": "The paper constructs a large-scale dataset, USC12K, aimed at improving salient and camouflaged object detection, a significant contribution to data construction and processing for these tasks, aligning with the data engineering stage for training data."
      },
      "tasks": [
        "Attribute",
        "Object",
        "object-detection",
        "Object Detection",
        "Salient Object Detection"
      ],
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2502.15680",
      "abstract": "Due to the sensitive nature of personally identifiable information (PII), its owners may have the authority to control its inclusion or request its removal from large-language model (LLM) training. Beyond this, PII may be added or removed from training datasets due to evolving dataset curation techniques, because they were newly scraped for retraining, or because they were included in a new downstream fine-tuning stage. We find that the amount and ease of PII memorization is a dynamic property of a model that evolves throughout training pipelines and depends on commonly altered design choices. We characterize three such novel phenomena: (1) similar-appearing PII seen later in training can elicit memorization of earlier-seen sequences in what we call assisted memorization, and this is a significant factor (in our settings, up to 1/3); (2) adding PII can increase memorization of other PII significantly (in our settings, as much as $\\approx\\!7.5\\times$); and (3) removing PII can lead to other PII being memorized. Model creators should consider these first- and second-order privacy risks when training models to avoid the risk of new PII regurgitation.",
      "authors": [
        "Jaydeep Borkar",
        "Matthew Jagielski",
        "Katherine Lee",
        "Niloofar Mireshghallah",
        "David A. Smith",
        "Christopher A. Choquette-Choo"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.15680",
        "HTML": "https://arxiv.org/html/2502.15680",
        "PDF": "https://arxiv.org/pdf/2502.15680"
      },
      "subjects": [
        "Computation and Language (cs.CL)",
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "Fri, 21 Feb 2025 18:59:14 GMT",
          "size": "9975kb",
          "version": "v1"
        },
        {
          "date": "Wed, 25 Jun 2025 21:37:19 GMT",
          "size": "9984kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Privacy Ripple Effects from Adding or Removing Personal Information in Language Model Training",
      "relevance": {
        "keyword": "train_data",
        "level": "strong",
        "reason": "The paper focuses on the inclusion and removal of personally identifiable information (PII) in LLM training datasets, which impacts data memorization and privacy. It discusses the dynamic properties of PII handling in training pipelines, directly relating to data processing for LLMs."
      },
      "tasks": [
        "Language Modeling",
        "Language Modelling",
        "Large Language Model",
        "Memorization"
      ],
      "repo_urls": [
        "https://github.com/jaydeepborkar/Assisted-Memorization"
      ],
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.01495",
      "abstract": "Ensuring that Large Language Models (LLMs) align with mainstream human values and ethical norms is crucial for the safe and sustainable development of AI. Current value evaluation and alignment are constrained by Western cultural bias and incomplete domestic frameworks reliant on non-native rules; furthermore, the lack of scalable, rule-driven scenario generation methods makes evaluations costly and inadequate across diverse cultural contexts. To address these challenges, we propose a hierarchical value framework grounded in core Chinese values, encompassing three main dimensions, 12 core values, and 50 derived values. Based on this framework, we construct a large-scale Chinese Values Corpus (CVC) containing over 250,000 value rules enhanced and expanded through human annotation. Experimental results show that CVC-guided scenarios outperform direct generation ones in value boundaries and content diversity. In the evaluation across six sensitive themes (e.g., surrogacy, suicide), seven mainstream LLMs preferred CVC-generated options in over 70.5% of cases, while five Chinese human annotators showed an 87.5% alignment with CVC, confirming its universality, cultural relevance, and strong alignment with Chinese values. Additionally, we construct 400,000 rule-based moral dilemma scenarios that objectively capture nuanced distinctions in conflicting value prioritization across 17 LLMs. Our work establishes a culturally-adaptive benchmarking framework for comprehensive value evaluation and alignment, representing Chinese characteristics. All data are available at https://huggingface.co/datasets/Beijing-AISI/CVC, and the code is available at https://github.com/Beijing-AISI/CVC.",
      "authors": [
        "Ping Wu",
        "Guobin Shen",
        "Dongcheng Zhao",
        "Yuwei Wang",
        "Yiting Dong",
        "Yu Shi",
        "Enmeng Lu",
        "Feifei Zhao",
        "Yi Zeng"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.01495",
        "HTML": "https://arxiv.org/html/2506.01495",
        "PDF": "https://arxiv.org/pdf/2506.01495"
      },
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "Mon, 02 Jun 2025 09:56:59 GMT",
          "size": "5614kb",
          "version": "v1"
        },
        {
          "date": "Sat, 07 Jun 2025 07:06:31 GMT",
          "size": "5614kb",
          "version": "v2"
        },
        {
          "date": "Thu, 19 Jun 2025 13:47:55 GMT",
          "size": "5614kb",
          "version": "v3"
        },
        {
          "date": "Thu, 26 Jun 2025 11:34:33 GMT",
          "size": "5614kb",
          "version": "v4"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "CVC: A Large-Scale Chinese Value Rule Corpus for Value Alignment of Large Language Models",
      "relevance": {
        "keyword": "train_data",
        "level": "strong",
        "reason": "The paper's primary contribution is the construction of a large-scale Chinese Values Corpus (CVC) for LLMs, directly related to creating and processing training data by enhancing it through human annotation and constructing rule-based moral dilemma scenarios."
      },
      "tasks": [
        "Benchmarking"
      ],
      "repo_urls": [
        "https://github.com/beijing-aisi/cvc"
      ],
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.19054",
      "abstract": "As LLMs become widespread across diverse applications, concerns about the security and safety of LLM interactions have intensified. Numerous guardrail models and benchmarks have been developed to ensure LLM content safety. However, existing guardrail benchmarks are often built upon ad hoc risk taxonomies that lack a principled grounding in standardized safety policies, limiting their alignment with real-world operational requirements. Moreover, they tend to overlook domain-specific risks, while the same risk category can carry different implications across different domains. To bridge these gaps, we introduce GuardSet-X, the first massive multi-domain safety policy-grounded guardrail dataset. GuardSet-X offers: (1) broad domain coverage across eight safety-critical domains, such as finance, law, and codeGen; (2) policy-grounded risk construction based on authentic, domain-specific safety guidelines; (3) diverse interaction formats, encompassing declarative statements, questions, instructions, and multi-turn conversations; (4) advanced benign data curation via detoxification prompting to challenge over-refusal behaviors; and (5) \\textbf{attack-enhanced instances} that simulate adversarial inputs designed to bypass guardrails. Based on GuardSet-X, we benchmark 19 advanced guardrail models and uncover a series of findings, such as: (1) All models achieve varied F1 scores, with many demonstrating high variance across risk categories, highlighting their limited domain coverage and insufficient handling of domain-specific safety concerns; (2) As models evolve, their coverage of safety risks broadens, but performance on common risk categories may decrease; (3) All models remain vulnerable to optimized adversarial attacks. We believe that \\dataset and the unique insights derived from our evaluations will advance the development of policy-aligned and resilient guardrail systems.",
      "authors": [
        "Mintong Kang",
        "Zhaorun Chen",
        "Chejian Xu",
        "Jiawei Zhang",
        "Chengquan Guo",
        "Minzhou Pan",
        "Ivan Revilla",
        "Yu Sun",
        "Bo Li"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.19054",
        "HTML": "https://arxiv.org/html/2506.19054",
        "PDF": "https://arxiv.org/pdf/2506.19054"
      },
      "subjects": [
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 18 Jun 2025 01:35:33 GMT",
          "size": "3611kb",
          "version": "v1"
        },
        {
          "date": "Thu, 26 Jun 2025 03:18:08 GMT",
          "size": "3611kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "GuardSet-X: Massive Multi-Domain Safety Policy-Grounded Guardrail Dataset",
      "relevance": {
        "keyword": "train_data",
        "level": "strong",
        "reason": "The paper introduces GuardSet-X, a dataset specifically designed for training and benchmarking LLM guardrail models. This involves safety policy-grounded data construction across multiple domains, aligning closely with LLM training-stage data processing and data engineering tasks, focusing on safety and risk mitigation."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.19268",
      "abstract": "We present HARPT, a large-scale annotated corpus of mobile health app store reviews aimed at advancing research in user privacy and trust. The dataset comprises over 480,000 user reviews labeled into seven categories that capture critical aspects of trust in applications, trust in providers and privacy concerns. Creating HARPT required addressing multiple complexities, such as defining a nuanced label schema, isolating relevant content from large volumes of noisy data, and designing an annotation strategy that balanced scalability with accuracy. This strategy integrated rule-based filtering, iterative manual labeling with review, targeted data augmentation, and weak supervision using transformer-based classifiers to accelerate coverage. In parallel, a carefully curated subset of 7,000 reviews was manually annotated to support model development and evaluation. We benchmark a broad range of classification models, demonstrating that strong performance is achievable and providing a baseline for future research. HARPT is released as a public resource to support work in health informatics, cybersecurity, and natural language processing.",
      "authors": [
        "Timoteo Kelly",
        "Abdulkadir Korkmaz",
        "Samuel Mallet",
        "Connor Souders",
        "Sadra Aliakbarpour",
        "Praveen Rao"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.19268",
        "HTML": "https://arxiv.org/html/2506.19268",
        "PDF": "https://arxiv.org/pdf/2506.19268"
      },
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Cryptography and Security (cs.CR)",
        "Emerging Technologies (cs.ET)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 24 Jun 2025 02:59:14 GMT",
          "size": "213kb",
          "version": "v1"
        },
        {
          "date": "Thu, 26 Jun 2025 15:23:54 GMT",
          "size": "213kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "HARPT: A Corpus for Analyzing Consumers' Trust and Privacy Concerns in Mobile Health Apps",
      "relevance": {
        "keyword": "train_data",
        "level": "strong",
        "reason": "The HARPT dataset paper discusses methods related to dataset construction and annotation, including noise reduction and data augmentation, which are directly related to data engineering tasks for LLM training. It highlights efforts to create a nuanced, high-quality annotated corpus, relevant for LLM data quality enhancement."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2412.18108",
      "abstract": "Recent advancements in Multimodal Large Language Models (MLLMs) have demonstrated remarkable progress in visual understanding. This impressive leap raises a compelling question: how can language models, initially trained solely on linguistic data, effectively interpret and process visual content? This paper aims to address this question with systematic investigation across 4 model families and 4 model scales, uncovering a unique class of attention heads that focus specifically on visual content. Our analysis reveals a strong correlation between the behavior of these attention heads, the distribution of attention weights, and their concentration on visual tokens within the input. These findings enhance our understanding of how LLMs adapt to multimodal tasks, demonstrating their potential to bridge the gap between textual and visual understanding. This work paves the way for the development of AI systems capable of engaging with diverse modalities.",
      "authors": [
        "Jing Bi",
        "Junjia Guo",
        "Yunlong Tang",
        "Lianggong Bruce Wen",
        "Zhang Liu",
        "Chenliang Xu"
      ],
      "last_revised_date": "2024/12/24",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.18108",
        "HTML": "https://arxiv.org/html/2412.18108",
        "PDF": "https://arxiv.org/pdf/2412.18108"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 24 Dec 2024 02:31:24 GMT",
          "size": "6927kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2024/12/24",
      "title": "Unveiling Visual Perception in Language Models: An Attention Head Analysis Approach",
      "relevance": {
        "keyword": "train_data",
        "level": "weak",
        "reason": "The paper investigates visual perceptions in LLMs with an emphasis on multimodal tasks but does not propose new data processing methods for LLM training or processing."
      },
      "conference_url_abs": "http://openaccess.thecvf.com//content/CVPR2025/html/Bi_Unveiling_Visual_Perception_in_Language_Models_An_Attention_Head_Analysis_CVPR_2025_paper.html",
      "tasks": [],
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2504.15217",
      "abstract": "We present Distributional RewArds for Generative OptimizatioN (DRAGON), a versatile framework for fine-tuning media generation models towards a desired outcome. Compared with traditional reinforcement learning with human feedback (RLHF) or pairwise preference approaches such as direct preference optimization (DPO), DRAGON is more flexible. It can optimize reward functions that evaluate either individual examples or distributions of them, making it compatible with a broad spectrum of instance-wise, instance-to-distribution, and distribution-to-distribution rewards. Leveraging this versatility, we construct novel reward functions by selecting an encoder and a set of reference examples to create an exemplar distribution. When cross-modality encoders such as CLAP are used, the reference examples may be of a different modality (e.g., text versus audio). Then, DRAGON gathers online and on-policy generations, scores them to construct a positive demonstration set and a negative set, and leverages the contrast between the two sets to maximize the reward. For evaluation, we fine-tune an audio-domain text-to-music diffusion model with 20 different reward functions, including a custom music aesthetics model, CLAP score, Vendi diversity, and Frechet audio distance (FAD). We further compare instance-wise (per-song) and full-dataset FAD settings while ablating multiple FAD encoders and reference sets. Over all 20 target rewards, DRAGON achieves an 81.45% average win rate. Moreover, reward functions based on exemplar sets indeed enhance generations and are comparable to model-based rewards. With an appropriate exemplar set, DRAGON achieves a 60.95% human-voted music quality win rate without training on human preference annotations. As such, DRAGON exhibits a new approach to designing and optimizing reward functions for improving human-perceived quality. Sound examples at https://ml-dragon.github.io/web.",
      "authors": [
        "Yatong Bai and Jonah Casebeer and Somayeh Sojoudi and Nicholas J. Bryan"
      ],
      "last_revised_date": "2025/04/21",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.15217",
        "HTML": "https://arxiv.org/html/2504.15217",
        "PDF": "https://arxiv.org/pdf/2504.15217"
      },
      "subjects": [
        "Sound (cs.SD)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)",
        "Multimedia (cs.MM)"
      ],
      "submission_historys": [
        {
          "date": "Mon, 21 Apr 2025 16:41:40 GMT",
          "size": "5075kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/04/21",
      "title": "DRAGON: Distributional Rewards Optimize Diffusion Generative Models",
      "relevance": {
        "keyword": "train_data",
        "level": "weak",
        "reason": "While the paper presents methods for optimizing generative models using rewards, it references fine-tuning data but does not focus on the processing of training data itself, making its relevance to LLM training data weak."
      },
      "tasks": [
        "FAD"
      ],
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2407.08306",
      "abstract": "As a crucial aspect of Music Information Retrieval (MIR), Symbolic Music Understanding (SMU) has garnered significant attention for its potential to assist both musicians and enthusiasts in learning and creating music. Recently, pre-trained language models have been widely adopted in SMU due to the substantial similarities between symbolic music and natural language, as well as the ability of these models to leverage limited music data effectively. However, some studies have shown the common pre-trained methods like Mask Language Model (MLM) may introduce bias issues like racism discrimination in Natural Language Process (NLP) and affects the performance of downstream tasks, which also happens in SMU. This bias often arises when masked tokens cannot be inferred from their context, forcing the model to overfit the training set instead of generalizing. To address this challenge, we propose Adversarial-MidiBERT for SMU, which adaptively determines what to mask during MLM via a masker network, rather than employing random masking. By avoiding the masking of tokens that are difficult to infer from context, our model is better equipped to capture contextual structures and relationships, rather than merely conforming to the training data distribution. We evaluate our method across four SMU tasks, and our approach demonstrates excellent performance in all cases. The code for our model is publicly available at https://github.com/RS2002/Adversarial-MidiBERT .",
      "authors": [
        "Zijian Zhao"
      ],
      "last_revised_date": "2025/04/30",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2407.08306",
        "HTML": "https://arxiv.org/html/2407.08306",
        "PDF": "https://arxiv.org/pdf/2407.08306"
      },
      "subjects": [
        "Sound (cs.SD)",
        "Artificial Intelligence (cs.AI)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 11 Jul 2024 08:54:38 GMT",
          "size": "608kb",
          "version": "v1"
        },
        {
          "date": "Wed, 15 Jan 2025 10:36:48 GMT",
          "size": "609kb",
          "version": "v2"
        },
        {
          "date": "Wed, 30 Apr 2025 05:22:05 GMT",
          "size": "1590kb",
          "version": "v3"
        }
      ],
      "submitted_date": "2025/04/30",
      "title": "Let Network Decide What to Learn: Symbolic Music Understanding Model Based on Large-scale Adversarial Pre-training",
      "relevance": {
        "keyword": "train_data",
        "level": "weak",
        "reason": "While the paper proposes a novel method for symbolic music understanding using pre-trained models, it briefly discusses data-related techniques that may slightly influence training data processing for LLMs."
      },
      "tasks": [
        "Information Retrieval",
        "Music Information Retrieval"
      ],
      "repo_urls": [
        "https://github.com/RS2002/Adversarial-MidiBERT"
      ],
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2501.10727",
      "abstract": "Datasets play a critical role in medical imaging research, yet issues such as label quality, shortcuts, and metadata are often overlooked. This lack of attention may harm the generalizability of algorithms and, consequently, negatively impact patient outcomes. While existing medical imaging literature reviews mostly focus on machine learning (ML) methods, with only a few focusing on datasets for specific applications, these reviews remain static -- they are published once and not updated thereafter. This fails to account for emerging evidence, such as biases, shortcuts, and additional annotations that other researchers may contribute after the dataset is published. We refer to these newly discovered findings of datasets as research artifacts. To address this gap, we propose a living review that continuously tracks public datasets and their associated research artifacts across multiple medical imaging applications. Our approach includes a framework for the living review to monitor data documentation artifacts, and an SQL database to visualize the citation relationships between research artifact and dataset. Lastly, we discuss key considerations for creating medical imaging datasets, review best practices for data annotation, discuss the significance of shortcuts and demographic diversity, and emphasize the importance of managing datasets throughout their entire lifecycle. Our demo is publicly available at http://inthepicture.itu.dk/.",
      "authors": [
        "Amelia Jim\\'enez-S\\'anchez",
        "Natalia-Rozalia Avlona",
        "Sarah de Boer",
        "V\\'ictor M. Campello",
        "Aasa Feragen",
        "Enzo Ferrante",
        "Melanie Ganz",
        "Judy Wawira Gichoya",
        "Camila Gonz\\'alez",
        "Steff Groefsema",
        "Alessa Hering",
        "Adam Hulman",
        "Leo Joskowicz",
        "Dovile Juodelyte",
        "Melih Kandemir",
        "Thijs Kooi",
        "Jorge del Pozo L\\'erida",
        "Livie Yumeng Li",
        "Andre Pacheco",
        "Tim R\\\"adsch",
        "Mauricio Reyes",
        "Th\\'eo Sourget",
        "Bram van Ginneken",
        "David Wen",
        "Nina Weng",
        "Jack Junchi Xu",
        "Hubert Dariusz Zaj\\k{a}c",
        "Maria A. Zuluaga",
        "Veronika Cheplygina"
      ],
      "last_revised_date": "2025/06/02",
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.10727",
        "HTML": "https://arxiv.org/html/2501.10727",
        "PDF": "https://arxiv.org/pdf/2501.10727"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Image and Video Processing (eess.IV)"
      ],
      "submission_historys": [
        {
          "date": "Sat, 18 Jan 2025 11:03:59 GMT",
          "size": "4531kb",
          "version": "v1"
        },
        {
          "date": "Mon, 02 Jun 2025 12:18:57 GMT",
          "size": "8976kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/02",
      "title": "In the Picture: Medical Imaging Datasets, Artifacts, and their Living Review",
      "relevance": {
        "keyword": "train_data",
        "level": "weak",
        "reason": "The paper focuses on the creation of a living review framework for medical imaging datasets and discusses key considerations for dataset documentation, annotation, and lifecycle management. While it touches upon data documentation, it does not directly introduce novel methods specifically for LLM training data processing."
      },
      "tasks": [],
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2409.18017",
      "abstract": "Developing meaningful and efficient representations that separate the fundamental structure of the data generation mechanism is crucial in representation learning. However, Disentangled Representation Learning has not fully shown its potential on real images, because of correlated generative factors, their resolution and limited access to ground truth labels. Specifically on the latter, we investigate the possibility of leveraging synthetic data to learn general-purpose disentangled representations applicable to real data, discussing the effect of fine-tuning and what properties of disentanglement are preserved after the transfer. We provide an extensive empirical study to address these issues. In addition, we propose a new interpretable intervention-based metric, to measure the quality of factors encoding in the representation. Our results indicate that some level of disentanglement, transferring a representation from synthetic to real data, is possible and effective.",
      "authors": [
        "Jacopo Dapueto",
        "Nicoletta Noceti",
        "Francesca Odone"
      ],
      "last_revised_date": "2024/12/06",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2409.18017",
        "HTML": "https://arxiv.org/html/2409.18017",
        "PDF": "https://arxiv.org/pdf/2409.18017"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Sep 2024 16:25:48 GMT",
          "size": "17118kb",
          "version": "v1"
        },
        {
          "date": "Thu, 05 Dec 2024 11:21:16 GMT",
          "size": "16985kb",
          "version": "v2"
        },
        {
          "date": "Fri, 06 Dec 2024 09:14:41 GMT",
          "size": "16978kb",
          "version": "v3"
        }
      ],
      "submitted_date": "2024/12/06",
      "title": "Transferring disentangled representations: bridging the gap between synthetic and real images",
      "relevance": {
        "keyword": "train_data",
        "level": "weak",
        "reason": "The paper discusses the use of synthetic data for learning disentangled representations and mentions fine-tuning. However, it does not propose new methods for LLM data processing specifically; the focus is on representation learning rather than data processing for LLMs."
      },
      "tasks": [
        "Disentanglement",
        "Representation Learning"
      ],
      "repo_urls": [
        "https://github.com/JacopoDapueto/transfer_disentanglement"
      ],
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.20737",
      "abstract": "The proliferation of LLM-based agents has led to increasing deployment of inter-agent collaboration for tasks like scheduling, negotiation, resource allocation etc. In such systems, privacy is critical, as agents often access proprietary tools and domain-specific databases requiring strict confidentiality. This paper examines whether LLM-based agents demonstrate an understanding of contextual privacy. And, if instructed, do these systems preserve inference time user privacy in non-adversarial multi-turn conversation. Existing benchmarks to evaluate contextual privacy in LLM-agents primarily assess single-turn, low-complexity tasks where private information can be easily excluded. We first present a benchmark - MAGPIE comprising 158 real-life high-stakes scenarios across 15 domains. These scenarios are designed such that complete exclusion of private data impedes task completion yet unrestricted information sharing could lead to substantial losses. We then evaluate the current state-of-the-art LLMs on (a) their understanding of contextually private data and (b) their ability to collaborate without violating user privacy. Empirical experiments demonstrate that current models, including GPT-4o and Claude-2.7-Sonnet, lack robust understanding of contextual privacy, misclassifying private data as shareable 25.2\\% and 43.6\\% of the time. In multi-turn conversations, these models disclose private information in 59.9\\% and 50.5\\% of cases even under explicit privacy instructions. Furthermore, multi-agent systems fail to complete tasks in 71\\% of scenarios. These results underscore that current models are not aligned towards both contextual privacy preservation and collaborative task-solving.",
      "authors": [
        "Gurusha Juneja",
        "Alon Albalak",
        "Wenyue Hua",
        "William Yang Wang"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20737",
        "HTML": "https://arxiv.org/html/2506.20737",
        "PDF": "https://arxiv.org/pdf/2506.20737"
      },
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 18:04:25 GMT",
          "size": "1182kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "MAGPIE: A dataset for Multi-AGent contextual PrIvacy Evaluation",
      "relevance": {
        "keyword": "train_data",
        "level": "weak",
        "reason": "The paper introduces a dataset (MAGPIE) for evaluating contextual privacy in LLM-based agents, but it does not propose new methods for LLM training data processing. It primarily addresses the evaluation of LLMs, which is tangential to training data processing."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.20743",
      "abstract": "Foundation models (FMs) are catalyzing a transformative shift in materials science (MatSci) by enabling scalable, general-purpose, and multimodal AI systems for scientific discovery. Unlike traditional machine learning models, which are typically narrow in scope and require task-specific engineering, FMs offer cross-domain generalization and exhibit emergent capabilities. Their versatility is especially well-suited to materials science, where research challenges span diverse data types and scales. This survey provides a comprehensive overview of foundation models, agentic systems, datasets, and computational tools supporting this growing field. We introduce a task-driven taxonomy encompassing six broad application areas: data extraction, interpretation and Q\\&A; atomistic simulation; property prediction; materials structure, design and discovery; process planning, discovery, and optimization; and multiscale modeling. We discuss recent advances in both unimodal and multimodal FMs, as well as emerging large language model (LLM) agents. Furthermore, we review standardized datasets, open-source tools, and autonomous experimental platforms that collectively fuel the development and integration of FMs into research workflows. We assess the early successes of foundation models and identify persistent limitations, including challenges in generalizability, interpretability, data imbalance, safety concerns, and limited multimodal fusion. Finally, we articulate future research directions centered on scalable pretraining, continual learning, data governance, and trustworthiness.",
      "authors": [
        "Minh-Hao Van",
        "Prateek Verma",
        "Chen Zhao",
        "Xintao Wu"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20743",
        "HTML": "https://arxiv.org/html/2506.20743",
        "PDF": "https://arxiv.org/pdf/2506.20743"
      },
      "subjects": [
        "Machine Learning (cs.LG)",
        "Computational Engineering, Finance, and Science (cs.CE)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 18:10:30 GMT",
          "size": "403kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "A Survey of AI for Materials Science: Foundation Models, LLM Agents, Datasets, and Tools",
      "relevance": {
        "keyword": "train_data",
        "level": "weak",
        "reason": "While the paper surveys datasets and tools related to the application of foundation models in materials science, it does not contribute specifically to the processing of training data for large language models."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.20756",
      "abstract": "Recent video depth estimation methods achieve great performance by following the paradigm of image depth estimation, i.e., typically fine-tuning pre-trained video diffusion models with massive data. However, we argue that video depth estimation is not a naive extension of image depth estimation. The temporal consistency requirements for dynamic and static regions in videos are fundamentally different. Consistent video depth in static regions, typically backgrounds, can be more effectively achieved via stereo matching across all frames, which provides much stronger global 3D cues. While the consistency for dynamic regions still should be learned from large-scale video depth data to ensure smooth transitions, due to the violation of triangulation constraints. Based on these insights, we introduce StereoDiff, a two-stage video depth estimator that synergizes stereo matching for mainly the static areas with video depth diffusion for maintaining consistent depth transitions in dynamic areas. We mathematically demonstrate how stereo matching and video depth diffusion offer complementary strengths through frequency domain analysis, highlighting the effectiveness of their synergy in capturing the advantages of both. Experimental results on zero-shot, real-world, dynamic video depth benchmarks, both indoor and outdoor, demonstrate StereoDiff's SoTA performance, showcasing its superior consistency and accuracy in video depth estimation.",
      "authors": [
        "Haodong Li",
        "Chen Wang",
        "Jiahui Lei",
        "Kostas Daniilidis",
        "Lingjie Liu"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20756",
        "HTML": "https://arxiv.org/html/2506.20756",
        "PDF": "https://arxiv.org/pdf/2506.20756"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 18:35:10 GMT",
          "size": "1746kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "StereoDiff: Stereo-Diffusion Synergy for Video Depth Estimation",
      "relevance": {
        "keyword": "train_data",
        "level": "weak",
        "reason": "The paper discusses a video depth estimation method leveraging stereo matching and video diffusion. While it involves training data (large-scale video depth data), it does not propose new methods for LLM training data processing."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.20793",
      "abstract": "Multi-lingual competence in large language models is often evaluated via static data benchmarks such as Belebele, M-MMLU and M-GSM. However, these evaluations often fail to provide an adequate understanding of the practical performance and robustness of models across multi-lingual settings. In response, we create multi-lingual functional benchmarks -- Cross-Lingual Grade School Math Symbolic (CL-GSM Symbolic) and Cross-Lingual Instruction-Following Eval (CL-IFEval)-- by translating existing functional benchmark templates from English to five additional languages that span the range of resources available for NLP: French, Spanish, Hindi, Arabic and Yoruba. Our results reveal that some static multi-lingual benchmarks capture functional performance much more closely than others (i.e. across models, there is a 24%, 17% and 18% decrease in performance between M-GSM and CL-GSM Symbolic in English, French and Spanish respectively; similarly there's a 15 - 24% performance drop across languages between Belebele and CL-IFEval, and only a 0.5% to 3% performance drop between M-MMLU and CL-IFEval). Similarly, we find that model robustness across languages varies significantly, with certain languages (eg. Arabic, English) being the most consistently well performing across evaluation iterations.",
      "authors": [
        "Victor Ojewale",
        "Inioluwa Deborah Raji",
        "Suresh Venkatasubramanian"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20793",
        "HTML": "https://arxiv.org/html/2506.20793",
        "PDF": "https://arxiv.org/pdf/2506.20793"
      },
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 19:32:31 GMT",
          "size": "7896kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Multi-lingual Functional Evaluation for Large Language Models",
      "relevance": {
        "keyword": "train_data",
        "level": "weak",
        "reason": "The paper discusses multi-lingual functional evaluation for LLMs, including the creation of translated benchmarks. While it addresses data usage for evaluation, it does not significantly delve into LLM training data processing."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.20821",
      "abstract": "Financial documents--such as 10-Ks, 10-Qs, and investor presentations--span hundreds of pages and combine diverse modalities, including dense narrative text, structured tables, and complex figures. Answering questions over such content often requires joint reasoning across modalities, which strains traditional large language models (LLMs) and retrieval-augmented generation (RAG) pipelines due to token limitations, layout loss, and fragmented cross-modal context. We introduce MultiFinRAG, a retrieval-augmented generation framework purpose-built for financial QA. MultiFinRAG first performs multimodal extraction by grouping table and figure images into batches and sending them to a lightweight, quantized open-source multimodal LLM, which produces both structured JSON outputs and concise textual summaries. These outputs, along with narrative text, are embedded and indexed with modality-aware similarity thresholds for precise retrieval. A tiered fallback strategy then dynamically escalates from text-only to text+table+image contexts when necessary, enabling cross-modal reasoning while reducing irrelevant context. Despite running on commodity hardware, MultiFinRAG achieves 19 percentage points higher accuracy than ChatGPT-4o (free-tier) on complex financial QA tasks involving text, tables, images, and combined multimodal reasoning.",
      "authors": [
        "Chinmay Gondhalekar",
        "Urjitkumar Patel",
        "Fang-Chun Yeh"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20821",
        "HTML": "https://arxiv.org/html/2506.20821",
        "PDF": "https://arxiv.org/pdf/2506.20821"
      },
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Computational Engineering, Finance, and Science (cs.CE)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 20:37:20 GMT",
          "size": "2203kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "MultiFinRAG: An Optimized Multimodal Retrieval-Augmented Generation (RAG) Framework for Financial Question Answering",
      "relevance": {
        "keyword": "train_data",
        "level": "weak",
        "reason": "The paper introduces MultiFinRAG, a framework for financial QA using retrieval-augmented generation, with a focus on processing financial documents, but only briefly mentions modalities in extraction without proposing new data processing techniques for LLM training."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.20879",
      "abstract": "Generation of images containing multiple humans, performing complex actions, while preserving their facial identities, is a significant challenge. A major factor contributing to this is the lack of a a dedicated benchmark. To address this, we introduce MultiHuman-Testbench, a novel benchmark for rigorously evaluating generative models for multi-human generation. The benchmark comprises 1800 samples, including carefully curated text prompts, describing a range of simple to complex human actions. These prompts are matched with a total of 5,550 unique human face images, sampled uniformly to ensure diversity across age, ethnic background, and gender. Alongside captions, we provide human-selected pose conditioning images which accurately match the prompt. We propose a multi-faceted evaluation suite employing four key metrics to quantify face count, ID similarity, prompt alignment, and action detection. We conduct a thorough evaluation of a diverse set of models, including zero-shot approaches and training-based methods, with and without regional priors. We also propose novel techniques to incorporate image and region isolation using human segmentation and Hungarian matching, significantly improving ID similarity. Our proposed benchmark and key findings provide valuable insights and a standardized tool for advancing research in multi-human image generation.",
      "authors": [
        "Shubhankar Borse",
        "Seokeon Choi",
        "Sunghyun Park",
        "Jeongho Kim",
        "Shreya Kadambi",
        "Risheek Garrepalli",
        "Sungrack Yun",
        "Munawar Hayat",
        "Fatih Porikli"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20879",
        "HTML": "https://arxiv.org/html/2506.20879",
        "PDF": "https://arxiv.org/pdf/2506.20879"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 23:00:57 GMT",
          "size": "21293kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "MultiHuman-Testbench: Benchmarking Image Generation for Multiple Humans",
      "relevance": {
        "keyword": "train_data",
        "level": "weak",
        "reason": "The paper introduces a unique benchmark for evaluating generative models for multi-human image generation, discussing curating data for evaluation. Although related to data handling, it does not propose new data processing methods for LLMs directly."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.20886",
      "abstract": "In recent years, the rapid advancement of deep neural networks (DNNs) has revolutionized artificial intelligence, enabling models with unprecedented capabilities in understanding, generating, and processing complex data. These powerful architectures have transformed a wide range of downstream applications, tackling tasks beyond human reach. In this paper, we introduce Omniwise, the first end-to-end, self-supervised fine-tuning pipeline that applies large language models (LLMs) to GPU kernel performance prediction--a novel use case in performance profiling. Omniwise is model-agnostic and lightweight, achieving strong results even with a small 3B-parameter model. It can predict key performance metrics, including memory bandwidth, cache hit rates, GFLOPs, and arithmetic intensity, directly from kernel code without the need for code execution or profiling tools. Our approach achieves over 90% of predictions within 10% relative error on GPU kernels executed on AMD MI250 and MI300X architectures. In addition to the pipeline, we develop an online inference server and a Visual Studio Code plugin that seamlessly integrate LLM-based performance prediction into developers' workflows.",
      "authors": [
        "Zixian Wang",
        "Cole Ramos",
        "Muhammad A. Awad",
        "and Keith Lowery"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20886",
        "HTML": "https://arxiv.org/html/2506.20886",
        "PDF": "https://arxiv.org/pdf/2506.20886"
      },
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 23:36:44 GMT",
          "size": "347kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "Omniwise: Predicting GPU Kernels Performance with LLMs",
      "relevance": {
        "keyword": "train_data",
        "level": "weak",
        "reason": "While this paper introduces a pipeline using LLMs for GPU performance prediction, it primarily focuses on the application of LLMs to a specific task rather than on the processing or engineering of LLM training data."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.20911",
      "abstract": "We develop a cost-efficient neurosymbolic agent to address challenging multi-turn image editing tasks such as \"Detect the bench in the image while recoloring it to pink. Also, remove the cat for a clearer view and recolor the wall to yellow.'' It combines the fast, high-level subtask planning by large language models (LLMs) with the slow, accurate, tool-use, and local A$^*$ search per subtask to find a cost-efficient toolpath -- a sequence of calls to AI tools. To save the cost of A$^*$ on similar subtasks, we perform inductive reasoning on previously successful toolpaths via LLMs to continuously extract/refine frequently used subroutines and reuse them as new tools for future tasks in an adaptive fast-slow planning, where the higher-level subroutines are explored first, and only when they fail, the low-level A$^*$ search is activated. The reusable symbolic subroutines considerably save exploration cost on the same types of subtasks applied to similar images, yielding a human-like fast-slow toolpath agent \"FaSTA$^*$'': fast subtask planning followed by rule-based subroutine selection per subtask is attempted by LLMs at first, which is expected to cover most tasks, while slow A$^*$ search is only triggered for novel and challenging subtasks. By comparing with recent image editing approaches, we demonstrate FaSTA$^*$ is significantly more computationally efficient while remaining competitive with the state-of-the-art baseline in terms of success rate.",
      "authors": [
        "Advait Gupta",
        "Rishie Raj",
        "Dang Nguyen",
        "Tianyi Zhou"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20911",
        "HTML": "https://arxiv.org/html/2506.20911",
        "PDF": "https://arxiv.org/pdf/2506.20911"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 00:33:43 GMT",
          "size": "41938kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "FaSTA$^*$: Fast-Slow Toolpath Agent with Subroutine Mining for Efficient Multi-turn Image Editing",
      "relevance": {
        "keyword": "train_data",
        "level": "weak",
        "reason": "The paper mentions using LLMs for high-level subtask planning, but the focus is on image editing tasks rather than LLM training data processing or improvement."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.20938",
      "abstract": "GPGPU architectures have become significantly diverse in recent years, which has led to an emergence of a variety of specialized programming models and software stacks to support them. While portable execution models exist, they still require significant developer effort to port to and optimize for different hardware architectures. Recent advances in large language models (LLMs) can help us reduce some of this programmer burden. In this paper, we present a novel benchmark and testing framework, ParEval-Repo, which can be used to evaluate the efficacy of LLM-based approaches in automatically translating entire codebases across GPGPU execution models. ParEval-Repo includes several scientific computing and AI mini-applications in a range of programming models, and levels of repository complexity. We use ParEval-Repo to evaluate a range of state-of-the-art open-source and commercial LLMs, with both a non-agentic and a top-down agentic approach. We assess code generated by the LLMs and approaches in terms of compilability, functional correctness, categories of build errors, and the cost of translation in terms of the number of inference tokens. Our results demonstrate that LLM translation of scientific applications is feasible for small programs but difficulty with generating functional build systems and cross-file dependencies pose challenges in scaling to larger codebases.",
      "authors": [
        "Joshua H. Davis",
        "Daniel Nichols",
        "Ishan Khillan",
        "Abhinav Bhatele"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20938",
        "HTML": "https://arxiv.org/html/2506.20938",
        "PDF": "https://arxiv.org/pdf/2506.20938"
      },
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 02:01:11 GMT",
          "size": "179kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "ParEval-Repo: A Benchmark Suite for Evaluating LLMs with Repository-level HPC Translation Tasks",
      "relevance": {
        "keyword": "train_data",
        "level": "weak",
        "reason": "While this paper introduces a benchmark for evaluating LLMs in codebase translation tasks, it primarily focuses on evaluating LLM capabilities rather than proposing novel data engineering or processing methods for LLM training data."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.20941",
      "abstract": "Large language models are trained on massive corpora of web data, which may include private data, copyrighted material, factually inaccurate data, or data that degrades model performance. Eliminating the influence of such problematic datapoints through complete retraining -- by repeatedly pretraining the model on datasets that exclude these specific instances -- is computationally prohibitive. For this reason, unlearning algorithms have emerged that aim to eliminate the influence of particular datapoints, while otherwise preserving the model -- at a low computational cost. However, precisely estimating and undoing the influence of individual datapoints has proved to be challenging. In this work, we propose a new algorithm, MSA, for estimating and undoing the influence of datapoints -- by leveraging model checkpoints i.e. artifacts capturing model states at different stages of pretraining. Our experimental results demonstrate that MSA consistently outperforms existing machine unlearning algorithms across multiple benchmarks, models, and evaluation metrics, suggesting that MSA could be an effective approach towards more flexible large language models that are capable of data erasure.",
      "authors": [
        "Keivan Rezaei",
        "Mehrdad Saberi",
        "Abhilasha Ravichander",
        "Soheil Feizi"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20941",
        "HTML": "https://arxiv.org/html/2506.20941",
        "PDF": "https://arxiv.org/pdf/2506.20941"
      },
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 02:16:16 GMT",
          "size": "1964kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Model State Arithmetic for Machine Unlearning",
      "relevance": {
        "keyword": "train_data",
        "level": "weak",
        "reason": "The paper focuses on an algorithm for machine unlearning rather than the primary tasks in LLM data engineering or training-stage data processing. It mentions model states during pretraining but does not propose novel data collection or preprocessing for LLMs."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.20949",
      "abstract": "Given the growing influence of language model-based agents on high-stakes societal decisions, from public policy to healthcare, ensuring their beneficial impact requires understanding the far-reaching implications of their suggestions. We propose a proof-of-concept framework that projects how model-generated advice could propagate through societal systems on a macroscopic scale over time, enabling more robust alignment. To assess the long-term safety awareness of language models, we also introduce a dataset of 100 indirect harm scenarios, testing models' ability to foresee adverse, non-obvious outcomes from seemingly harmless user prompts. Our approach achieves not only over 20% improvement on the new dataset but also an average win rate exceeding 70% against strong baselines on existing safety benchmarks (AdvBench, SafeRLHF, WildGuardMix), suggesting a promising direction for safer agents.",
      "authors": [
        "Chenkai Sun",
        "Denghui Zhang",
        "ChengXiang Zhai",
        "Heng Ji"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20949",
        "HTML": "https://arxiv.org/html/2506.20949",
        "PDF": "https://arxiv.org/pdf/2506.20949"
      },
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 02:28:58 GMT",
          "size": "3440kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Beyond Reactive Safety: Risk-Aware LLM Alignment via Long-Horizon Simulation",
      "relevance": {
        "keyword": "train_data",
        "level": "weak",
        "reason": "The paper briefly mentions the introduction of a dataset for evaluating long-term safety awareness in language models, but its primary focus is on alignment and safety, not novel methods for LLM training data processing."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.20960",
      "abstract": "In this paper, we introduce OmniEval, a benchmark for evaluating omni-modality models like MiniCPM-O 2.6, which encompasses visual, auditory, and textual inputs. Compared with existing benchmarks, our OmniEval has several distinctive features: (i) Full-modal collaboration: We design evaluation tasks that highlight the strong coupling between audio and video, requiring models to effectively leverage the collaborative perception of all modalities; (ii) Diversity of videos: OmniEval includes 810 audio-visual synchronized videos, 285 Chinese videos and 525 English videos; (iii) Diversity and granularity of tasks: OmniEval contains 2617 question-answer pairs, comprising 1412 open-ended questions and 1205 multiple-choice questions. These questions are divided into 3 major task types and 12 sub-task types to achieve comprehensive evaluation. Among them, we introduce a more granular video localization task named Grounding. Then we conduct experiments on OmniEval with several omni-modality models. We hope that our OmniEval can provide a platform for evaluating the ability to construct and understand coherence from the context of all modalities. Codes and data could be found at https://omnieval.github.io/.",
      "authors": [
        "Yiman Zhang",
        "Ziheng Luo",
        "Qiangyu Yan",
        "Wei He",
        "Borui Jiang",
        "Xinghao Chen",
        "Kai Han"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20960",
        "HTML": "https://arxiv.org/html/2506.20960",
        "PDF": "https://arxiv.org/pdf/2506.20960"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 02:54:24 GMT",
          "size": "947kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "OmniEval: A Benchmark for Evaluating Omni-modal Models with Visual, Auditory, and Textual Inputs",
      "relevance": {
        "keyword": "train_data",
        "level": "weak",
        "reason": "OmniEval introduces a benchmark for multi-modal models, which includes textual inputs but does not provide new methods for LLM training data processing. Its focus is on evaluation across modalities, not data engineering or processing for LLMs."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.20964",
      "abstract": "Pathology is experiencing rapid digital transformation driven by whole-slide imaging and artificial intelligence (AI). While deep learning-based computational pathology has achieved notable success, traditional models primarily focus on image analysis without integrating natural language instruction or rich, text-based context. Current multimodal large language models (MLLMs) in computational pathology face limitations, including insufficient training data, inadequate support and evaluation for multi-image understanding, and a lack of autonomous, diagnostic reasoning capabilities. To address these limitations, we introduce PathChat+, a new MLLM specifically designed for human pathology, trained on over 1 million diverse, pathology-specific instruction samples and nearly 5.5 million question answer turns. Extensive evaluations across diverse pathology benchmarks demonstrated that PathChat+ substantially outperforms the prior PathChat copilot, as well as both state-of-the-art (SOTA) general-purpose and other pathology-specific models. Furthermore, we present SlideSeek, a reasoning-enabled multi-agent AI system leveraging PathChat+ to autonomously evaluate gigapixel whole-slide images (WSIs) through iterative, hierarchical diagnostic reasoning, reaching high accuracy on DDxBench, a challenging open-ended differential diagnosis benchmark, while also capable of generating visually grounded, humanly-interpretable summary reports.",
      "authors": [
        "Chengkuan Chen",
        "Luca L. Weishaupt",
        "Drew F. K. Williamson",
        "Richard J. Chen",
        "Tong Ding",
        "Bowen Chen",
        "Anurag Vaidya",
        "Long Phi Le",
        "Guillaume Jaume",
        "Ming Y. Lu",
        "and Faisal Mahmood"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20964",
        "HTML": "https://arxiv.org/html/2506.20964",
        "PDF": "https://arxiv.org/pdf/2506.20964"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 03:02:16 GMT",
          "size": "8278kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Evidence-based diagnostic reasoning with multi-agent copilot for human pathology",
      "relevance": {
        "keyword": "train_data",
        "level": "weak",
        "reason": "The paper discusses PathChat+, a model trained on specific human pathology data, highlighting the creation of a dataset, but it focuses more on the diagnostic application and model performance rather than novel methods for processing LLM training data itself."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.20966",
      "abstract": "Vision-language-action (VLA) models extend vision-language models (VLM) by integrating action generation modules for robotic manipulation. Leveraging strengths of VLM in vision perception and instruction understanding, VLA models exhibit promising generalization across diverse manipulation tasks. However, applications demanding high precision and accuracy reveal performance gaps without further adaptation. Evidence from multiple domains highlights the critical role of post-training to align foundational models with downstream applications, spurring extensive research on post-training VLA models. VLA model post-training aims to address the challenge of improving an embodiment's ability to interact with the environment for the given tasks, analogous to the process of humans motor skills acquisition. Accordingly, this paper reviews post-training strategies for VLA models through the lens of human motor learning, focusing on three dimensions: environments, embodiments, and tasks. A structured taxonomy is introduced aligned with human learning mechanisms: (1) enhancing environmental perception, (2) improving embodiment awareness, (3) deepening task comprehension, and (4) multi-component integration. Finally, key challenges and trends in post-training VLA models are identified, establishing a conceptual framework to guide future research. This work delivers both a comprehensive overview of current VLA model post-training methods from a human motor learning perspective and practical insights for VLA model development. (Project website: https://github.com/AoqunJin/Awesome-VLA-Post-Training)",
      "authors": [
        "Tian-Yu Xiang",
        "Ao-Qun Jin",
        "Xiao-Hu Zhou",
        "Mei-Jiang Gui",
        "Xiao-Liang Xie",
        "Shi-Qi Liu",
        "Shuang-Yi Wang",
        "Sheng-Bin Duan",
        "Fu-Chao Xie",
        "Wen-Kai Wang",
        "Si-Cheng Wang",
        "Ling-Yun Li",
        "Tian Tu",
        "Zeng-Guang Hou"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20966",
        "HTML": "https://arxiv.org/html/2506.20966",
        "PDF": "https://arxiv.org/pdf/2506.20966"
      },
      "subjects": [
        "Robotics (cs.RO)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 03:06:57 GMT",
          "size": "1194kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Parallels Between VLA Model Post-Training and Human Motor Learning: Progress, Challenges, and Trends",
      "relevance": {
        "keyword": "train_data",
        "level": "weak",
        "reason": "The paper discusses post-training for VLA models to enhance alignment with task requirements, analogous to human motor learning, but no new methods for LLM-specific data processing are proposed, merely adapting existing models for improved task performance."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.20971",
      "abstract": "In this study, we analyze 2,398 research articles published between 2020 and 2024 across eight core venues related to the field of Artificial Intelligence in Education (AIED). Using a three-step knowledge co-occurrence network analysis, we analyze the knowledge structure of the field, the evolving knowledge clusters, and the emerging frontiers. Our findings reveal that AIED research remains strongly technically focused, with sustained themes such as intelligent tutoring systems, learning analytics, and natural language processing, alongside rising interest in large language models (LLMs) and generative artificial intelligence (GenAI). By tracking the bridging keywords over the past five years, we identify four emerging frontiers in AIED--LLMs, GenAI, multimodal learning analytics, and human-AI collaboration. The current research interests in GenAI are centered around GAI-driven personalization, self-regulated learning, feedback, assessment, motivation, and ethics.The key research interests and emerging frontiers in AIED reflect a growing emphasis on co-adaptive, human-centered AI for education. This study provides the first large-scale field-level mapping of AIED's transformation in the GenAI era and sheds light on the future research development and educational practices.",
      "authors": [
        "Shihui Feng",
        "Huilin Zhang",
        "Dragan Ga\\v{s}evi\\'c"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20971",
        "HTML": "https://arxiv.org/html/2506.20971",
        "PDF": "https://arxiv.org/pdf/2506.20971"
      },
      "subjects": [
        "Social and Information Networks (cs.SI)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 03:24:30 GMT",
          "size": "4379kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Where is AIED Headed? Key Topics and Emerging Frontiers (2020-2024)",
      "relevance": {
        "keyword": "train_data",
        "level": "weak",
        "reason": "The paper discusses trends in AI in Education, including LLMs and GenAI, but its primary focus is on mapping the field rather than on processing training data for LLMs."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.20982",
      "abstract": "Finding balanced ways to employ Large Language Models (LLMs) in education is a challenge due to inherent risks of poor understanding of the technology and of a susceptible audience. This is particularly so with younger children, who are known to have difficulties with pervasive screen time. Working with a tangible programming robot called Cubetto, we propose an approach to benefit from the capabilities of LLMs by employing such models in the preparation of personalised storytelling, necessary for preschool children to get accustomed to the practice of commanding the robot. We engage in action research to develop an early version of a formalised process to rapidly prototype game stories for Cubetto. Our approach has both reproducible results, because it employs open weight models, and is model-agnostic, because we test it with 5 different LLMs. We document on one hand the process, the used materials and prompts, and on the other the learning experience and outcomes. We deem the generation successful for the intended purposes of using the results as a teacher aid. Testing the models on 4 different task scenarios, we encounter issues of consistency and hallucinations and document the corresponding evaluation process and attempts (some successful and some not) to overcome these issues. Importantly, the process does not expose children to LLMs directly. Rather, the technology is used to help teachers easily develop personalised narratives on children's preferred topics. We believe our method is adequate for preschool classes and we are planning to further experiment in real-world educational settings.",
      "authors": [
        "Martin Ruskov"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20982",
        "HTML": "https://arxiv.org/html/2506.20982",
        "PDF": "https://arxiv.org/pdf/2506.20982"
      },
      "subjects": [
        "Computers and Society (cs.CY)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 03:54:25 GMT",
          "size": "1079kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Our Coding Adventure: Using LLMs to Personalise the Narrative of a Tangible Programming Robot for Preschoolers",
      "relevance": {
        "keyword": "train_data",
        "level": "weak",
        "reason": "While the focus is on using LLMs for educational narrative generation, the paper discusses the preparation of materials and prompts but does not contribute significantly to LLM training data processing methodologies."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.20988",
      "abstract": "Pathology image segmentation is crucial in computational pathology for analyzing histological features relevant to cancer diagnosis and prognosis. However, current methods face major challenges in clinical applications due to limited annotated data and restricted category definitions. To address these limitations, we propose PathSegmentor, the first text-prompted segmentation foundation model designed specifically for pathology images. We also introduce PathSeg , the largest and most comprehensive dataset for pathology segmentation, built from 17 public sources and containing 275k image-mask-label triples across 160 diverse categories. With PathSegmentor, users can perform semantic segmentation using natural language prompts, eliminating the need for laborious spatial inputs such as points or boxes. Extensive experiments demonstrate that PathSegmentor outperforms specialized models with higher accuracy and broader applicability, while maintaining a compact architecture. It significantly surpasses existing spatial- and text-prompted models by 0.145 and 0.429 in overall Dice scores, respectively, showing strong robustness in segmenting complex structures and generalizing to external datasets. Moreover, PathSegmentor's outputs enhance the interpretability of diagnostic models through feature importance estimation and imaging biomarker discovery, offering pathologists evidence-based support for clinical decision-making. This work advances the development of explainable AI in precision oncology.",
      "authors": [
        "Zhixuan Chen",
        "Junlin Hou",
        "Liqi Lin",
        "Yihui Wang",
        "Yequan Bie",
        "Xi Wang",
        "Yanning Zhou",
        "Ronald Cheong Kin Chan and Hao Chen"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20988",
        "HTML": "https://arxiv.org/html/2506.20988",
        "PDF": "https://arxiv.org/pdf/2506.20988"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 04:01:40 GMT",
          "size": "14163kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Segment Anything in Pathology Images with Natural Language",
      "relevance": {
        "keyword": "train_data",
        "level": "weak",
        "reason": "The paper introduces PathSeg, a dataset for pathology segmentation, but the focus is on medical image segmentation rather than LLM training data. It mentions data creation in terms of pathology image segmentation, which marginally aligns with data engineering concepts."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21017",
      "abstract": "Prompt learning has been widely adopted to efficiently adapt vision-language models (VLMs) like CLIP for various downstream tasks. Despite their success, current VLM-based facial expression recognition (FER) methods struggle to capture fine-grained textual-visual relationships, which are essential for distinguishing subtle differences between facial expressions. To address this challenge, we propose a multimodal prompt alignment framework for FER, called MPA-FER, that provides fine-grained semantic guidance to the learning process of prompted visual features, resulting in more precise and interpretable representations. Specifically, we introduce a multi-granularity hard prompt generation strategy that utilizes a large language model (LLM) like ChatGPT to generate detailed descriptions for each facial expression. The LLM-based external knowledge is injected into the soft prompts by minimizing the feature discrepancy between the soft prompts and the hard prompts. To preserve the generalization abilities of the pretrained CLIP model, our approach incorporates prototype-guided visual feature alignment, ensuring that the prompted visual features from the frozen image encoder align closely with class-specific prototypes. Additionally, we propose a cross-modal global-local alignment module that focuses on expression-relevant facial features, further improving the alignment between textual and visual features. Extensive experiments demonstrate our framework outperforms state-of-the-art methods on three FER benchmark datasets, while retaining the benefits of the pretrained model and minimizing computational costs.",
      "authors": [
        "Fuyan Ma",
        "Yiran He",
        "Bin Sun",
        "Shutao Li"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21017",
        "HTML": "https://arxiv.org/html/2506.21017",
        "PDF": "https://arxiv.org/pdf/2506.21017"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 05:28:57 GMT",
          "size": "4624kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Multimodal Prompt Alignment for Facial Expression Recognition",
      "relevance": {
        "keyword": "train_data",
        "level": "weak",
        "reason": "The paper proposes a multimodal prompt alignment framework for facial expression recognition using LLMs to generate detailed prompts. However, the focus is on improving model performance through prompt design rather than LLM training data processing."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21028",
      "abstract": "Molecular property prediction aims to learn representations that map chemical structures to functional properties. While multimodal learning has emerged as a powerful paradigm to learn molecular representations, prior works have largely overlooked textual and taxonomic information of molecules for representation learning. We introduce TRIDENT, a novel framework that integrates molecular SMILES, textual descriptions, and taxonomic functional annotations to learn rich molecular representations. To achieve this, we curate a comprehensive dataset of molecule-text pairs with structured, multi-level functional annotations. Instead of relying on conventional contrastive loss, TRIDENT employs a volume-based alignment objective to jointly align tri-modal features at the global level, enabling soft, geometry-aware alignment across modalities. Additionally, TRIDENT introduces a novel local alignment objective that captures detailed relationships between molecular substructures and their corresponding sub-textual descriptions. A momentum-based mechanism dynamically balances global and local alignment, enabling the model to learn both broad functional semantics and fine-grained structure-function mappings. TRIDENT achieves state-of-the-art performance on 11 downstream tasks, demonstrating the value of combining SMILES, textual, and taxonomic functional annotations for molecular property prediction.",
      "authors": [
        "Feng Jiang",
        "Mangal Prakash",
        "Hehuan Ma",
        "Jianyuan Deng",
        "Yuzhi Guo",
        "Amina Mollaysa",
        "Tommaso Mansi",
        "Rui Liao",
        "Junzhou Huang"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21028",
        "HTML": "https://arxiv.org/html/2506.21028",
        "PDF": "https://arxiv.org/pdf/2506.21028"
      },
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 06:09:47 GMT",
          "size": "1209kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "TRIDENT: Tri-Modal Molecular Representation Learning with Taxonomic Annotations and Local Correspondence",
      "relevance": {
        "keyword": "train_data",
        "level": "weak",
        "reason": "While the paper discusses data curation for molecular representation learning, it primarily focuses on integrating multimodal features, without contributions to LLM training data processing or engineering."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21031",
      "abstract": "Advanced intelligent systems, particularly Large Language Models (LLMs), are significantly reshaping financial practices through advancements in Natural Language Processing (NLP). However, the extent to which these models effectively capture and apply domain-specific financial knowledge remains uncertain. Addressing a critical gap in the expansive Indian financial context, this paper introduces CA-Ben, a Chartered Accountancy benchmark specifically designed to evaluate the financial, legal, and quantitative reasoning capabilities of LLMs. CA-Ben comprises structured question-answer datasets derived from the rigorous examinations conducted by the Institute of Chartered Accountants of India (ICAI), spanning foundational, intermediate, and advanced CA curriculum stages. Six prominent LLMs i.e. GPT 4o, LLAMA 3.3 70B, LLAMA 3.1 405B, MISTRAL Large, Claude 3.5 Sonnet, and Microsoft Phi 4 were evaluated using standardized protocols. Results indicate variations in performance, with Claude 3.5 Sonnet and GPT-4o outperforming others, especially in conceptual and legal reasoning. Notable challenges emerged in numerical computations and legal interpretations. The findings emphasize the strengths and limitations of current LLMs, suggesting future improvements through hybrid reasoning and retrieval-augmented generation methods, particularly for quantitative analysis and accurate legal interpretation.",
      "authors": [
        "Jatin Gupta",
        "Akhil Sharma",
        "Saransh Singhania",
        "Mohammad Adnan",
        "Sakshi Deo",
        "Ali Imam Abidi and Keshav Gupta"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21031",
        "HTML": "https://arxiv.org/html/2506.21031",
        "PDF": "https://arxiv.org/pdf/2506.21031"
      },
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 06:10:37 GMT",
          "size": "1123kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Large Language Models Acing Chartered Accountancy",
      "relevance": {
        "keyword": "train_data",
        "level": "weak",
        "reason": "The paper describes using datasets for evaluating LLMs but does not contribute new methods or processes related to LLM training data engineering or processing."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21033",
      "abstract": "The hallucination problem of Large Language Models (LLMs) has increasingly drawn attention. Augmenting LLMs with external knowledge is a promising solution to address this issue. However, due to privacy and security concerns, a vast amount of downstream task-related knowledge remains dispersed and isolated across various \"silos,\" making it difficult to access. To bridge this knowledge gap, we propose a blockchain-based external knowledge framework that coordinates multiple knowledge silos to provide reliable foundational knowledge for large model retrieval while ensuring data security. Technically, we distill knowledge from local data into prompts and execute transactions and records on the blockchain. Additionally, we introduce a reputation mechanism and cross-validation to ensure knowledge quality and provide incentives for participation. Furthermore, we design a query generation framework that provides a direct API interface for large model retrieval. To evaluate the performance of our proposed framework, we conducted extensive experiments on various knowledge sources. The results demonstrate that the proposed framework achieves efficient LLM service knowledge sharing in blockchain environments.",
      "authors": [
        "Zhaojiacheng Zhou",
        "Hongze Liu",
        "Shijing Yuan",
        "Hanning Zhang",
        "Jiong Lou",
        "Chentao Wu",
        "Jie Li"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21033",
        "HTML": "https://arxiv.org/html/2506.21033",
        "PDF": "https://arxiv.org/pdf/2506.21033"
      },
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 06:16:33 GMT",
          "size": "2035kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "BLOCKS: Blockchain-supported Cross-Silo Knowledge Sharing for Efficient LLM Services",
      "relevance": {
        "keyword": "train_data",
        "level": "weak",
        "reason": "The paper primarily focuses on using blockchain for knowledge sharing and security, with mentions of knowledge distillation and query frameworks, which might involve some preprocessing, but the main contribution is not on data engineering for LLM training."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21035",
      "abstract": "Continual learning (CL) with large pre-trained models is challenged by catastrophic forgetting and task interference. Existing LoRA-based Mixture-of-Experts (MoE) approaches mitigate forgetting by assigning and freezing task-specific adapters, but suffer from interference, redundancy, and ambiguous routing due to coarse adapter-level selection. However, this design introduces three key challenges: 1) Interference: Activating full LoRA experts per input leads to subspace interference and prevents selective reuse of useful components across tasks. 2) Redundancy: Newly added experts often duplicate or contradict existing knowledge due to unnecessary activation of unrelated ranks and insufficient reuse of relevant ones. 3) Ambiguity: Overlapping features across tasks confuse the router, resulting in unstable expert assignments. As more experts accumulate, earlier task routing degrades, accelerating forgetting. We propose MoRA, a Mixture-of-Rank Adaptive learning approach with self-activated and sparse rank activation for CL. Unlike mixing multiple low-rank matrices, MoRA decomposes each rank-r update into r rank-1 components, each treated as an independent expert, enabling fine-grained mixture of rank-1 expert utilization while mitigating interference and redundancy. To avoid ambiguous routing, we propose that each rank-1 expert can infer its own relevance via intermediate activations. Coupled with our proposed rank pruning and activation budgets, MoRA adaptively selects a sparse mixture of ranks per input. We validate MoRA on continual learning tasks with CLIP and large language models (LLMs), analyzing both in-domain learning and out-of-domain forgetting/generalization during fine-tuning. MoRA shows significant effectiveness on enhancing CL with PTMs, and improving generalization while mitigating forgetting.",
      "authors": [
        "Haodong Lu",
        "Chongyang Zhao",
        "Jason Xue",
        "Lina Yao",
        "Kristen Moore",
        "Dong Gong"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21035",
        "HTML": "https://arxiv.org/html/2506.21035",
        "PDF": "https://arxiv.org/pdf/2506.21035"
      },
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 06:19:05 GMT",
          "size": "3609kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Little By Little: Continual Learning via Self-Activated Sparse Mixture-of-Rank Adaptive Learning",
      "relevance": {
        "keyword": "train_data",
        "level": "weak",
        "reason": "The primary discussion is on continual learning strategies with pre-trained models, mentioning the use of LLMs in experiments but not focusing on data processing or engineering specific to LLM training."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21041",
      "abstract": "Ensuring robust planning and decision-making under rare, diverse, and visually degraded long-tail scenarios remains a fundamental challenge for autonomous driving in urban environments. This issue becomes more critical in cooperative settings, where vehicles and infrastructure jointly perceive and reason across complex environments. To address this challenge, we propose V2X-REALM, a vision-language model (VLM)-based framework with adaptive multimodal learning for robust cooperative autonomous driving under long-tail scenarios. V2X-REALM introduces three core innovations: (i) a prompt-driven long-tail scenario generation and evaluation pipeline that leverages foundation models to synthesize realistic long-tail conditions such as snow and fog across vehicle- and infrastructure-side views, enriching training diversity efficiently; (ii) a gated multi-scenario adaptive attention module that modulates the visual stream using scenario priors to recalibrate ambiguous or corrupted features; and (iii) a multi-task scenario-aware contrastive learning objective that improves multimodal alignment and promotes cross-scenario feature separability. Extensive experiments demonstrate that V2X-REALM significantly outperforms existing baselines in robustness, semantic reasoning, safety, and planning accuracy under complex, challenging driving conditions, advancing the scalability of end-to-end cooperative autonomous driving.",
      "authors": [
        "Junwei You",
        "Pei Li",
        "Zhuoyu Jiang",
        "Zilin Huang",
        "Rui Gan",
        "Haotian Shi",
        "Bin Ran"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21041",
        "HTML": "https://arxiv.org/html/2506.21041",
        "PDF": "https://arxiv.org/pdf/2506.21041"
      },
      "subjects": [
        "Robotics (cs.RO)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 06:42:03 GMT",
          "size": "7599kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "V2X-REALM: Vision-Language Model-Based Robust End-to-End Cooperative Autonomous Driving with Adaptive Long-Tail Modeling",
      "relevance": {
        "keyword": "train_data",
        "level": "weak",
        "reason": "The paper introduces V2X-REALM, a vision-language model-based framework for autonomous driving, slightly touching on the generation and evaluation pipeline for training scenarios, which involves enhancing training diversity."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21049",
      "abstract": "Query classification, including multiple subtasks such as intent and category prediction, is vital to e-commerce applications. E-commerce queries are usually short and lack context, and the information between labels cannot be used, resulting in insufficient prior information for modeling. Most existing industrial query classification methods rely on users' posterior click behavior to construct training samples, resulting in a Matthew vicious cycle. Furthermore, the subtasks of query classification lack a unified framework, leading to low efficiency for algorithm optimization.\n  In this paper, we propose a novel Semi-supervised Scalable Unified Framework (SSUF), containing multiple enhanced modules to unify the query classification tasks. The knowledge-enhanced module uses world knowledge to enhance query representations and solve the problem of insufficient query information. The label-enhanced module uses label semantics and semi-supervised signals to reduce the dependence on posterior labels. The structure-enhanced module enhances the label representation based on the complex label relations. Each module is highly pluggable, and input features can be added or removed as needed according to each subtask. We conduct extensive offline and online A/B experiments, and the results show that SSUF significantly outperforms the state-of-the-art models.",
      "authors": [
        "Chunyuan Yuan",
        "Chong Zhang",
        "Zheng Fang",
        "Ming Pang",
        "Xue Jiang",
        "Changping Peng",
        "Zhangang Lin",
        "Ching Law"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21049",
        "HTML": "https://arxiv.org/html/2506.21049",
        "PDF": "https://arxiv.org/pdf/2506.21049"
      },
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 06:52:33 GMT",
          "size": "237kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "A Semi-supervised Scalable Unified Framework for E-commerce Query Classification",
      "relevance": {
        "keyword": "train_data",
        "level": "weak",
        "reason": "The paper discusses a semi-supervised framework for query classification using world knowledge and semi-supervised signals. It involves preprocessing and enhancing data representation but does not introduce novel methods specifically for LLM training data processing."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21095",
      "abstract": "Federated Learning (FL) enables collaborative model training across multiple clients without sharing clients' private data. However, fairness remains a key concern, as biases in local clients' datasets can impact the entire federated system. Heterogeneous data distributions across clients may lead to models that are fairer for some clients than others. Although several fairness-enhancing solutions are present in the literature, most focus on mitigating bias for a single sensitive attribute, typically binary, overlooking the diverse and sometimes conflicting fairness needs of different clients. This limited perspective can limit the effectiveness of fairness interventions for the different clients. To support more robust and reproducible fairness research in FL, we aim to enable a consistent benchmarking of fairness-aware FL methods at both the global and client levels. In this paper, we contribute in three ways: (1) We introduce FeDa4Fair, a library to generate tabular datasets tailored to evaluating fair FL methods under heterogeneous client bias; (2) we release four bias-heterogeneous datasets and corresponding benchmarks to compare fairness mitigation methods in a controlled environment; (3) we provide ready-to-use functions for evaluating fairness outcomes for these datasets.",
      "authors": [
        "Xenia Heilmann",
        "Luca Corbucci",
        "Mattia Cerrato",
        "Anna Monreale"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21095",
        "HTML": "https://arxiv.org/html/2506.21095",
        "PDF": "https://arxiv.org/pdf/2506.21095"
      },
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 08:43:12 GMT",
          "size": "474kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "FeDa4Fair: Client-Level Federated Datasets for Fairness Evaluation",
      "relevance": {
        "keyword": "train_data",
        "level": "weak",
        "reason": "The paper focuses primarily on fairness in federated learning by providing datasets and benchmarks for evaluating FL methods. Although it involves dataset construction, it does not specifically address LLM training data processing."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21119",
      "abstract": "Fine-tuning is a promising technique for leveraging Transformer-based language models in downstream tasks. As model sizes continue to grow, updating all model parameters becomes increasingly costly. Parameter-efficient fine-tuning methods effectively address this issue by selectively updating a small subset of parameters. However, fine-tuning and most existing parameter-efficient fine-tuning methods require updating the same number of parameters as the initial size, ignoring the unequal contribution across Transformer blocks and leading to extremely inefficient allocation of computing resources. In this paper, we propose Progtuning, the novel fine-tuning framework combined with progressive learning for Transformer-based language models. Specifically, Progtuning progressively reduces the number of updated transformer blocks based on the contribution. Remarkably, Progtuning optimizes resource allocation and reduces the number of updated parameters by approximately 25\\%, while still maintaining competitive performance. And it also exhibits high adaptability with parameter-efficient fine-tuning methods, demonstrating excellent performance across various adaptation scenarios.",
      "authors": [
        "Xiaoshuang Ji",
        "Zhendong Zhao",
        "Xiaojun Chen",
        "Xin Zhao",
        "and Zeyao Liu"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21119",
        "HTML": "https://arxiv.org/html/2506.21119",
        "PDF": "https://arxiv.org/pdf/2506.21119"
      },
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 09:37:15 GMT",
          "size": "383kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Progtuning: Progressive Fine-tuning Framework for Transformer-based Language Models",
      "relevance": {
        "keyword": "train_data",
        "level": "weak",
        "reason": "While this paper proposes Progtuning, a fine-tuning framework that reduces updated transformer blocks, it primarily focuses on parameter efficiency rather than specific data preparation or processing for LLM fine-tuning."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21151",
      "abstract": "The accurate segmentation of myocardial scars from cardiac MRI is essential for clinical assessment and treatment planning. In this study, we propose a robust deep-learning pipeline for fully automated myocardial scar detection and segmentation by fine-tuning state-of-the-art models. The method explicitly addresses challenges of label noise from semi-automatic annotations, data heterogeneity, and class imbalance through the use of Kullback-Leibler loss and extensive data augmentation. We evaluate the model's performance on both acute and chronic cases and demonstrate its ability to produce accurate and smooth segmentations despite noisy labels. In particular, our approach outperforms state-of-the-art models like nnU-Net and shows strong generalizability in an out-of-distribution test set, highlighting its robustness across various imaging conditions and clinical tasks. These results establish a reliable foundation for automated myocardial scar quantification and support the broader clinical adoption of deep learning in cardiac imaging.",
      "authors": [
        "Aida Moafi",
        "Danial Moafi",
        "Evgeny M. Mirkes",
        "Gerry P. McCann",
        "Abbas S. Alatrany",
        "Jayanth R. Arnold",
        "Mostafa Mehdipour Ghazi"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21151",
        "HTML": "https://arxiv.org/html/2506.21151",
        "PDF": "https://arxiv.org/pdf/2506.21151"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 11:21:58 GMT",
          "size": "5889kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Robust Deep Learning for Myocardial Scar Segmentation in Cardiac MRI with Noisy Labels",
      "relevance": {
        "keyword": "train_data",
        "level": "weak",
        "reason": "The paper primarily addresses the segmentation of MRI images and challenges related to noisy labels, with a focus on deep-learning model fine-tuning and data augmentation. No direct advancement in LLM training data engineering or processing is mentioned."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21170",
      "abstract": "Autoregressive language models dominate modern text generation, yet their sequential nature introduces fundamental limitations: decoding is slow, and maintaining global coherence remains challenging. Diffusion models offer a promising alternative by enabling parallel generation and flexible control; however, their application to text generation is hindered by the high dimensionality of token-level representations. We introduce Cosmos, a novel approach to text generation that operates entirely in a compressed, smooth latent space tailored specifically for diffusion. This space is learned using an autoencoder trained simultaneously for token-level reconstruction and alignment with frozen activations from a pretrained language encoder, providing robust semantic grounding and enabling effective perturbation-based augmentations. Empirically, we demonstrate that text representations can be compressed by $8\\times$ while maintaining generation quality comparable to token-level diffusion models. Furthermore, increasing the latent sequence length allows Cosmos to surpass both diffusion-based and autoregressive baselines. We evaluate Cosmos on four diverse generative tasks including story generation, question generation, summarization, and detoxification and compare it with various generative paradigms. Cosmos achieves comparable or superior generation quality while offering more than $2\\times$ faster inference.",
      "authors": [
        "Viacheslav Meshchaninov",
        "Egor Chimbulatov",
        "Alexander Shabalin",
        "Aleksandr Abramov",
        "Dmitry Vetrov"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21170",
        "HTML": "https://arxiv.org/html/2506.21170",
        "PDF": "https://arxiv.org/pdf/2506.21170"
      },
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 12:05:13 GMT",
          "size": "335kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Compressed and Smooth Latent Space for Text Diffusion Modeling",
      "relevance": {
        "keyword": "train_data",
        "level": "weak",
        "reason": "While the paper discusses text generation models, it does not focus on the construction or processing of training data for LLMs specifically. The primary focus is on proposing a novel generation approach that improves text diffusion models."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21182",
      "abstract": "The Massive Text Embedding Benchmark (MTEB) has become a standard evaluation platform for text embedding models. While previous work has established the core benchmark methodology, this paper focuses on the engineering aspects that ensure MTEB's continued reproducibility and extensibility. We present our approach to maintaining robust continuous integration pipelines that validate dataset integrity, automate test execution, and assess benchmark results' generalizability. We detail the design choices that collectively enhance reproducibility and usability. Furthermore, we discuss our strategies for handling community contributions and extending the benchmark with new tasks and datasets. These engineering practices have been instrumental in scaling MTEB to become more comprehensive while maintaining quality and, ultimately, relevance to the field. Our experiences offer valuable insights for benchmark maintainers facing similar challenges in ensuring reproducibility and usability in machine learning evaluation frameworks. The MTEB repository is available at: https://github.com/embeddings-benchmark/mteb",
      "authors": [
        "Isaac Chung",
        "Imene Kerboua",
        "Marton Kardos",
        "Roman Solomatin",
        "Kenneth Enevoldsen"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21182",
        "HTML": "https://arxiv.org/html/2506.21182",
        "PDF": "https://arxiv.org/pdf/2506.21182"
      },
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 12:40:48 GMT",
          "size": "840kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Maintaining MTEB: Towards Long Term Usability and Reproducibility of Embedding Benchmarks",
      "relevance": {
        "keyword": "train_data",
        "level": "weak",
        "reason": "The paper discusses robust integration pipelines for the Massive Text Embedding Benchmark (MTEB), focusing on dataset integrity and maintenance, which loosely relates to data quality processes, but not directly to LLM training data processing contributions."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21184",
      "abstract": "Long-video understanding (LVU) remains a severe challenge for existing multimodal large language models (MLLMs), primarily due to the prohibitive computational cost. Recent approaches have explored KV compression to mitigate this issue, but they often suffer from significant information loss at high compression ratios. In this paper, we introduce Video-X^2L, which flexibly preserves critical video information for each LVU task. Video-X^2L involves two key operations. The first one is called bi-level KV compression. During the MLLM's pre-filling stage, Video-X^2L generates two types of compressed KVs: low-compression KVs (L-KVs) to capture fine-grained video details and high-compression KVs (H-KVs) to offer compact video representations. The second one is called selective KV re-loading. During the MLLM's decoding stage, Video-X^2L selectively re-loads L-KVs for the most critical video chunks while using H-KVs for other less important ones. This allows the MLLM to fully utilize task-specific information while maintaining the overall compactness. Video-X^2L is simple yet effective: it is free from additional training and directly compatible with existing KV-compressible MLLMs. We evaluate Video-X^2L with a variety of popular LVU benchmarks, including VideoMME, MLVU, LongVideoBench, and VNBench. Our experiment result shows that Video-X^2L outperforms existing KV-compression methods by a huge advantage while substantially saving the computation cost.",
      "authors": [
        "Minghao Qin",
        "Yan Shu",
        "Peitian Zhang",
        "Kun Lun",
        "Huaying Yuan",
        "Juenjie Zhou",
        "Shitao Xiao",
        "Bo Zhao",
        "Zheng Liu"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21184",
        "HTML": "https://arxiv.org/html/2506.21184",
        "PDF": "https://arxiv.org/pdf/2506.21184"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 12:43:43 GMT",
          "size": "353kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Task-Aware KV Compression For Cost-Effective Long Video Understanding",
      "relevance": {
        "keyword": "train_data",
        "level": "weak",
        "reason": "The paper presents Video-X^2L for improving computational costs in long-video understanding by using KV compression in MLLMs. While it involves data processing techniques, it focuses more on model efficiency rather than LLM-specific data preprocessing pipelines."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21191",
      "abstract": "Turn-taking prediction models are essential components in spoken dialogue systems and conversational robots. Recent approaches leverage transformer-based architectures to predict speech activity continuously and in real-time. In this study, we propose a novel model that enables turn-taking prediction to be dynamically controlled via textual prompts. This approach allows intuitive and explicit control through instructions such as \"faster\" or \"calmer\" adapting dynamically to conversational partners and contexts. The proposed model builds upon a transformer-based voice activity projection (VAP) model, incorporating textual prompt embeddings into both channel-wise transformers and a cross-channel transformer. We evaluated the feasibility of our approach using over 950 hours of human-human spoken dialogue data. Since textual prompt data for the proposed approach was not available in existing datasets, we utilized a large language model (LLM) to generate synthetic prompt sentences. Experimental results demonstrated that the proposed model improved prediction accuracy and effectively varied turn-taking timing behaviors according to the textual prompts.",
      "authors": [
        "Koji Inoue",
        "Mikey Elmers",
        "Yahui Fu",
        "Zi Haur Pang",
        "Divesh Lala",
        "Keiko Ochi",
        "Tatsuya Kawahara"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21191",
        "HTML": "https://arxiv.org/html/2506.21191",
        "PDF": "https://arxiv.org/pdf/2506.21191"
      },
      "subjects": [
        "Computation and Language (cs.CL)",
        "Sound (cs.SD)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 12:49:07 GMT",
          "size": "518kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Prompt-Guided Turn-Taking Prediction",
      "relevance": {
        "keyword": "train_data",
        "level": "weak",
        "reason": "The paper utilizes a large language model to generate synthetic prompt sentences due to a lack of existing data, but does not propose new methods specifically for enhancing or processing LLM training data."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21209",
      "abstract": "State-of-the-art text-to-image models like Infinity generate photorealistic images at an unprecedented speed. These models operate in a bitwise autoregressive manner over a discrete set of tokens that is practically infinite in size. However, their impressive generative power comes with a growing risk: as their outputs increasingly populate the Internet, they are likely to be scraped and reused as training data-potentially by the very same models. This phenomenon has been shown to lead to model collapse, where repeated training on generated content, especially from the models' own previous versions, causes a gradual degradation in performance. A promising mitigation strategy is watermarking, which embeds human-imperceptible yet detectable signals into generated images-enabling the identification of generated content. In this work, we introduce BitMark, a robust bitwise watermarking framework for Infinity. Our method embeds a watermark directly at the bit level of the token stream across multiple scales (also referred to as resolutions) during Infinity's image generation process. Our bitwise watermark subtly influences the bits to preserve visual fidelity and generation speed while remaining robust against a spectrum of removal techniques. Furthermore, it exhibits high radioactivity, i.e., when watermarked generated images are used to train another image generative model, this second model's outputs will also carry the watermark. The radioactive traces remain detectable even when only fine-tuning diffusion or image autoregressive models on images watermarked with our BitMark. Overall, our approach provides a principled step toward preventing model collapse in image generative models by enabling reliable detection of generated outputs.",
      "authors": [
        "Louis Kerner",
        "Michel Meintz",
        "Bihe Zhao",
        "Franziska Boenisch",
        "Adam Dziedzic"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21209",
        "HTML": "https://arxiv.org/html/2506.21209",
        "PDF": "https://arxiv.org/pdf/2506.21209"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 13:03:13 GMT",
          "size": "30877kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "BitMark for Infinity: Watermarking Bitwise Autoregressive Image Generative Models",
      "relevance": {
        "keyword": "train_data",
        "level": "weak",
        "reason": "The paper discusses watermarking for image generative models to prevent model collapse, mentioning the risk of training data contamination. It briefly touches on preventing generated content from becoming training data without novel LLM data processing techniques."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21233",
      "abstract": "Training-free open-vocabulary semantic segmentation (OVS) aims to segment images given a set of arbitrary textual categories without costly model fine-tuning. Existing solutions often explore attention mechanisms of pre-trained models, such as CLIP, or generate synthetic data and design complex retrieval processes to perform OVS. However, their performance is limited by the capability of reliant models or the suboptimal quality of reference sets. In this work, we investigate the largely overlooked data quality problem for this challenging dense scene understanding task, and identify that a high-quality reference set can significantly benefit training-free OVS. With this observation, we introduce a data-quality-oriented framework, comprising a data pipeline to construct a reference set with well-paired segment-text embeddings and a simple similarity-based retrieval to unveil the essential effect of data. Remarkably, extensive evaluations on ten benchmark datasets demonstrate that our method outperforms all existing training-free OVS approaches, highlighting the importance of data-centric design for advancing OVS without training. Our code is available at https://github.com/xiweix/ReME .",
      "authors": [
        "Xiwei Xuan",
        "Ziquan Deng",
        "Kwan-Liu Ma"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21233",
        "HTML": "https://arxiv.org/html/2506.21233",
        "PDF": "https://arxiv.org/pdf/2506.21233"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 13:22:03 GMT",
          "size": "35778kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "ReME: A Data-Centric Framework for Training-Free Open-Vocabulary Segmentation",
      "relevance": {
        "keyword": "train_data",
        "level": "weak",
        "reason": "The paper highlights the significance of high-quality reference sets in training-free open-vocabulary segmentation but does not focus primarily on LLM training data processing."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21240",
      "abstract": "Component obsolescence poses significant challenges in industries reliant on electronic components, causing increased costs and disruptions in the security and availability of systems. Accurate obsolescence risk prediction is essential but hindered by a lack of reliable data. This paper proposes a novel approach to forecasting obsolescence risk using zero-shot learning (ZSL) with large language models (LLMs) to address data limitations by leveraging domain-specific knowledge from tabular datasets. Applied to two real-world datasets, the method demonstrates effective risk prediction. A comparative evaluation of four LLMs underscores the importance of selecting the right model for specific forecasting tasks.",
      "authors": [
        "Elie Saad",
        "Aya Mrabah",
        "Mariem Besbes",
        "Marc Zolghadri",
        "Victor Czmil",
        "Claude Baron",
        "Vincent Bourgeois"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21240",
        "HTML": "https://arxiv.org/html/2506.21240",
        "PDF": "https://arxiv.org/pdf/2506.21240"
      },
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 13:23:57 GMT",
          "size": "157kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Zero-Shot Learning for Obsolescence Risk Forecasting",
      "relevance": {
        "keyword": "train_data",
        "level": "weak",
        "reason": "While the paper employs LLMs for zero-shot learning in forecasting obsolescence risk, it primarily focuses on application rather than proposing new methods for LLM training data processing."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21252",
      "abstract": "As Multimodal Large Language Models (MLLMs) advance, multimodal agents show promise in real-world tasks like web navigation and embodied intelligence. However, due to limitations in a lack of external feedback, these agents struggle with self-correction and generalization. A promising approach is to use reward models as external feedback, but there is no clear on how to select reward models for agents. Thus, there is an urgent need to build a reward bench targeted at agents. To address these challenges, we propose Agent-RewardBench, a benchmark designed to evaluate reward modeling ability in MLLMs. The benchmark is characterized by three key features: (1) Multiple dimensions and real-world agent scenarios evaluation. It covers perception, planning, and safety with 7 scenarios; (2) Step-level reward evaluation. It allows for the assessment of agent capabilities at the individual steps of a task, providing a more granular view of performance during the planning process; and (3) Appropriately difficulty and high-quality. We carefully sample from 10 diverse models, difficulty control to maintain task challenges, and manual verification to ensure the integrity of the data. Experiments demonstrate that even state-of-the-art multimodal models show limited performance, highlighting the need for specialized training in agent reward modeling. Code is available at github.",
      "authors": [
        "Tianyi Men and Zhuoran Jin and Pengfei Cao and Yubo Chen and Kang Liu and Jun Zhao"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21252",
        "HTML": "https://arxiv.org/html/2506.21252",
        "PDF": "https://arxiv.org/pdf/2506.21252"
      },
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 13:36:12 GMT",
          "size": "3599kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Agent-RewardBench: Towards a Unified Benchmark for Reward Modeling across Perception, Planning, and Safety in Real-World Multimodal Agents",
      "relevance": {
        "keyword": "train_data",
        "level": "weak",
        "reason": "The paper proposes a benchmark, Agent-RewardBench, but its primary focus is on evaluating reward models for multimodal agents rather than on the processing of training data for LLMs."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21274",
      "abstract": "Large language models can produce convincing \"fake text\" in domains such as academic writing, product reviews, and political news. Many approaches have been investigated for the detection of artificially generated text. While this may seem to presage an endless \"arms race\", we note that newer LLMs use ever more parameters, training data, and energy, while relatively simple classifiers demonstrate a good level of detection accuracy with modest resources. To approach the question of whether the models' ability to beat the detectors may therefore reach a plateau, we examine the ability of statistical classifiers to identify \"fake text\" in the style of classical detective fiction. Over a 0.5 version increase, we found that Gemini showed an increased ability to generate deceptive text, while GPT did not. This suggests that reliable detection of fake text may remain feasible even for ever-larger models, though new model architectures may improve their deceptiveness",
      "authors": [
        "Andrea McGlinchey and Peter J Barclay"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21274",
        "HTML": "https://arxiv.org/html/2506.21274",
        "PDF": "https://arxiv.org/pdf/2506.21274"
      },
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 13:58:43 GMT",
          "size": "18kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Cat and Mouse -- Can Fake Text Generation Outpace Detector Systems?",
      "relevance": {
        "keyword": "train_data",
        "level": "weak",
        "reason": "The paper discusses the generation and detection of 'fake text' using LLMs. Although it mentions LLMs in the context of generating deceptive text, there is no new contribution to LLM training data processing methodologies."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21285",
      "abstract": "While slow-thinking large language models (LLMs) exhibit reflection-like reasoning, commonly referred to as the \"aha moment:, their ability to generate informative critiques and refine prior solutions remains limited. In this paper, we introduce Double-Checker, a principled framework designed to enhance the reasoning capabilities of slow-thinking LLMs by fostering explicit self-critique and iterative refinement of their previous solutions. By fine-tuning on our curated 1,730 self-critical instances, Double-Checker empowers long-CoT LLMs to iteratively critique and refine their outputs during inference until they evaluate their solutions as correct under self-generated critiques. We validate the efficacy of Double-Checker across a comprehensive suite of reasoning benchmarks, demonstrating that iterative self-critique significantly enhances the reasoning capabilities of long-CoT LLMs. Notably, our Double-Checker increases the pass@1 performance on challenging AIME benchmarks from 4.4% to 18.2% compared to the original long-CoT LLMs. These results highlight a promising direction for developing more trustworthy and effective LLMs capable of structured self-critique.",
      "authors": [
        "Xin Xu",
        "Tianhao Chen",
        "Fan Zhang",
        "Wanlong Liu",
        "Pengxiang Li",
        "Ajay Kumar Jaiswal",
        "Yuchen Yan",
        "Jishan Hu",
        "Yang Wang",
        "Hao Chen",
        "Shiwei Liu",
        "Shizhe Diao",
        "Can Yang",
        "Lu Yin"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21285",
        "HTML": "https://arxiv.org/html/2506.21285",
        "PDF": "https://arxiv.org/pdf/2506.21285"
      },
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 14:05:45 GMT",
          "size": "988kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Double-Checker: Enhancing Reasoning of Slow-Thinking LLMs via Self-Critical Fine-Tuning",
      "relevance": {
        "keyword": "train_data",
        "level": "weak",
        "reason": "The paper focuses on enhancing reasoning capabilities through self-critical fine-tuning of LLMs using curated datasets. It briefly mentions fine-tuning data but does not contribute any novel methods for data processing."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21294",
      "abstract": "In this paper, we explore the use of a text-only, autoregressive language modeling approach for the extraction of referring expressions from visually grounded dialogue. More specifically, the aim is to investigate the extent to which the linguistic context alone can inform the detection of mentions that have a (visually perceivable) referent in the visual context of the conversation. To this end, we adapt a pretrained large language model (LLM) to perform a relatively course-grained annotation of mention spans in unfolding conversations by demarcating mention span boundaries in text via next-token prediction. Our findings indicate that even when using a moderately sized LLM, relatively small datasets, and parameter-efficient fine-tuning, a text-only approach can be effective, highlighting the relative importance of the linguistic context for this task. Nevertheless, we argue that the task represents an inherently multimodal problem and discuss limitations fundamental to unimodal approaches.",
      "authors": [
        "Bram Willemsen",
        "Gabriel Skantze"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21294",
        "HTML": "https://arxiv.org/html/2506.21294",
        "PDF": "https://arxiv.org/pdf/2506.21294"
      },
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 14:14:20 GMT",
          "size": "3086kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Detecting Referring Expressions in Visually Grounded Dialogue with Autoregressive Language Models",
      "relevance": {
        "keyword": "train_data",
        "level": "weak",
        "reason": "The paper examines adapting LLMs for extracting referring expressions in visually grounded dialogue, mentioning fine-tuning but not proposing new data processing methods."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21298",
      "abstract": "Fine-tuning large-scale music generation models, such as MusicGen and Mustango, is a computationally expensive process, often requiring updates to billions of parameters and, therefore, significant hardware resources. Parameter-Efficient Fine-Tuning (PEFT) techniques, particularly adapter-based methods, have emerged as a promising alternative, enabling adaptation with minimal trainable parameters while preserving model performance. However, the design choices for adapters, including their architecture, placement, and size, are numerous, and it is unclear which of these combinations would produce optimal adapters and why, for a given case of low-resource music genre. In this paper, we attempt to answer this question by studying various adapter configurations for two AI music models, MusicGen and Mustango, on two genres: Hindustani Classical and Turkish Makam music.\n  Our findings reveal distinct trade-offs: convolution-based adapters excel in capturing fine-grained local musical details such as ornamentations and short melodic phrases, while transformer-based adapters better preserve long-range dependencies crucial for structured improvisation. Additionally, we analyze computational resource requirements across different adapter scales, demonstrating how mid-sized adapters (40M parameters) achieve an optimal balance between expressivity and quality. Furthermore, we find that Mustango, a diffusion-based model, generates more diverse outputs with better adherence to the description in the input prompt while lacking in providing stability in notes, rhythm alignment, and aesthetics. Also, it is computationally intensive and requires significantly more time to train. In contrast, autoregressive models like MusicGen offer faster training and are more efficient, and can produce better quality output in comparison, but have slightly higher redundancy in their generations.",
      "authors": [
        "Atharva Mehta",
        "Shivam Chauhan and Monojit Choudhury"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21298",
        "HTML": "https://arxiv.org/html/2506.21298",
        "PDF": "https://arxiv.org/pdf/2506.21298"
      },
      "subjects": [
        "Sound (cs.SD)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)",
        "Machine Learning (cs.LG)",
        "Multimedia (cs.MM)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 14:18:39 GMT",
          "size": "2143kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Exploring Adapter Design Tradeoffs for Low Resource Music Generation",
      "relevance": {
        "keyword": "train_data",
        "level": "weak",
        "reason": "The paper discusses parameter-efficient fine-tuning methods for music generation models but does not focus on data processing techniques for LLMs specifically, although it touches on fine-tuning which is part of training-stage processing."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21308",
      "abstract": "Privacy risks in differentially private (DP) systems increase significantly when data is correlated, as standard DP metrics often underestimate the resulting privacy leakage, leaving sensitive information vulnerable. Given the ubiquity of dependencies in real-world databases, this oversight poses a critical challenge for privacy protections. Bayesian differential privacy (BDP) extends DP to account for these correlations, yet current BDP mechanisms indicate notable utility loss, limiting its adoption.\n  In this work, we address whether BDP can be realistically implemented in common data structures without sacrificing utility -- a key factor for its applicability. By analyzing arbitrary and structured correlation models, including Gaussian multivariate distributions and Markov chains, we derive practical utility guarantees for BDP. Our contributions include theoretical links between DP and BDP and a novel methodology for adapting DP mechanisms to meet the BDP requirements. Through evaluations on real-world databases, we demonstrate that our novel theorems enable the design of BDP mechanisms that maintain competitive utility, paving the way for practical privacy-preserving data practices in correlated settings.",
      "authors": [
        "Martin Lange",
        "Patricia Guerra-Balboa",
        "Javier Parra-Arnau",
        "Thorsten Strufe"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21308",
        "HTML": "https://arxiv.org/html/2506.21308",
        "PDF": "https://arxiv.org/pdf/2506.21308"
      },
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 14:25:44 GMT",
          "size": "893kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Balancing Privacy and Utility in Correlated Data: A Study of Bayesian Differential Privacy",
      "relevance": {
        "keyword": "train_data",
        "level": "weak",
        "reason": "The study discusses privacy in correlated data and Bayesian differential privacy, mentioning data-related challenges but does not provide new methods or processes specifically for LLM training data."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21316",
      "abstract": "Visual grounding in text-rich document images is a critical yet underexplored challenge for document intelligence and visual question answering (VQA) systems. We present \\drishtikon, a multi-granular visual grounding framework designed to enhance interpretability and trust in VQA for complex, multilingual documents. Our approach integrates robust multi-lingual OCR, large language models, and a novel region matching algorithm to accurately localize answer spans at block, line, word, and point levels. We curate a new benchmark from the CircularsVQA test set, providing fine-grained, human-verified annotations across multiple granularities. Extensive experiments demonstrate that our method achieves state-of-the-art grounding accuracy, with line-level granularity offering the best trade-off between precision and recall. Ablation studies further highlight the benefits of multi-block and multi-line reasoning. Comparative evaluations with leading vision-language models reveal the limitations of current VLMs in precise localization, underscoring the effectiveness of our structured, alignment-based approach. Our findings pave the way for more robust and interpretable document understanding systems in real-world, text-centric scenarios. Code and dataset has been made available at https://github.com/kasuba-badri-vishal/DhrishtiKon.",
      "authors": [
        "Badri Vishal Kasuba",
        "Parag Chaudhuri",
        "Ganesh Ramakrishnan"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21316",
        "HTML": "https://arxiv.org/html/2506.21316",
        "PDF": "https://arxiv.org/pdf/2506.21316"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 14:32:23 GMT",
          "size": "2721kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "DrishtiKon: Multi-Granular Visual Grounding for Text-Rich Document Images",
      "relevance": {
        "keyword": "train_data",
        "level": "weak",
        "reason": "The abstract mentions an approach that integrates large language models for visual grounding in document images, but does not detail novel data processing contributions specifically for LLM training."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21343",
      "abstract": "Traditional benchmarks for large language models (LLMs) typically rely on static evaluations through storytelling or opinion expression, which fail to capture the dynamic requirements of real-time information processing in contemporary applications. To address this limitation, we present DynamicBench, a benchmark designed to evaluate the proficiency of LLMs in storing and processing up-to-the-minute data. DynamicBench utilizes a dual-path retrieval pipeline, integrating web searches with local report databases. It necessitates domain-specific knowledge, ensuring accurate responses report generation within specialized fields. By evaluating models in scenarios that either provide or withhold external documents, DynamicBench effectively measures their capability to independently process recent information or leverage contextual enhancements. Additionally, we introduce an advanced report generation system adept at managing dynamic information synthesis. Our experimental results confirm the efficacy of our approach, with our method achieving state-of-the-art performance, surpassing GPT4o in document-free and document-assisted scenarios by 7.0% and 5.8%, respectively. The code and data will be made publicly available.",
      "authors": [
        "Jingyao Li",
        "Hao Sun",
        "Zile Qiao",
        "Yong Jiang",
        "Pengjun Xie",
        "Fei Huang",
        "Hong Xu",
        "Jiaya Jia"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21343",
        "HTML": "https://arxiv.org/html/2506.21343",
        "PDF": "https://arxiv.org/pdf/2506.21343"
      },
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 14:53:44 GMT",
          "size": "1699kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "DynamicBench: Evaluating Real-Time Report Generation in Large Language Models",
      "relevance": {
        "keyword": "train_data",
        "level": "weak",
        "reason": "While mentioning DynamicBench for evaluating LLMs, the contributions relate more to benchmarking LLMs rather than novel data processing methods or training data construction for LLMs."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21355",
      "abstract": "Multimodal in-context learning (ICL) remains underexplored despite significant potential for domains such as medicine. Clinicians routinely encounter diverse, specialized tasks requiring adaptation from limited examples, such as drawing insights from a few relevant prior cases or considering a constrained set of differential diagnoses. While multimodal large language models (MLLMs) have shown advances in medical visual question answering (VQA), their ability to learn multimodal tasks from context is largely unknown. We introduce SMMILE, the first expert-driven multimodal ICL benchmark for medical tasks. Eleven medical experts curated problems, each including a multimodal query and multimodal in-context examples as task demonstrations. SMMILE encompasses 111 problems (517 question-image-answer triplets) covering 6 medical specialties and 13 imaging modalities. We further introduce SMMILE++, an augmented variant with 1038 permuted problems. A comprehensive evaluation of 15 MLLMs demonstrates that most models exhibit moderate to poor multimodal ICL ability in medical tasks. In open-ended evaluations, ICL contributes only 8% average improvement over zero-shot on SMMILE and 9.4% on SMMILE++. We observe a susceptibility for irrelevant in-context examples: even a single noisy or irrelevant example can degrade performance by up to 9.5%. Moreover, example ordering exhibits a recency bias, i.e., placing the most relevant example last can lead to substantial performance improvements by up to 71%. Our findings highlight critical limitations and biases in current MLLMs when learning multimodal medical tasks from context.",
      "authors": [
        "Melanie Rieff",
        "Maya Varma",
        "Ossian Rabow",
        "Subathra Adithan",
        "Julie Kim",
        "Ken Chang",
        "Hannah Lee",
        "Nidhi Rohatgi",
        "Christian Bluethgen",
        "Mohamed S. Muneer",
        "Jean-Benoit Delbrouck",
        "Michael Moor"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21355",
        "HTML": "https://arxiv.org/html/2506.21355",
        "PDF": "https://arxiv.org/pdf/2506.21355"
      },
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 15:08:18 GMT",
          "size": "15496kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "SMMILE: An Expert-Driven Benchmark for Multimodal Medical In-Context Learning",
      "relevance": {
        "keyword": "train_data",
        "level": "weak",
        "reason": "While the paper introduces a benchmark for multimodal in-context learning in the medical domain, it only briefly mentions using existing models without contributing new methods for LLM data processing or construction."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21356",
      "abstract": "Cinematography, the fundamental visual language of film, is essential for conveying narrative, emotion, and aesthetic quality. While recent Vision-Language Models (VLMs) demonstrate strong general visual understanding, their proficiency in comprehending the nuanced cinematic grammar embedded within individual shots remains largely unexplored and lacks robust evaluation. This critical gap limits both fine-grained visual comprehension and the precision of AI-assisted video generation. To address this, we introduce \\textbf{ShotBench}, a comprehensive benchmark specifically designed for cinematic language understanding. It features over 3.5k expert-annotated QA pairs from images and video clips, meticulously curated from over 200 acclaimed (predominantly Oscar-nominated) films and spanning eight key cinematography dimensions. Our evaluation of 24 leading VLMs on ShotBench reveals their substantial limitations: even the top-performing model achieves less than 60\\% average accuracy, particularly struggling with fine-grained visual cues and complex spatial reasoning. To catalyze advancement in this domain, we construct \\textbf{ShotQA}, a large-scale multimodal dataset comprising approximately 70k cinematic QA pairs. Leveraging ShotQA, we develop \\textbf{ShotVL} through supervised fine-tuning and Group Relative Policy Optimization. ShotVL significantly outperforms all existing open-source and proprietary models on ShotBench, establishing new \\textbf{state-of-the-art} performance. We open-source our models, data, and code to foster rapid progress in this crucial area of AI-driven cinematic understanding and generation.",
      "authors": [
        "Hongbo Liu",
        "Jingwen He",
        "Yi Jin",
        "Dian Zheng",
        "Yuhao Dong",
        "Fan Zhang",
        "Ziqi Huang",
        "Yinan He",
        "Yangguang Li",
        "Weichao Chen",
        "Yu Qiao",
        "Wanli Ouyang",
        "Shengjie Zhao",
        "Ziwei Liu"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21356",
        "HTML": "https://arxiv.org/html/2506.21356",
        "PDF": "https://arxiv.org/pdf/2506.21356"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 15:09:21 GMT",
          "size": "10722kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "ShotBench: Expert-Level Cinematic Understanding in Vision-Language Models",
      "relevance": {
        "keyword": "train_data",
        "level": "weak",
        "reason": "The paper introduces a benchmark for cinematic understanding in vision-language models and uses supervised fine-tuning, but it does not primarily focus on novel data processing or collection methods for LLM training."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21374",
      "abstract": "Finetuning large pretrained neural networks is known to be resource-intensive, both in terms of memory and computational cost. To mitigate this, a common approach is to restrict training to a subset of the model parameters. By analyzing the relationship between gradients and weights during finetuning, we observe a notable pattern: large gradients are often associated with small-magnitude weights. This correlation is more pronounced in finetuning settings than in training from scratch. Motivated by this observation, we propose NANOADAM, which dynamically updates only the small-magnitude weights during finetuning and offers several practical advantages: first, this criterion is gradient-free -- the parameter subset can be determined without gradient computation; second, it preserves large-magnitude weights, which are likely to encode critical features learned during pretraining, thereby reducing the risk of catastrophic forgetting; thirdly, it permits the use of larger learning rates and consistently leads to better generalization performance in experiments. We demonstrate this for both NLP and vision tasks.",
      "authors": [
        "Chao Zhou",
        "Tom Jacobs",
        "Advait Gadhikar",
        "Rebekka Burkholz"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21374",
        "HTML": "https://arxiv.org/html/2506.21374",
        "PDF": "https://arxiv.org/pdf/2506.21374"
      },
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 15:22:55 GMT",
          "size": "16136kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Pay Attention to Small Weights",
      "relevance": {
        "keyword": "train_data",
        "level": "weak",
        "reason": "The paper focuses on a finetuning technique (NANOADAM) for neural networks by updating small-magnitude weights, which indirectly involves LLM training data processing, but does not introduce new methods for data collection or preprocessing."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21408",
      "abstract": "Despite their widespread use, large language models (LLMs) are known to hallucinate incorrect information and be poorly calibrated. This makes the uncertainty quantification of these models of critical importance, especially in high-stakes domains, such as autonomy and healthcare. Prior work has made Bayesian deep learning-based approaches to this problem more tractable by performing inference over the low-rank adaptation (LoRA) parameters of a fine-tuned model. While effective, these approaches struggle to scale to larger LLMs due to requiring further additional parameters compared to LoRA. In this work we present $\\textbf{Scala}$ble $\\textbf{B}$ayesian $\\textbf{L}$ow-Rank Adaptation via Stochastic Variational Subspace Inference (ScalaBL). We perform Bayesian inference in an $r$-dimensional subspace, for LoRA rank $r$. By repurposing the LoRA parameters as projection matrices, we are able to map samples from this subspace into the full weight space of the LLM. This allows us to learn all the parameters of our approach using stochastic variational inference. Despite the low dimensionality of our subspace, we are able to achieve competitive performance with state-of-the-art approaches while only requiring ${\\sim}1000$ additional parameters. Furthermore, it allows us to scale up to the largest Bayesian LLM to date, with four times as a many base parameters as prior work.",
      "authors": [
        "Colin Samplawski",
        "Adam D. Cobb",
        "Manoj Acharya",
        "Ramneet Kaur",
        "Susmit Jha"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21408",
        "HTML": "https://arxiv.org/html/2506.21408",
        "PDF": "https://arxiv.org/pdf/2506.21408"
      },
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 15:54:45 GMT",
          "size": "943kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Scalable Bayesian Low-Rank Adaptation of Large Language Models via Stochastic Variational Subspace Inference",
      "relevance": {
        "keyword": "train_data",
        "level": "weak",
        "reason": "The paper focuses on improving uncertainty quantification and scalability in large language models via Bayesian low-rank adaptation. It involves a data processing aspect in stochastic variational inference but does not primarily contribute to new methods for LLM training data processing."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21443",
      "abstract": "Detecting deceptive conversations on dynamic platforms is increasingly difficult due to evolving language patterns and Concept Drift (CD)\\-i.e., semantic or topical shifts that alter the context or intent of interactions over time. These shifts can obscure malicious intent or mimic normal dialogue, making accurate classification challenging. While Large Language Models (LLMs) show strong performance in natural language tasks, they often struggle with contextual ambiguity and hallucinations in risk\\-sensitive scenarios. To address these challenges, we present a Domain Knowledge (DK)\\-Enhanced LLM framework that integrates pretrained LLMs with structured, task\\-specific insights to perform fraud and concept drift detection. The proposed architecture consists of three main components: (1) a DK\\-LLM module to detect fake or deceptive conversations; (2) a drift detection unit (OCDD) to determine whether a semantic shift has occurred; and (3) a second DK\\-LLM module to classify the drift as either benign or fraudulent. We first validate the value of domain knowledge using a fake review dataset and then apply our full framework to SEConvo, a multiturn dialogue dataset that includes various types of fraud and spam attacks. Results show that our system detects fake conversations with high accuracy and effectively classifies the nature of drift. Guided by structured prompts, the LLaMA\\-based implementation achieves 98\\% classification accuracy. Comparative studies against zero\\-shot baselines demonstrate that incorporating domain knowledge and drift awareness significantly improves performance, interpretability, and robustness in high\\-stakes NLP applications.",
      "authors": [
        "Ali \\c{S}enol",
        "Garima Agrawal",
        "Huan Liu"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21443",
        "HTML": "https://arxiv.org/html/2506.21443",
        "PDF": "https://arxiv.org/pdf/2506.21443"
      },
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 16:29:45 GMT",
          "size": "229kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Domain Knowledge-Enhanced LLMs for Fraud and Concept Drift Detection",
      "relevance": {
        "keyword": "train_data",
        "level": "weak",
        "reason": "The paper mentions the use of a dataset for validating an LLM framework for fraud detection but focuses on the integration of domain knowledge with LLMs rather than novel contributions to LLM training data processing."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21445",
      "abstract": "Recent advances in large language models have enabled natural language interfaces that translate user questions into database queries, such as Text2SQL, Text2SPARQL, and Text2Cypher. While these interfaces enhance database accessibility, most research today focuses solely on English, with limited evaluation in other languages. This paper investigates the performance of foundational LLMs on the Text2Cypher task across multiple languages. We create and release a multilingual test set by translating English questions into Spanish and Turkish while preserving the original Cypher queries, enabling fair cross-lingual comparison. We evaluate multiple foundational models using standardized prompts and metrics. Our results show a consistent performance pattern: highest on English, then Spanish, and lowest on Turkish. We attribute this to differences in training data availability and linguistic characteristics. Additionally, we explore the impact of translating task prompts into Spanish and Turkish. Results show little to no change in evaluation metrics, suggesting prompt translation has minor impact. Our findings highlight the need for more inclusive evaluation and development in multilingual query generation. Future work includes schema localization and fine-tuning across diverse languages.",
      "authors": [
        "Makbule Gulcin Ozsoy",
        "William Tai"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21445",
        "HTML": "https://arxiv.org/html/2506.21445",
        "PDF": "https://arxiv.org/pdf/2506.21445"
      },
      "subjects": [
        "Computation and Language (cs.CL)",
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 16:31:10 GMT",
          "size": "413kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Text2Cypher Across Languages: Evaluating Foundational Models Beyond English",
      "relevance": {
        "keyword": "train_data",
        "level": "weak",
        "reason": "The paper discusses the creation of a multilingual test set for evaluating LLMs on Text2Cypher tasks across different languages, mentioning differences in training data availability. However, it does not propose new data processing methods or data engineering for LLM training."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21463",
      "abstract": "We propose a novel preference alignment framework for improving spoken dialogue models on real-time conversations from user interactions. Current preference learning methods primarily focus on text-based language models, and are not directly suited to the complexities of real-time speech interactions, with richer dynamics (e.g. interruption, interjection) and no explicit segmentation between speaker turns.We create a large-scale dataset of more than 150,000 preference pairs from raw multi-turn speech conversations, annotated with AI feedback, to cover preferences over both linguistic content and temporal context variations. We leverage offline alignment methods to finetune a full-duplex autoregressive speech-to-speech model. Extensive experiments demonstrate that feedback on generic conversations can be consistently effective in improving spoken dialogue models to produce more factual, safer and more contextually aligned interactions. We deploy the finetuned model and conduct holistic human evaluations to assess the impact beyond single-turn conversations. Our findings shed light on the importance of a well-calibrated balance among various dynamics, crucial for natural real-time speech dialogue systems.",
      "authors": [
        "Anne Wu",
        "Laurent Mazar\\'e",
        "Neil Zeghidour",
        "Alexandre D\\'efossez"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21463",
        "HTML": "https://arxiv.org/html/2506.21463",
        "PDF": "https://arxiv.org/pdf/2506.21463"
      },
      "subjects": [
        "Computation and Language (cs.CL)",
        "Machine Learning (cs.LG)",
        "Sound (cs.SD)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 16:45:20 GMT",
          "size": "1286kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Aligning Spoken Dialogue Models from User Interactions",
      "relevance": {
        "keyword": "train_data",
        "level": "weak",
        "reason": "The paper creates a dataset of preference pairs from speech conversations to improve dialogue models, briefly referencing data preparation but focusing mainly on model fine-tuning rather than new data processing techniques."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21467",
      "abstract": "Finding the optimal set of cloud resources to deploy a given workload at minimal cost while meeting a defined service level agreement is an active area of research. Combining tens of parameters applicable across a large selection of compute, storage, and services offered by cloud providers with similar numbers of application-specific parameters leads to configuration spaces with millions of deployment options.\n  In this paper, we propose Discovery Space, an abstraction that formalizes the description of workload configuration problems, and exhibits a set of characteristics required for structured, robust and distributed investigations of large search spaces. We describe a concrete implementation of the Discovery Space abstraction and show that it is generalizable across a diverse set of workloads such as Large Language Model inference and Big Data Analytics.\n  We demonstrate that our approach enables safe, transparent sharing of data between executions of best-of-breed optimizers increasing the efficiency of optimal configuration detection in large search spaces. We also demonstrate how Discovery Spaces enable transfer and reuse of knowledge across similar search spaces, enabling configuration search speed-ups of over 90%.",
      "authors": [
        "Michael Johnston",
        "Burkhard Ringlein",
        "Christoph Hagleitner",
        "Alessandro Pomponio",
        "Vassilis Vassiliadis",
        "Christian Pinto",
        "and Srikumar Venugopal"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21467",
        "HTML": "https://arxiv.org/html/2506.21467",
        "PDF": "https://arxiv.org/pdf/2506.21467"
      },
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 16:54:39 GMT",
          "size": "639kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Efficient and Reuseable Cloud Configuration Search Using Discovery Spaces",
      "relevance": {
        "keyword": "train_data",
        "level": "weak",
        "reason": "The paper discusses cloud configuration for deploying workloads like LLM inference, indirectly touching on LLM-related processes, but it centers on cloud resource optimization rather than LLM data engineering."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21490",
      "abstract": "Achieving seamless coordination between AI agents and humans is crucial for real-world applications, yet it remains a significant open challenge. Hanabi is a cooperative card game featuring imperfect information, constrained communication, theory of mind requirements, and coordinated action -- making it an ideal testbed for human-AI coordination. However, its use for human-AI interaction has been limited by the challenges of human evaluation. In this work, we introduce the Ad-Hoc Human-AI Coordination Challenge (AH2AC2) to overcome the constraints of costly and difficult-to-reproduce human evaluations. We develop \\textit{human proxy agents} on a large-scale human dataset that serve as robust, cheap, and reproducible human-like evaluation partners in AH2AC2. To encourage the development of data-efficient methods, we open-source a dataset of 3,079 games, deliberately limiting the amount of available human gameplay data. We present baseline results for both two- and three- player Hanabi scenarios. To ensure fair evaluation, we host the proxy agents through a controlled evaluation system rather than releasing them publicly. The code is available at \\href{https://github.com/FLAIROx/ah2ac2}{https://github.com/FLAIROx/ah2ac2}.",
      "authors": [
        "Tin Dizdarevi\\'c",
        "Ravi Hammond",
        "Tobias Gessler",
        "Anisoara Calinescu",
        "Jonathan Cook",
        "Matteo Gallici",
        "Andrei Lupu",
        "Jakob Nicolaus Foerster"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21490",
        "HTML": "https://arxiv.org/html/2506.21490",
        "PDF": "https://arxiv.org/pdf/2506.21490"
      },
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Human-Computer Interaction (cs.HC)",
        "Multiagent Systems (cs.MA)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 17:19:52 GMT",
          "size": "1683kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Ad-Hoc Human-AI Coordination Challenge",
      "relevance": {
        "keyword": "train_data",
        "level": "weak",
        "reason": "The paper introduces a dataset for human-AI coordination challenges, mentioning data-efficient methods, but does not significantly contribute to LLM training data creation or processing."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21512",
      "abstract": "The concurrent optimization of language models and instructional prompts presents a significant challenge for deploying efficient and effective AI systems, particularly when balancing performance against computational costs like token usage. This paper introduces and assesses a bi-objective evolutionary search engine designed to navigate this complex space, focusing specifically on Small Language Models (SLMs). We employ the NSGA-II algorithm and prompt grammar to simultaneously optimize for task accuracy and token efficiency across some reasoning tasks. Our results successfully identify diverse, high-performing model-prompt combinations, quantitatively revealing the critical trade-off between the two objectives. This research highlights task-specific affinities between particular SLMs and prompt structures (e.g., instructions, context, chain of thought). The generated practical Pareto fronts offer decision-makers a portfolio of optimized solutions adaptable to their specific constraints. This automated approach moves beyond traditional manual tuning, providing a foundational framework for discovering effective human-AI interaction patterns.",
      "authors": [
        "Cl\\'audio L\\'ucio do Val Lopes and Lucca Machado"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21512",
        "HTML": "https://arxiv.org/html/2506.21512",
        "PDF": "https://arxiv.org/pdf/2506.21512"
      },
      "subjects": [
        "Neural and Evolutionary Computing (cs.NE)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 17:36:23 GMT",
          "size": "79kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Assessing an evolutionary search engine for small language models, prompts, and evaluation metrics",
      "relevance": {
        "keyword": "train_data",
        "level": "weak",
        "reason": "The paper discusses an evolutionary search engine for optimizing small language models and prompts but does not focus on data collection or processing methods specific to LLM training data."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21536",
      "abstract": "With the rapid development of digital technology, AI-driven psychological counseling has gradually become an important research direction in the field of mental health. However, existing models still have deficiencies in dialogue safety, detailed scenario handling, and lightweight deployment. To address these issues, this study proposes PsyLite, a lightweight psychological counseling large language model agent developed based on the base model InternLM2.5-7B-chat. Through a two-stage training strategy (hybrid distillation data fine-tuning and ORPO preference optimization), PsyLite enhances the model's deep-reasoning ability, psychological counseling ability, and safe dialogue ability. After deployment using Ollama and Open WebUI, a custom workflow is created with Pipelines. An innovative conditional RAG is designed to introduce crosstalk humor elements at appropriate times during psychological counseling to enhance user experience and decline dangerous requests to strengthen dialogue safety. Evaluations show that PsyLite outperforms the baseline models in the Chinese general evaluation (CEval), psychological counseling professional evaluation (CPsyCounE), and dialogue safety evaluation (SafeDialBench), particularly in psychological counseling professionalism (CPsyCounE score improvement of 47.6\\%) and dialogue safety (\\safe{} score improvement of 2.4\\%). Additionally, the model uses quantization technology (GGUF q4\\_k\\_m) to achieve low hardware deployment (5GB memory is sufficient for operation), providing a feasible solution for psychological counseling applications in resource-constrained environments.",
      "authors": [
        "Fangjun Ding and Renyu Zhang and Xinyu Feng and Chengye Xie and Zheng Zhang and Yanting Zhang"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21536",
        "HTML": "https://arxiv.org/html/2506.21536",
        "PDF": "https://arxiv.org/pdf/2506.21536"
      },
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 17:54:42 GMT",
          "size": "3209kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "PsyLite Technical Report",
      "relevance": {
        "keyword": "train_data",
        "level": "weak",
        "reason": "The paper reports on a model enhancement through a two-stage training strategy, including fine-tuning with hybrid distillation, which relates to training-stage data processing. However, the focus is more on the capabilities of the model rather than on novel training data engineering methods."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21547",
      "abstract": "We present SAM4D, a multi-modal and temporal foundation model designed for promptable segmentation across camera and LiDAR streams. Unified Multi-modal Positional Encoding (UMPE) is introduced to align camera and LiDAR features in a shared 3D space, enabling seamless cross-modal prompting and interaction. Additionally, we propose Motion-aware Cross-modal Memory Attention (MCMA), which leverages ego-motion compensation to enhance temporal consistency and long-horizon feature retrieval, ensuring robust segmentation across dynamically changing autonomous driving scenes. To avoid annotation bottlenecks, we develop a multi-modal automated data engine that synergizes VFM-driven video masklets, spatiotemporal 4D reconstruction, and cross-modal masklet fusion. This framework generates camera-LiDAR aligned pseudo-labels at a speed orders of magnitude faster than human annotation while preserving VFM-derived semantic fidelity in point cloud representations. We conduct extensive experiments on the constructed Waymo-4DSeg, which demonstrate the powerful cross-modal segmentation ability and great potential in data annotation of proposed SAM4D.",
      "authors": [
        "Jianyun Xu",
        "Song Wang",
        "Ziqian Ni",
        "Chunyong Hu",
        "Sheng Yang",
        "Jianke Zhu",
        "Qiang Li"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21547",
        "HTML": "https://arxiv.org/html/2506.21547",
        "PDF": "https://arxiv.org/pdf/2506.21547"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 17:59:14 GMT",
          "size": "12997kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "SAM4D: Segment Anything in Camera and LiDAR Streams",
      "relevance": {
        "keyword": "train_data",
        "level": "weak",
        "reason": "While the paper discusses automated data engines for generating pseudo-labels, it focuses on camera and LiDAR streams for segmentation rather than LLM data processing."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21549",
      "abstract": "We propose SiM3D, the first benchmark considering the integration of multiview and multimodal information for comprehensive 3D anomaly detection and segmentation (ADS), where the task is to produce a voxel-based Anomaly Volume. Moreover, SiM3D focuses on a scenario of high interest in manufacturing: single-instance anomaly detection, where only one object, either real or synthetic, is available for training. In this respect, SiM3D stands out as the first ADS benchmark that addresses the challenge of generalising from synthetic training data to real test data. SiM3D includes a novel multimodal multiview dataset acquired using top-tier industrial sensors and robots. The dataset features multiview high-resolution images (12 Mpx) and point clouds (7M points) for 333 instances of eight types of objects, alongside a CAD model for each type. We also provide manually annotated 3D segmentation GTs for anomalous test samples. To establish reference baselines for the proposed multiview 3D ADS task, we adapt prominent singleview methods and assess their performance using novel metrics that operate on Anomaly Volumes.",
      "authors": [
        "Alex Costanzino",
        "Pierluigi Zama Ramirez",
        "Luigi Lella",
        "Matteo Ragaglia",
        "Alessandro Oliva",
        "Giuseppe Lisanti",
        "Luigi Di Stefano"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21549",
        "HTML": "https://arxiv.org/html/2506.21549",
        "PDF": "https://arxiv.org/pdf/2506.21549"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 17:59:55 GMT",
          "size": "14058kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "SiM3D: Single-instance Multiview Multimodal and Multisetup 3D Anomaly Detection Benchmark",
      "relevance": {
        "keyword": "train_data",
        "level": "weak",
        "reason": "The paper presents a novel multimodal multiview dataset and benchmark for anomaly detection in manufacturing. While it introduces synthetic training data, the main contribution is in the realm of 3D anomaly detection and segmentation rather than LLM training data processing."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21550",
      "abstract": "Multivariate time series anomaly detection (MTS-AD) is critical in domains like healthcare, cybersecurity, and industrial monitoring, yet remains challenging due to complex inter-variable dependencies, temporal dynamics, and sparse anomaly labels. We introduce mTSBench, the largest benchmark to date for MTS-AD and unsupervised model selection, spanning 344 labeled time series across 19 datasets and 12 diverse application domains. mTSBench evaluates 24 anomaly detection methods, including large language model (LLM)-based detectors for multivariate time series, and systematically benchmarks unsupervised model selection techniques under standardized conditions. Consistent with prior findings, our results confirm that no single detector excels across datasets, underscoring the importance of model selection. However, even state-of-the-art selection methods remain far from optimal, revealing critical gaps. mTSBench provides a unified evaluation suite to enable rigorous, reproducible comparisons and catalyze future advances in adaptive anomaly detection and robust model selection.",
      "authors": [
        "Xiaona Zhou",
        "Constantin Brif",
        "Ismini Lourentzou"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21550",
        "HTML": "https://arxiv.org/html/2506.21550",
        "PDF": "https://arxiv.org/pdf/2506.21550"
      },
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 17:59:58 GMT",
          "size": "575kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "mTSBench: Benchmarking Multivariate Time Series Anomaly Detection and Model Selection at Scale",
      "relevance": {
        "keyword": "train_data",
        "level": "weak",
        "reason": "Although the paper discusses anomaly detection methods including LLM-based detectors, the focus is on comparing different methodologies for MTS-AD rather than directly contributing new approaches to LLM training data processing."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.20930",
      "abstract": "We propose a hybrid quantum-classical reinforcement learning framework for sector rotation in the Taiwan stock market. Our system employs Proximal Policy Optimization (PPO) as the backbone algorithm and integrates both classical architectures (LSTM, Transformer) and quantum-enhanced models (QNN, QRWKV, QASA) as policy and value networks. An automated feature engineering pipeline extracts financial indicators from capital share data to ensure consistent model input across all configurations. Empirical backtesting reveals a key finding: although quantum-enhanced models consistently achieve higher training rewards, they underperform classical models in real-world investment metrics such as cumulative return and Sharpe ratio. This discrepancy highlights a core challenge in applying reinforcement learning to financial domains -- namely, the mismatch between proxy reward signals and true investment objectives. Our analysis suggests that current reward designs may incentivize overfitting to short-term volatility rather than optimizing risk-adjusted returns. This issue is compounded by the inherent expressiveness and optimization instability of quantum circuits under Noisy Intermediate-Scale Quantum (NISQ) constraints. We discuss the implications of this reward-performance gap and propose directions for future improvement, including reward shaping, model regularization, and validation-based early stopping. Our work offers a reproducible benchmark and critical insights into the practical challenges of deploying quantum reinforcement learning in real-world finance.",
      "authors": [
        "Chi-Sheng Chen",
        "Xinyu Zhang",
        "Ya-Chuan Chen"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20930",
        "HTML": "https://arxiv.org/html/2506.20930",
        "PDF": "https://arxiv.org/pdf/2506.20930"
      },
      "subjects": [
        "Quantum Physics (quant-ph)",
        "Machine Learning (cs.LG)",
        "Computational Finance (q-fin.CP)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 01:29:19 GMT",
          "size": "360kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Quantum Reinforcement Learning Trading Agent for Sector Rotation in the Taiwan Stock Market",
      "relevance": {
        "keyword": "train_data",
        "level": "weak",
        "reason": "The paper involves automated feature engineering for consistency in model input, which touches on data preparation for reinforcement learning models but does not specifically focus on LLM training data processing tasks."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21245",
      "abstract": "This work introduces a novel framework for brain tumor segmentation leveraging pre-trained GANs and Unet architectures. By combining a global anomaly detection module with a refined mask generation network, the proposed model accurately identifies tumor-sensitive regions and iteratively enhances segmentation precision using adversarial loss constraints. Multi-modal MRI data and synthetic image augmentation are employed to improve robustness and address the challenge of limited annotated datasets. Experimental results on the BraTS dataset demonstrate the effectiveness of the approach, achieving high sensitivity and accuracy in both lesion-wise Dice and HD95 metrics than the baseline. This scalable method minimizes the dependency on fully annotated data, paving the way for practical real-world applications in clinical settings.",
      "authors": [
        "Qifei Cui",
        "Xinyu Lu"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21245",
        "HTML": "https://arxiv.org/html/2506.21245",
        "PDF": "https://arxiv.org/pdf/2506.21245"
      },
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 13:28:09 GMT",
          "size": "1121kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "GANet-Seg: Adversarial Learning for Brain Tumor Segmentation with Hybrid Generative Models",
      "relevance": {
        "keyword": "train_data",
        "level": "weak",
        "reason": "The paper discusses a framework for brain tumor segmentation using GANs and pre-trained models. It indirectly involves training data in the context of data augmentation and the use of MRI data but does not propose new methods related to LLMs data processing."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.21535",
      "abstract": "Multimodal Large Language Models (MLLMs) have emerged as a promising way to automate Radiology Report Generation (RRG). In this work, we systematically investigate the design space of 3D MLLMs, including visual input representation, projectors, Large Language Models (LLMs), and fine-tuning techniques for 3D CT report generation. We also introduce two knowledge-based report augmentation methods that improve performance on the GREEN score by up to 10\\%, achieving the 2nd place on the MICCAI 2024 AMOS-MM challenge. Our results on the 1,687 cases from the AMOS-MM dataset show that RRG is largely independent of the size of LLM under the same training protocol. We also show that larger volume size does not always improve performance if the original ViT was pre-trained on a smaller volume size. Lastly, we show that using a segmentation mask along with the CT volume improves performance. The code is publicly available at https://github.com/bowang-lab/AMOS-MM-Solution",
      "authors": [
        "Mohammed Baharoon",
        "Jun Ma",
        "Congyu Fang",
        "Augustin Toma",
        "Bo Wang"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21535",
        "HTML": "https://arxiv.org/html/2506.21535",
        "PDF": "https://arxiv.org/pdf/2506.21535"
      },
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 26 Jun 2025 17:54:20 GMT",
          "size": "666kb",
          "version": "v1"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Exploring the Design Space of 3D MLLMs for CT Report Generation",
      "relevance": {
        "keyword": "train_data",
        "level": "weak",
        "reason": "The paper mentions fine-tuning techniques for 3D CT report generation in MLLMs but does not primarily contribute to LLM training data processing methods or pipelines."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2402.09225",
      "abstract": "This article introduces the Membership Inference Test (MINT), a novel approach that aims to empirically assess if given data was used during the training of AI/ML models. Specifically, we propose two MINT architectures designed to learn the distinct activation patterns that emerge when an Audited Model is exposed to data used during its training process. These architectures are based on Multilayer Perceptrons (MLPs) and Convolutional Neural Networks (CNNs). The experimental framework focuses on the challenging task of Face Recognition, considering three state-of-the-art Face Recognition systems. Experiments are carried out using six publicly available databases, comprising over 22 million face images in total. Different experimental scenarios are considered depending on the context of the AI model to test. Our proposed MINT approach achieves promising results, with up to 90\\% accuracy, indicating the potential to recognize if an AI model has been trained with specific data. The proposed MINT approach can serve to enforce privacy and fairness in several AI applications, e.g., revealing if sensitive or private data was used for training or tuning Large Language Models (LLMs).",
      "authors": [
        "Daniel DeAlcala",
        "Aythami Morales",
        "Julian Fierrez",
        "Gonzalo Mancera",
        "Ruben Tolosana",
        "Javier Ortega-Garcia"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2402.09225",
        "HTML": "https://arxiv.org/html/2402.09225",
        "PDF": "https://arxiv.org/pdf/2402.09225"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 14 Feb 2024 15:09:01 GMT",
          "size": "359kb",
          "version": "v1"
        },
        {
          "date": "Fri, 06 Sep 2024 11:15:23 GMT",
          "size": "1915kb",
          "version": "v2"
        },
        {
          "date": "Thu, 26 Jun 2025 10:49:33 GMT",
          "size": "464kb",
          "version": "v3"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Is my Data in your AI Model? Membership Inference Test with Application to Face Images",
      "relevance": {
        "keyword": "train_data",
        "level": "weak",
        "reason": "The paper introduces an approach (MINT) to assess if data was used in model training, mentioning its application to enforce privacy for LLMs. However, it does not propose new LLM training data processing methods but instead focuses on testing membership of data in models."
      },
      "tasks": [
        "Face Recognition",
        "Fairness"
      ],
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2405.15668",
      "abstract": "Large language models (LLMs) have been effectively used for many computer vision tasks, including image classification. In this paper, we present a simple yet effective approach for zero-shot image classification using multimodal LLMs. Using multimodal LLMs, we generate comprehensive textual representations from input images. These textual representations are then utilized to generate fixed-dimensional features in a cross-modal embedding space. Subsequently, these features are fused together to perform zero-shot classification using a linear classifier. Our method does not require prompt engineering for each dataset; instead, we use a single, straightforward set of prompts across all datasets. We evaluated our method on several datasets and our results demonstrate its remarkable effectiveness, surpassing benchmark accuracy on multiple datasets. On average, for ten benchmarks, our method achieved an accuracy gain of 6.2 percentage points, with an increase of 6.8 percentage points on the ImageNet dataset, compared to prior methods re-evaluated with the same setup. Our findings highlight the potential of multimodal LLMs to enhance computer vision tasks such as zero-shot image classification, offering a significant improvement over traditional methods.",
      "authors": [
        "Abdelrahman Abdelhamed",
        "Mahmoud Afifi",
        "Alec Go"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2405.15668",
        "HTML": "https://arxiv.org/html/2405.15668",
        "PDF": "https://arxiv.org/pdf/2405.15668"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Fri, 24 May 2024 16:05:15 GMT",
          "size": "3035kb",
          "version": "v1"
        },
        {
          "date": "Thu, 03 Oct 2024 22:53:09 GMT",
          "size": "3323kb",
          "version": "v2"
        },
        {
          "date": "Sat, 08 Mar 2025 18:53:47 GMT",
          "size": "3420kb",
          "version": "v3"
        },
        {
          "date": "Thu, 27 Mar 2025 09:41:01 GMT",
          "size": "3420kb",
          "version": "v4"
        },
        {
          "date": "Wed, 25 Jun 2025 20:57:49 GMT",
          "size": "2912kb",
          "version": "v5"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "What Do You See? Enhancing Zero-Shot Image Classification with Multimodal Large Language Models",
      "relevance": {
        "keyword": "train_data",
        "level": "weak",
        "reason": "The paper makes use of multimodal LLMs for image classification tasks, briefly touching on the use of standardized prompts across datasets but does not focus on LLM training data processing or new data-related methods."
      },
      "tasks": [
        "Classification",
        "image-classification",
        "Image Classification",
        "Prompt Engineering",
        "Zero-Shot Image Classification",
        "Zero-Shot Learning"
      ],
      "repo_urls": [
        "https://github.com/donatoaz/what-do-you-see-zero-shot-image-classification-multimodal-llm"
      ],
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2406.09838",
      "abstract": "Meteorological heatmaps play a vital role in deciphering extreme weather phenomena, yet their inherent complexities marked by irregular contours, unstructured patterns, and complex color variations present unique analytical hurdles for state-of-the-art Vision-Language Models (VLMs). Current state-of-the-art models like GPT-4o, Qwen-VL, and LLaVA 1.6 struggle with tasks such as precise color identification and spatial localization, resulting in inaccurate or incomplete interpretations. To address these challenges, we introduce Sparse Position and Outline Tracking (SPOT), a novel algorithm specifically designed to process irregularly shaped colored regions in visual data. SPOT identifies and localizes these regions by extracting their spatial coordinates, enabling structured representations of irregular shapes. Building on SPOT, we construct ClimateIQA, a novel meteorological visual question answering (VQA) dataset, comprising 26,280 high-resolution heatmaps and 762,120 instruction samples for wind gust, total precipitation, wind chill index and heat index analysis. ClimateIQA enhances VLM training by incorporating spatial cues, geographic metadata, and reanalysis data, improving model accuracy in interpreting and describing extreme weather features. Furthermore, we develop Climate-Zoo, a suite of fine-tuned VLMs based on SPOT-empowered ClimateIQA, which significantly outperforms existing models in meteorological heatmap tasks.",
      "authors": [
        "Jian Chen",
        "Peilin Zhou",
        "Yining Hua",
        "Dading Chong",
        "Meng Cao",
        "Yaowei Li",
        "Wei Chen",
        "Bing Zhu",
        "Junwei Liang",
        "Zixuan Yuan"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2406.09838",
        "HTML": "https://arxiv.org/html/2406.09838",
        "PDF": "https://arxiv.org/pdf/2406.09838"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Fri, 14 Jun 2024 08:46:44 GMT",
          "size": "8338kb",
          "version": "v1"
        },
        {
          "date": "Tue, 24 Jun 2025 03:53:09 GMT",
          "size": "2933kb",
          "version": "v2"
        },
        {
          "date": "Thu, 26 Jun 2025 00:46:53 GMT",
          "size": "2933kb",
          "version": "v3"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "ClimateIQA: A New Dataset and Benchmark to Advance Vision-Language Models in Meteorology Anomalies Analysis",
      "relevance": {
        "keyword": "train_data",
        "level": "weak",
        "reason": "While the paper introduces a new meteorological dataset which may be used for training models, it primarily focuses on a dataset for vision-language tasks rather than novel methods or contributions for LLM data processing specifically."
      },
      "datasets": [
        {
          "dataset_name": "GPS-Lab/ClimateIQA",
          "downloads": "44",
          "likes": "4",
          "link": "https://huggingface.co/datasets/GPS-Lab/ClimateIQA"
        }
      ],
      "tasks": [
        "Question Answering",
        "Visual Question Answering",
        "Visual Question Answering (VQA)"
      ],
      "repo_urls": [
        "https://github.com/AlexJJJChen/Climate-Zoo"
      ],
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2406.15677",
      "abstract": "Controlling robots through natural language is pivotal for enhancing human-robot collaboration and synthesizing complex robot behaviors. Recent works that are trained on large robot datasets show impressive generalization abilities. However, such pretrained methods are (1) often fragile to unseen scenarios, and (2) expensive to adapt to new tasks. This paper introduces Grounded Equivariant Manipulation (GEM), a robust yet efficient approach that leverages pretrained vision-language models with equivariant language mapping for language-conditioned manipulation tasks. Our experiments demonstrate GEM's high sample efficiency and generalization ability across diverse tasks in both simulation and the real world. GEM achieves similar or higher performance with orders of magnitude fewer robot data compared with major data-efficient baselines such as CLIPort and VIMA. Finally, our approach demonstrates greater robustness compared to large VLA model, e.g, OpenVLA, at correctly interpreting natural language commands on unseen objects and poses. Code, data, and training details are available https://saulbatman.github.io/gem_page/",
      "authors": [
        "Mingxi Jia",
        "Haojie Huang",
        "Zhewen Zhang",
        "Chenghao Wang",
        "Linfeng Zhao",
        "Dian Wang",
        "Jason Xinyu Liu",
        "Robin Walters",
        "Robert Platt",
        "Stefanie Tellex"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2406.15677",
        "HTML": "https://arxiv.org/html/2406.15677",
        "PDF": "https://arxiv.org/pdf/2406.15677"
      },
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "Fri, 21 Jun 2024 22:49:23 GMT",
          "size": "29854kb",
          "version": "v1"
        },
        {
          "date": "Thu, 26 Jun 2025 14:35:25 GMT",
          "size": "3574kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Learning Efficient and Robust Language-conditioned Manipulation using Textual-Visual Relevancy and Equivariant Language Mapping",
      "relevance": {
        "keyword": "train_data",
        "level": "weak",
        "reason": "The paper briefly mentions leveraging pretrained vision-language models for language-conditioned tasks, which implies some data preprocessing, but it does not focus on novel methods for LLM training data construction or processing."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2407.13358",
      "abstract": "A wide range of Deep Natural Language Processing (NLP) models integrates continuous and low dimensional representations of words and documents. Surprisingly, very few models study representation learning for authors. These representations can be used for many NLP tasks, such as author identification and classification, or in recommendation systems. A strong limitation of existing works is that they do not explicitly capture writing style, making them hardly applicable to literary data. We therefore propose a new architecture based on Variational Information Bottleneck (VIB) that learns embeddings for both authors and documents with a stylistic constraint. Our model fine-tunes a pre-trained document encoder. We stimulate the detection of writing style by adding predefined stylistic features making the representation axis interpretable with respect to writing style indicators. We evaluate our method on three datasets: a literary corpus extracted from the Gutenberg Project, the Blog Authorship Corpus and IMDb62, for which we show that it matches or outperforms strong/recent baselines in authorship attribution while capturing much more accurately the authors stylistic aspects.",
      "authors": [
        "Enzo Terreau and Antoine Gourru and Julien Velcin"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2407.13358",
        "HTML": "https://arxiv.org/html/2407.13358",
        "PDF": "https://arxiv.org/pdf/2407.13358"
      },
      "subjects": [
        "Computation and Language (cs.CL)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 18 Jul 2024 10:01:09 GMT",
          "size": "824kb",
          "version": "v1"
        },
        {
          "date": "Thu, 26 Jun 2025 13:21:53 GMT",
          "size": "599kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Capturing Style in Author and Document Representation",
      "relevance": {
        "keyword": "train_data",
        "level": "weak",
        "reason": "The paper discusses the representation learning of authors and documents, focusing on capturing writing styles. It involves fine-tuning a pre-trained document encoder but does not introduce novel methods for data engineering or data processing specifically for LLM training data."
      },
      "tasks": [
        "Authorship Attribution",
        "Recommendation Systems",
        "Representation Learning"
      ],
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2409.00488",
      "abstract": "Low-cost gyroscope calibration is essential for ensuring the accuracy and reliability of gyroscope measurements. Stationary calibration estimates the deterministic parts of measurement errors. To this end, a common practice is to average the gyroscope readings during a predefined period and estimate the gyroscope bias. Calibration duration plays a crucial role in performance, therefore, longer periods are preferred. However, some applications require quick startup times and calibration is therefore allowed only for a short time. In this work, we focus on reducing low-cost gyroscope calibration time using deep learning methods. We propose an end-to-end convolutional neural network for the application of gyroscope calibration. We explore the possibilities of using multiple real and virtual gyroscopes to improve the calibration performance of single gyroscopes. To train and validate our approach, we recorded a dataset consisting of 186.6 hours of gyroscope readings, using 36 gyroscopes of four different brands. We also created a virtual dataset consisting of simulated gyroscope readings. The six datasets were used to evaluate our proposed approach. One of our key achievements in this work is reducing gyroscope calibration time by up to 89% using three low-cost gyroscopes. Our dataset is publicly available to allow reproducibility of our work and to increase research in the field.",
      "authors": [
        "Yair Stolero and Itzik Klein"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2409.00488",
        "HTML": "https://arxiv.org/html/2409.00488",
        "PDF": "https://arxiv.org/pdf/2409.00488"
      },
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Robotics (cs.RO)",
        "Signal Processing (eess.SP)"
      ],
      "submission_historys": [
        {
          "date": "Sat, 31 Aug 2024 15:47:31 GMT",
          "size": "712kb",
          "version": "v1"
        },
        {
          "date": "Wed, 02 Oct 2024 12:55:53 GMT",
          "size": "712kb",
          "version": "v2"
        },
        {
          "date": "Thu, 26 Jun 2025 13:16:22 GMT",
          "size": "715kb",
          "version": "v3"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Rapid Gyroscope Calibration: A Deep Learning Approach",
      "relevance": {
        "keyword": "train_data",
        "level": "weak",
        "reason": "The paper describes a new deep learning approach for gyroscope calibration, involving the creation of a dataset for training and validation. However, it does not focus on LLM training data or contribute novel methods for LLM data processing."
      },
      "tasks": [
        "Deep Learning"
      ],
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2409.09510",
      "abstract": "Despite its substantial impact on various search, recommendation, and question answering tasks, privacy-preserving methods for personalizing large language models (LLMs) have received relatively limited exploration. There is one primary approach in this area through retrieval-augmented generation (RAG), which generates personalized outputs by enriching the input prompt with information retrieved from the user's personal data. This paper studies an orthogonal approach to RAG that involves learning user-dependent LLM parameters through parameter-efficient fine-tuning (PEFT). This paper presents the first systematic study for exploration of PEFT for LLM personalization and provides an extensive comparisons between RAG- and PEFT-based solutions, across a broad set of seven diverse datasets from the LaMP benchmark. Our results demonstrate that, on average, both RAG- and PEFT-based personalization methods yield 14.92% and 1.07% improvements over non-personalized LLMs, respectively. When combining RAG with PEFT, we observe a further improvement of 15.98%, highlighting the effectiveness of their integration in enhancing personalized text generation. Additionally, we identify a positive correlation between the amount of user data available and the effectiveness of PEFT. This finding suggests that RAG is particularly beneficial for cold-start users -- users with limited personal data -- while PEFT performs better when more user-specific data is available.",
      "authors": [
        "Alireza Salemi",
        "Hamed Zamani"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2409.09510",
        "HTML": "https://arxiv.org/html/2409.09510",
        "PDF": "https://arxiv.org/pdf/2409.09510"
      },
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "Sat, 14 Sep 2024 19:18:26 GMT",
          "size": "368kb",
          "version": "v1"
        },
        {
          "date": "Thu, 26 Jun 2025 03:19:56 GMT",
          "size": "129kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Comparing Retrieval-Augmentation and Parameter-Efficient Fine-Tuning for Privacy-Preserving Personalization of Large Language Models",
      "relevance": {
        "keyword": "train_data",
        "level": "weak",
        "reason": "Although the paper explores privacy-preserving personalization of LLMs using retrieval-augmentation and parameter-efficient fine-tuning, it primarily compares model tuning methods rather than contributing to LLM training data processing itself."
      },
      "tasks": [
        "parameter-efficient fine-tuning",
        "Privacy Preserving",
        "RAG",
        "Retrieval"
      ],
      "repo_urls": [
        "https://github.com/lamp-benchmark/lamp"
      ],
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2411.05199",
      "abstract": "Large Language Models (LLMs) have revolutionized code generation but require significant resources and often over-generalize, limiting their task-specific efficiency. Fine-tuning smaller, open-source LLMs provides a cost-effective alternative. However, standard supervised approaches rely only on correct examples, missing valuable insights from failures. We introduce CodeLutra, a framework that leverages both correct and incorrect code attempts. Instead of using only correct solutions, CodeLutra applies iterative preference-based refinement, comparing successful and failed outputs to better approximate desired results. This approach narrows the performance gap with state-of-the-art larger models without requiring massive datasets or auxiliary models. For instance, on a challenging data science coding task, using only 500 samples improved Llama-3-8B's accuracy from 28.2% to 48.6%, approaching GPT-4's level. By learning from both successes and mistakes, CodeLutra provides a scalable and efficient path to high-quality code generation, making smaller open-source models more competitive with leading closed-source alternatives.",
      "authors": [
        "Leitian Tao",
        "Xiang Chen",
        "Tong Yu",
        "Tung Mai",
        "Ryan Rossi",
        "Yixuan Li",
        "Saayan Mitra"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.05199",
        "HTML": "https://arxiv.org/html/2411.05199",
        "PDF": "https://arxiv.org/pdf/2411.05199"
      },
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 07 Nov 2024 21:51:07 GMT",
          "size": "1920kb",
          "version": "v1"
        },
        {
          "date": "Thu, 19 Dec 2024 18:46:21 GMT",
          "size": "3857kb",
          "version": "v2"
        },
        {
          "date": "Wed, 25 Jun 2025 18:20:39 GMT",
          "size": "1548kb",
          "version": "v3"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "CodeLutra: Boosting LLM Code Generation via Preference-Guided Refinement",
      "relevance": {
        "keyword": "train_data",
        "level": "weak",
        "reason": "The paper focuses on boosting LLM code generation via a novel framework called CodeLutra, which leverages both successful and failed code attempts for refinement. While it involves using LLMs, the contribution is more about model refinement rather than novel data processing or engineering for LLM training."
      },
      "tasks": [
        "Code Generation"
      ],
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2502.13898",
      "abstract": "Current image captioning systems lack the ability to link descriptive text to specific visual elements, making their outputs difficult to verify. While recent approaches offer some grounding capabilities, they cannot track object identities across multiple references or ground both actions and objects simultaneously. We propose a novel ID-based grounding system that enables consistent object reference tracking and action-object linking. We present GroundCap, a dataset containing 52,016 images from 77 movies, with 344 human-annotated and 52,016 automatically generated captions. Each caption is grounded on detected objects (132 classes) and actions (51 classes) using a tag system that maintains object identity while linking actions to the corresponding objects. Our approach features persistent object IDs for reference tracking, explicit action-object linking, and the segmentation of background elements through K-means clustering. We propose gMETEOR, a metric combining caption quality with grounding accuracy, and establish baseline performance by fine-tuning Pixtral-12B and Qwen2.5-VL 7B on GroundCap. Human evaluation demonstrates our approach's effectiveness in producing verifiable descriptions with coherent object references.",
      "authors": [
        "Daniel A. P. Oliveira",
        "Louren\\c{c}o Teodoro",
        "David Martins de Matos"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.13898",
        "HTML": "https://arxiv.org/html/2502.13898",
        "PDF": "https://arxiv.org/pdf/2502.13898"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 19 Feb 2025 17:31:59 GMT",
          "size": "2751kb",
          "version": "v1"
        },
        {
          "date": "Mon, 24 Mar 2025 17:51:52 GMT",
          "size": "2749kb",
          "version": "v2"
        },
        {
          "date": "Wed, 25 Jun 2025 23:11:51 GMT",
          "size": "2742kb",
          "version": "v3"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "GroundCap: A Visually Grounded Image Captioning Dataset",
      "relevance": {
        "keyword": "train_data",
        "level": "weak",
        "reason": "The paper presents GroundCap, a dataset used for image captioning tasks and describes grounding processes but primarily in relation to image data. It touches lightly on dataset fine-tuning but does not propose novel LLM data-specific processing methods."
      },
      "models": [
        {
          "model_path": "daniel3303/PixtralGroundCap",
          "downloads": "5",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/daniel3303/PixtralGroundCap"
        }
      ],
      "datasets": [
        {
          "dataset_name": "daniel3303/GroundCap",
          "downloads": "826",
          "likes": "2",
          "link": "https://huggingface.co/datasets/daniel3303/GroundCap"
        }
      ],
      "tasks": [
        "Image Captioning",
        "Object Detection",
        "Visual Grounding"
      ],
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2503.04065",
      "abstract": "With the rapid advancement of digitalization, various document images are being applied more extensively in production and daily life, and there is an increasingly urgent need for fast and accurate parsing of the content in document images. Therefore, this report presents PP-DocBee, a novel multimodal large language model designed for end-to-end document image understanding. First, we develop a data synthesis strategy tailored to document scenarios in which we build a diverse dataset to improve the model generalization. Then, we apply a few training techniques, including dynamic proportional sampling, data preprocessing, and OCR postprocessing strategies. Extensive evaluations demonstrate the superior performance of PP-DocBee, achieving state-of-the-art results on English document understanding benchmarks and even outperforming existing open source and commercial models in Chinese document understanding. The source code and pre-trained models are publicly available at \\href{https://github.com/PaddlePaddle/PaddleMIX}{https://github.com/PaddlePaddle/PaddleMIX}.",
      "authors": [
        "Feng Ni",
        "Kui Huang",
        "Yao Lu",
        "Wenyu Lv",
        "Guanzhong Wang",
        "Zeyu Chen",
        "Yi Liu"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.04065",
        "HTML": "https://arxiv.org/html/2503.04065",
        "PDF": "https://arxiv.org/pdf/2503.04065"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 06 Mar 2025 03:43:21 GMT",
          "size": "6866kb",
          "version": "v1"
        },
        {
          "date": "Mon, 10 Mar 2025 03:22:24 GMT",
          "size": "6866kb",
          "version": "v2"
        },
        {
          "date": "Thu, 26 Jun 2025 01:11:25 GMT",
          "size": "4681kb",
          "version": "v3"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "PP-DocBee: Improving Multimodal Document Understanding Through a Bag of Tricks",
      "relevance": {
        "keyword": "train_data",
        "level": "weak",
        "reason": "The paper discusses PP-DocBee, a multimodal large language model for document understanding, and mentions developing a data synthesis strategy and data preprocessing, but does not primarily focus on novel methods for LLM training data processing."
      },
      "models": [
        {
          "model_path": "PaddleMIX/PPDocBee2-3B",
          "downloads": "64",
          "likes": "1",
          "trending_score": "0.0",
          "link": "https://huggingface.co/PaddleMIX/PPDocBee2-3B"
        }
      ],
      "tasks": [
        "document understanding",
        "Language Modeling",
        "Language Modelling",
        "Large Language Model",
        "Multimodal Large Language Model",
        "Optical Character Recognition (OCR)"
      ],
      "repo_urls": [
        "https://github.com/PaddlePaddle/PaddleMIX"
      ],
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2503.13952",
      "abstract": "With the rapid advancement of autonomous driving technology, a lack of data has become a major obstacle to enhancing perception model accuracy. Researchers are now exploring controllable data generation using world models to diversify datasets. However, previous work has been limited to studying image generation quality on specific public datasets. There is still relatively little research on how to build data generation engines for real-world application scenes to achieve large-scale data generation for challenging scenes. In this paper, a simulator-conditioned scene generation engine based on world model is proposed. By constructing a simulation system consistent with real-world scenes, simulation data and labels, which serve as the conditions for data generation in the world model, for any scenes can be collected. It is a novel data generation pipeline by combining the powerful scene simulation capabilities of the simulation engine with the robust data generation capabilities of the world model. In addition, a benchmark with proportionally constructed virtual and real data, is provided for exploring the capabilities of world models in real-world scenes. Quantitative results show that these generated images significantly improve downstream perception models performance. Finally, we explored the generative performance of the world model in urban autonomous driving scenarios. All the data and code will be available at https://github.com/Li-Zn-H/SimWorld.",
      "authors": [
        "Xinqing Li",
        "Ruiqi Song",
        "Qingyu Xie",
        "Ye Wu",
        "Nanxin Zeng",
        "Yunfeng Ai"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.13952",
        "HTML": "https://arxiv.org/html/2503.13952",
        "PDF": "https://arxiv.org/pdf/2503.13952"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 18 Mar 2025 06:41:02 GMT",
          "size": "6570kb",
          "version": "v1"
        },
        {
          "date": "Thu, 26 Jun 2025 17:52:58 GMT",
          "size": "6368kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "SimWorld: A Unified Benchmark for Simulator-Conditioned Scene Generation via World Model",
      "relevance": {
        "keyword": "train_data",
        "level": "weak",
        "reason": "Although primarily about data generation for simulator-conditioned scene generation, the paper briefly mentions the need for large-scale data generation, which can be tangentially related to data processing concerns in LLM contexts, but not directly in terms of language data."
      },
      "tasks": [
        "Autonomous Driving",
        "Image Generation",
        "Scene Generation"
      ],
      "repo_urls": [
        "https://github.com/li-zn-h/simworld"
      ],
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2503.15676",
      "abstract": "Semantic segmentation from RGB cameras is essential to the perception of autonomous flying vehicles. The stability of predictions through the captured videos is paramount to their reliability and, by extension, to the trustworthiness of the agents. In this paper, we propose a lightweight video semantic segmentation approach-suited to onboard real-time inference-achieving high temporal consistency on aerial data through Semantic Similarity Propagation across frames. SSP temporally propagates the predictions of an efficient image segmentation model with global registration alignment to compensate for camera movements. It combines the current estimation and the prior prediction with linear interpolation using weights computed from the features similarities of the two frames. Because data availability is a challenge in this domain, we propose a consistency-aware Knowledge Distillation training procedure for sparsely labeled datasets with few annotations. Using a large image segmentation model as a teacher to train the efficient SSP, we leverage the strong correlations between labeled and unlabeled frames in the same training videos to obtain high-quality supervision on all frames. KD-SSP obtains a significant temporal consistency increase over the base image segmentation model of 12.5% and 6.7% TC on UAVid and RuralScapes respectively, with higher accuracy and comparable inference speed. On these aerial datasets, KD-SSP provides a superior segmentation quality and inference speed trade-off than other video methods proposed for general applications and shows considerably higher consistency. Project page: https://github.com/FraunhoferIVI/SSP.",
      "authors": [
        "C\\'edric Vincent",
        "Taehyoung Kim",
        "Henri Mee{\\ss}"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.15676",
        "HTML": "https://arxiv.org/html/2503.15676",
        "PDF": "https://arxiv.org/pdf/2503.15676"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 19 Mar 2025 20:12:07 GMT",
          "size": "3073kb",
          "version": "v1"
        },
        {
          "date": "Thu, 26 Jun 2025 06:44:22 GMT",
          "size": "3065kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "High Temporal Consistency through Semantic Similarity Propagation in Semi-Supervised Video Semantic Segmentation for Autonomous Flight",
      "relevance": {
        "keyword": "train_data",
        "level": "weak",
        "reason": "The paper proposes a method for semantic segmentation in video data and mentions data sparsity challenges, but it does not contribute new methods specific to LLM training data processing or engineering. The mention of data is primarily in using sparsely labeled datasets."
      },
      "conference_url_abs": "http://openaccess.thecvf.com//content/CVPR2025/html/Vincent_High_Temporal_Consistency_through_Semantic_Similarity_Propagation_in_Semi-Supervised_Video_CVPR_2025_paper.html",
      "tasks": [
        "Image Segmentation",
        "Knowledge Distillation",
        "Segmentation",
        "Semantic Segmentation",
        "Semantic Similarity",
        "Semantic Textual Similarity",
        "Video Semantic Segmentation"
      ],
      "repo_urls": [
        "https://github.com/fraunhoferivi/ssp"
      ],
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2503.18104",
      "abstract": "The Remote Sensing Copy-Move Question Answering (RSCMQA) task focuses on interpreting complex tampering scenarios and inferring the relationships between objects. Currently, publicly available datasets often use randomly generated tampered images, which lack spatial logic and do not meet the practical needs of defense security and land resource monitoring. To address this, we propose a high-quality manually annotated RSCMQA dataset, Real-RSCM, which provides more realistic evaluation metrics for the identification and understanding of remote sensing image tampering. The tampered images in the Real-RSCM dataset are subtle, authentic, and challenging, posing significant difficulties for model discrimination capabilities. To overcome these challenges, we introduce a multimodal gated mixture of experts model (CM-MMoE), which guides multi-expert models to discern tampered information in images through multi-level visual semantics and textual joint modeling. Extensive experiments demonstrate that CM-MMoE provides a stronger benchmark for the RSCMQA task compared to general VQA and CMQA models. Our dataset and code are available at https://github.com/shenyedepisa/CM-MMoE.",
      "authors": [
        "Ze Zhang",
        "Enyuan Zhao",
        "Yi Jiang",
        "Jie Nie and Xinyue Liang"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.18104",
        "HTML": "https://arxiv.org/html/2503.18104",
        "PDF": "https://arxiv.org/pdf/2503.18104"
      },
      "subjects": [
        "Multimedia (cs.MM)"
      ],
      "submission_historys": [
        {
          "date": "Sun, 23 Mar 2025 15:22:37 GMT",
          "size": "23842kb",
          "version": "v1"
        },
        {
          "date": "Tue, 01 Apr 2025 14:15:03 GMT",
          "size": "23842kb",
          "version": "v2"
        },
        {
          "date": "Thu, 26 Jun 2025 06:05:39 GMT",
          "size": "12507kb",
          "version": "v3"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Challenging Dataset and Multi-modal Gated Mixture of Experts Model for Remote Sensing Copy-Move Forgery Understanding",
      "relevance": {
        "keyword": "train_data",
        "level": "weak",
        "reason": "The paper introduces a manually annotated dataset for remote sensing forgery analysis, which could relate to data preparation for certain ML tasks but it does not directly propose advancements in LLM training data processing or engineering specific to LLMs."
      },
      "repo_urls": [
        "https://github.com/shenyedepisa/cm-mmoe"
      ],
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2503.19263",
      "abstract": "Visual reasoning (VR), which is crucial in many fields for enabling human-like visual understanding, remains highly challenging. Recently, compositional visual reasoning approaches, which leverage the reasoning abilities of large language models (LLMs) with integrated tools to solve problems, have shown promise as more effective strategies than end-to-end VR methods. However, these approaches face limitations, as frozen LLMs lack tool awareness in VR, leading to performance bottlenecks. While leveraging LLMs for reasoning is widely used in other domains, they are not directly applicable to VR due to limited training data, imperfect tools that introduce errors and reduce data collection efficiency in VR, and challenging in fine-tuning on noisy workflows. To address these challenges, we propose DWIM: i) Discrepancy-aware training Workflow generation, which assesses tool usage and extracts more viable workflows for training; and ii) Instruct-Masking fine-tuning, which guides the model to only clone effective actions, enabling the generation of more practical solutions. Our experiments demonstrate that DWIM achieves state-of-the-art performance across various VR tasks, exhibiting strong generalization on multiple widely-used datasets.",
      "authors": [
        "Fucai Ke",
        "Vijay Kumar B G",
        "Xingjian Leng",
        "Zhixi Cai",
        "Zaid Khan",
        "Weiqing Wang",
        "Pari Delir Haghighi",
        "Hamid Rezatofighi",
        "Manmohan Chandraker"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.19263",
        "HTML": "https://arxiv.org/html/2503.19263",
        "PDF": "https://arxiv.org/pdf/2503.19263"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 25 Mar 2025 01:57:59 GMT",
          "size": "31229kb",
          "version": "v1"
        },
        {
          "date": "Thu, 26 Jun 2025 01:13:38 GMT",
          "size": "27520kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "DWIM: Towards Tool-aware Visual Reasoning via Discrepancy-aware Workflow Generation & Instruct-Masking Tuning",
      "relevance": {
        "keyword": "train_data",
        "level": "weak",
        "reason": "While the paper discusses enhancements in visual reasoning tasks using LLMs with compositional approaches, it addresses issues with training data but does not provide direct contributions to LLM training data processing or data engineering."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2503.21004",
      "abstract": "Pulmonary embolism (PE) registries accelerate practice improving research but rely on labor intensive manual abstraction of radiology reports. We examined whether openly available large language models (LLMs) can automate concept extraction from computed tomography PE (CTPE) reports without loss of data quality. Four Llama 3 variants (3.0 8B, 3.1 8B, 3.1 70B, 3.3 70B) and one reviewer model, Phi 4 14B, were tested on 250 dual annotated CTPE reports from each of MIMIC IV and Duke University. Accuracy, positive predictive value (PPV) and negative predictive value (NPV) versus a human gold standard were measured across model size, temperature and shot count. Mean accuracy rose with scale: 0.83 (3.0 8B), 0.91 (3.1 8B) and 0.96 for both 70B variants; Phi 4 14B reached 0.98. Accuracy differed by less than 0.03 between datasets, indicating external robustness. In dual model concordance (L3 70B plus Phi 4 14B) PPV for PE presence was at least 0.95 and NPV at least 0.98, while location, thrombus burden, right heart strain and image quality artifacts each achieved PPV of at least 0.90 and NPV of at least 0.95. Fewer than four percent of individual concept annotations were discordant, and full agreement occurred in more than seventy five percent of reports. Large language models therefore provide a scalable, accurate solution for PE registry abstraction, and a dual model review workflow can safeguard data quality with minimal human oversight.",
      "authors": [
        "Mahmoud Alwakeel",
        "Emory Buck",
        "Jonathan G. Martin",
        "Imran Aslam",
        "Sudarshan Rajagopal",
        "Jian Pei",
        "Mihai V. Podgoreanu",
        "Christopher J. Lindsell",
        "An-Kwok Ian Wong"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.21004",
        "HTML": "https://arxiv.org/html/2503.21004",
        "PDF": "https://arxiv.org/pdf/2503.21004"
      },
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 26 Mar 2025 21:38:06 GMT",
          "size": "1977kb",
          "version": "v1"
        },
        {
          "date": "Thu, 26 Jun 2025 02:02:45 GMT",
          "size": "1292kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Evaluating Large Language Models for Automated Clinical Abstraction in Pulmonary Embolism Registries: Performance Across Model Sizes, Versions, and Parameters",
      "relevance": {
        "keyword": "train_data",
        "level": "weak",
        "reason": "The paper uses existing LLMs to automate clinical abstraction, mentioning data sources and measuring performance, but it doesn't propose novel data processing methods for LLM training."
      },
      "tasks": [
        "Management"
      ],
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2504.05312",
      "abstract": "Retrieval-Augmented Generation (RAG), by integrating non-parametric knowledge from external knowledge bases into models, has emerged as a promising approach to enhancing response accuracy while mitigating factual errors and hallucinations. This method has been widely applied in tasks such as Question Answering (QA). However, existing RAG methods struggle with open-domain QA tasks because they perform independent retrieval operations and directly incorporate the retrieved information into generation without maintaining a summarizing memory or using adaptive retrieval strategies, leading to noise from redundant information and insufficient information integration. To address these challenges, we propose Adaptive memory-based optimization for enhanced RAG (Amber) for open-domain QA tasks, which comprises an Agent-based Memory Updater, an Adaptive Information Collector, and a Multi-granular Content Filter, working together within an iterative memory updating paradigm. Specifically, Amber integrates and optimizes the language model's memory through a multi-agent collaborative approach, ensuring comprehensive knowledge integration from previous retrieval steps. It dynamically adjusts retrieval queries and decides when to stop retrieval based on the accumulated knowledge, enhancing retrieval efficiency and effectiveness. Additionally, it reduces noise by filtering irrelevant content at multiple levels, retaining essential information to improve overall model performance. We conduct extensive experiments on several open-domain QA datasets, and the results demonstrate the superiority and effectiveness of our method and its components. The source code is available \\footnote{https://anonymous.4open.science/r/Amber-B203/}.",
      "authors": [
        "Qitao Qin",
        "Yucong Luo",
        "Yihang Lu",
        "Zhibo Chu",
        "Xianwei Meng"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.05312",
        "HTML": "https://arxiv.org/html/2504.05312",
        "PDF": "https://arxiv.org/pdf/2504.05312"
      },
      "subjects": [
        "Information Retrieval (cs.IR)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 19 Feb 2025 04:23:12 GMT",
          "size": "375kb",
          "version": "v1"
        },
        {
          "date": "Thu, 26 Jun 2025 06:44:43 GMT",
          "size": "375kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Towards Adaptive Memory-Based Optimization for Enhanced Retrieval-Augmented Generation",
      "relevance": {
        "keyword": "train_data",
        "level": "weak",
        "reason": "While the paper discusses optimizing retrieval-augmented generation through adaptive memory and filtering strategies, it primarily focuses on the model's performance improvements rather than direct contributions to LLM training data processing or engineering."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2504.07378",
      "abstract": "Recognizing geometric features on B-rep models is a cornerstone technique for multimedia content-based retrieval and has been widely applied in intelligent manufacturing. However, previous research often merely focused on Machining Feature Recognition (MFR), falling short in effectively capturing the intricate topological and geometric characteristics of complex geometry features. In this paper, we propose BRepFormer, a novel transformer-based model to recognize both machining feature and complex CAD models' features. BRepFormer encodes and fuses the geometric and topological features of the models. Afterwards, BRepFormer utilizes a transformer architecture for feature propagation and a recognition head to identify geometry features. During each iteration of the transformer, we incorporate a bias that combines edge features and topology features to reinforce geometric constraints on each face. In addition, we also proposed a dataset named Complex B-rep Feature Dataset (CBF), comprising 20,000 B-rep models. By covering more complex B-rep models, it is better aligned with industrial applications. The experimental results demonstrate that BRepFormer achieves state-of-the-art accuracy on the MFInstSeg, MFTRCAD, and our CBF datasets.",
      "authors": [
        "Yongkang Dai",
        "Xiaoshui Huang",
        "Yunpeng Bai",
        "Hao Guo",
        "Hongping Gan",
        "Ling Yang",
        "Yilei Shi"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.07378",
        "HTML": "https://arxiv.org/html/2504.07378",
        "PDF": "https://arxiv.org/pdf/2504.07378"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Thu, 10 Apr 2025 01:36:06 GMT",
          "size": "4502kb",
          "version": "v1"
        },
        {
          "date": "Fri, 11 Apr 2025 03:08:12 GMT",
          "size": "4502kb",
          "version": "v2"
        },
        {
          "date": "Thu, 26 Jun 2025 02:33:53 GMT",
          "size": "1157kb",
          "version": "v3"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "BRepFormer: Transformer-Based B-rep Geometric Feature Recognition",
      "relevance": {
        "keyword": "train_data",
        "level": "weak",
        "reason": "The paper introduces a transformer-based model for recognizing geometric features and proposes a new dataset (CBF) but does not directly address LLM training data processing or engineering stages."
      },
      "tasks": [],
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2504.09103",
      "abstract": "While most prior research has focused on improving the precision of multimodal trajectory predictions, the explicit modeling of multimodal behavioral intentions (e.g., yielding, overtaking) remains relatively underexplored. This paper proposes a unified framework that jointly predicts both behavioral intentions and trajectories to enhance prediction accuracy, interpretability, and efficiency. Specifically, we employ a shared context encoder for both intention and trajectory predictions, thereby reducing structural redundancy and information loss. Moreover, we address the lack of ground-truth behavioral intention labels in mainstream datasets (Waymo, Argoverse) by auto-labeling these datasets, thus advancing the community's efforts in this direction. We further introduce a vectorized occupancy prediction module that infers the probability of each map polyline being occupied by the target vehicle's future trajectory. By leveraging these intention and occupancy prediction priors, our method conducts dynamic, modality-dependent pruning of irrelevant agents and map polylines in the decoding stage, effectively reducing computational overhead and mitigating noise from non-critical elements. Our approach ranks first among LiDAR-free methods on the Waymo Motion Dataset and achieves first place on the Waymo Interactive Prediction Dataset. Remarkably, even without model ensembling, our single-model framework improves the soft mean average precision (softmAP) by 10 percent compared to the second-best method in the Waymo Interactive Prediction Leaderboard. Furthermore, the proposed framework has been successfully deployed on real vehicles, demonstrating its practical effectiveness in real-world applications.",
      "authors": [
        "Jiawei Sun",
        "Xibin Yue",
        "Jiahui Li",
        "Tianle Shen",
        "Chengran Yuan",
        "Shuo Sun",
        "Sheng Guo",
        "Quanyun Zhou and Marcelo H Ang Jr"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.09103",
        "HTML": "https://arxiv.org/html/2504.09103",
        "PDF": "https://arxiv.org/pdf/2504.09103"
      },
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "Sat, 12 Apr 2025 06:56:36 GMT",
          "size": "20514kb",
          "version": "v1"
        },
        {
          "date": "Thu, 26 Jun 2025 05:57:41 GMT",
          "size": "19799kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "IMPACT: Behavioral Intention-aware Multimodal Trajectory Prediction with Adaptive Context Trimming",
      "relevance": {
        "keyword": "train_data",
        "level": "weak",
        "reason": "The paper discusses trajectory prediction enhancements through auto-labeling existing datasets and feature pruning. It involves data preparation but does not significantly contribute to LLM-specific data processing methods."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2505.11277",
      "abstract": "Large language models have demonstrated impressive reasoning capabilities but are inherently limited by their knowledge reservoir. Retrieval-augmented reasoning mitigates this limitation by allowing LLMs to query external resources, but existing methods often retrieve irrelevant or noisy information, hindering accurate reasoning. In this paper, we propose AutoRefine, a reinforcement learning post-training framework that adopts a new ``search-and-refine-during-think'' paradigm. AutoRefine introduces explicit knowledge refinement steps between successive search calls, enabling the model to iteratively filter, distill, and organize evidence before generating an answer. Furthermore, we incorporate tailored retrieval-specific rewards alongside answer correctness rewards using group relative policy optimization. Experiments on single-hop and multi-hop QA benchmarks demonstrate that AutoRefine significantly outperforms existing approaches, particularly in complex, multi-hop reasoning scenarios. Detailed analysis shows that AutoRefine issues frequent, higher-quality searches and synthesizes evidence effectively.",
      "authors": [
        "Yaorui Shi",
        "Sihang Li",
        "Chang Wu",
        "Zhiyuan Liu",
        "Junfeng Fang",
        "Hengxing Cai",
        "An Zhang",
        "Xiang Wang"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.11277",
        "HTML": "https://arxiv.org/html/2505.11277",
        "PDF": "https://arxiv.org/pdf/2505.11277"
      },
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Fri, 16 May 2025 14:11:29 GMT",
          "size": "634kb",
          "version": "v1"
        },
        {
          "date": "Wed, 28 May 2025 02:19:51 GMT",
          "size": "634kb",
          "version": "v2"
        },
        {
          "date": "Thu, 26 Jun 2025 06:52:37 GMT",
          "size": "637kb",
          "version": "v3"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Search and Refine During Think: Autonomous Retrieval-Augmented Reasoning of LLMs",
      "relevance": {
        "keyword": "train_data",
        "level": "weak",
        "reason": "The paper introduces AutoRefine, a post-training framework for LLMs involving retrieval-augmented reasoning, which involves some process on data post-training, but does not focus on new methods for LLM training data collection or construction."
      },
      "tasks": [
        "Retrieval"
      ],
      "repo_urls": [
        "https://github.com/syr-cn/autorefine"
      ],
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2505.13379",
      "abstract": "Reasoning Language Models, capable of extended chain-of-thought reasoning, have demonstrated remarkable performance on tasks requiring complex logical inference. However, applying elaborate reasoning for all queries often results in substantial computational inefficiencies, particularly when many problems admit straightforward solutions. This motivates an open question: Can LLMs learn when to think? To answer this, we propose Thinkless, a learnable framework that empowers an LLM to adaptively select between short-form and long-form reasoning, based on both task complexity and the model's ability. Thinkless is trained under a reinforcement learning paradigm and employs two control tokens, <short> for concise responses and <think> for detailed reasoning. At the core of our method is a Decoupled Group Relative Policy Optimization (DeGRPO) algorithm, which decomposes the learning objective of hybrid reasoning into two components: (1) a control token loss that governs the selection of the reasoning mode, and (2) a response loss that improves the accuracy of the generated answers. This decoupled formulation enables fine-grained control over the contributions of each objective, stabilizing training and effectively preventing collapse observed in vanilla GRPO. Empirically, on several benchmarks such as Minerva Algebra, MATH-500, and GSM8K, Thinkless is able to reduce the usage of long-chain thinking by 50% - 90%, significantly improving the efficiency of Reasoning Language Models. The code is available at https://github.com/VainF/Thinkless",
      "authors": [
        "Gongfan Fang",
        "Xinyin Ma",
        "Xinchao Wang"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.13379",
        "HTML": "https://arxiv.org/html/2505.13379",
        "PDF": "https://arxiv.org/pdf/2505.13379"
      },
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Mon, 19 May 2025 17:24:16 GMT",
          "size": "518kb",
          "version": "v1"
        },
        {
          "date": "Thu, 26 Jun 2025 14:06:49 GMT",
          "size": "518kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Thinkless: LLM Learns When to Think",
      "relevance": {
        "keyword": "train_data",
        "level": "weak",
        "reason": "Thinkless proposes a framework for adaptive reasoning selection in LLMs via reinforcement learning but does not introduce new methods for LLM training data processing. Data-related aspects are only indirectly mentioned through benchmarks."
      },
      "models": [
        {
          "model_path": "Vinnnf/Thinkless-1.5B-Warmup",
          "downloads": "3295",
          "likes": "3",
          "trending_score": "0.0",
          "link": "https://huggingface.co/Vinnnf/Thinkless-1.5B-Warmup"
        },
        {
          "model_path": "Vinnnf/Thinkless-1.5B-RL-DeepScaleR",
          "downloads": "3110",
          "likes": "2",
          "trending_score": "0.0",
          "link": "https://huggingface.co/Vinnnf/Thinkless-1.5B-RL-DeepScaleR"
        }
      ],
      "datasets": [
        {
          "dataset_name": "Vinnnf/Hybrid-OpenThoughts2-1M-1.5B",
          "downloads": "199",
          "likes": "4",
          "link": "https://huggingface.co/datasets/Vinnnf/Hybrid-OpenThoughts2-1M-1.5B"
        }
      ],
      "tasks": [
        "GSM8K",
        "Math"
      ],
      "repo_urls": [
        "https://github.com/vainf/thinkless"
      ],
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2505.19197",
      "abstract": "Extracting structured and quantitative insights from unstructured financial filings is essential in investment research, yet remains time-consuming and resource-intensive. Conventional approaches in practice rely heavily on labor-intensive manual processes, limiting scalability and delaying the research workflow. In this paper, we propose an efficient and scalable method for accurately extracting quantitative insights from unstructured financial documents, leveraging a multi-agent system composed of large language models. Our proposed multi-agent system consists of two specialized agents: the \\emph{Extraction Agent} and the \\emph{Text-to-SQL Agent}. The \\textit{Extraction Agent} automatically identifies key performance indicators from unstructured financial text, standardizes their formats, and verifies their accuracy. On the other hand, the \\textit{Text-to-SQL Agent} generates executable SQL statements from natural language queries, allowing users to access structured data accurately without requiring familiarity with the database schema. Through experiments, we demonstrate that our proposed system effectively transforms unstructured text into structured data accurately and enables precise retrieval of key information. First, we demonstrate that our system achieves approximately 95\\% accuracy in transforming financial filings into structured data, matching the performance level typically attained by human annotators. Second, in a human evaluation of the retrieval task -- where natural language queries are used to search information from structured data -- 91\\% of the responses were rated as correct by human evaluators. In both evaluations, our system generalizes well across financial document types, consistently delivering reliable performance.",
      "authors": [
        "Chanyeol Choi",
        "Alejandro Lopez-Lira",
        "Yongjae Lee",
        "Jihoon Kwon",
        "Minjae Kim",
        "Juneha Hwang",
        "Minsoo Ha",
        "Chaewoon Kim",
        "Jaeseon Ha",
        "Suyeol Yun",
        "Jin Kim"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.19197",
        "HTML": "https://arxiv.org/html/2505.19197",
        "PDF": "https://arxiv.org/pdf/2505.19197"
      },
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Sun, 25 May 2025 15:45:46 GMT",
          "size": "1259kb",
          "version": "v1"
        },
        {
          "date": "Tue, 27 May 2025 13:32:03 GMT",
          "size": "1942kb",
          "version": "v2"
        },
        {
          "date": "Thu, 26 Jun 2025 04:56:31 GMT",
          "size": "1942kb",
          "version": "v3"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Structuring the Unstructured: A Multi-Agent System for Extracting and Querying Financial KPIs and Guidance",
      "relevance": {
        "keyword": "train_data",
        "level": "weak",
        "reason": "The paper employs large language models to transform unstructured financial data into structured formats, closely related to data processing involving LLMs, but does not focus primarily on LLM training data processing."
      },
      "tasks": [
        "Natural Language Queries",
        "Retrieval",
        "Text to SQL",
        "Text-To-SQL"
      ],
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2505.24466",
      "abstract": "Text-based person retrieval aims to identify a target individual from a gallery of images based on a natural language description. It presents a significant challenge due to the complexity of real-world scenes and the ambiguity of appearance-related descriptions. Existing methods primarily emphasize appearance-based cross-modal retrieval, often neglecting the contextual information embedded within the scene, which can offer valuable complementary insights for retrieval. To address this, we introduce SCENEPERSON-13W, a large-scale dataset featuring over 100,000 scenes with rich annotations covering both pedestrian appearance and environmental cues. Based on this, we propose SA-Person, a two-stage retrieval framework. In the first stage, it performs discriminative appearance grounding by aligning textual cues with pedestrian-specific regions. In the second stage, it introduces SceneRanker, a training-free, scene-aware re-ranking method leveraging multimodal large language models to jointly reason over pedestrian appearance and the global scene context. Experiments on SCENEPERSON-13W validate the effectiveness of our framework in challenging scene-level retrieval scenarios. The code and dataset will be made publicly available.",
      "authors": [
        "Yingjia Xu",
        "Jinlin Wu",
        "Zhen Chen",
        "Daming Gao",
        "Yang Yang",
        "Zhen Lei",
        "Min Cao"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.24466",
        "HTML": "https://arxiv.org/html/2505.24466",
        "PDF": "https://arxiv.org/pdf/2505.24466"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Fri, 30 May 2025 11:10:28 GMT",
          "size": "3388kb",
          "version": "v1"
        },
        {
          "date": "Thu, 26 Jun 2025 12:46:10 GMT",
          "size": "3388kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "SA-Person: Text-Based Person Retrieval with Scene-aware Re-ranking",
      "relevance": {
        "keyword": "train_data",
        "level": "weak",
        "reason": "The paper introduces a dataset and retrieval framework but does not primarily focus on LLM training data processing methods. It mentions the creation and use of a new dataset which slightly touches on data construction."
      },
      "tasks": [
        "Cross-Modal Retrieval",
        "Person Retrieval",
        "Re-Ranking",
        "Retrieval",
        "Text based Person Retrieval",
        "Text-based Person Retrieval"
      ],
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.02280",
      "abstract": "Large Language Models (LLMs) are transforming Natural Language Processing (NLP), but their benefits are largely absent for Africa's 2,000 low-resource languages. This paper comparatively analyzes African language coverage across six LLMs, eight Small Language Models (SLMs), and six Specialized SLMs (SSLMs). The evaluation covers language coverage, training sets, technical limitations, script problems, and language modelling roadmaps. The work identifies 42 supported African languages and 23 available public data sets, and it shows a big gap where four languages (Amharic, Swahili, Afrikaans, and Malagasy) are always treated while there is over 98\\% of unsupported African languages. Moreover, the review shows that just Latin, Arabic, and Ge'ez scripts are identified while 20 active scripts are neglected. Some of the primary challenges are lack of data, tokenization biases, computational costs being very high, and evaluation issues. These issues demand language standardization, corpus development by the community, and effective adaptation methods for African languages.",
      "authors": [
        "Kedir Yassin Hussen",
        "Walelign Tewabe Sewunetie",
        "Abinew Ali Ayele",
        "Sukairaj Hafiz Imam",
        "Shamsuddeen Hassan Muhammad",
        "Seid Muhie Yimam"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.02280",
        "HTML": "https://arxiv.org/html/2506.02280",
        "PDF": "https://arxiv.org/pdf/2506.02280"
      },
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Mon, 02 Jun 2025 21:39:40 GMT",
          "size": "9654kb",
          "version": "v1"
        },
        {
          "date": "Wed, 25 Jun 2025 16:31:32 GMT",
          "size": "561kb",
          "version": "v2"
        },
        {
          "date": "Thu, 26 Jun 2025 01:01:18 GMT",
          "size": "561kb",
          "version": "v3"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "The State of Large Language Models for African Languages: Progress and Challenges",
      "relevance": {
        "keyword": "train_data",
        "level": "weak",
        "reason": "The paper discusses the state of LLMs for African languages, identifying data gaps and challenges, but does not propose new methods for data processing or construction for LLM training."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.12113",
      "abstract": "In a context of malware analysis, numerous approaches rely on Artificial Intelligence to handle a large volume of data. However, these techniques focus on data view (images, sequences) and not on an expert's view. Noticing this issue, we propose a preprocessing that focuses on expert knowledge to improve malware semantic analysis and result interpretability. We propose a new preprocessing method which creates JSON reports for Portable Executable files. These reports gather features from both static and behavioral analysis, and incorporate packer signature detection, MITRE ATT\\&CK and Malware Behavior Catalog (MBC) knowledge. The purpose of this preprocessing is to gather a semantic representation of binary files, understandable by malware analysts, and that can enhance AI models' explainability for malicious files analysis. Using this preprocessing to train a Large Language Model for Malware classification, we achieve a weighted-average F1-score of 0.94 on a complex dataset, representative of market reality.",
      "authors": [
        "Benjamin Marais",
        "Tony Quertier",
        "Gr\\'egoire Barrue"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.12113",
        "HTML": "https://arxiv.org/html/2506.12113",
        "PDF": "https://arxiv.org/pdf/2506.12113"
      },
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "Fri, 13 Jun 2025 13:39:00 GMT",
          "size": "484kb",
          "version": "v1"
        },
        {
          "date": "Thu, 19 Jun 2025 09:55:01 GMT",
          "size": "566kb",
          "version": "v2"
        },
        {
          "date": "Thu, 26 Jun 2025 15:09:42 GMT",
          "size": "566kb",
          "version": "v3"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Semantic Preprocessing for LLM-based Malware Analysis",
      "relevance": {
        "keyword": "train_data",
        "level": "weak",
        "reason": "The paper mentions using preprocessing methods to structure data for LLM-based malware classification, but it doesn't propose new data-related methods specific to LLM training."
      },
      "tasks": [
        "Language Modeling",
        "Language Modelling",
        "Large Language Model",
        "Malware Analysis",
        "Malware Classification"
      ],
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.13056",
      "abstract": "Recent advancements in large language models (LLMs) have witnessed a surge in the development of advanced reasoning paradigms, which are now being integrated into multimodal large language models (MLLMs). However, existing approaches often fall short: methods solely employing reinforcement learning (RL) can struggle with sample inefficiency and activating entirely absent reasoning capabilities, while conventional pipelines that initiate with a cold-start supervised fine-tuning (SFT) phase before RL may restrict the model's exploratory capacity and face suboptimal convergence. In this work, we introduce \\textbf{Metis-RISE} (\\textbf{R}L \\textbf{I}ncentivizes and \\textbf{S}FT \\textbf{E}nhances) for multimodal reasoning model learning. Unlike conventional approaches, Metis-RISE distinctively omits an initial SFT stage, beginning instead with an RL phase (e.g., using a Group Relative Policy Optimization variant) to incentivize and activate the model's latent reasoning capacity. Subsequently, the targeted SFT stage addresses two key challenges identified during RL: (1) \\textit{inefficient trajectory sampling} for tasks where the model possesses but inconsistently applies correct reasoning, which we tackle using self-distilled reasoning trajectories from the RL model itself; and (2) \\textit{fundamental capability absence}, which we address by injecting expert-augmented knowledge for prompts where the model entirely fails. This strategic application of RL for incentivization followed by SFT for enhancement forms the core of Metis-RISE, leading to two versions of our MLLMs (7B and 72B parameters). Evaluations on the OpenCompass Multimodal Reasoning Leaderboard demonstrate that both models achieve state-of-the-art performance among similar-sized models, with the 72B version ranking fourth overall. Please refer to our project page for open-source information.",
      "authors": [
        "Haibo Qiu",
        "Xiaohan Lan",
        "Fanfan Liu",
        "Xiaohu Sun",
        "Delian Ruan",
        "Peng Shi",
        "Lin Ma"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.13056",
        "HTML": "https://arxiv.org/html/2506.13056",
        "PDF": "https://arxiv.org/pdf/2506.13056"
      },
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Mon, 16 Jun 2025 02:56:13 GMT",
          "size": "2185kb",
          "version": "v1"
        },
        {
          "date": "Thu, 26 Jun 2025 11:45:11 GMT",
          "size": "2185kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Metis-RISE: RL Incentivizes and SFT Enhances Multimodal Reasoning Model Learning",
      "relevance": {
        "keyword": "train_data",
        "level": "weak",
        "reason": "Although the paper describes a novel training pipeline involving reinforcement learning and supervised fine-tuning, it does not introduce new methods specifically for LLM training data engineering or processing."
      },
      "models": [
        {
          "model_path": "mmthinking/Metis-RISE-7B",
          "downloads": "7",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/mmthinking/Metis-RISE-7B"
        },
        {
          "model_path": "mmthinking/Metis-RISE-72B",
          "downloads": "4",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/mmthinking/Metis-RISE-72B"
        }
      ],
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.13846",
      "abstract": "An effective reward model plays a pivotal role in reinforcement learning for post-training enhancement of visual generative models. However, current approaches of reward modeling suffer from implementation complexity due to their reliance on extensive human-annotated preference data or meticulously engineered quality dimensions that are often incomplete and engineering-intensive. Inspired by adversarial training in generative adversarial networks (GANs), this paper proposes GAN-RM, an efficient reward modeling framework that eliminates manual preference annotation and explicit quality dimension engineering. Our method trains the reward model through discrimination between a small set of representative, unpaired target samples(denoted as Preference Proxy Data) and model-generated ordinary outputs, requiring only a few hundred target samples. Comprehensive experiments demonstrate our GAN-RM's effectiveness across multiple key applications including test-time scaling implemented as Best-of-N sample filtering, post-training approaches like Supervised Fine-Tuning (SFT) and Direct Preference Optimization (DPO). Code and data will be released at https://github.com/Visualignment/GAN-RM.",
      "authors": [
        "Runtao Liu",
        "Jiahao Zhan",
        "Yingqing He",
        "Chen Wei",
        "Alan Yuille",
        "Qifeng Chen"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.13846",
        "HTML": "https://arxiv.org/html/2506.13846",
        "PDF": "https://arxiv.org/pdf/2506.13846"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Mon, 16 Jun 2025 17:59:40 GMT",
          "size": "16938kb",
          "version": "v1"
        },
        {
          "date": "Thu, 26 Jun 2025 16:39:32 GMT",
          "size": "16938kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Fake it till You Make it: Reward Modeling as Discriminative Prediction",
      "relevance": {
        "keyword": "train_data",
        "level": "weak",
        "reason": "The paper discusses a reward modeling framework for reinforcement learning and post-training enhancement, but it does not primarily focus on LLM training data collection or processing."
      },
      "tasks": [],
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.13897",
      "abstract": "Despite LiDAR (Light Detection and Ranging) being an effective privacy-preserving alternative to RGB cameras to perceive human activities, it remains largely underexplored in the context of multi-modal contrastive pre-training for human activity understanding (e.g., human activity recognition (HAR), retrieval, or person re-identification (RE-ID)). To close this gap, our work explores learning the correspondence between LiDAR point clouds, human skeleton poses, IMU data, and text in a joint embedding space. More specifically, we present DeSPITE, a Deep Skeleton-Pointcloud-IMU-Text Embedding model, which effectively learns a joint embedding space across these four modalities. At the heart of our empirical exploration, we have combined the existing LIPD and Babel datasets, which enabled us to synchronize data of all four modalities, allowing us to explore the learning of a new joint embedding space. Our experiments demonstrate novel human activity understanding tasks for point cloud sequences enabled through DeSPITE, including Skeleton<->Pointcloud<->IMU matching, retrieval, and temporal moment retrieval. Furthermore, we show that DeSPITE is an effective pre-training strategy for point cloud HAR through experiments in MSR-Action3D and HMPEAR.",
      "authors": [
        "Thomas Kreutz",
        "Max M\\\"uhlh\\\"auser",
        "Alejandro Sanchez Guinea"
      ],
      "last_revised_date": "2025/06/25",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.13897",
        "HTML": "https://arxiv.org/html/2506.13897",
        "PDF": "https://arxiv.org/pdf/2506.13897"
      },
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Mon, 16 Jun 2025 18:18:44 GMT",
          "size": "17477kb",
          "version": "v1"
        },
        {
          "date": "Fri, 20 Jun 2025 14:16:26 GMT",
          "size": "17477kb",
          "version": "v2"
        },
        {
          "date": "Wed, 25 Jun 2025 19:20:54 GMT",
          "size": "17477kb",
          "version": "v3"
        }
      ],
      "submitted_date": "2025/06/25",
      "title": "DeSPITE: Exploring Contrastive Deep Skeleton-Pointcloud-IMU-Text Embeddings for Advanced Point Cloud Human Activity Understanding",
      "relevance": {
        "keyword": "train_data",
        "level": "weak",
        "reason": "The paper focuses on learning a joint embedding space of modalities including text, suggesting some preprocessing of text data, but its primary contribution is in multi-modal learning for human activity understanding rather than LLM data processing."
      },
      "tasks": [
        "Activity Recognition",
        "Human Activity Recognition",
        "Moment Retrieval",
        "Person Re-Identification",
        "Privacy Preserving",
        "Retrieval"
      ],
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.15830",
      "abstract": "Optimization in large language models (LLMs) unfolds over high-dimensional parameter spaces with non-Euclidean structure. Information geometry frames this landscape using the Fisher information metric, enabling more principled learning via natural gradient descent. Though often impractical, this geometric lens clarifies phenomena such as sharp minima, generalization, and observed scaling laws. We argue that curvature-aware approaches deepen our understanding of LLM training. Finally, we speculate on quantum analogies based on the Fubini-Study metric and Quantum Fisher Information, hinting at efficient optimization in quantum-enhanced systems.",
      "authors": [
        "Riccardo Di Sipio"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.15830",
        "HTML": "https://arxiv.org/html/2506.15830",
        "PDF": "https://arxiv.org/pdf/2506.15830"
      },
      "subjects": [
        "Computation and Language (cs.CL)",
        "Quantum Physics (quant-ph)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 18 Jun 2025 19:17:47 GMT",
          "size": "140kb",
          "version": "v1"
        },
        {
          "date": "Thu, 26 Jun 2025 16:14:42 GMT",
          "size": "141kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Rethinking LLM Training through Information Geometry and Quantum Metrics",
      "relevance": {
        "keyword": "train_data",
        "level": "weak",
        "reason": "The paper discusses optimization in LLMs using geometric and quantum metrics without addressing direct training data processing or data engineering methods for LLMs."
      },
      "tasks": [],
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.17450",
      "abstract": "We present BlenderFusion, a generative visual compositing framework that synthesizes new scenes by recomposing objects, camera, and background. It follows a layering-editing-compositing pipeline: (i) segmenting and converting visual inputs into editable 3D entities (layering), (ii) editing them in Blender with 3D-grounded control (editing), and (iii) fusing them into a coherent scene using a generative compositor (compositing). Our generative compositor extends a pre-trained diffusion model to process both the original (source) and edited (target) scenes in parallel. It is fine-tuned on video frames with two key training strategies: (i) source masking, enabling flexible modifications like background replacement; (ii) simulated object jittering, facilitating disentangled control over objects and camera. BlenderFusion significantly outperforms prior methods in complex compositional scene editing tasks.",
      "authors": [
        "Jiacheng Chen",
        "Ramin Mehran",
        "Xuhui Jia",
        "Saining Xie",
        "Sanghyun Woo"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.17450",
        "HTML": "https://arxiv.org/html/2506.17450",
        "PDF": "https://arxiv.org/pdf/2506.17450"
      },
      "subjects": [
        "Graphics (cs.GR)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Fri, 20 Jun 2025 19:38:34 GMT",
          "size": "20063kb",
          "version": "v1"
        },
        {
          "date": "Thu, 26 Jun 2025 02:46:40 GMT",
          "size": "14915kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "BlenderFusion: 3D-Grounded Visual Editing and Generative Compositing",
      "relevance": {
        "keyword": "train_data",
        "level": "weak",
        "reason": "The paper focuses on a visual compositing framework, particularly for scene editing using 3D entities. It mentions fine-tuning a diffusion model, which might involve some data processing, but it does not propose new methods for LLM training data processing."
      },
      "tasks": [],
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.18728",
      "abstract": "LLM serving systems typically treat user prompts as monolithic inputs, optimizing inference through decoding tricks or inter-query batching. However, many real-world prompts contain latent semantic parallelism--decomposable structures where subtasks can be executed independently to reduce latency while preserving meaning. We introduce PARALLELPROMPT, the first benchmark for measuring intra-query parallelism in natural user prompts. Our dataset comprises over 37,000 real-world prompts from public LLM chat logs, each annotated with a structured schema capturing task templates, shared context, and iteration inputs. These schemas are extracted using LLM-assisted prompting with rule-based multilingual validation. To evaluate the benefits of decomposition, we provide an execution suite that benchmarks serial vs. parallel strategies, measuring latency, structural adherence, and semantic fidelity. Our results show that intra-query parallelism can be successfully parsed in over 75% of curated datasets, unlocking up to 5x speedups on tasks like translation, comprehension, and comparative analysis, with minimal quality degradation. By releasing this benchmark, curation pipeline, and evaluation suite, we provide the first standardized testbed for studying structure-aware execution in LLM serving pipelines.",
      "authors": [
        "Steven Kolawole",
        "Keshav Santhanam",
        "Virginia Smith",
        "and Pratiksha Thaker"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.18728",
        "HTML": "https://arxiv.org/html/2506.18728",
        "PDF": "https://arxiv.org/pdf/2506.18728"
      },
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Mon, 23 Jun 2025 15:05:54 GMT",
          "size": "251kb",
          "version": "v1"
        },
        {
          "date": "Thu, 26 Jun 2025 16:35:54 GMT",
          "size": "251kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "PARALLELPROMPT: Extracting Parallelism from Large Language Model Queries",
      "relevance": {
        "keyword": "train_data",
        "level": "weak",
        "reason": "The paper introduces PARALLELPROMPT, which involves optimizing LLM serving systems for better parallel execution of prompts. While it involves real-world prompts, it doesn't contribute directly to the processing of LLM training data."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.19014",
      "abstract": "Advancements in audio deepfake technology offers benefits like AI assistants, better accessibility for speech impairments, and enhanced entertainment. However, it also poses significant risks to security, privacy, and trust in digital communications. Detecting and mitigating these threats requires comprehensive datasets. Existing datasets lack diverse ethnic accents, making them inadequate for many real-world scenarios. Consequently, models trained on these datasets struggle to detect audio deepfakes in diverse linguistic and cultural contexts such as in South-Asian countries. Ironically, there is a stark lack of South-Asian speaker samples in the existing datasets despite constituting a quarter of the worlds population. This work introduces the IndieFake Dataset (IFD), featuring 27.17 hours of bonafide and deepfake audio from 50 English speaking Indian speakers. IFD offers balanced data distribution and includes speaker-level characterization, absent in datasets like ASVspoof21 (DF). We evaluated various baselines on IFD against existing ASVspoof21 (DF) and In-The-Wild (ITW) datasets. IFD outperforms ASVspoof21 (DF) and proves to be more challenging compared to benchmark ITW dataset. The complete dataset, along with documentation and sample reference clips, is publicly accessible for research use on project website.",
      "authors": [
        "Abhay Kumar",
        "Kunal Verma",
        "Omkar More"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.19014",
        "HTML": "https://arxiv.org/html/2506.19014",
        "PDF": "https://arxiv.org/pdf/2506.19014"
      },
      "subjects": [
        "Sound (cs.SD)",
        "Artificial Intelligence (cs.AI)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "Mon, 23 Jun 2025 18:10:06 GMT",
          "size": "1739kb",
          "version": "v1"
        },
        {
          "date": "Thu, 26 Jun 2025 17:21:45 GMT",
          "size": "1740kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "IndieFake Dataset: A Benchmark Dataset for Audio Deepfake Detection",
      "relevance": {
        "keyword": "train_data",
        "level": "weak",
        "reason": "The paper focuses on the creation of the IndieFake Dataset for audio deepfake detection, which is primarily relevant to advancing models in that area. While it mentions dataset diversity and its construction, it does not contribute directly to LLM training data processing or data engineering."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.19360",
      "abstract": "Advances in generative models have transformed the field of synthetic image generation for privacy-preserving data synthesis (PPDS). However, the field lacks a comprehensive survey and comparison of synthetic image generation methods across diverse settings. In particular, when we generate synthetic images for the purpose of training a classifier, there is a pipeline of generation-sampling-classification which takes private training as input and outputs the final classifier of interest. In this survey, we systematically categorize existing image synthesis methods, privacy attacks, and mitigations along this generation-sampling-classification pipeline. To empirically compare diverse synthesis approaches, we provide a benchmark with representative generative methods and use model-agnostic membership inference attacks (MIAs) as a measure of privacy risk. Through this study, we seek to answer critical questions in PPDS: Can synthetic data effectively replace real data? Which release strategy balances utility and privacy? Do mitigations improve the utility-privacy tradeoff? Which generative models perform best across different scenarios? With a systematic evaluation of diverse methods, our study provides actionable insights into the utility-privacy tradeoffs of synthetic data generation methods and guides the decision on optimal data releasing strategies for real-world applications.",
      "authors": [
        "Yunsung Chung",
        "Yunbei Zhang",
        "Nassir Marrouche",
        "Jihun Hamm"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.19360",
        "HTML": "https://arxiv.org/html/2506.19360",
        "PDF": "https://arxiv.org/pdf/2506.19360"
      },
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 24 Jun 2025 06:41:34 GMT",
          "size": "3840kb",
          "version": "v1"
        },
        {
          "date": "Thu, 26 Jun 2025 01:32:12 GMT",
          "size": "3800kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "SoK: Can Synthetic Images Replace Real Data? A Survey of Utility and Privacy of Synthetic Image Generation",
      "relevance": {
        "keyword": "train_data",
        "level": "weak",
        "reason": "While the survey discusses synthetic image generation for classifier training, it primarily addresses image data and privacy concerns rather than contributing to LLM-specific data processing or engineering. Its focus is on image data synthesis methodologies."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.19780",
      "abstract": "While large-scale unsupervised language models (LMs) capture broad world knowledge and reasoning capabilities, steering their behavior toward desired objectives remains challenging due to the lack of explicit supervision. Existing alignment techniques, such as reinforcement learning from human feedback (RLHF), rely on training a reward model and performing reinforcement learning to align with human preferences. However, RLHF is often computationally intensive, unstable, and sensitive to hyperparameters.\n  To address these limitations, Direct Preference Optimization (DPO) was introduced as a lightweight and stable alternative, enabling direct alignment of language models with pairwise preference data via classification loss. However, DPO and its extensions generally assume a single static preference distribution, limiting flexibility in multi-objective or dynamic alignment settings.\n  In this paper, we propose a novel framework: Multi-Preference Lambda-weighted Listwise DPO, which extends DPO to incorporate multiple human preference dimensions (e.g., helpfulness, harmlessness, informativeness) and enables dynamic interpolation through a controllable simplex-weighted formulation. Our method supports both listwise preference feedback and flexible alignment across varying user intents without re-training. Empirical and theoretical analysis demonstrates that our method is as effective as traditional DPO on static objectives while offering greater generality and adaptability for real-world deployment.",
      "authors": [
        "Yuhui Sun (University of Alberta)",
        "Xiyao Wang (University of Toronto)",
        "Zixi Li (Zhejiang University) and Jinman Zhao (University of Toronto)"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.19780",
        "HTML": "https://arxiv.org/html/2506.19780",
        "PDF": "https://arxiv.org/pdf/2506.19780"
      },
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "Tue, 24 Jun 2025 16:47:17 GMT",
          "size": "26kb",
          "version": "v1"
        },
        {
          "date": "Thu, 26 Jun 2025 17:28:25 GMT",
          "size": "27kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "Multi-Preference Lambda-weighted Listwise DPO for Dynamic Preference Alignment",
      "relevance": {
        "keyword": "train_data",
        "level": "weak",
        "reason": "The paper mentions handling multi-objective alignment using preference data to train and align language models, but it does not specifically propose new data engineering methods or processing techniques directly related to LLM training data."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.20409",
      "abstract": "Recent advancements in tool-augmented large language models have enabled them to interact with external tools, enhancing their ability to perform complex user tasks. However, existing approaches overlook the role of personalisation in guiding tool use. This work investigates how user preferences can be effectively integrated into goal-oriented dialogue agents. Through extensive analysis, we identify key weaknesses in the ability of LLMs to personalise tool use. To this end, we introduce TAPS, a novel solution that enhances personalised tool use by leveraging a structured tagging tool and an uncertainty-based tool detector. TAPS significantly improves the ability of LLMs to incorporate user preferences, achieving the new state-of-the-art for open source models on the NLSI task.",
      "authors": [
        "Ekaterina Taktasheva and Jeff Dalton"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20409",
        "HTML": "https://arxiv.org/html/2506.20409",
        "PDF": "https://arxiv.org/pdf/2506.20409"
      },
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 13:24:46 GMT",
          "size": "8691kb",
          "version": "v1"
        },
        {
          "date": "Thu, 26 Jun 2025 13:09:40 GMT",
          "size": "8691kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "TAPS: Tool-Augmented Personalisation via Structured Tagging",
      "relevance": {
        "keyword": "train_data",
        "level": "weak",
        "reason": "The paper mentions leveraging structured tagging for personalisation in LLMs, but its primary focus is on enhancing tool use rather than novel methods of LLM training data processing."
      },
      "type": "Paper",
      "source": "arXiv"
    },
    {
      "id": "2506.20639",
      "abstract": "Diffusion large language models (dLLMs) are compelling alternatives to autoregressive (AR) models because their denoising models operate over the entire sequence. The global planning and iterative refinement features of dLLMs are particularly useful for code generation. However, current training and inference mechanisms for dLLMs in coding are still under-explored. To demystify the decoding behavior of dLLMs and unlock their potential for coding, we systematically investigate their denoising processes and reinforcement learning (RL) methods. We train a 7B dLLM, \\textbf{DiffuCoder}, on 130B tokens of code. Using this model as a testbed, we analyze its decoding behavior, revealing how it differs from that of AR models: (1) dLLMs can decide how causal their generation should be without relying on semi-AR decoding, and (2) increasing the sampling temperature diversifies not only token choices but also their generation order. This diversity creates a rich search space for RL rollouts. For RL training, to reduce the variance of token log-likelihood estimates and maintain training efficiency, we propose \\textbf{coupled-GRPO}, a novel sampling scheme that constructs complementary mask noise for completions used in training. In our experiments, coupled-GRPO significantly improves DiffuCoder's performance on code generation benchmarks (+4.4\\% on EvalPlus) and reduces reliance on AR bias during decoding. Our work provides deeper insight into the machinery of dLLM generation and offers an effective, diffusion-native RL training framework. https://github.com/apple/ml-diffucoder.",
      "authors": [
        "Shansan Gong and Ruixiang Zhang and Huangjie Zheng and Jiatao Gu and Navdeep Jaitly and Lingpeng Kong and Yizhe Zhang"
      ],
      "last_revised_date": "2025/06/26",
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20639",
        "HTML": "https://arxiv.org/html/2506.20639",
        "PDF": "https://arxiv.org/pdf/2506.20639"
      },
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "Wed, 25 Jun 2025 17:35:47 GMT",
          "size": "2004kb",
          "version": "v1"
        },
        {
          "date": "Thu, 26 Jun 2025 15:46:40 GMT",
          "size": "2004kb",
          "version": "v2"
        }
      ],
      "submitted_date": "2025/06/26",
      "title": "DiffuCoder: Understanding and Improving Masked Diffusion Models for Code Generation",
      "relevance": {
        "keyword": "train_data",
        "level": "weak",
        "reason": "The paper discusses training and analyzing the DiffuCoder model using RL and introduces a new sampling scheme. Although it involves training a LLM on code, the focus is on RL training mechanisms rather than novel data processing methods for LLM training data."
      },
      "type": "Paper",
      "source": "arXiv"
    }
  ],
  "subjects": [
    "Geophysics (physics.geo-ph)",
    "Logic in Computer Science (cs.LO)",
    "Computer Vision and Pattern Recognition (cs.CV)",
    "Statistics Theory (stat.TH)",
    "Networking and Internet Architecture (cs.NI)",
    "Quantum Physics (quant-ph)",
    "Optimization and Control (math.OC)",
    "Cosmology and Nongalactic Astrophysics (astro-ph.CO)",
    "Multimedia (cs.MM)",
    "Physics and Society (physics.soc-ph)",
    "Computer Science and Game Theory (cs.GT)",
    "Cell Behavior (q-bio.CB)",
    "Computational Engineering, Finance, and Science (cs.CE)",
    "Computation and Language (cs.CL)",
    "Databases (cs.DB)",
    "Other Quantitative Biology (q-bio.OT)",
    "Sound (cs.SD)",
    "Image and Video Processing (eess.IV)",
    "Performance (cs.PF)",
    "Cellular Automata and Lattice Gases (nlin.CG)",
    "Methodology (stat.ME)",
    "Instrumentation and Detectors (physics.ins-det)",
    "Systems and Control (eess.SY)",
    "Cryptography and Security (cs.CR)",
    "Robotics (cs.RO)",
    "Materials Science (cond-mat.mtrl-sci)",
    "Information Retrieval (cs.IR)",
    "Strongly Correlated Electrons (cond-mat.str-el)",
    "Portfolio Management (q-fin.PM)",
    "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
    "Artificial Intelligence (cs.AI)",
    "Computational Geometry (cs.CG)",
    "Neurons and Cognition (q-bio.NC)",
    "Fluid Dynamics (physics.flu-dyn)",
    "Applications (stat.AP)",
    "Applied Physics (physics.app-ph)",
    "Adaptation and Self-Organizing Systems (nlin.AO)",
    "Accelerator Physics (physics.acc-ph)",
    "Data Analysis, Statistics and Probability (physics.data-an)",
    "High Energy Physics - Phenomenology (hep-ph)",
    "Analysis of PDEs (math.AP)",
    "Computational Complexity (cs.CC)",
    "Quantitative Methods (q-bio.QM)",
    "Logic (math.LO)",
    "Plasma Physics (physics.plasm-ph)",
    "Statistical Finance (q-fin.ST)",
    "High Energy Physics - Experiment (hep-ex)",
    "Systems and Control (cs.SY)",
    "Programming Languages (cs.PL)",
    "Category Theory (math.CT)",
    "Symbolic Computation (cs.SC)",
    "Biological Physics (physics.bio-ph)",
    "Probability (math.PR)",
    "Discrete Mathematics (cs.DM)",
    "Information Theory (math.IT)",
    "Classical Physics (physics.class-ph)",
    "Emerging Technologies (cs.ET)",
    "Medical Physics (physics.med-ph)",
    "Signal Processing (eess.SP)",
    "Number Theory (math.NT)",
    "Computation (stat.CO)",
    "Audio and Speech Processing (eess.AS)",
    "Social and Information Networks (cs.SI)",
    "Metric Geometry (math.MG)",
    "Combinatorics (math.CO)",
    "Machine Learning (stat.ML)",
    "Information Theory (cs.IT)",
    "Computers and Society (cs.CY)",
    "Biomolecules (q-bio.BM)",
    "Molecular Networks (q-bio.MN)",
    "Group Theory (math.GR)",
    "Functional Analysis (math.FA)",
    "Numerical Analysis (cs.NA)",
    "Statistics Theory (math.ST)",
    "Multiagent Systems (cs.MA)",
    "High Energy Physics - Theory (hep-th)",
    "Hardware Architecture (cs.AR)",
    "Risk Management (q-fin.RM)",
    "Neural and Evolutionary Computing (cs.NE)",
    "Soft Condensed Matter (cond-mat.soft)",
    "General Finance (q-fin.GN)",
    "Computational Physics (physics.comp-ph)",
    "Geometric Topology (math.GT)",
    "Computational Finance (q-fin.CP)",
    "High Energy Physics - Lattice (hep-lat)",
    "Software Engineering (cs.SE)",
    "Distributed, Parallel, and Cluster Computing (cs.DC)",
    "Human-Computer Interaction (cs.HC)",
    "Data Structures and Algorithms (cs.DS)",
    "Theoretical Economics (econ.TH)",
    "Graphics (cs.GR)",
    "Digital Libraries (cs.DL)",
    "Algebraic Geometry (math.AG)",
    "Machine Learning (cs.LG)",
    "General Economics (econ.GN)",
    "Chemical Physics (physics.chem-ph)",
    "Dynamical Systems (math.DS)",
    "Formal Languages and Automata Theory (cs.FL)",
    "Numerical Analysis (math.NA)",
    "Economics (q-fin.EC)"
  ],
  "prompt": {
    "train_data": "\nYou are a computer science expert specializing in training data processing and data engineering for large language models (LLMs). You are skilled at identifying technical content in research papers that is related to **LLM training data**. I will provide you with a list of research papers from the arXiv (cs.\\*) domain.\n\n---\n\n### **Task Objective**\n\nFor each paper, determine whether it is directly related to the **processing of training data for LLMs**. Focus on identifying contributions in the following two areas:\n\n1. **Data Engineering Stage**:\n\n   * Includes tasks such as data collection, construction, cleaning, noise reduction, deduplication, filtering, format transformation, and data quality enhancement.\n\n2. **Training-Stage Data Processing**:\n\n   * Includes data preparation and processing for pre-training and post-training stages (e.g., fine-tuning, supervised fine-tuning (SFT), instruction tuning, etc.).\n\n---\n\n### **Relevance Level Classification Criteria**\n\n* `\"strong\"`: The paper's primary contribution involves the design, construction, or processing of LLM training data\u2014for example, proposing a novel data pipeline, creating large-scale training data, or contributing new methods for improving data quality.\n* `\"weak\"`: The paper mentions data sources or preprocessing briefly in the background or experiments section, uses public datasets or existing tools, and does not propose new data-related methods.\n* `\"none\"`: The paper does not address any aspect of LLM training data collection, construction, or processing.\n\n---\n\n### **Output Format (strictly follow this JSON schema)**\n\n```json\n{\n  \"result\": [\n    {\n      \"id\": \"<paper id>\",\n      \"level\": \"strong | weak | none\",\n      \"reason\": \"A 1-2 sentence explanation citing key parts of the abstract or methodology that justify the classification\"\n    }\n    // More papers...\n  ]\n}\n"
  },
  "description": "Data source: https://arxiv.org/list/cs/new"
}